[
    {
        "title": "Simple linear attention language models balance the recall-throughput tradeoff",
        "authorids": [
            "~Simran_Arora1",
            "~Sabri_Eyuboglu1",
            "~Michael_Zhang4",
            "~Aman_Timalsina1",
            "~Silas_Alberti2",
            "~James_Zou1",
            "~Atri_Rudra1",
            "~Christopher_Re1"
        ],
        "abstract": "Recent work has shown that attention-based language models excel at \"recall\", the ability to ground generations in tokens previously seen in context. However, the efficiency of attention-based models is bottle-necked during inference by the KV-cache's aggressive memory consumption. In this work, we explore whether we can improve language model efficiency (e.g. by reducing memory consumption) without compromising on recall. By applying experiments and theory to a broad set of architectures, we identify a key tradeoff between a model's recurrent state size and recall ability. We show that efficient alternatives to attention (e.g. H3, Mamba, RWKV) maintain a fixed-size recurrent state, but struggle at recall. We propose BASED a simple architecture combining linear and sliding window attention. By varying BASED window size and linear attention feature dimension, we can dial the state size and traverse the Pareto frontier of the recall-memory tradeoff curve, recovering the full quality of attention on one end and the small state size of attention-alternatives on the other. We train language models up to $1.3$b parameters and show that BASED matches the strongest sub-quadratic models (e.g. Mamba) in perplexity and outperforms them on real-world recall-intensive tasks by 10.36 accuracy points. We further develop IO-aware algorithms that enable BASED to provide 24\u00d7 higher throughput on language generation than FlashAttention-2, when generating 1024 tokens using 1.3b parameter models. Overall, BASED expands the Pareto frontier of the throughput-recall tradeoff space beyond prior architectures.",
        "_bibtex": "@inproceedings{\narora2024simple,\ntitle={Simple linear attention language models balance the recall-throughput tradeoff},\nauthor={Simran Arora and Sabri Eyuboglu and Michael Zhang and Aman Timalsina and Silas Alberti and James Zou and Atri Rudra and Christopher Re},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=e93ffDcpH3}\n}"
    },
    {
        "title": "Allocation Requires Prediction Only if Inequality Is Low",
        "authorids": [
            "~Ali_Shirali1",
            "~Rediet_Abebe2",
            "~Moritz_Hardt1"
        ],
        "abstract": "Algorithmic predictions are emerging as a promising solution concept for efficiently allocating societal resources. Fueling their use is an underlying assumption that such systems are necessary to identify individuals for interventions. We propose a principled framework for assessing this assumption: Using a simple mathematical model, we evaluate the efficacy of prediction-based allocations in settings where individuals belong to larger units such as hospitals, neighborhoods, or schools. We find that prediction-based allocations outperform baseline methods using aggregate unit-level statistics only when between-unit inequality is low and the intervention budget is high. Our results hold for a wide range of settings for the price of prediction, treatment effect heterogeneity, and unit-level statistics' learnability. Combined, we highlight the potential limits to improving the efficacy of interventions through prediction.",
        "_bibtex": "@inproceedings{\nshirali2024allocation,\ntitle={Allocation Requires Prediction Only if Inequality Is Low},\nauthor={Ali Shirali and Rediet Abebe and Moritz Hardt},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=WUicA0hOF9}\n}"
    },
    {
        "title": "Multi-Track Message Passing: Tackling Oversmoothing and Oversquashing in Graph Learning via Preventing Heterophily Mixing",
        "authorids": [
            "~Hongbin_Pei1",
            "~Yu_Li30",
            "~Huiqi_Deng1",
            "haijingxin@stu.xjtu.edu.cn",
            "~Pinghui_Wang1",
            "~Jie_Ma1",
            "~Jing_Tao2",
            "~Yuheng_Xiong1",
            "~Xiaohong_Guan2"
        ],
        "abstract": "The advancement toward deeper graph neural networks is currently obscured by two inherent issues in message passing, *oversmoothing* and *oversquashing*. We identify the root cause of these issues as information loss due to *heterophily mixing* in aggregation, where messages of diverse category semantics are mixed. We propose a novel multi-track graph convolutional network to address oversmoothing and oversquashing effectively. Our basic idea is intuitive: if messages are separated and independently propagated according to their category semantics, heterophilic mixing can be prevented. Consequently, we present a novel multi-track message passing scheme capable of preventing heterophilic mixing, enhancing long-distance information flow, and improving separation condition. Empirical validations show that our model achieved state-of-the-art performance on several graph datasets and effectively tackled oversmoothing and oversquashing, setting a new benchmark of $86.4$% accuracy on Cora.",
        "_bibtex": "@inproceedings{\npei2024multitrack,\ntitle={Multi-Track Message Passing: Tackling Oversmoothing  and Oversquashing in Graph Learning via Preventing Heterophily Mixing},\nauthor={Hongbin Pei and Yu Li and Huiqi Deng and Jingxin Hai and Pinghui Wang and Jie Ma and Jing Tao and Yuheng Xiong and Xiaohong Guan},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=1sRuv4cnuZ}\n}"
    },
    {
        "title": "BBox-Adapter: Lightweight Adapting for Black-Box Large Language Models",
        "authorids": [
            "~Haotian_Sun1",
            "~Yuchen_Zhuang1",
            "~Wei_Wei15",
            "~Chao_Zhang15",
            "~Bo_Dai1"
        ],
        "abstract": "Adapting state-of-the-art Large Language Models (LLMs) like GPT-4 and Gemini for specific tasks is challenging. Due to the opacity in their parameters, embeddings, and even output probabilities, existing fine-tuning adaptation methods are inapplicable. Consequently, adapting these black-box LLMs is only possible through their API services, raising concerns about transparency, privacy, and cost. To address these challenges, we introduce BBox-Adapter, a novel lightweight adapter for black-box LLMs. BBox-Adapter distinguishes target and source domain data by treating target data as positive and source data as negative. It employs a ranking-based Noise Contrastive Estimation (NCE) loss to promote the likelihood of target domain data while penalizing that of the source domain. Furthermore, it features an online adaptation mechanism, which incorporates real-time positive data sampling from ground-truth, human, or AI feedback, coupled with negative data from previous adaptations. Extensive experiments demonstrate BBox-Adapter's effectiveness and cost efficiency. It improves model performance by up to 6.77% across diverse tasks and domains, while reducing training and inference costs by 31.30x and 1.84x, respectively.",
        "_bibtex": "@inproceedings{\nsun2024bboxadapter,\ntitle={{BB}ox-Adapter: Lightweight Adapting for Black-Box Large Language Models},\nauthor={Haotian Sun and Yuchen Zhuang and Wei Wei and Chao Zhang and Bo Dai},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=jdRIaUu3xY}\n}"
    },
    {
        "title": "Position: Understanding LLMs Requires More Than Statistical Generalization",
        "authorids": [
            "~Patrik_Reizinger1",
            "~Szilvia_Ujv\u00e1ry1",
            "~Anna_M\u00e9sz\u00e1ros1",
            "~Anna_Kerekes1",
            "~Wieland_Brendel1",
            "~Ferenc_Husz\u00e1r1"
        ],
        "abstract": "The last decade has seen blossoming research in deep learning theory attempting to answer, ``Why does deep learning generalize?\" A powerful shift in perspective precipitated this progress: the study of overparametrized models in the interpolation regime. In this paper, we argue that another perspective shift is due, since some of the desirable qualities of LLMs are not a consequence of good statistical generalization and require a separate theoretical explanation. Our core argument relies on the observation that AR probabilistic models are inherently non-identifiable: models zero or near-zero KL divergence apart---thus, equivalent test loss---can exhibit markedly different behaviors. We support our position with mathematical examples and empirical observations, illustrating why non-identifiability has practical relevance through three case studies: (1) the non-identifiability of zero-shot rule extrapolation; (2) the approximate non-identifiability of in-context learning; and (3) the non-identifiability of fine-tunability. We review promising research directions focusing on LLM-relevant generalization measures, transferability, and inductive biases.",
        "_bibtex": "@inproceedings{\nreizinger2024position,\ntitle={Position: Understanding {LLM}s Requires More Than Statistical Generalization},\nauthor={Patrik Reizinger and Szilvia Ujv{\\'a}ry and Anna M{\\'e}sz{\\'a}ros and Anna Kerekes and Wieland Brendel and Ferenc Husz{\\'a}r},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=pVyOchWUBa}\n}"
    },
    {
        "title": "DRCT: Diffusion Reconstruction Contrastive Training towards Universal Detection of Diffusion Generated Images",
        "authorids": [
            "~Baoying_Chen1",
            "~Jishen_Zeng1",
            "~Jianquan_Yang1",
            "~Rui_Yang18"
        ],
        "abstract": "Diffusion models have made significant strides in visual content generation but also raised increasing demands on generated image detection. Existing detection methods have achieved considerable progress, but they usually suffer a significant decline in accuracy when detecting images generated by an unseen diffusion model. In this paper, we seek to address the generalizability of generated image detectors from the perspective of hard sample classification. The basic idea is that if a classifier can distinguish generated images that closely resemble real ones, then it can also effectively detect less similar samples, potentially even those produced by a different diffusion model. Based on this idea, we propose Diffusion Reconstruction Contrastive Learning (DRCT), a universal framework to enhance the generalizability of the existing detectors. DRCT generates hard samples by high-quality diffusion reconstruction and adopts contrastive training to guide the learning of diffusion artifacts. In addition, we have built a million-scale dataset, DRCT-2M, including 16 types diffusion models for the evaluation of generalizability of detection methods. Extensive experimental results show that detectors enhanced with DRCT achieve over a 10% accuracy improvement in cross-set tests. The code, models, and dataset will soon be available at https://github.com/beibuwandeluori/DRCT.",
        "_bibtex": "@inproceedings{\nchen2024drct,\ntitle={{DRCT}: Diffusion Reconstruction Contrastive Training towards Universal Detection of Diffusion Generated Images},\nauthor={Baoying Chen and Jishen Zeng and Jianquan Yang and Rui Yang},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=oRLwyayrh1}\n}"
    },
    {
        "title": "Explaining Probabilistic Models with Distributional Values",
        "authorids": [
            "~Luca_Franceschi1",
            "~Michele_Donini1",
            "~Cedric_Archambeau1",
            "~Matthias_Seeger2"
        ],
        "abstract": "A large branch of explainable machine learning is grounded in cooperative game theory. However, research indicates that game-theoretic explanations may mislead or be hard to interpret. We argue that often there is a critical mismatch between what one wishes to explain (e.g. the output of a classifier) and what current methods such as SHAP explain (e.g. the scalar probability of a class). This paper addresses such gap for probabilistic models by generalising cooperative games and value operators. We introduce the *distributional values*, random variables that track changes in the model output (e.g. flipping of the predicted class) and derive their analytic expressions for games with Gaussian, Bernoulli and Categorical payoffs. We further establish several characterising properties, and show that our framework provides fine-grained and insightful explanations with case studies on vision and language models.",
        "_bibtex": "@inproceedings{\nfranceschi2024explaining,\ntitle={Explaining Probabilistic Models with Distributional Values},\nauthor={Luca Franceschi and Michele Donini and Cedric Archambeau and Matthias Seeger},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=37xFIeYgE0}\n}"
    },
    {
        "title": "Relaxing the Accurate Imputation Assumption in Doubly Robust Learning for Debiased Collaborative Filtering",
        "authorids": [
            "~Haoxuan_Li6",
            "~Chunyuan_Zheng1",
            "~Shuyi_Wang3",
            "~Kunhan_Wu1",
            "~Eric_Wang3",
            "~Peng_Wu5",
            "~Zhi_Geng1",
            "~Xu_Chen13",
            "~Xiao-Hua_Zhou1"
        ],
        "abstract": "Recommender system aims to recommend items or information that may interest users based on their behaviors and preferences. However, there may be sampling selection bias in the data collection process, i.e., the collected data is not a representative of the target population. Many debiasing methods are developed based on pseudo-labelings. Nevertheless, the validity of these methods relies heavily on accurate pseudo-labelings (i.e., the imputed labels), which is difficult to satisfy in practice. In this paper, we theoretically propose several novel doubly robust estimators that are unbiased when either (a) the pseudo-labelings deviate from the true labels with an arbitrary user-specific inductive bias, item-specific inductive bias, or a combination of both, or (b) the learned propensities are accurate. We further propose a propensity reconstruction learning approach that adaptively updates the constraint weights using an attention mechanism and effectively controls the variance. Extensive experiments show that our approach outperforms the state-of-the-art on one semi-synthetic and three real-world datasets.",
        "_bibtex": "@inproceedings{\nli2024relaxing,\ntitle={Relaxing the Accurate Imputation Assumption in Doubly Robust Learning for Debiased Collaborative Filtering},\nauthor={Haoxuan Li and Chunyuan Zheng and Shuyi Wang and Kunhan Wu and Eric Wang and Peng Wu and Zhi Geng and Xu Chen and Xiao-Hua Zhou},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=Ln3moCobjO}\n}"
    },
    {
        "title": "Test-Time Degradation Adaptation for Open-Set Image Restoration",
        "authorids": [
            "~Yuanbiao_Gou1",
            "~Haiyu_Zhao2",
            "~Boyun_Li1",
            "~Xinyan_Xiao1",
            "~Xi_Peng3"
        ],
        "abstract": "In contrast to close-set scenarios that restore images from a predefined set of degradations, open-set image restoration aims to handle the unknown degradations that were unforeseen during the pretraining phase, which is less-touched as far as we know. This work study this challenging problem and reveal its essence as unidentified distribution shifts between the test and training data. Recently, test-time adaptation has emerged as a fundamental method to address this inherent disparities. Inspired by it, we propose a test-time degradation adaptation framework for open-set image restoration, which consists of three components, *i.e.*, i) a pre-trained and degradation-agnostic diffusion model for generating clean images, ii) a test-time degradation adapter adapts the unknown degradations based on the input image during the testing phase, and iii) the adapter-guided image restoration guides the model through the adapter to produce the corresponding clean image. Through experiments on multiple degradations, we show that our method achieves comparable even better performance than those task-specific methods. The code is available at https://github.com/XLearning-SCU/2024-ICML-TAO.",
        "_bibtex": "@inproceedings{\ngou2024testtime,\ntitle={Test-Time Degradation Adaptation for Open-Set Image Restoration},\nauthor={Yuanbiao Gou and Haiyu Zhao and Boyun Li and Xinyan Xiao and Xi Peng},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=XLlQb24X2o}\n}"
    },
    {
        "title": "Regression with Multi-Expert Deferral",
        "authorids": [
            "~Anqi_Mao1",
            "~Mehryar_Mohri2",
            "~Yutao_Zhong1"
        ],
        "abstract": "Learning to defer with multiple experts is a framework where the learner can choose to defer the prediction to several experts. While this problem has received significant attention in classification contexts, it presents unique challenges in regression due to the infinite and continuous nature of the label space. In this work, we introduce a novel framework of *regression with deferral*, which involves deferring the prediction to multiple experts. We present a comprehensive analysis for both the single-stage scenario, where there is simultaneous learning of predictor and deferral functions, and the two-stage scenario, which involves a pre-trained predictor with a learned deferral function. We introduce new surrogate loss functions for both scenarios and prove that they are supported by $H$-consistency bounds. These bounds provide consistency guarantees that are stronger than Bayes consistency, as they are non-asymptotic and hypothesis set-specific. Our framework is versatile, applying to multiple experts, accommodating any bounded regression losses, addressing both instance-dependent and label-dependent costs, and supporting both single-stage and two-stage methods. Our single-stage formulation subsumes as a special case the recent *regression with abstention* (Cheng et al., 2023) framework, where only a single expert is considered, specifically for the squared loss and a label-independent cost. Minimizing our proposed loss functions directly leads to novel algorithms for regression with deferral. We report the results of extensive experiments showing the effectiveness of our proposed algorithms.",
        "_bibtex": "@inproceedings{\nmao2024regression,\ntitle={Regression with Multi-Expert Deferral},\nauthor={Anqi Mao and Mehryar Mohri and Yutao Zhong},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=5NTTCCO74S}\n}"
    },
    {
        "title": "High-Dimensional Bayesian Optimization via Semi-Supervised Learning with Optimized Unlabeled Data Sampling",
        "authorids": [
            "~Yuxuan_Yin1",
            "~Yu_Wang29",
            "~Peng_Li8"
        ],
        "abstract": "We introduce a novel semi-supervised learning approach, named Teacher-Student Bayesian Optimization ($\\texttt{TSBO}$), integrating the teacher-student paradigm into BO to minimize expensive labeled data queries for the first time. $\\texttt{TSBO}$ incorporates a teacher model, an unlabeled data sampler, and a student model. The student is trained on unlabeled data locations generated by the sampler, with pseudo labels predicted by the teacher. The interplay between these three components implements a unique *selective regularization* to the teacher in the form of student feedback. This scheme enables the teacher to predict high-quality pseudo labels, enhancing the generalization of the GP surrogate model in the search space. To fully exploit $\\texttt{TSBO}$, we propose two optimized unlabeled data samplers to construct effective student feedback that well aligns with the objective of Bayesian optimization. Furthermore, we quantify and leverage the uncertainty of the teacher-student model for the provision of reliable feedback to the teacher in the presence of risky pseudo-label predictions. $\\texttt{TSBO}$ demonstrates significantly improved sample-efficiency in several global optimization tasks under tight labeled data budgets. The implementation is available at https://github.com/reminiscenty/TSBO-Official.",
        "_bibtex": "@inproceedings{\nyin2024highdimensional,\ntitle={High-Dimensional Bayesian Optimization via Semi-Supervised Learning with Optimized  Unlabeled Data Sampling},\nauthor={Yuxuan Yin and Yu Wang and Peng Li},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=beXQVQorse}\n}"
    },
    {
        "title": "Failures Are Fated, But Can Be Faded: Characterizing and Mitigating Unwanted Behaviors in Large-Scale Vision and Language Models",
        "authorids": [
            "~Som_Sagar1",
            "~Aditya_Taparia1",
            "~Ransalu_Senanayake1"
        ],
        "abstract": "In large deep neural networks that seem to perform surprisingly well on many tasks, we also observe a few failures related to accuracy, social biases, and alignment with human values, among others. Therefore, before deploying these models, it is crucial to characterize this failure landscape for engineers to debug and legislative bodies to audit models. Nevertheless, it is infeasible to exhaustively test for all possible combinations of factors that could lead to a model's failure. In this paper, we introduce a post-hoc method that utilizes *deep reinforcement learning* to explore and construct the landscape of failure modes in pre-trained discriminative and generative models. With the aid of limited human feedback, we then demonstrate how to restructure the failure landscape to be more desirable by moving away from the discovered failure modes. We empirically show the effectiveness of the proposed method across common Computer Vision, Natural Language Processing, and Vision-Language tasks.",
        "_bibtex": "@inproceedings{\nsagar2024failures,\ntitle={Failures Are Fated, But Can Be Faded: Characterizing and Mitigating Unwanted Behaviors in Large-Scale Vision and Language Models},\nauthor={Som Sagar and Aditya Taparia and Ransalu Senanayake},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=DkqiId4AuR}\n}"
    },
    {
        "title": "Efficient Pareto Manifold Learning with Low-Rank Structure",
        "authorids": [
            "~Weiyu_Chen1",
            "~James_Kwok1"
        ],
        "abstract": "Multi-task learning, which optimizes performance across multiple tasks, is inherently a multi-objective optimization problem. Various algorithms are developed to provide discrete trade-off solutions on the Pareto front. Recently, continuous Pareto front approximations using a linear combination of base networks have emerged as a compelling strategy. However, it suffers from scalability issues when the number of tasks is large. To address this issue, we propose a novel approach that integrates a main network with several low-rank matrices to efficiently learn the Pareto manifold. It significantly reduces the number of parameters and facilitates the extraction of shared features. We also introduce orthogonal regularization to further bolster performance. Extensive experimental results demonstrate that the proposed approach outperforms state-of-the-art baselines, especially on datasets with a large number of tasks.",
        "_bibtex": "@inproceedings{\nchen2024efficient,\ntitle={Efficient Pareto Manifold Learning with Low-Rank Structure},\nauthor={Weiyu Chen and James Kwok},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=a2uFstsHPb}\n}"
    },
    {
        "title": "Tabular Insights, Visual Impacts: Transferring Expertise from Tables to Images",
        "authorids": [
            "~Jun-Peng_Jiang2",
            "~Han-Jia_Ye1",
            "~Leye_Wang1",
            "~Yang_Yang17",
            "~Yuan_Jiang1",
            "~De-Chuan_Zhan1"
        ],
        "abstract": "Transferring knowledge across diverse data modalities is receiving increasing attention in machine learning. This paper tackles the task of leveraging expert-derived, yet expensive, tabular data to enhance image-based predictions when tabular data is unavailable during inference. The primary challenges stem from the inherent complexity of accurately mapping diverse tabular data to visual contexts, coupled with the necessity to devise distinct strategies for numerical and categorical tabular attributes. We propose CHannel tAbulaR alignment with optiMal tranSport (Charms), which establishes an alignment between image channels and tabular attributes, enabling selective knowledge transfer that is pertinent to visual features. Specifically, Charms measures similarity distributions across modalities to effectively differentiate and transfer relevant tabular features, with a focus on morphological characteristics, enhancing the capabilities of visual classifiers. By maximizing the mutual information between image channels and tabular features, knowledge from both numerical and categorical tabular attributes are extracted. Experimental results demonstrate that Charms not only enhances the performance of image classifiers but also improves their interpretability by effectively utilizing tabular knowledge.",
        "_bibtex": "@inproceedings{\njiang2024tabular,\ntitle={Tabular Insights, Visual Impacts: Transferring Expertise from Tables to Images},\nauthor={Jun-Peng Jiang and Han-Jia Ye and Leye Wang and Yang Yang and Yuan Jiang and De-Chuan Zhan},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=v7I5FtL2pV}\n}"
    },
    {
        "title": "Convergence of Some Convex Message Passing Algorithms to a Fixed Point",
        "authorids": [
            "~Vaclav_Voracek1",
            "~Tomas_Werner1"
        ],
        "abstract": "A popular approach to the MAP inference problem in graphical models is to minimize an upper bound obtained from a dual linear programming or Lagrangian relaxation by (block-)coordinate descent. This is also known as convex/convergent message passing; examples are max-sum diffusion and sequential tree-reweighted message passing (TRW-S). Convergence properties of these methods are currently not fully understood. They have been proved to converge to the set characterized by local consistency of active constraints, with unknown convergence rate; however, it was not clear if the iterates converge at all (to any point). We prove a stronger result (conjectured before but never proved): the iterates converge to a fixed point of the method. Moreover, we show that the algorithm terminates within $\\mathcal{O}(1/\\varepsilon)$ iterations. We first prove this for a version of coordinate descent applied to a general piecewise-affine convex objective. Then we show that several convex message passing methods are special cases of this method. Finally, we show that a slightly different version of coordinate descent can cycle.",
        "_bibtex": "@inproceedings{\nvoracek2024convergence,\ntitle={Convergence of Some Convex Message Passing Algorithms to a Fixed Point},\nauthor={Vaclav Voracek and Tomas Werner},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=CaxQ5IbHgF}\n}"
    },
    {
        "title": "Unsupervised Zero-Shot Reinforcement Learning via Functional Reward Encodings",
        "authorids": [
            "~Kevin_Frans1",
            "~Seohong_Park1",
            "~Pieter_Abbeel2",
            "~Sergey_Levine1"
        ],
        "abstract": "Can we pre-train a generalist agent from a large amount of unlabeled offline trajectories such that it can be immediately adapted to any new downstream tasks in a zero-shot manner? In this work, we present a *functional* reward encoding (FRE) as a general, scalable solution to this *zero-shot RL* problem. Our main idea is to learn functional representations of any arbitrary tasks by encoding their state-reward samples using a transformer-based variational auto-encoder. This functional encoding not only enables the pre-training of an agent from a wide diversity of general unsupervised reward functions, but also provides a way to solve any new downstream tasks in a zero-shot manner, given a small number of reward-annotated samples. We empirically show that FRE agents trained on diverse random unsupervised reward functions can generalize to solve novel tasks in a range of simulated robotic benchmarks, often outperforming previous zero-shot RL and offline RL methods.",
        "_bibtex": "@inproceedings{\nfrans2024unsupervised,\ntitle={Unsupervised Zero-Shot Reinforcement Learning via Functional Reward Encodings},\nauthor={Kevin Frans and Seohong Park and Pieter Abbeel and Sergey Levine},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=a6wCNfIj8E}\n}"
    },
    {
        "title": "Neural Jump-Diffusion Temporal Point Processes",
        "authorids": [
            "~Shuai_Zhang23",
            "~Chuan_Zhou3",
            "~Yang_Aron_Liu1",
            "~PENG_ZHANG2",
            "~Xixun_Lin3",
            "~Zhi-Ming_Ma1"
        ],
        "abstract": "We present a novel perspective on temporal point processes (TPPs) by reformulating their intensity processes as solutions to stochastic differential equations (SDEs). In particular, we first prove the equivalent SDE formulations of several classical TPPs, including Poisson processes, Hawkes processes, and self-correcting processes. Based on these proofs, we introduce a unified TPP framework called Neural Jump-Diffusion Temporal Point Process (NJDTPP), whose intensity process is governed by a neural jump-diffusion SDE (NJDSDE) where the drift, diffusion, and jump coefficient functions are parameterized by neural networks. Compared to previous works, NJDTPP exhibits model flexibility in capturing intensity dynamics without relying on any specific functional form, and provides theoretical guarantees regarding the existence and uniqueness of the solution to the proposed NJDSDE. Experiments on both synthetic and real-world datasets demonstrate that NJDTPP is capable of capturing the dynamics of intensity processes in different scenarios and significantly outperforms the state-of-the-art TPP models in prediction tasks.",
        "_bibtex": "@inproceedings{\nzhang2024neural,\ntitle={Neural Jump-Diffusion Temporal Point Processes},\nauthor={Shuai Zhang and Chuan Zhou and Yang Aron Liu and PENG ZHANG and Xixun Lin and Zhi-Ming Ma},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=d1P6GtRzuV}\n}"
    },
    {
        "title": "Sequential Neural Score Estimation: Likelihood-Free Inference with Conditional Score Based Diffusion Models",
        "authorids": [
            "~Louis_Sharrock1",
            "~Jack_Simons1",
            "~Song_Liu1",
            "~Mark_Beaumont1"
        ],
        "abstract": "We introduce Sequential Neural Posterior Score Estimation (SNPSE), a score-based method for Bayesian inference in simulator-based models. Our method, inspired by the remarkable success of score-based methods in generative modelling, leverages conditional score-based diffusion models to generate samples from the posterior distribution of interest. The model is trained using an objective function which directly estimates the score of the posterior. We embed the model into a sequential training procedure, which guides simulations using the current approximation of the posterior at the observation of interest, thereby reducing the simulation cost. We also introduce several alternative sequential approaches, and discuss their relative merits. We then validate our method, as well as its amortised, non-sequential, variant on several numerical examples, demonstrating comparable or superior performance to existing state-of-the-art methods such as Sequential Neural Posterior Estimation (SNPE).",
        "_bibtex": "@inproceedings{\nsharrock2024sequential,\ntitle={Sequential Neural Score Estimation: Likelihood-Free Inference with Conditional Score Based Diffusion Models},\nauthor={Louis Sharrock and Jack Simons and Song Liu and Mark Beaumont},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=8viuf9PdzU}\n}"
    },
    {
        "title": "Model Alignment as Prospect Theoretic Optimization",
        "authorids": [
            "~Kawin_Ethayarajh1",
            "~Winnie_Xu1",
            "~Niklas_Muennighoff1",
            "~Dan_Jurafsky1",
            "~Douwe_Kiela1"
        ],
        "abstract": "Kahneman & Tversky's $\\textit{prospect theory}$ tells us that humans perceive random variables in a biased but well-defined manner (1992); for example, humans are famously loss-averse. We show that objectives for aligning LLMs with human feedback implicitly incorporate many of these biases---the success of these objectives (e.g., DPO) over cross-entropy minimization can partly be ascribed to them belonging to a family of loss functions that we call $\\textit{human-aware losses}$ (HALOs). However, the utility functions these methods attribute to humans still differ from those in the prospect theory literature. Using a Kahneman-Tversky model of human utility, we propose a HALO that directly maximizes the utility of generations instead of maximizing the log-likelihood of preferences, as current methods do. We call this approach KTO, and it matches or exceeds the performance of preference-based methods at scales from 1B to 30B, despite only learning from a binary signal of whether an output is desirable. More broadly, our work suggests that there is no one HALO that is universally superior; the best loss depends on the inductive biases most appropriate for a given setting, an oft-overlooked consideration.",
        "_bibtex": "@inproceedings{\nethayarajh2024model,\ntitle={Model Alignment as Prospect Theoretic Optimization},\nauthor={Kawin Ethayarajh and Winnie Xu and Niklas Muennighoff and Dan Jurafsky and Douwe Kiela},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=iUwHnoENnl}\n}"
    },
    {
        "title": "Stay on Topic with Classifier-Free Guidance",
        "authorids": [
            "~Guillaume_Sanchez1",
            "~Alexander_Spangher2",
            "~Honglu_Fan1",
            "~Elad_Levi1",
            "~Stella_Biderman1"
        ],
        "abstract": "Classifier-Free Guidance (CFG) has recently emerged in as a lightweight technique to encourage prompt-adherence in generations, yet has not yet been successfully applied to language modeling. In this work, we demonstrate across a wide array of benchmarks that CFG can be used broadly as an inference-time technique in pure language modeling. We show that CFG (1) improves the performance of Pythia, GPT-2 and LLaMA-family models across: Q&A, reasoning, code generation, and machine translation, achieving SOTA on LAMBADA with LLaMA-7B over PaLM-540B; (2) brings improvements equivalent to a model with twice the parameter-count; (3) can stack alongside other inference-time methods like Chain-of-Thought and Self-Consistency, yielding further improvements in difficult tasks; (4) can be used to increase the faithfulness and coherence of assistants in challenging form-driven and content-driven prompts: in human evaluations we show a 75% preference for using CFG over baseline.",
        "_bibtex": "@inproceedings{\nsanchez2024stay,\ntitle={Stay on Topic with Classifier-Free Guidance},\nauthor={Guillaume Sanchez and Alexander Spangher and Honglu Fan and Elad Levi and Stella Biderman},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=RiM3cl9MdK}\n}"
    },
    {
        "title": "Jetfire: Efficient and Accurate Transformer Pretraining with INT8 Data Flow and Per-Block Quantization",
        "authorids": [
            "~Haocheng_Xi1",
            "~Yuxiang_Chen2",
            "~Kang_Zhao5",
            "~KAI_JUN_TEH1",
            "~Jianfei_Chen1",
            "~Jun_Zhu2"
        ],
        "abstract": "Pretraining transformers are generally time-consuming. Fully quantized training (FQT) is a promising approach to speed up pretraining. However, most FQT methods adopt a quantize-compute-dequantize procedure, which often leads to suboptimal speedup and significant performance degradation when used in transformers due to the high memory access overheads and low-precision computations. In this work, we propose Jetfire, an efficient and accurate INT8 training method specific to transformers. Our method features an INT8 data flow to optimize memory access and a per-block quantization method to maintain the accuracy of pretrained transformers. Extensive experiments demonstrate that our INT8 FQT method achieves comparable accuracy to the FP16 training baseline and outperforms the existing INT8 training works for transformers. Moreover, for a standard transformer block, our method offers an end-to-end training speedup of 1.42x and a 1.49x memory reduction compared to the FP16 baseline.",
        "_bibtex": "@inproceedings{\nxi2024jetfire,\ntitle={Jetfire: Efficient and Accurate Transformer Pretraining with {INT}8 Data Flow and Per-Block Quantization},\nauthor={Haocheng Xi and Yuxiang Chen and Kang Zhao and KAI JUN TEH and Jianfei Chen and Jun Zhu},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=ltzTHGFF5i}\n}"
    },
    {
        "title": "QuRating: Selecting High-Quality Data for Training Language Models",
        "authorids": [
            "~Alexander_Wettig1",
            "~Aatmik_Gupta1",
            "~Saumya_Malik1",
            "~Danqi_Chen1"
        ],
        "abstract": "Selecting high-quality pre-training data is important for creating capable language models, but existing methods rely on simple heuristics. We introduce QuRating, a method for selecting pre-training data that can capture human intuitions about data quality. In this paper, we investigate four qualities - writing style, required expertise, facts & trivia, and educational value - and find that LLMs are able to discern these qualities, especially when making pairwise judgments of texts. We train a QuRater model to learn scalar ratings from pairwise judgments, and use it to annotate a 260B training corpus with quality ratings for each of the four criteria. In our experiments, we select 30B tokens according to the different quality ratings and train 1.3B-parameter language models on the selected data. We find that it is important to balance quality and diversity. When we sample using quality ratings as logits over documents, our models obtain lower perplexity and stronger in-context learning performance than baselines. Our best model is based on educational value and performs similarly to a model trained with uniform sampling for 50% more steps. Beyond data selection, we use the quality ratings to construct a training curriculum which improves performance without changing the training dataset. We extensively analyze the quality ratings and discuss their characteristics, biases, and wider implications.",
        "_bibtex": "@inproceedings{\nwettig2024qurating,\ntitle={QuRating: Selecting High-Quality Data for Training Language Models},\nauthor={Alexander Wettig and Aatmik Gupta and Saumya Malik and Danqi Chen},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=GLGYYqPwjy}\n}"
    },
    {
        "title": "Tuning-Free Stochastic Optimization",
        "authorids": [
            "~Ahmed_Khaled1",
            "~Chi_Jin1"
        ],
        "abstract": "Large-scale machine learning problems make the cost of hyperparameter tuning ever more prohibitive. This creates a need for algorithms that can tune themselves on-the-fly. We formalize the notion of *``tuning-free''* algorithms that can match the performance of optimally-tuned optimization algorithms up to polylogarithmic factors given only loose hints on the relevant problem parameters. We consider in particular algorithms that can match optimally-tuned Stochastic Gradient Descent (SGD). When the domain of optimization is bounded, we show tuning-free matching of SGD is possible and achieved by several existing algorithms. We prove that for the task of minimizing a convex and smooth or Lipschitz function over an unbounded domain, tuning-free optimization is impossible. We discuss conditions under which tuning-free optimization is possible even over unbounded domains. In particular, we show that the recently proposed DoG and DoWG algorithms are tuning-free when the noise distribution is sufficiently well-behaved. For the task of finding a stationary point of a smooth and potentially nonconvex function, we give a variant of SGD that matches the best-known high-probability convergence rate for tuned SGD at only an additional polylogarithmic cost. However, we also give an impossibility result that shows no algorithm can hope to match the optimal expected convergence rate for tuned SGD with high probability.",
        "_bibtex": "@inproceedings{\nkhaled2024tuningfree,\ntitle={Tuning-Free Stochastic Optimization},\nauthor={Ahmed Khaled and Chi Jin},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=A6fmX9QCEa}\n}"
    },
    {
        "title": "Second-Order Uncertainty Quantification: A Distance-Based Approach",
        "authorids": [
            "~Yusuf_Sale1",
            "~Viktor_Bengs1",
            "~Michele_Caprio1",
            "~Eyke_H\u00fcllermeier1"
        ],
        "abstract": "In the past couple of years, various approaches to representing and quantifying different types of predictive uncertainty in machine learning, notably in the setting of classification, have been proposed on the basis of second-order probability distributions, i.e., predictions in the form of distributions on probability distributions. A completely conclusive solution has not yet been found, however, as shown by recent criticisms of commonly used uncertainty measures associated with second-order distributions, identifying undesirable theoretical properties of these measures. In light of these criticisms, we propose a set of formal criteria that meaningful uncertainty measures for predictive uncertainty based on second-order distributions should obey. Moreover, we provide a general framework for developing uncertainty measures to account for these criteria, and offer an instantiation based on the Wasserstein distance, for which we prove that all criteria are satisfied.",
        "_bibtex": "@inproceedings{\nsale2024secondorder,\ntitle={Second-Order Uncertainty Quantification: A Distance-Based Approach},\nauthor={Yusuf Sale and Viktor Bengs and Michele Caprio and Eyke H{\\\"u}llermeier},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=VJjjNrUi8j}\n}"
    },
    {
        "title": "Fundamental Benefit of Alternating Updates in Minimax Optimization",
        "authorids": [
            "~Jaewook_Lee6",
            "~Hanseul_Cho1",
            "~Chulhee_Yun1"
        ],
        "abstract": "The Gradient Descent-Ascent (GDA) algorithm, designed to solve minimax optimization problems, takes the descent and ascent steps either simultaneously (Sim-GDA) or alternately (Alt-GDA). While Alt-GDA is commonly observed to converge faster, the performance gap between the two is not yet well understood theoretically, especially in terms of global convergence rates. To address this theory-practice gap, we present fine-grained convergence analyses of both algorithms for strongly-convex-strongly-concave and Lipschitz-gradient objectives. Our new iteration complexity upper bound of Alt-GDA is strictly smaller than the lower bound of Sim-GDA; i.e., Alt-GDA is provably faster. Moreover, we propose Alternating-Extrapolation GDA (Alex-GDA), a general algorithmic framework that subsumes Sim-GDA and Alt-GDA, for which the main idea is to alternately take gradients from extrapolations of the iterates. We show that Alex-GDA satisfies a smaller iteration complexity bound, identical to that of the Extra-gradient method, while requiring less gradient computations. We also prove that Alex-GDA enjoys linear convergence for bilinear problems, for which both Sim-GDA and Alt-GDA fail to converge at all.",
        "_bibtex": "@inproceedings{\nlee2024fundamental,\ntitle={Fundamental Benefit of Alternating Updates in Minimax Optimization},\nauthor={Jaewook Lee and Hanseul Cho and Chulhee Yun},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=s6ZAT8MLKU}\n}"
    },
    {
        "title": "Leveraging Attractor Dynamics in Spatial Navigation for Better Language Parsing",
        "authorids": [
            "~Xiaolong_Zou1",
            "~Xingxing_Cao1",
            "~Xiaojiao_Yang1",
            "~Bo_Hong2"
        ],
        "abstract": "Increasing experimental evidence suggests that the human hippocampus, evolutionarily shaped by spatial navigation tasks, also plays an important role in language comprehension, indicating a shared computational mechanism for both functions. However, the specific relationship between the hippocampal formation's computational mechanism in spatial navigation and its role in language processing remains elusive. To investigate this question, we develop a prefrontal-hippocampal-entorhinal model (which called PHE-trinity) that features two key aspects: 1) the use of a modular continuous attractor neural network to represent syntactic structure, akin to the grid network in the entorhinal cortex; 2) the creation of two separate input streams, mirroring the factorized structure-content representation found in the hippocampal formation. We evaluate our model on language command parsing tasks, specifically using the SCAN dataset. Our findings include: 1) attractor dynamics can facilitate systematic generalization and efficient learning from limited data; 2) through visualization and reverse engineering, we unravel a potential dynamic mechanism for grid network representing syntactic structure. Our research takes an initial step in uncovering the dynamic mechanism shared by spatial navigation and language information processing.",
        "_bibtex": "@inproceedings{\nzou2024leveraging,\ntitle={Leveraging Attractor Dynamics in Spatial Navigation for Better Language Parsing},\nauthor={Xiaolong Zou and Xingxing Cao and Xiaojiao Yang and Bo Hong},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=eapFRURALQ}\n}"
    },
    {
        "title": "Differentially Private Synthetic Data via Foundation Model APIs 2: Text",
        "authorids": [
            "~Chulin_Xie1",
            "~Zinan_Lin1",
            "~Arturs_Backurs1",
            "~Sivakanth_Gopi1",
            "~Da_Yu1",
            "~Huseyin_A_Inan1",
            "~Harsha_Nori1",
            "~Haotian_Jiang2",
            "~Huishuai_Zhang3",
            "~Yin_Tat_Lee1",
            "~Bo_Li19",
            "~Sergey_Yekhanin1"
        ],
        "abstract": "Text data has become extremely valuable due to the emergence of machine learning algorithms that learn from it. A lot of high-quality text data generated in the real world is private and therefore cannot be shared or used freely due to privacy concerns. Generating synthetic replicas of private text data with a formal privacy guarantee, i.e., differential privacy (DP), offers a promising and scalable solution. However, existing methods necessitate DP finetuning of large language models (LLMs) on private data to generate DP synthetic data. This approach is not viable for proprietary LLMs (e.g., GPT-3.5) and also demands considerable computational resources for open-source LLMs. Lin et al. (2024) recently introduced the Private Evolution (PE) algorithm to generate DP synthetic images with only API access to diffusion models. In this work, we propose an augmented PE algorithm, named Aug-PE, that applies to the complex setting of text. We use API access to an LLM and generate DP synthetic text without any model training. We conduct comprehensive experiments on three benchmark datasets. Our results demonstrate that Aug-PE produces DP synthetic text that yields competitive utility with the SOTA DP finetuning baselines. This underscores the feasibility of relying solely on API access of LLMs to produce high-quality DP synthetic texts, thereby facilitating more accessible routes to privacy-preserving LLM applications.",
        "_bibtex": "@inproceedings{\nxie2024differentially,\ntitle={Differentially Private Synthetic Data via Foundation Model {API}s 2: Text},\nauthor={Chulin Xie and Zinan Lin and Arturs Backurs and Sivakanth Gopi and Da Yu and Huseyin A Inan and Harsha Nori and Haotian Jiang and Huishuai Zhang and Yin Tat Lee and Bo Li and Sergey Yekhanin},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=LWD7upg1ob}\n}"
    },
    {
        "title": "DISCRET: Synthesizing Faithful Explanations For Treatment Effect Estimation",
        "authorids": [
            "~Yinjun_Wu1",
            "~Mayank_Keoliya1",
            "~Kan_Chen3",
            "~Neelay_Velingker1",
            "~Ziyang_Li2",
            "~Emily_J_Getzen1",
            "~Qi_Long1",
            "~Mayur_Naik1",
            "~Ravi_B_Parikh1",
            "~Eric_Wong1"
        ],
        "abstract": "Designing faithful yet accurate AI models is challenging, particularly in the field of individual treatment effect estimation (ITE). ITE prediction models deployed in critical settings such as healthcare should ideally be (i) accurate, and (ii) provide faithful explanations. However, current solutions are inadequate: state-of-the-art black-box models do not supply explanations, post-hoc explainers for black-box models lack faithfulness guarantees, and self-interpretable models greatly compromise accuracy. To address these issues, we propose DISCRET, a self-interpretable ITE framework that synthesizes faithful, rule-based explanations for each sample. A key insight behind DISCRET is that explanations can serve dually as *database queries* to identify similar subgroups of samples. We provide a novel RL algorithm to efficiently synthesize these explanations from a large search space. We evaluate DISCRET on diverse tasks involving tabular, image, and text data. DISCRET outperforms the best self-interpretable models and has accuracy comparable to the best black-box models while providing faithful explanations. DISCRET is available at https://github.com/wuyinjun-1993/DISCRET-ICML2024.",
        "_bibtex": "@inproceedings{\nwu2024discret,\ntitle={{DISCRET}: Synthesizing Faithful Explanations For Treatment Effect Estimation},\nauthor={Yinjun Wu and Mayank Keoliya and Kan Chen and Neelay Velingker and Ziyang Li and Emily J Getzen and Qi Long and Mayur Naik and Ravi B Parikh and Eric Wong},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=B0xmynxt4f}\n}"
    },
    {
        "title": "Position: Graph Foundation Models Are Already Here",
        "authorids": [
            "~Haitao_Mao1",
            "~Zhikai_Chen3",
            "~Wenzhuo_Tang1",
            "~Jianan_Zhao2",
            "~Yao_Ma3",
            "~Tong_Zhao3",
            "~Neil_Shah2",
            "~Mikhail_Galkin1",
            "~Jiliang_Tang1"
        ],
        "abstract": "Graph Foundation Models (GFMs) are emerging as a significant research topic in the graph domain, aiming to develop graph models trained on extensive and diverse data to enhance their applicability across various tasks and domains. Developing GFMs presents unique challenges over traditional Graph Neural Networks (GNNs), which are typically trained from scratch for specific tasks on particular datasets. The primary challenge in constructing GFMs lies in effectively leveraging vast and diverse graph data to achieve positive transfer. Drawing inspiration from existing foundation models in the CV and NLP domains, we propose a novel perspective for the GFM development by advocating for a \"graph vocabulary'', in which the basic transferable units underlying graphs encode the invariance on graphs. We ground the graph vocabulary construction from essential aspects including network analysis, expressiveness, and stability. Such a vocabulary perspective can potentially advance the future GFM design in line with the neural scaling laws. All relevant resources with GFM design can be found here.",
        "_bibtex": "@inproceedings{\nmao2024position,\ntitle={Position: Graph Foundation Models Are Already Here},\nauthor={Haitao Mao and Zhikai Chen and Wenzhuo Tang and Jianan Zhao and Yao Ma and Tong Zhao and Neil Shah and Mikhail Galkin and Jiliang Tang},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=Edz0QXKKAo}\n}"
    },
    {
        "title": "Improved Operator Learning by Orthogonal Attention",
        "authorids": [
            "~Zipeng_Xiao1",
            "~Zhongkai_Hao1",
            "~Bokai_Lin1",
            "~Zhijie_Deng1",
            "~Hang_Su3"
        ],
        "abstract": "This work presents orthogonal attention for constructing neural operators to serve as surrogates to model the solutions of a family of Partial Differential Equations (PDEs). The motivation is that the kernel integral operator, which is usually at the core of neural operators, can be reformulated with orthonormal eigenfunctions. Inspired by the success of the neural approximation of eigenfunctions (Deng et al., 2022), we opt to directly parameterize the involved eigenfunctions with flexible neural networks (NNs), based on which the input function is then transformed by the rule of kernel integral. Surprisingly, the resulting NN module bears a striking resemblance to regular attention mechanisms, albeit without softmax. Instead, it incorporates an orthogonalization operation that provides regularization during model training and helps mitigate overfitting, particularly in scenarios with limited data availability. In practice, the orthogonalization operation can be implemented with minimal additional overheads. Experiments on six standard neural operator benchmark datasets comprising both regular and irregular geometries show that our method can outperform competing baselines with decent margins.",
        "_bibtex": "@inproceedings{\nxiao2024improved,\ntitle={Improved Operator Learning by Orthogonal Attention},\nauthor={Zipeng Xiao and Zhongkai Hao and Bokai Lin and Zhijie Deng and Hang Su},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=6w7zkf9FBR}\n}"
    },
    {
        "title": "Exploiting Code Symmetries for Learning Program Semantics",
        "authorids": [
            "~Kexin_Pei1",
            "~Weichen_Li1",
            "~Qirui_Jin1",
            "~Shuyang_Liu2",
            "~Scott_Geng1",
            "~Lorenzo_Cavallaro1",
            "~Junfeng_Yang1",
            "~Suman_Jana1"
        ],
        "abstract": "This paper tackles the challenge of teaching code semantics to Large Language Models (LLMs) for program analysis by incorporating code symmetries into the model architecture. We introduce a group-theoretic framework that defines code symmetries as semantics-preserving transformations, where forming a code symmetry group enables precise and efficient reasoning of code semantics. Our solution, SymC, develops a novel variant of self-attention that is provably equivariant to code symmetries from the permutation group defined over the program dependence graph. SymC obtains superior performance on five program analysis tasks, outperforming state-of-the-art code models, including GPT-4, without any pre-training. Our results suggest that code LLMs that encode the code structural prior via the code symmetry group generalize better and faster.",
        "_bibtex": "@inproceedings{\npei2024exploiting,\ntitle={Exploiting Code Symmetries for Learning Program Semantics},\nauthor={Kexin Pei and Weichen Li and Qirui Jin and Shuyang Liu and Scott Geng and Lorenzo Cavallaro and Junfeng Yang and Suman Jana},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=OLvgrLtv6J}\n}"
    },
    {
        "title": "Resisting Stochastic Risks in Diffusion Planners with the Trajectory Aggregation Tree",
        "authorids": [
            "~Lang_Feng1",
            "~Pengjie_Gu1",
            "~Bo_An2",
            "~Gang_Pan1"
        ],
        "abstract": "Diffusion planners have shown promise in handling long-horizon and sparse-reward tasks due to the non-autoregressive plan generation. However, their inherent stochastic risk of generating infeasible trajectories presents significant challenges to their reliability and stability. We introduce a novel approach, the Trajectory Aggregation Tree (TAT), to address this issue in diffusion planners. Compared to prior methods that rely solely on raw trajectory predictions, TAT aggregates information from both historical and current trajectories, forming a dynamic tree-like structure. Each trajectory is conceptualized as a branch and individual states as nodes. As the structure evolves with the integration of new trajectories, unreliable states are marginalized, and the most impactful nodes are prioritized for decision-making. TAT can be deployed without modifying the original training and sampling pipelines of diffusion planners, making it a training-free, ready-to-deploy solution. We provide both theoretical analysis and empirical evidence to support TAT's effectiveness. Our results highlight its remarkable ability to resist the risk from unreliable trajectories, guarantee the performance boosting of diffusion planners in 100% of tasks, and exhibit an appreciable tolerance margin for sample quality, thereby enabling planning with a more than $3\\times$ acceleration.",
        "_bibtex": "@inproceedings{\nfeng2024resisting,\ntitle={Resisting Stochastic Risks in Diffusion Planners with the Trajectory Aggregation Tree},\nauthor={Lang Feng and Pengjie Gu and Bo An and Gang Pan},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=NbYAmsFJrc}\n}"
    },
    {
        "title": "Stochastic Interpolants with Data-Dependent Couplings",
        "authorids": [
            "~Michael_Samuel_Albergo1",
            "~Mark_Goldstein1",
            "~Nicholas_Matthew_Boffi1",
            "~Rajesh_Ranganath2",
            "~Eric_Vanden-Eijnden1"
        ],
        "abstract": "Generative models inspired by dynamical transport of measure -- such as flows and diffusions -- construct a continuous-time map between two probability densities. Conventionally, one of these is the target density, only accessible through samples, while the other is taken as a simple base density that is data-agnostic. In this work, using the framework of stochastic interpolants, we formalize how to *couple* the base and the target densities, whereby samples from the base are computed conditionally given samples from the target in a way that is different from (but does not preclude) incorporating information about class labels or continuous embeddings. This enables us to construct dynamical transport maps that serve as conditional generative models. We show that these transport maps can be learned by solving a simple square loss regression problem analogous to the standard independent setting. We demonstrate the usefulness of constructing dependent couplings in practice through experiments in super-resolution and in-painting. The code is available at [https://github.com/interpolants/couplings](https://github.com/interpolants/couplings).",
        "_bibtex": "@inproceedings{\nalbergo2024stochastic,\ntitle={Stochastic Interpolants with Data-Dependent Couplings},\nauthor={Michael Samuel Albergo and Mark Goldstein and Nicholas Matthew Boffi and Rajesh Ranganath and Eric Vanden-Eijnden},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=FFILRGD0jG}\n}"
    },
    {
        "title": "How Free is Parameter-Free Stochastic Optimization?",
        "authorids": [
            "~Amit_Attia1",
            "~Tomer_Koren1"
        ],
        "abstract": "We study the problem of parameter-free stochastic optimization, inquiring whether, and under what conditions, do fully parameter-free methods exist: these are methods that achieve convergence rates competitive with optimally tuned methods, without requiring significant knowledge of the true problem parameters. Existing parameter-free methods can only be considered ``partially'' parameter-free, as they require some non-trivial knowledge of the true problem parameters, such as a bound on the stochastic gradient norms, a bound on the distance to a minimizer, etc. In the non-convex setting, we demonstrate that a simple hyperparameter search technique results in a fully parameter-free method that outperforms more sophisticated state-of-the-art algorithms. We also provide a similar result in the convex setting with access to noisy function values under mild noise assumptions. Finally, assuming only access to stochastic gradients, we establish a lower bound that renders fully parameter-free stochastic convex optimization infeasible, and provide a method which is (partially) parameter-free up to the limit indicated by our lower bound.",
        "_bibtex": "@inproceedings{\nattia2024how,\ntitle={How Free is Parameter-Free Stochastic Optimization?},\nauthor={Amit Attia and Tomer Koren},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=6L4K5jmSJq}\n}"
    },
    {
        "title": "Transformers, parallel computation, and logarithmic depth",
        "authorids": [
            "~Clayton_Sanford1",
            "~Daniel_Hsu1",
            "~Matus_Telgarsky1"
        ],
        "abstract": "We show that a constant number of self-attention layers can efficiently simulate\u2014and be simulated by\u2014a constant number of communication rounds of *Massively Parallel Computation*. As a consequence, we show that logarithmic-depth is sufficient for transformers to solve basic computational tasks that cannot be efficiently solved by several other neural sequence models and sub-quadratic transformer approximations. We thus establish parallelism as a key distinguishing property of transformers.",
        "_bibtex": "@inproceedings{\nsanford2024transformers,\ntitle={Transformers, parallel computation, and logarithmic depth},\nauthor={Clayton Sanford and Daniel Hsu and Matus Telgarsky},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=QCZabhKQhB}\n}"
    },
    {
        "title": "StackSight: Unveiling WebAssembly through Large Language Models and Neurosymbolic Chain-of-Thought Decompilation",
        "authorids": [
            "~Weike_Fang1",
            "~Zhejian_Zhou1",
            "~Junzhou_He1",
            "~Weihang_Wang3"
        ],
        "abstract": "WebAssembly enables near-native execution in web applications and is increasingly adopted for tasks that demand high performance and robust security. However, its assembly-like syntax, implicit stack machine, and low-level data types make it extremely difficult for human developers to understand, spurring the need for effective WebAssembly reverse engineering techniques. In this paper, we propose StackSight, a novel neurosymbolic approach that combines Large Language Models (LLMs) with advanced program analysis to decompile complex WebAssembly code into readable C++ snippets. StackSight visualizes and tracks virtual stack alterations via a static analysis algorithm and then applies chain-of-thought prompting to harness LLM's complex reasoning capabilities. Evaluation results show that StackSight significantly improves WebAssembly decompilation. Our user study also demonstrates that code snippets generated by StackSight have significantly higher win rates and enable a better grasp of code semantics.",
        "_bibtex": "@inproceedings{\nfang2024stacksight,\ntitle={StackSight: Unveiling WebAssembly through Large Language Models and Neurosymbolic Chain-of-Thought Decompilation},\nauthor={Weike Fang and Zhejian Zhou and Junzhou He and Weihang Wang},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=gn5AsHIIwb}\n}"
    },
    {
        "title": "Adaptive Online Experimental Design for Causal Discovery",
        "authorids": [
            "~Muhammad_Qasim_Elahi1",
            "~Lai_Wei5",
            "~Murat_Kocaoglu1",
            "~Mahsa_Ghasemi1"
        ],
        "abstract": "Causal discovery aims to uncover cause-and-effect relationships encoded in causal graphs by leveraging observational, interventional data, or their combination. The majority of existing causal discovery methods are developed assuming infinite interventional data. We focus on interventional data efficiency and formalize causal discovery from the perspective of online learning, inspired by pure exploration in bandit problems. A graph separating system, consisting of interventions that cut every edge of the graph at least once, is sufficient for learning causal graphs when infinite interventional data is available, even in the worst case. We propose a track-and-stop causal discovery algorithm that adaptively selects interventions from the graph separating system via allocation matching and learns the causal graph based on sampling history. Given any desired confidence value, the algorithm determines a termination condition and runs until it is met. We analyze the algorithm to establish a problem-dependent upper bound on the expected number of required interventional samples. Our proposed algorithm outperforms existing methods in simulations across various randomly generated causal graphs. It achieves higher accuracy, measured by the structural hamming distance (SHD) between the learned causal graph and the ground truth, with significantly fewer samples.",
        "_bibtex": "@inproceedings{\nelahi2024adaptive,\ntitle={Adaptive Online Experimental Design for Causal Discovery},\nauthor={Muhammad Qasim Elahi and Lai Wei and Murat Kocaoglu and Mahsa Ghasemi},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=nJzf3TVnOn}\n}"
    },
    {
        "title": "Convex Relaxations of ReLU Neural Networks Approximate Global Optima in Polynomial Time",
        "authorids": [
            "~Sungyoon_Kim3",
            "~Mert_Pilanci3"
        ],
        "abstract": "In this paper, we study the optimality gap between two-layer ReLU networks regularized with weight decay and their convex relaxations. We show that when the training data is random, the relative optimality gap between the original problem and its relaxation can be bounded by a factor of O(\u221alog n), where n is the number of training samples. A simple application leads to a tractable polynomial-time algorithm that is guaranteed to solve the original non-convex problem up to a logarithmic factor. Moreover, under mild assumptions, we show that local gradient methods converge to a point with low training loss with high probability. Our result is an exponential improvement compared to existing results and sheds new light on understanding why local gradient methods work well.",
        "_bibtex": "@inproceedings{\nkim2024convex,\ntitle={Convex Relaxations of Re{LU} Neural Networks Approximate Global Optima in Polynomial Time},\nauthor={Sungyoon Kim and Mert Pilanci},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=Zn44XGFGam}\n}"
    },
    {
        "title": "Testing the Feasibility of Linear Programs with Bandit Feedback",
        "authorids": [
            "~Aditya_Gangrade1",
            "~Aditya_Gopalan1",
            "~Venkatesh_Saligrama1",
            "~Clayton_Scott1"
        ],
        "abstract": "While the recent literature has seen a surge in the study of constrained bandit problems, all existing methods for these begin by assuming the feasibility of the underlying problem. We initiate the study of testing such feasibility assumptions, and in particular address the problem in the linear bandit setting, thus characterising the costs of feasibility testing for an unknown linear program using bandit feedback. Concretely, we test if $\\exists x: Ax \\ge 0$ for an unknown $A \\in \\mathbb{R}^{m \\times d}$, by playing a sequence of actions $x_t\\in \\mathbb{R}^d$, and observing $Ax_t + \\mathrm{noise}$ in response. By identifying the hypothesis as determining the sign of the value of a minimax game, we construct a novel test based on low-regret algorithms and a nonasymptotic law of iterated logarithms. We prove that this test is reliable, and adapts to the `signal level,' $\\Gamma,$ of any instance, with mean sample costs scaling as $\\widetilde{O}(d^2/\\Gamma^2)$. We complement this by a minimax lower bound of $\\Omega(d/\\Gamma^2)$ for sample costs of reliable tests, dominating prior asymptotic lower bounds by capturing the dependence on $d$, and thus elucidating a basic insight missing in the extant literature on such problems.",
        "_bibtex": "@inproceedings{\ngangrade2024testing,\ntitle={Testing the Feasibility of Linear Programs with Bandit Feedback},\nauthor={Aditya Gangrade and Aditya Gopalan and Venkatesh Saligrama and Clayton Scott},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=TfwGtfPkhV}\n}"
    },
    {
        "title": "Batch and match: black-box variational inference with a score-based divergence",
        "authorids": [
            "~Diana_Cai1",
            "~Chirag_Modi1",
            "~Loucas_Pillaud-Vivien1",
            "~Charles_Margossian1",
            "~Robert_M._Gower1",
            "~David_Blei2",
            "~Lawrence_K._Saul3"
        ],
        "abstract": "Most leading implementations of black-box variational inference (BBVI) are based on optimizing a stochastic evidence lower bound (ELBO). But such approaches to BBVI often converge slowly due to the high variance of their gradient estimates and their sensitivity to hyperparameters. In this work, we propose _batch and match_ (BaM), an alternative approach to BBVI based on a score-based divergence. Notably, this score-based divergence can be optimized by a closed-form proximal update for Gaussian variational families with full covariance matrices. We analyze the convergence of BaM when the target distribution is Gaussian, and we prove that in the limit of infinite batch size the variational parameter updates converge exponentially quickly to the target mean and covariance. We also evaluate the performance of BaM on Gaussian and non-Gaussian target distributions that arise from posterior inference in hierarchical and deep generative models. In these experiments, we find that BaM typically converges in fewer (and sometimes significantly fewer) gradient evaluations than leading implementations of BBVI based on ELBO maximization.",
        "_bibtex": "@inproceedings{\ncai2024batch,\ntitle={Batch and match: black-box variational inference with a score-based divergence},\nauthor={Diana Cai and Chirag Modi and Loucas Pillaud-Vivien and Charles Margossian and Robert M. Gower and David Blei and Lawrence K. Saul},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=bplNmU2ROC}\n}"
    },
    {
        "title": "A Distributional Analogue to the Successor Representation",
        "authorids": [
            "~Harley_Wiltzer1",
            "~Jesse_Farebrother1",
            "~Arthur_Gretton1",
            "~Yunhao_Tang1",
            "~Andre_Barreto1",
            "~Will_Dabney1",
            "~Marc_G_Bellemare1",
            "~Mark_Rowland1"
        ],
        "abstract": "This paper contributes a new approach for distributional reinforcement learning which elucidates a clean separation of transition structure and reward in the learning process. Analogous to how the successor representation (SR) describes the expected consequences of behaving according to a given policy, our distributional successor measure (SM) describes the distributional consequences of this behaviour. We formulate the distributional SM as a distribution over distributions and provide theory connecting it with distributional and model-based reinforcement learning. Moreover, we propose an algorithm that learns the distributional SM from data by minimizing a two-level maximum mean discrepancy. Key to our method are a number of algorithmic techniques that are independently valuable for learning generative models of state. As an illustration of the usefulness of the distributional SM, we show that it enables zero-shot risk-sensitive policy evaluation in a way that was not previously possible.",
        "_bibtex": "@inproceedings{\nwiltzer2024a,\ntitle={A Distributional Analogue to the Successor Representation},\nauthor={Harley Wiltzer and Jesse Farebrother and Arthur Gretton and Yunhao Tang and Andre Barreto and Will Dabney and Marc G Bellemare and Mark Rowland},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=zajsXCxMgW}\n}"
    },
    {
        "title": "MALIBO: Meta-learning for Likelihood-free Bayesian Optimization",
        "authorids": [
            "~Jiarong_Pan1",
            "~Stefan_Falkner1",
            "~Felix_Berkenkamp1",
            "~Joaquin_Vanschoren1"
        ],
        "abstract": "Bayesian optimization (BO) is a popular method to optimize costly black-box functions, and meta-learning has emerged as a way to leverage knowledge from related tasks to optimize new tasks faster. However, existing meta-learning methods for BO rely on surrogate models that are not scalable or are sensitive to varying input scales and noise types across tasks. Moreover, they often overlook the uncertainty associated with task similarity, leading to unreliable task adaptation when a new task differs significantly or has not been sufficiently explored yet. We propose a novel meta-learning BO approach that bypasses the surrogate model and directly learns the utility of queries across tasks. It explicitly models task uncertainty and includes an auxiliary model to enable robust adaptation to new tasks. Extensive experiments show that our method achieves strong performance and outperforms multiple meta-learning BO methods across various benchmarks.",
        "_bibtex": "@inproceedings{\npan2024malibo,\ntitle={{MALIBO}: Meta-learning for Likelihood-free Bayesian Optimization},\nauthor={Jiarong Pan and Stefan Falkner and Felix Berkenkamp and Joaquin Vanschoren},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=3QM5SWfeov}\n}"
    },
    {
        "title": "Triple Changes Estimator for Targeted Policies",
        "authorids": [
            "~Sina_Akbari1",
            "~Negar_Kiyavash1"
        ],
        "abstract": "The renowned difference-in-differences (DiD) estimator relies on the assumption of 'parallel trends,' which may not hold in many practical applications. To address this issue, economists are increasingly considering the triple difference estimator as a more credible alternative. Both DiD and triple difference are limited to assessing average effects exclusively. An alternative avenue is offered by the changes-in-changes (CiC) estimator, which provides an estimate of the entire counterfactual distribution by relying on assumptions imposed on the distribution of potential outcomes. In this work, we extend the triple difference estimator to accommodate the CiC framework, presenting the `triple changes estimator' and its identification assumptions, thereby expanding the scope of the CiC paradigm. Subsequently, we empirically evaluate the proposed framework and apply it to a study examining the impact of Medicaid expansion on children's preventive care.",
        "_bibtex": "@inproceedings{\nakbari2024triple,\ntitle={Triple Changes Estimator for Targeted Policies},\nauthor={Sina Akbari and Negar Kiyavash},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=yzNEkTmcoF}\n}"
    },
    {
        "title": "Time Weaver: A Conditional Time Series Generation Model",
        "authorids": [
            "~Sai_Shankar_Narasimhan1",
            "~Shubhankar_Agarwal1",
            "~Oguzhan_Akcin2",
            "~sujay_sanghavi1",
            "~Sandeep_P._Chinchali1"
        ],
        "abstract": "Imagine generating a city\u2019s electricity demand pattern based on weather, the presence of an electric vehicle, and location, which could be used for capacity planning during a winter freeze. Such real-world time series are often enriched with paired heterogeneous contextual metadata (e.g., weather and location). Current approaches to time series generation often ignore this paired metadata. Additionally, the heterogeneity in metadata poses several practical challenges in adapting existing conditional generation approaches from the image, audio, and video domains to the time series domain. To address this gap, we introduce TIME WEAVER, a novel diffusion-based model that leverages the heterogeneous metadata in the form of categorical, continuous, and even time-variant variables to significantly improve time series generation. Additionally, we show that naive extensions of standard evaluation metrics from the image to the time series domain are insufficient. These metrics do not penalize conditional generation approaches for their poor specificity in reproducing the metadata-specific features in the generated time series. Thus, we innovate a novel evaluation metric that accurately captures the specificity of conditional generation and the realism of the generated time series. We show that TIME WEAVER outperforms state-of-the-art benchmarks, such as Generative Adversarial Networks (GANs), by up to 30% in downstream classification tasks on real-world energy, medical, air quality, and traffic datasets.",
        "_bibtex": "@inproceedings{\nnarasimhan2024time,\ntitle={Time Weaver: A Conditional Time Series Generation Model},\nauthor={Sai Shankar Narasimhan and Shubhankar Agarwal and Oguzhan Akcin and sujay sanghavi and Sandeep P. Chinchali},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=WpKDeixmFr}\n}"
    },
    {
        "title": "Position: LLMs Can\u2019t Plan, But Can Help Planning in LLM-Modulo Frameworks",
        "authorids": [
            "~Subbarao_Kambhampati1",
            "~Karthik_Valmeekam1",
            "~Lin_Guan1",
            "~Mudit_Verma2",
            "~Kaya_Stechly1",
            "~Siddhant_Bhambri1",
            "~Lucas_Paul_Saldyt1",
            "~Anil_B_Murthy1"
        ],
        "abstract": "We argue that auto-regressive LLMs cannot, by themselves, do planning or self-verification (which is after all a form of reasoning), and shed some light on the reasons for misunderstandings in the literature. We will also argue that LLMs should be viewed as universal approximate knowledge sources that have much more meaningful roles to play in planning/reasoning tasks beyond simple front-end/back-end format translators. We present a vision of LLM-Modulo Frameworks that combine the strengths of LLMs with external model-based verifiers in a tighter bi-directional interaction regime. We will show how the models driving the external verifiers themselves can be acquired with the help of LLMs. We will also argue that rather than simply pipelining LLMs and symbolic components, this LLM-Modulo Framework provides a better neuro-symbolic approach that offers tighter integration between LLMs and symbolic components, and allows extending the scope of model-based planning/reasoning regimes towards more flexible knowledge, problem and preference specifications.",
        "_bibtex": "@inproceedings{\nkambhampati2024position,\ntitle={Position: {LLM}s Can{\\textquoteright}t Plan, But Can Help Planning in {LLM}-Modulo Frameworks},\nauthor={Subbarao Kambhampati and Karthik Valmeekam and Lin Guan and Mudit Verma and Kaya Stechly and Siddhant Bhambri and Lucas Paul Saldyt and Anil B Murthy},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=Th8JPEmH4z}\n}"
    },
    {
        "title": "Craftax: A Lightning-Fast Benchmark for Open-Ended Reinforcement Learning",
        "authorids": [
            "~Michael_Matthews4",
            "~Michael_Beukman1",
            "~Benjamin_Ellis1",
            "~Mikayel_Samvelyan1",
            "~Matthew_Thomas_Jackson1",
            "~Samuel_Coward1",
            "~Jakob_Nicolaus_Foerster1"
        ],
        "abstract": "Benchmarks play a crucial role in the development and analysis of reinforcement learning (RL) algorithms. We identify that existing benchmarks used for research into open-ended learning fall into one of two categories. Either they are too slow for meaningful research to be performed without enormous computational resources, like Crafter, NetHack and Minecraft, or they are not complex enough to pose a significant challenge, like Minigrid and Procgen. To remedy this, we first present Craftax-Classic: a ground-up rewrite of Crafter in JAX that runs up to 250x faster than the Python-native original. A run of PPO using 1 billion environment interactions finishes in under an hour using only a single GPU and averages 90% of the optimal reward. To provide a more compelling challenge we present the main Craftax benchmark, a significant extension of the Crafter mechanics with elements inspired from NetHack. Solving Craftax requires deep exploration, long term planning and memory, as well as continual adaptation to novel situations as more of the world is discovered. We show that existing methods including global and episodic exploration, as well as unsupervised environment design fail to make material progress on the benchmark. We therefore believe that Craftax can for the first time allow researchers to experiment in a complex, open-ended environment with limited computational resources.",
        "_bibtex": "@inproceedings{\nmatthews2024craftax,\ntitle={Craftax: A Lightning-Fast Benchmark for Open-Ended Reinforcement Learning},\nauthor={Michael Matthews and Michael Beukman and Benjamin Ellis and Mikayel Samvelyan and Matthew Thomas Jackson and Samuel Coward and Jakob Nicolaus Foerster},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=hg4wXlrQCV}\n}"
    },
    {
        "title": "A Tensor Decomposition Perspective on Second-order RNNs",
        "authorids": [
            "~Maude_Lizaire1",
            "~Michael_Rizvi-Martel1",
            "~Marawan_Gamal1",
            "~Guillaume_Rabusseau1"
        ],
        "abstract": "Second-order Recurrent Neural Networks (2RNNs) extend RNNs by leveraging second-order interactions for sequence modelling. These models are provably more expressive than their first-order counterparts and have connections to well-studied models from formal language theory. However, their large parameter tensor makes computations intractable. To circumvent this issue, one approach known as MIRNN consists in limiting the type of interactions used by the model. Another is to leverage tensor decomposition to diminish the parameter count. In this work, we study the model resulting from parameterizing 2RNNs using the CP decomposition, which we call CPRNN. Intuitively, the rank of the decomposition should reduce expressivity. We analyze how rank and hidden size affect model capacity and show the relationships between RNNs, 2RNNs, MIRNNs, and CPRNNs based on these parameters. We support these results empirically with experiments on the Penn Treebank dataset which demonstrate that, with a fixed parameter budget, CPRNNs outperforms RNNs, 2RNNs, and MIRNNs with the right choice of rank and hidden size.",
        "_bibtex": "@inproceedings{\nlizaire2024a,\ntitle={A Tensor Decomposition Perspective on Second-order {RNN}s},\nauthor={Maude Lizaire and Michael Rizvi-Martel and Marawan Gamal and Guillaume Rabusseau},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=EsSSDjwFra}\n}"
    },
    {
        "title": "Adapt and Diffuse: Sample-adaptive Reconstruction via Latent Diffusion Models",
        "authorids": [
            "~Zalan_Fabian1",
            "~Berk_Tinaz1",
            "~Mahdi_Soltanolkotabi1"
        ],
        "abstract": "Inverse problems arise in a multitude of applications, where the goal is to recover a clean signal from noisy and possibly (non)linear observations. The difficulty of a reconstruction problem depends on multiple factors, such as the ground truth signal structure, the severity of the degradation and the complex interactions between the above. This results in natural sample-by-sample variation in the difficulty of a reconstruction problem. Our key observation is that most existing inverse problem solvers lack the ability to adapt their compute power to the difficulty of the reconstruction task, resulting in subpar performance and wasteful resource allocation. We propose a novel method, *severity encoding*, to estimate the degradation severity of corrupted signals in the latent space of an autoencoder. We show that the estimated severity has strong correlation with the true corruption level and can provide useful hints on the difficulty of reconstruction problems on a sample-by-sample basis. Furthermore, we propose a reconstruction method based on latent diffusion models that leverages the predicted degradation severities to fine-tune the reverse diffusion sampling trajectory and thus achieve sample-adaptive inference times. Our framework, Flash-Diffusion, acts as a wrapper that can be combined with any latent diffusion-based baseline solver, imbuing it with sample-adaptivity and acceleration. We perform experiments on both linear and nonlinear inverse problems and demonstrate that our technique greatly improves the performance of the baseline solver and achieves up to $10\\times$ acceleration in mean sampling speed.",
        "_bibtex": "@inproceedings{\nfabian2024adapt,\ntitle={Adapt and Diffuse: Sample-adaptive Reconstruction via Latent Diffusion Models},\nauthor={Zalan Fabian and Berk Tinaz and Mahdi Soltanolkotabi},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=V3OpGwo68Z}\n}"
    },
    {
        "title": "Physics of Language Models: Part 3.1, Knowledge Storage and Extraction",
        "authorids": [
            "~Zeyuan_Allen-Zhu1",
            "~Yuanzhi_Li1"
        ],
        "abstract": "Large language models (LLMs) can store a vast amount of world knowledge, often extractable via question-answering (e.g., \"What is Abraham Lincoln's birthday?''). However, do they answer such questions based on exposure to similar questions during training (i.e., cheating), or by genuinely learning to extract knowledge from sources like Wikipedia? In this paper, we investigate this issue using a controlled biography dataset. We find a strong correlation between the model's ability to extract knowledge and various _diversity measures_ of the training data. **Essentially**, for knowledge to be reliably extracted, it must be sufficiently augmented (e.g., through paraphrasing, sentence shuffling) _during pretraining_. Without such augmentation, knowledge may be memorized but not extractable, leading to 0% accuracy, regardless of subsequent instruction fine-tuning. To understand why this occurs, we employ (nearly) linear probing to demonstrate a strong connection between the observed correlation and _how the model internally encodes knowledge_ --- whether it is linearly encoded in the hidden embeddings of entity names or distributed across other token embeddings in the training text. **This paper provides several key recommendations for LLM pretraining in the industry:** (1) rewrite the pretraining data --- using small, auxiliary models --- to provide knowledge augmentation, and (2) incorporate more instruction-finetuning data into the pretraining stage before it becomes too late.",
        "_bibtex": "@inproceedings{\nallen-zhu2024physics,\ntitle={Physics of Language Models: Part 3.1, Knowledge Storage and Extraction},\nauthor={Zeyuan Allen-Zhu and Yuanzhi Li},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=5x788rqbcj}\n}"
    },
    {
        "title": "Fast Sampling-Based Sketches for Tensors",
        "authorids": [
            "~William_Joseph_Swartworth1",
            "~David_Woodruff1"
        ],
        "abstract": "We introduce a new approach for applying sampling-based sketches to two and three mode tensors. We illustrate our technique to construct sketches for the classical problems of $\\ell_0$ sampling and producing $\\ell_1$ embeddings. In both settings we achieve sketches that can be applied to a rank one tensor in $(\\mathbb{R}^d)^{\\otimes q}$ (for $q=2,3$) in time scaling with $d$ rather than $d^2$ or $d^3$. Our main idea is a particular sampling construction based on fast convolution which allows us to quickly compute sums over sufficiently random subsets of tensor entries.",
        "_bibtex": "@inproceedings{\nswartworth2024fast,\ntitle={Fast Sampling-Based Sketches for Tensors},\nauthor={William Joseph Swartworth and David Woodruff},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=tMkPL7Tiul}\n}"
    },
    {
        "title": "Gambling-Based Confidence Sequences for Bounded Random Vectors",
        "authorids": [
            "~Jongha_Jon_Ryu1",
            "~Gregory_W._Wornell1"
        ],
        "abstract": "A confidence sequence (CS) is a sequence of confidence sets that contains a target parameter of an underlying stochastic process at any time step with high probability. This paper proposes a new approach to constructing CSs for means of bounded multivariate stochastic processes using a general gambling framework, extending the recently established coin toss framework for bounded random processes. The proposed gambling framework provides a general recipe for constructing CSs for categorical and probability-vector-valued observations, as well as for general bounded multidimensional observations through a simple reduction. This paper specifically explores the use of the mixture portfolio, akin to Cover's universal portfolio, in the proposed framework and investigates the properties of the resulting CSs. Simulations demonstrate the tightness of these confidence sequences compared to existing methods. When applied to the sampling without-replacement setting for finite categorical data, it is shown that the resulting CS based on a universal gambling strategy is provably tighter than that of the posterior-prior ratio martingale proposed by Waudby-Smith and Ramdas.",
        "_bibtex": "@inproceedings{\nryu2024gamblingbased,\ntitle={Gambling-Based Confidence Sequences for Bounded Random Vectors},\nauthor={Jongha Jon Ryu and Gregory W. Wornell},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=mu7Er7f9NQ}\n}"
    },
    {
        "title": "WebLINX: Real-World Website Navigation with Multi-Turn Dialogue",
        "authorids": [
            "~Xing_Han_Lu2",
            "~Zden\u011bk_Kasner1",
            "~Siva_Reddy1"
        ],
        "abstract": "We propose the problem of conversational web navigation, where a digital agent controls a web browser and follows user instructions to solve real-world tasks in a multi-turn dialogue fashion. To support this problem, we introduce WEBLINX - a large-scale benchmark of 100K interactions across 2300 expert demonstrations of conversational web navigation. Our benchmark covers a broad range of patterns on over 150 real-world websites and can be used to train and evaluate agents in diverse scenarios. Due to the magnitude of information present, Large Language Models (LLMs) cannot process entire web pages in real-time. To solve this bottleneck, we design a retrieval-inspired model that efficiently prunes HTML pages by ranking relevant elements. We use the selected elements, along with screenshots and action history, to assess a variety of models for their ability to replicate human behavior when navigating the web. Our experiments span from small text-only to proprietary multimodal LLMs. We find that smaller finetuned decoders surpass the best zero-shot LLMs (including GPT-4V), but also larger finetuned multimodal models which were explicitly pretrained on screenshots. However, all finetuned models struggle to generalize to unseen websites. Our findings highlight the need for large multimodal models that can generalize to novel settings.",
        "_bibtex": "@inproceedings{\nlu2024weblinx,\ntitle={Web{LINX}: Real-World Website Navigation with Multi-Turn Dialogue},\nauthor={Xing Han Lu and Zden{\\v{e}}k Kasner and Siva Reddy},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=mUSPhG4uDW}\n}"
    },
    {
        "title": "Position: Data Authenticity, Consent, & Provenance for AI are all broken: what will it take to fix them?",
        "authorids": [
            "~Shayne_Longpre1",
            "~Robert_Mahari1",
            "~Naana_Obeng-Marnu1",
            "~William_Brannon1",
            "~Tobin_South1",
            "~Katy_Ilonka_Gero1",
            "~Alex_Pentland1",
            "~Jad_Kabbara1"
        ],
        "abstract": "New capabilities in foundation models are owed in large part to massive, widely-sourced, and under-documented training data collections. Existing practices in data collection have led to challenges in tracing authenticity, verifying consent, preserving privacy, addressing representation and bias, respecting copyright, and overall developing ethical and trustworthy foundation models. In response, regulation is emphasizing the need for training data transparency to understand foundation models\u2019 limitations. Based on a large-scale analysis of the foundation model training data landscape and existing solutions, we identify the missing infrastructure to facilitate responsible foundation model development practices. We examine the current shortcomings of common tools for tracing data authenticity, consent, and documentation, and outline how policymakers, developers, and data creators can facilitate responsible foundation model development by adopting universal data provenance standards.",
        "_bibtex": "@inproceedings{\nlongpre2024position,\ntitle={Position: Data Authenticity, Consent, \\& Provenance for {AI} are all broken: what will it take to fix them?},\nauthor={Shayne Longpre and Robert Mahari and Naana Obeng-Marnu and William Brannon and Tobin South and Katy Ilonka Gero and Alex Pentland and Jad Kabbara},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=3hSTecKy1b}\n}"
    },
    {
        "title": "Representing Molecules as Random Walks Over Interpretable Grammars",
        "authorids": [
            "~Michael_Sun1",
            "~Minghao_Guo1",
            "~Weize_Yuan1",
            "~Veronika_Thost1",
            "~Crystal_Elaine_Owens1",
            "~Aristotle_Franklin_Grosz1",
            "~Sharvaa_Selvan1",
            "~Katelyn_Zhou1",
            "~Hassan_Mohiuddin1",
            "~Benjamin_J_Pedretti1",
            "zpsmith@mit.edu",
            "~Jie_Chen1",
            "~Wojciech_Matusik2"
        ],
        "abstract": "Recent research in molecular discovery has primarily been devoted to small, drug-like molecules, leaving many similarly important applications in material design without adequate technology. These applications often rely on more complex molecular structures with fewer examples that are carefully designed using known substructures. We propose a data-efficient and interpretable model for representing and reasoning over such molecules in terms of graph grammars that explicitly describe the hierarchical design space featuring motifs to be the design basis. We present a novel representation in the form of random walks over the design space, which facilitates both molecule generation and property prediction. We demonstrate clear advantages over existing methods in terms of performance, efficiency, and synthesizability of predicted molecules, and we provide detailed insights into the method's chemical interpretability.",
        "_bibtex": "@inproceedings{\nsun2024representing,\ntitle={Representing Molecules as Random Walks Over Interpretable Grammars},\nauthor={Michael Sun and Minghao Guo and Weize Yuan and Veronika Thost and Crystal Elaine Owens and Aristotle Franklin Grosz and Sharvaa Selvan and Katelyn Zhou and Hassan Mohiuddin and Benjamin J Pedretti and Zachary P Smith and Jie Chen and Wojciech Matusik},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=gS3nc9iUrH}\n}"
    },
    {
        "title": "Replicable Learning of Large-Margin Halfspaces",
        "authorids": [
            "~Alkis_Kalavasis1",
            "~Amin_Karbasi3",
            "~Kasper_Green_Larsen1",
            "~Grigoris_Velegkas1",
            "~Felix_Zhou1"
        ],
        "abstract": "We provide an efficient replicable algorithm for the problem of learning large-margin halfspaces. Our results improve upon the algorithms provided by Impagliazzo, Lei, Pitassi, and Sorrell (STOC, 2022). We design the first dimension-independent replicable algorithm for this task which runs in polynomial time, is proper, and has strictly improved sample complexity compared to the one achieved by Impagliazzo et al. (STOC, 2022) with respect to all the relevant parameters. Moreover, our algorithm has sample complexity that is optimal with respect to the accuracy parameter $\\epsilon$. Departing from the requirement of polynomial time algorithms, using the DP-to-Replicability reduction of Bun et al. (STOC 2023), we show how to obtain a replicable algorithm for large-margin halfspaces with improved sample complexity with respect to the margin parameter $\\tau$, but running time doubly exponential in $1/\\tau^2$ and worse sample complexity dependence on $\\epsilon$ than our previous algorithm. We then design an improved algorithm with better sample complexity than both of our previous algorithms and running time exponential in $1/\\tau^{2}.$",
        "_bibtex": "@inproceedings{\nkalavasis2024replicable,\ntitle={Replicable Learning of Large-Margin Halfspaces},\nauthor={Alkis Kalavasis and Amin Karbasi and Kasper Green Larsen and Grigoris Velegkas and Felix Zhou},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=CKCzfU9YKE}\n}"
    },
    {
        "title": "Transport of Algebraic Structure to Latent Embeddings",
        "authorids": [
            "~Samuel_Pfrommer1",
            "~Brendon_G._Anderson1",
            "~Somayeh_Sojoudi1"
        ],
        "abstract": "Machine learning often aims to produce latent embeddings of inputs which lie in a larger, abstract mathematical space. For example, in the field of 3D modeling, subsets of Euclidean space can be embedded as vectors using implicit neural representations. Such subsets also have a natural algebraic structure including operations (e.g., union) and corresponding laws (e.g., associativity). How can we learn to \"union\" two sets using only their latent embeddings while respecting associativity? We propose a general procedure for parameterizing latent space operations that are provably consistent with the laws on the input space. This is achieved by learning a bijection from the latent space to a carefully designed *mirrored algebra* which is constructed on Euclidean space in accordance with desired laws. We evaluate these *structural transport nets* for a range of mirrored algebras against baselines that operate directly on the latent space. Our experiments provide strong evidence that respecting the underlying algebraic structure of the input space is key for learning accurate and self-consistent operations.",
        "_bibtex": "@inproceedings{\npfrommer2024transport,\ntitle={Transport of Algebraic Structure to Latent Embeddings},\nauthor={Samuel Pfrommer and Brendon G. Anderson and Somayeh Sojoudi},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=rK6AZem0hX}\n}"
    },
    {
        "title": "Do Models Explain Themselves? Counterfactual Simulatability of Natural Language Explanations",
        "authorids": [
            "~Yanda_Chen1",
            "~Ruiqi_Zhong1",
            "~Narutatsu_Ri1",
            "~Chen_Zhao2",
            "~He_He2",
            "~Jacob_Steinhardt1",
            "~Zhou_Yu1",
            "~Kathleen_McKeown1"
        ],
        "abstract": "Large language models (LLMs) are trained to imitate humans to explain human decisions. However, do LLMs explain themselves? Can they help humans build mental models of how LLMs process different inputs? To answer these questions, we propose to evaluate $\\textbf{counterfactual simulatability}$ of natural language explanations: whether an explanation can enable humans to precisely infer the model's outputs on diverse counterfactuals of the explained input. For example, if a model answers ''$\\textit{yes}$'' to the input question ''$\\textit{Can eagles fly?}$'' with the explanation ''$\\textit{all birds can fly}$'', then humans would infer from the explanation that it would also answer ''$\\textit{yes}$'' to the counterfactual input ''$\\textit{Can penguins fly?}$''. If the explanation is precise, then the model's answer should match humans' expectations. We implemented two metrics based on counterfactual simulatability: precision and generality. We generated diverse counterfactuals automatically using LLMs. We then used these metrics to evaluate state-of-the-art LLMs (e.g., GPT-4) on two tasks: multi-hop factual reasoning and reward modeling. We found that LLM's explanations have low precision and that precision does not correlate with plausibility. Therefore, naively optimizing human approvals (e.g., RLHF) may be insufficient.",
        "_bibtex": "@inproceedings{\nchen2024do,\ntitle={Do Models Explain Themselves? Counterfactual Simulatability of Natural Language Explanations},\nauthor={Yanda Chen and Ruiqi Zhong and Narutatsu Ri and Chen Zhao and He He and Jacob Steinhardt and Zhou Yu and Kathleen McKeown},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=99jx5U81jx}\n}"
    },
    {
        "title": "Harnessing the Power of Neural Operators with Automatically Encoded Conservation Laws",
        "authorids": [
            "~Ning_Liu6",
            "~Yiming_Fan1",
            "~Xianyi_Zeng1",
            "~Milan_Kl\u00f6wer1",
            "~LU_ZHANG18",
            "~Yue_Yu3"
        ],
        "abstract": "Neural operators (NOs) have emerged as effective tools for modeling complex physical systems in scientific machine learning. In NOs, a central characteristic is to learn the governing physical laws directly from data. In contrast to other machine learning applications, partial knowledge is often known a priori about the physical system at hand whereby quantities such as mass, energy and momentum are exactly conserved. Currently, NOs have to learn these conservation laws from data and can only approximately satisfy them due to finite training data and random noise. In this work, we introduce conservation law-encoded neural operators (clawNOs), a suite of NOs that endow inference with automatic satisfaction of such conservation laws. ClawNOs are built with a divergence-free prediction of the solution field, with which the continuity equation is automatically guaranteed. As a consequence, clawNOs are compliant with the most fundamental and ubiquitous conservation laws essential for correct physical consistency. As demonstrations, we consider a wide variety of scientific applications ranging from constitutive modeling of material deformation, incompressible fluid dynamics, to atmospheric simulation. ClawNOs significantly outperform the state-of-the-art NOs in learning efficacy, especially in small-data regimes.",
        "_bibtex": "@inproceedings{\nliu2024harnessing,\ntitle={Harnessing the Power of Neural Operators with Automatically Encoded Conservation Laws},\nauthor={Ning Liu and Yiming Fan and Xianyi Zeng and Milan Kl{\\\"o}wer and LU ZHANG and Yue Yu},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=ToHkAg936Y}\n}"
    },
    {
        "title": "Stochastic Localization via Iterative Posterior Sampling",
        "authorids": [
            "~Louis_Grenioux1",
            "~Maxence_Noble1",
            "~Marylou_Gabri\u00e91",
            "~Alain_Oliviero_Durmus1"
        ],
        "abstract": "Building upon score-based learning, new interest in stochastic localization techniques has recently emerged. In these models, one seeks to noise a sample from the data distribution through a stochastic process, called observation process, and progressively learns a denoiser associated to this dynamics. Apart from specific applications, the use of stochastic localization for the problem of sampling from an unnormalized target density has not been explored extensively. This work contributes to fill this gap. We consider a general stochastic localization framework and introduce an explicit class of observation processes, associated with flexible denoising schedules. We provide a complete methodology, *Stochastic Localization via Iterative Posterior Sampling* (**SLIPS**), to obtain approximate samples of these dynamics, and as a by-product, samples from the target distribution. Our scheme is based on a Markov chain Monte Carlo estimation of the denoiser and comes with detailed practical guidelines. We illustrate the benefits and applicability of **SLIPS** on several benchmarks of multi-modal distributions, including Gaussian mixtures in increasing dimensions, Bayesian logistic regression and a high-dimensional field system from statistical-mechanics.",
        "_bibtex": "@inproceedings{\ngrenioux2024stochastic,\ntitle={Stochastic Localization via Iterative Posterior Sampling},\nauthor={Louis Grenioux and Maxence Noble and Marylou Gabri{\\'e} and Alain Oliviero Durmus},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=2Gr5wZR6uc}\n}"
    },
    {
        "title": "On a Neural Implementation of Brenier's Polar Factorization",
        "authorids": [
            "~Nina_Vesseron1",
            "~marco_cuturi2"
        ],
        "abstract": "In 1991, Brenier proved a theorem that generalizes the polar decomposition for square matrices -- factored as PSD $\\times$ unitary -- to any vector field $F:\\mathbb{R}^d\\rightarrow \\mathbb{R}^d$. The theorem, known as the polar factorization theorem, states that any field $F$ can be recovered as the composition of the gradient of a convex function $u$ with a measure-preserving map $M$, namely $F=\\nabla u \\circ M$. We propose a practical implementation of this far-reaching theoretical result, and explore possible uses within machine learning. The theorem is closely related to optimal transport (OT) theory, and we borrow from recent advances in the field of neural optimal transport to parameterize the potential $u$ as an input convex neural network. The map $M$ can be either evaluated pointwise using $u^*$, the convex conjugate of $u$, through the identity $M=\\nabla u^* \\circ F$, or learned as an auxiliary network. Because $M$ is, in general, not injective, we consider the additional task of estimating the ill-posed inverse map that can approximate the pre-image measure $M^{-1}$ using a stochastic generator. We illustrate possible applications of Brenier's polar factorization to non-convex optimization problems, as well as sampling of densities that are not log-concave.",
        "_bibtex": "@inproceedings{\nvesseron2024on,\ntitle={On a Neural Implementation of Brenier's Polar Factorization},\nauthor={Nina Vesseron and marco cuturi},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=zDCwJQY3eI}\n}"
    },
    {
        "title": "Position: Reinforcement Learning in Dynamic Treatment Regimes Needs Critical Reexamination",
        "authorids": [
            "~Zhiyao_Luo1",
            "~Yangchen_Pan2",
            "~Peter_Watkinson1",
            "~Tingting_Zhu1"
        ],
        "abstract": "In the rapidly changing healthcare landscape, the implementation of offline reinforcement learning (RL) in dynamic treatment regimes (DTRs) presents a mix of unprecedented opportunities and challenges. This position paper offers a critical examination of the current status of offline RL in the context of DTRs. We argue for a reassessment of applying RL in DTRs, citing concerns such as inconsistent and potentially inconclusive evaluation metrics, the absence of naive and supervised learning baselines, and the diverse choice of RL formulation in existing research. Through a case study with more than 17,000 evaluation experiments using a publicly available Sepsis dataset, we demonstrate that the performance of RL algorithms can significantly vary with changes in evaluation metrics and Markov Decision Process (MDP) formulations. Surprisingly, it is observed that in some instances, RL algorithms can be surpassed by random baselines subjected to policy evaluation methods and reward design. This calls for more careful policy evaluation and algorithm development in future DTR works. Additionally, we discussed potential enhancements toward more reliable development of RL-based dynamic treatment regimes and invited further discussion within the community. Code is available at https://github.com/GilesLuo/ReassessDTR.",
        "_bibtex": "@inproceedings{\nluo2024position,\ntitle={Position: Reinforcement Learning in Dynamic Treatment Regimes Needs Critical Reexamination},\nauthor={Zhiyao Luo and Yangchen Pan and Peter Watkinson and Tingting Zhu},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=xtKWwB6lzT}\n}"
    },
    {
        "title": "Decoding-time Realignment of Language Models",
        "authorids": [
            "~Tianlin_Liu2",
            "~Shangmin_Guo1",
            "leonardo.martins-bianco@universite-paris-saclay.fr",
            "~Daniele_Calandriello1",
            "~Quentin_Berthet2",
            "~Felipe_Llinares-L\u00f3pez1",
            "~Jessica_Hoffmann1",
            "~Lucas_Dixon1",
            "~Michal_Valko1",
            "~Mathieu_Blondel1"
        ],
        "abstract": "Aligning language models with human preferences is crucial for reducing errors and biases in these models. Alignment techniques, such as reinforcement learning from human feedback (RLHF), are typically cast as optimizing a tradeoff between human preference rewards and a proximity regularization term that encourages staying close to the unaligned model. Selecting an appropriate level of regularization is critical: insufficient regularization can lead to reduced model capabilities due to reward hacking, whereas excessive regularization hinders alignment. Traditional methods for finding the optimal regularization level require retraining multiple models with varying regularization strengths. This process, however, is resource-intensive, especially for large models. To address this challenge, we propose decoding-time realignment (DeRa), a simple method to explore and evaluate different regularization strengths in aligned models without retraining. DeRa enables control over the degree of alignment, allowing users to smoothly transition between unaligned and aligned models. It also enhances the efficiency of hyperparameter tuning by enabling the identification of effective regularization strengths using a validation dataset.",
        "_bibtex": "@inproceedings{\nliu2024decodingtime,\ntitle={Decoding-time Realignment of Language Models},\nauthor={Tianlin Liu and Shangmin Guo and Leonardo Bianco and Daniele Calandriello and Quentin Berthet and Felipe Llinares-L{\\'o}pez and Jessica Hoffmann and Lucas Dixon and Michal Valko and Mathieu Blondel},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=n8g6WMxt09}\n}"
    },
    {
        "title": "Predictive Linear Online Tracking for Unknown Targets",
        "authorids": [
            "~Anastasios_Tsiamis1",
            "~Aren_Karapetyan1",
            "yuesli@student.ethz.ch",
            "~Efe_C._Balta1",
            "~John_Lygeros1"
        ],
        "abstract": "In this paper, we study the problem of online tracking in linear control systems, where the objective is to follow a moving target. Unlike classical tracking control, the target is unknown, non-stationary, and its state is revealed sequentially, thus, fitting the framework of online non-stochastic control. We consider the case of quadratic costs and propose a new algorithm, called predictive linear online tracking (PLOT). The algorithm uses recursive least squares with exponential forgetting to learn a time-varying dynamic model of the target. The learned model is used in the optimal policy under the framework of receding horizon control. We show the dynamic regret of PLOT scales with $\\mathcal{O}(\\sqrt{TV_T})$, where $V_T$ is the total variation of the target dynamics and $T$ is the time horizon. Unlike prior work, our theoretical results hold for non-stationary targets. We implement our online control algorithm on a real quadrotor, thus, showcasing one of the first successful applications of online control methods on real hardware.",
        "_bibtex": "@inproceedings{\ntsiamis2024predictive,\ntitle={Predictive Linear Online Tracking for Unknown Targets},\nauthor={Anastasios Tsiamis and Aren Karapetyan and Yueshan Li and Efe C. Balta and John Lygeros},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=lT3W4AkyM7}\n}"
    },
    {
        "title": "Perturb-and-Project: Differentially Private Similarities and Marginals",
        "authorids": [
            "~Vincent_Cohen-Addad1",
            "~Tommaso_d'Orsi1",
            "~Alessandro_Epasto3",
            "~Vahab_Mirrokni2",
            "~Peilin_Zhong1"
        ],
        "abstract": "We revisit the objective perturbations framework for differential privacy where noise is added to the input $A\\in \\mathcal{S}$ and the result is then projected back to the space of admissible datasets $\\mathcal{S}$. Through this framework, we first design novel efficient algorithms to privately release pair-wise cosine similarities. Second, we derive a novel algorithm to compute $k$-way marginal queries over $n$ features. Prior work could achieve comparable guarantees only for $k$ even. Furthermore, we extend our results to $t$-sparse datasets, where our efficient algorithms yields novel, stronger guarantees whenever $t\\le n^{5/6}/\\log n.$ Finally, we provide a theoretical perspective on why *fast* input perturbation algorithms works well in practice. The key technical ingredients behind our results are tight sum-of-squares certificates upper bounding the Gaussian complexity of sets of solutions.",
        "_bibtex": "@inproceedings{\ncohen-addad2024perturbandproject,\ntitle={Perturb-and-Project: Differentially Private Similarities and Marginals},\nauthor={Vincent Cohen-Addad and Tommaso d'Orsi and Alessandro Epasto and Vahab Mirrokni and Peilin Zhong},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=45HNimd4YI}\n}"
    },
    {
        "title": "Promoting External and Internal Equities Under Ex-Ante/Ex-Post Metrics in Online Resource Allocation",
        "authorids": [
            "~Karthik_Abinav_Sankararaman1",
            "~Aravind_Srinivasan1",
            "~Pan_Xu2"
        ],
        "abstract": "This paper proposes two different models for equitable resource allocation in online settings. The first one is called *external* equity promotion, where sequentially arriving agents are heterogeneous in their external attributes, namely how many resources they demand, which are drawn from a probability distribution (accessible to the algorithm). The focus is then to devise an allocation policy such that every requester can get a fair share of resources *proportional to their demands*, regardless of their arrival time. The second is called *internal* equity promotion, where arriving requesters can be treated homogeneously in external attributes (demands) but are heterogeneous in internal traits such as demographics. In particular, each requester can be identified as belonging to one or several groups, and an allocation of resources is regarded as equitable when every group of requesters can receive a fair share of resources proportional to the percentage of that group in the whole population. For both models above, we consider as the benchmark a clairvoyant optimal solution that has the privilege to access all random demand realizations in advance. We consider two equity metrics, namely *ex-post* and *ex-ante*, and discuss the challenges under the two metrics in detail. Specifically, we present two linear program (LP)-based policies for external equity promotion under ex-ante with independent demands, each achieving an *optimal* CR of $1/2$ with respect to the benchmark LP. For internal equity promotion, we present optimal policies under both ex-ante and ex-post metrics.",
        "_bibtex": "@inproceedings{\nsankararaman2024promoting,\ntitle={Promoting External and Internal Equities Under Ex-Ante/Ex-Post Metrics in Online Resource Allocation},\nauthor={Karthik Abinav Sankararaman and Aravind Srinivasan and Pan Xu},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=1OsRSrkFWl}\n}"
    },
    {
        "title": "LIDAO: Towards Limited Interventions for Debiasing (Large) Language Models",
        "authorids": [
            "~Tianci_Liu1",
            "~Haoyu_Wang6",
            "wang5348@purdue.edu",
            "~Yu_Cheng1",
            "~Jing_Gao2"
        ],
        "abstract": "Large language models (LLMs) have achieved impressive performance on various natural language generation tasks. Nonetheless, they suffer from generating negative and harmful contents that are biased against certain demographic groups (e.g., female), raising severe fairness concerns. As remedies, prior works intervened the generation by removing attitude or demographic information, inevitably degrading the generation quality and resulting in notable *fairness-fluency* trade-offs. However, it is still under-explored to what extent the fluency *has to* be affected in order to achieve a desired level of fairness. In this work, we conduct the first formal study from an information-theoretic perspective. We show that previous approaches are excessive for debiasing and propose LIDAO, a general framework to debias a (L)LM at a better fluency provably. We further robustify LIDAO in adversarial scenarios, where a carefully-crafted prompt may stimulate LLMs exhibiting instruction-following abilities to generate texts with fairness issue appears only when the prompt is also taken into account. Experiments on three LMs ranging from 0.7B to 7B parameters demonstrate the superiority of our method.",
        "_bibtex": "@inproceedings{\nliu2024lidao,\ntitle={{LIDAO}: Towards Limited Interventions for Debiasing (Large) Language Models},\nauthor={Tianci Liu and Haoyu Wang and Shiyang Wang and Yu Cheng and Jing Gao},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=NsHxeSCtgr}\n}"
    },
    {
        "title": "Robust and Conjugate Gaussian Process Regression",
        "authorids": [
            "~Matias_Altamirano2",
            "~Francois-Xavier_Briol1",
            "~Jeremias_Knoblauch1"
        ],
        "abstract": "To enable closed form conditioning, a common assumption in Gaussian process (GP) regression is independent and identically distributed Gaussian observation noise. This strong and simplistic assumption is often violated in practice, which leads to unreliable inferences and uncertainty quantification. Unfortunately, existing methods for robustifying GPs break closed-form conditioning, which makes them less attractive to practitioners and significantly more computationally expensive. In this paper, we demonstrate how to perform provably robust and conjugate Gaussian process (RCGP) regression at virtually no additional cost using generalised Bayesian inference. RCGP is particularly versatile as it enables exact conjugate closed form updates in all settings where standard GPs admit them. To demonstrate its strong empirical performance, we deploy RCGP for problems ranging from Bayesian optimisation to sparse variational Gaussian processes.",
        "_bibtex": "@inproceedings{\naltamirano2024robust,\ntitle={Robust and Conjugate Gaussian Process Regression},\nauthor={Matias Altamirano and Francois-Xavier Briol and Jeremias Knoblauch},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=5WnKLIAX4q}\n}"
    },
    {
        "title": "DsDm: Model-Aware Dataset Selection with Datamodels",
        "authorids": [
            "~Logan_Engstrom1"
        ],
        "abstract": "When selecting data for training large-scale models, standard practice is to filter for examples that match human notions of data quality. Such filtering yields qualitatively clean datapoints that intuitively should improve model behavior. However, in practice the opposite can often happen: we find that selecting according to similarity with \"high quality\" data sources may not increase (and can even hurt) performance compared to randomly selecting data. To develop better methods for selecting data, we start by framing dataset selection as an optimization problem that we can directly solve for: given target tasks, a learning algorithm, and candidate data, select the subset that maximizes model performance. This framework thus avoids handpicked notions of data quality, and instead models explicitly how the learning process uses train datapoints to predict on the target tasks. Our resulting method greatly improves language model (LM) performance on both pre-specified tasks and previously unseen tasks. Specifically, choosing target tasks representative of standard LM problems and evaluating on diverse held-out benchmarks, our selected datasets provide a 2x compute multiplier over baseline methods.",
        "_bibtex": "@inproceedings{\nengstrom2024dsdm,\ntitle={DsDm: Dataset Selection with Datamodels},\nauthor={Logan Engstrom},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=GC8HkKeH8s}\n}"
    },
    {
        "title": "LLM Maybe LongLM: SelfExtend LLM Context Window Without Tuning",
        "authorids": [
            "~Hongye_Jin1",
            "~Xiaotian_Han1",
            "~Jingfeng_Yang2",
            "~Zhimeng_Jiang1",
            "~Zirui_Liu1",
            "~Chia-Yuan_Chang3",
            "~Huiyuan_Chen1",
            "~Xia_Hu4"
        ],
        "abstract": "It is well known that LLMs cannot generalize well to long contexts whose lengths are larger than the training sequence length. This poses challenges when employing LLMs for processing long input sequences during inference. In this work, we argue that LLMs themselves have inherent capabilities to handles s long contexts without fine-tuning. To achieve this goal, we propose SelfExtend to extend the context window of LLMs by constructing bi-level attention information: the grouped attention and the neighbor attention. The grouped attention captures the dependencies among tokens that are far apart, while neighbor attention captures dependencies among adjacent tokens within a specified range. The two-level attentions are computed based on the original model's self-attention mechanism during inference. With minor code modification, our SelfExtend can effortlessly extend existing LLMs' context window without any fine-tuning. We conduct comprehensive experiments on multiple benchmarks and the results show that our SelfExtend can effectively extend existing LLMs' context window length.",
        "_bibtex": "@inproceedings{\njin2024llm,\ntitle={{LLM} Maybe Long{LM}: SelfExtend {LLM} Context Window Without Tuning},\nauthor={Hongye Jin and Xiaotian Han and Jingfeng Yang and Zhimeng Jiang and Zirui Liu and Chia-Yuan Chang and Huiyuan Chen and Xia Hu},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=nkOMLBIiI7}\n}"
    },
    {
        "title": "Block Acceleration Without Momentum: On Optimal Stepsizes of Block Gradient Descent for Least-Squares",
        "authorids": [
            "~Liangzu_Peng2",
            "~Wotao_Yin1"
        ],
        "abstract": "Block coordinate descent is a powerful algorithmic template suitable for big data optimization. This template admits a lot of variants including block gradient descent (BGD), which performs gradient descent on a selected block of variables, while keeping other variables fixed. For a very long time, the stepsize for each block has tacitly been set to one divided by the block-wise Lipschitz smoothness constant, imitating the vanilla stepsize rule for gradient descent (GD). However, such a choice for BGD has not yet been able to theoretically justify its empirical superiority over GD, as existing convergence rates for BGD have worse constants than GD in the deterministic cases. To discover such theoretical justification, we set up a simple environment where we consider BGD applied to least-squares with two blocks of variables. Assuming the data matrix corresponding to each block is orthogonal, we find optimal stepsizes of BGD in closed form, which provably lead to asymptotic convergence rates twice as fast as GD with Polyak's momentum; this means, under that orthogonality assumption, one can accelerate BGD by just tuning stepsizes and without adding any momentum. An application that satisfies this assumption is *generalized alternating projection* between two subspaces, and applying our stepsizes to it improves the prior convergence rate that was once claimed, slightly inaccurately, to be optimal. The main proof idea is to minimize, in stepsize variables, the spectral radius of a matrix that controls convergence rates.",
        "_bibtex": "@inproceedings{\npeng2024block,\ntitle={Block Acceleration Without Momentum: On Optimal Stepsizes of Block Gradient Descent for Least-Squares},\nauthor={Liangzu Peng and Wotao Yin},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=iLyUEPZ0fR}\n}"
    },
    {
        "title": "Local vs. Global Interpretability: A Computational Complexity Perspective",
        "authorids": [
            "~Shahaf_Bassan1",
            "~Guy_Amir1",
            "~Guy_Katz1"
        ],
        "abstract": "The local and global interpretability of various ML models has been studied extensively in recent years. However, despite significant progress in the field, many known results remain informal or lack sufficient mathematical rigor. We propose a framework for bridging this gap, by using computational complexity theory to assess local and global perspectives of interpreting ML models. We begin by proposing proofs for two novel insights that are essential for our analysis: (1) a duality between local and global forms of explanations; and (2) the inherent uniqueness of certain global explanation forms. We then use these insights to evaluate the complexity of computing explanations, across three model types representing the extremes of the interpretability spectrum: (1) linear models; (2) decision trees; and (3) neural networks. Our findings offer insights into both the local and global interpretability of these models. For instance, under standard complexity assumptions such as P != NP, we prove that selecting *global* sufficient subsets in linear models is computationally harder than selecting *local* subsets. Interestingly, with neural networks and decision trees, the opposite is true: it is harder to carry out this task locally than globally. We believe that our findings demonstrate how examining explainability through a computational complexity lens can help us develop a more rigorous grasp of the inherent interpretability of ML models.",
        "_bibtex": "@inproceedings{\nbassan2024local,\ntitle={Local vs. Global Interpretability: A Computational Complexity Perspective},\nauthor={Shahaf Bassan and Guy Amir and Guy Katz},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=veEjiN2w9F}\n}"
    },
    {
        "title": "ULAREF: A Unified Label Refinement Framework for Learning with Inaccurate Supervision",
        "authorids": [
            "~Congyu_Qiao3",
            "~Ning_Xu5",
            "~Yihao_Hu2",
            "~Xin_Geng1"
        ],
        "abstract": "Learning with inaccurate supervision is often encountered in weakly supervised learning, and researchers have invested a considerable amount of time and effort in designing specialized algorithms for different forms of annotations in inaccurate supervision. In fact, different forms of these annotations share the fundamental characteristic that they all still incorporate some portion of correct labeling information. This commonality can serve as a lever, enabling the creation of a cohesive framework designed to tackle the challenges associated with various forms of annotations in learning with inaccurate supervision. In this paper, we propose a unified label refinement framework named ULAREF, i.e., a Unified LAbel REfinement Framework for learning with inaccurate supervision, which is capable of leveraging label refinement to handle inaccurate supervision. Specifically, our framework trains the predictive model with refined labels through global detection of reliability and local enhancement using an enhanced model fine-tuned by a proposed consistency loss. Also, we theoretically justify that the enhanced model in local enhancement can achieve higher accuracy than the predictive model on the detected unreliable set under mild assumptions.",
        "_bibtex": "@inproceedings{\nqiao2024ularef,\ntitle={{ULAREF}: A Unified Label Refinement Framework for Learning with Inaccurate Supervision},\nauthor={Congyu Qiao and Ning Xu and Yihao Hu and Xin Geng},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=ssFMq35UUY}\n}"
    },
    {
        "title": "Learning Optimal Deterministic Policies with Stochastic Policy Gradients",
        "authorids": [
            "~Alessandro_Montenegro1",
            "~Marco_Mussi1",
            "~Alberto_Maria_Metelli2",
            "~Matteo_Papini1"
        ],
        "abstract": "Policy gradient (PG) methods are successful approaches to deal with continuous reinforcement learning (RL) problems. They learn stochastic parametric (hyper)policies by either exploring in the space of actions or in the space of parameters. Stochastic controllers, however, are often undesirable from a practical perspective because of their lack of robustness, safety, and traceability. In common practice, stochastic (hyper)policies are learned only to deploy their deterministic version. In this paper, we make a step towards the theoretical understanding of this practice. After introducing a novel framework for modeling this scenario, we study the global convergence to the best deterministic policy, under (weak) gradient domination assumptions. Then, we illustrate how to tune the exploration level used for learning to optimize the trade-off between the sample complexity and the performance of the deployed deterministic policy. Finally, we quantitatively compare action-based and parameter-based exploration, giving a formal guise to intuitive results.",
        "_bibtex": "@inproceedings{\nmontenegro2024learning,\ntitle={Learning Optimal Deterministic Policies with Stochastic Policy Gradients},\nauthor={Alessandro Montenegro and Marco Mussi and Alberto Maria Metelli and Matteo Papini},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=ABt0jlLZtX}\n}"
    },
    {
        "title": "A Geometric Decomposition of Finite Games: Convergence vs. Recurrence under Exponential Weights",
        "authorids": [
            "davide.legacci@univ-grenoble-alpes.fr",
            "~Panayotis_Mertikopoulos1",
            "~Bary_Pradelski1"
        ],
        "abstract": "In view of the complexity of the dynamics of learning in games, we seek to decompose a game into simpler components where the dynamics' long-run behavior is well understood. A natural starting point for this is Helmholtz's theorem, which decomposes a vector field into a potential and an incompressible component. However, the geometry of game dynamics - and, in particular, the dynamics of exponential / multiplicative weights (EW) schemes - is not compatible with the Euclidean underpinnings of Helmholtz's theorem. This leads us to consider a specific Riemannian framework based on the so-called *Shahshahani metric*, and introduce the class of *incompressible games*, for which we establish the following results: First, in addition to being volume-preserving, the continuous-time EW dynamics in incompressible games admit a constant of motion and are *Poincar\u00e9 recurrent* - i.e., almost every trajectory of play comes arbitrarily close to its starting point infinitely often. Second, we establish a deep connection with a well-known decomposition of games into a potential and harmonic component (where the players' objectives are aligned and anti-aligned respectively): a game is incompressible if and only if it is harmonic, implying in turn that the EW dynamics lead to Poincar\u00e9 recurrence in harmonic games.",
        "_bibtex": "@inproceedings{\nlegacci2024a,\ntitle={A Geometric Decomposition of Finite Games: Convergence vs. Recurrence under Exponential Weights},\nauthor={Davide Legacci and Panayotis Mertikopoulos and Bary Pradelski},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=7RSIGQRT1F}\n}"
    },
    {
        "title": "Target Networks and Over-parameterization Stabilize Off-policy Bootstrapping with Function Approximation",
        "authorids": [
            "~Fengdi_Che1",
            "~Chenjun_Xiao1",
            "~Jincheng_Mei1",
            "~Bo_Dai1",
            "~Ramki_Gummadi1",
            "~Oscar_A_Ramirez1",
            "~Christopher_K_Harris1",
            "~A._Rupam_Mahmood1",
            "~Dale_Schuurmans1"
        ],
        "abstract": "We prove that the combination of a target network and over-parameterized linear function approximation establishes a weaker convergence condition for bootstrapped value estimation in certain cases, even with off-policy data. Our condition is naturally satisfied for expected updates over the entire state-action space or learning with a batch of complete trajectories from episodic Markov decision processes. Notably, using only a target network or an over-parameterized model does not provide such a convergence guarantee. Additionally, we extend our results to learning with truncated trajectories, showing that convergence is achievable for all tasks with minor modifications, akin to value truncation for the final states in trajectories. Our primary result focuses on temporal difference estimation for prediction, providing high-probability value estimation error bounds and empirical analysis on Baird's counterexample and a Four-room task. Furthermore, we explore the control setting, demonstrating that similar convergence conditions apply to Q-learning.",
        "_bibtex": "@inproceedings{\nche2024target,\ntitle={Target Networks and Over-parameterization Stabilize Off-policy Bootstrapping with Function Approximation},\nauthor={Fengdi Che and Chenjun Xiao and Jincheng Mei and Bo Dai and Ramki Gummadi and Oscar A Ramirez and Christopher K Harris and A. Rupam Mahmood and Dale Schuurmans},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=R6GT1UDcOW}\n}"
    },
    {
        "title": "What needs to go right for an induction head? A mechanistic study of in-context learning circuits and their formation",
        "authorids": [
            "~Aaditya_K_Singh1",
            "~Ted_Moskovitz1",
            "~Felix_Hill1",
            "~Stephanie_C.Y._Chan1",
            "~Andrew_M_Saxe1"
        ],
        "abstract": "In-context learning is a powerful emergent ability in transformer models. Prior work in mechanistic interpretability has identified a circuit element that may be critical for in-context learning \u2013 the induction head (IH), which performs a match-and-copy operation. During training of large transformers on natural language data, IHs emerge around the same time as a notable phase change in the loss. Despite the robust evidence for IHs and this interesting coincidence with the phase change, relatively little is known about the diversity and emergence dynamics of IHs. Why is there more than one IH, and how are they dependent on each other? Why do IHs appear all of a sudden, and what are the subcircuits that enable them to emerge? We answer these questions by studying IH emergence dynamics in a controlled setting by training on synthetic data. In doing so, we develop and share a novel optogenetics-inspired causal framework for modifying activations throughout training. Using this framework, we delineate the diverse and additive nature of IHs. By \"clamping\" subsets of activations throughout training, we then identify three underlying subcircuits that interact to drive IH formation, yielding the phase change. Furthermore, these subcircuits shed light on data-dependent properties of formation, such as phase change timing, already showing the promise of this more in-depth understanding of subcircuits that need to \"go right\" for an induction head.",
        "_bibtex": "@inproceedings{\nsingh2024what,\ntitle={What needs to go right for an induction head? A mechanistic study of in-context learning circuits and their formation},\nauthor={Aaditya K Singh and Ted Moskovitz and Felix Hill and Stephanie C.Y. Chan and Andrew M Saxe},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=O8rrXl71D5}\n}"
    },
    {
        "title": "Pairwise Alignment Improves Graph Domain Adaptation",
        "authorids": [
            "~Shikun_Liu3",
            "~Deyu_Zou1",
            "~Han_Zhao1",
            "~Pan_Li2"
        ],
        "abstract": "Graph-based methods, pivotal for label inference over interconnected objects in many real-world applications, often encounter generalization challenges, if the graph used for model training differs significantly from the graph used for testing. This work delves into Graph Domain Adaptation (GDA) to address the unique complexities of distribution shifts over graph data, where interconnected data points experience shifts in features, labels, and in particular, connecting patterns. We propose a novel, theoretically principled method, Pairwise Alignment (Pair-Align) to counter graph structure shift by mitigating conditional structure shift (CSS) and label shift (LS). Pair-Align uses edge weights to recalibrate the influence among neighboring nodes to handle CSS and adjusts the classification loss with label weights to handle LS. Our method demonstrates superior performance in real-world applications, including node classification with region shift in social networks, and the pileup mitigation task in particle colliding experiments. For the first application, we also curate the largest dataset by far for GDA studies. Our method shows strong performance in synthetic and other existing benchmark datasets.",
        "_bibtex": "@inproceedings{\nliu2024pairwise,\ntitle={Pairwise Alignment Improves Graph Domain Adaptation},\nauthor={Shikun Liu and Deyu Zou and Han Zhao and Pan Li},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=ttnbM598vZ}\n}"
    },
    {
        "title": "Estimating Unknown Population Sizes Using the Hypergeometric Distribution",
        "authorids": [
            "~Liam_Hodgson1",
            "~Danilo_Bzdok2"
        ],
        "abstract": "The multivariate hypergeometric distribution describes sampling without replacement from a discrete population of elements divided into multiple categories. Addressing a gap in the literature, we tackle the challenge of estimating discrete distributions when both the total population size and the category sizes are unknown. Here, we propose a novel solution using the hypergeometric likelihood to solve this estimation problem, even in the presence of severe under-sampling. Our approach accounts for a data generating process where the ground-truth is a mixture of distributions conditional on a continuous latent variable, as seen in collaborative filtering, using the variational autoencoder framework. Empirical data simulation demonstrates that our method outperforms other likelihood functions used to model count data, both in terms of accuracy of population size estimate and learning an informative latent space. We showcase our method's versatility through applications in NLP, by inferring and estimating the complexity of latent vocabularies in reading passage excerpts, and in biology, by accurately recovering the true number of gene transcripts from sparse single-cell genomics data.",
        "_bibtex": "@inproceedings{\nhodgson2024estimating,\ntitle={Estimating Unknown Population Sizes Using the Hypergeometric Distribution},\nauthor={Liam Hodgson and Danilo Bzdok},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=qE4nkfyMYl}\n}"
    },
    {
        "title": "Beyond the Norms: Detecting Prediction Errors in Regression Models",
        "authorids": [
            "~Andres_Altieri1",
            "~Marco_Romanelli1",
            "~Georg_Pichler1",
            "~Florence_Alberge1",
            "~Pablo_Piantanida2"
        ],
        "abstract": "This paper tackles the challenge of detecting unreliable behavior in regression algorithms, which may arise from intrinsic variability (e.g., aleatoric uncertainty) or modeling errors (e.g., model uncertainty). First, we formally introduce the notion of unreliability in regression, i.e., when the output of the regressor exceeds a specified discrepancy (or error). Then, using powerful tools for probabilistic modeling, we estimate the discrepancy density, and we measure its statistical diversity using our proposed metric for statistical dissimilarity. In turn, this allows us to derive a data-driven score that expresses the uncertainty of the regression outcome. We show empirical improvements in error detection for multiple regression tasks, consistently outperforming popular baseline approaches, and contributing to the broader field of uncertainty quantification and safe machine learning systems.",
        "_bibtex": "@inproceedings{\naltieri2024beyond,\ntitle={Beyond the Norms: Detecting Prediction Errors in Regression Models},\nauthor={Andres Altieri and Marco Romanelli and Georg Pichler and Florence Alberge and Pablo Piantanida},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=YqIIhl2ToH}\n}"
    },
    {
        "title": "Memory Consolidation Enables Long-Context Video Understanding",
        "authorids": [
            "~Ivana_Balazevic1",
            "~Yuge_Shi2",
            "~Pinelopi_Papalampidi1",
            "~Rahma_Chaabouni1",
            "~Skanda_Koppula1",
            "~Olivier_J_Henaff1"
        ],
        "abstract": "Most transformer-based video encoders are limited to short temporal contexts due to their quadratic complexity. While various attempts have been made to extend this context, this has often come at the cost of both conceptual and computational complexity. We propose to instead re-purpose existing pre-trained video transformers by simply fine-tuning them to attend to memories derived non-parametrically from past activations. By leveraging redundancy reduction, our memory-consolidated vision transformer (MC-ViT) effortlessly extends its context far into the past and exhibits excellent scaling behavior when learning from longer videos. In doing so, MC-ViT sets a new state-of-the-art in long-context video understanding on EgoSchema, Perception Test, and Diving48, outperforming methods that benefit from orders of magnitude more parameters.",
        "_bibtex": "@inproceedings{\nbalazevic2024memory,\ntitle={Memory Consolidation Enables Long-Context Video Understanding},\nauthor={Ivana Balazevic and Yuge Shi and Pinelopi Papalampidi and Rahma Chaabouni and Skanda Koppula and Olivier J Henaff},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=qeFgvVVAJ2}\n}"
    },
    {
        "title": "Re-Dock: Towards Flexible and Realistic Molecular Docking with Diffusion Bridge",
        "authorids": [
            "~Yufei_Huang4",
            "~Odin_Zhang1",
            "~Lirong_Wu1",
            "~Cheng_Tan1",
            "~Haitao_Lin2",
            "~Zhangyang_Gao1",
            "~Siyuan_Li6",
            "~Stan_Z._Li2"
        ],
        "abstract": "Accurate prediction of protein-ligand binding structures, a task known as molecular docking is crucial for drug design but remains challenging. While deep learning has shown promise, existing methods often depend on holo-protein structures (docked, and not accessible in realistic tasks) or neglect pocket sidechain conformations, leading to limited practical utility and unrealistic conformation predictions. To fill these gaps, we introduce an under-explored task, named flexible docking to predict poses of ligand and pocket sidechains simultaneously and introduce Re-Dock, a novel diffusion bridge generative model extended to geometric manifolds. Specifically, we propose energy-to-geometry mapping inspired by the Newton-Euler equation to co-model the binding energy and conformations for reflecting the energy-constrained docking generative process. Comprehensive experiments on designed benchmark datasets including apo-dock and cross-dock demonstrate our model's superior effectiveness and efficiency over current methods.",
        "_bibtex": "@inproceedings{\nhuang2024redock,\ntitle={Re-Dock: Towards Flexible and Realistic Molecular Docking with Diffusion Bridge},\nauthor={Yufei Huang and Odin Zhang and Lirong Wu and Cheng Tan and Haitao Lin and Zhangyang Gao and Siyuan Li and Stan Z. Li},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=QRjTDhCIO8}\n}"
    },
    {
        "title": "Position: Intent-aligned AI Systems Must Optimize for Agency Preservation",
        "authorids": [
            "~Catalin_Mitelut1",
            "benjsmith@gmail.com",
            "~Peter_Vamplew2"
        ],
        "abstract": "A central approach to AI-safety research has been to generate aligned AI systems: i.e. systems that do not deceive users and yield actions or recommendations that humans might judge as consistent with their intentions and goals. Here we argue that truthful AIs aligned solely to human intent are insufficient and that preservation of long-term agency of humans may be a more robust standard that may need to be separated and explicitly optimized for. We discuss the science of intent and control and how human intent can be manipulated and we provide a formal definition of agency-preserving AI-human interactions focusing on forward-looking explicit agency evaluations. Our work points to a novel pathway for human harm in AI-human interactions and proposes solutions to this challenge.",
        "_bibtex": "@inproceedings{\nmitelut2024position,\ntitle={Position: Intent-aligned {AI} Systems Must Optimize for Agency Preservation},\nauthor={Catalin Mitelut and Benjamin Smith and Peter Vamplew},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=rfvgdfd1K9}\n}"
    },
    {
        "title": "Fine-tuning Reinforcement Learning Models is Secretly a Forgetting Mitigation Problem",
        "authorids": [
            "~Maciej_Wolczyk1",
            "~Bart\u0142omiej_Cupia\u01421",
            "~Mateusz_Ostaszewski1",
            "~Micha\u0142_Bortkiewicz1",
            "~Micha\u0142_Zaj\u0105c1",
            "~Razvan_Pascanu1",
            "~\u0141ukasz_Kuci\u0144ski1",
            "~Piotr_Mi\u0142o\u015b1"
        ],
        "abstract": "Fine-tuning is a widespread technique that allows practitioners to transfer pre-trained capabilities, as recently showcased by the successful applications of foundation models. However, fine-tuning reinforcement learning (RL) models remains a challenge. This work conceptualizes one specific cause of poor transfer, accentuated in the RL setting by the interplay between actions and observations: *forgetting of pre-trained capabilities*. Namely, a model deteriorates on the state subspace of the downstream task not visited in the initial phase of fine-tuning, on which the model behaved well due to pre-training. This way, we lose the anticipated transfer benefits. We identify conditions when this problem occurs, showing that it is common and, in many cases, catastrophic. Through a detailed empirical analysis of the challenging NetHack and Montezuma's Revenge environments, we show that standard knowledge retention techniques mitigate the problem and thus allow us to take full advantage of the pre-trained capabilities. In particular, in NetHack, we achieve a new state-of-the-art for neural models, improving the previous best score from $5$K to over $10$K points in the Human Monk scenario.",
        "_bibtex": "@inproceedings{\nwolczyk2024finetuning,\ntitle={Fine-tuning Reinforcement Learning Models is Secretly a Forgetting Mitigation Problem},\nauthor={Maciej Wolczyk and Bart{\\l}omiej Cupia{\\l} and Mateusz Ostaszewski and Micha{\\l} Bortkiewicz and Micha{\\l} Zaj{\\k{a}}c and Razvan Pascanu and {\\L}ukasz Kuci{\\'n}ski and Piotr Mi{\\l}o{\\'s}},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=53iSXb1m8w}\n}"
    },
    {
        "title": "Learning with Partial-Label and Unlabeled Data: A Uniform Treatment for Supervision Redundancy and Insufficiency",
        "authorids": [
            "~Yangfan_Liu1",
            "~Jiaqi_Lv1",
            "~Xin_Geng1",
            "~Ning_Xu5"
        ],
        "abstract": "One major challenge in weakly supervised learning is learning from inexact supervision, ranging from partial labels (PLs) with *redundant* information to the extreme of unlabeled data with *insufficient* information. While recent work has made significant strides in specific inexact supervision contexts, supervision forms typically *coexist* in complex combinations. This is exemplified in *semi-supervised partial label learning*, where PLs act as the exclusive supervision in a semi-supervised setting. Current strategies addressing combined inexact scenarios are usually composite, which can lead to incremental solutions that essentially replicate existing methods. In this paper, we propose a novel approach to *uniformly* tackle both label redundancy and insufficiency, derived from a mutual information-based perspective. We design a label channel that facilitates dynamic label exchange within the candidate label sets, which identifies potential true labels and filters out likely incorrect ones, thereby minimizing error accumulation. Experimental results demonstrate the superiority of our method over existing state-of-the-art PL and semi-supervised learning approaches by directly integrating them. Furthermore, our extended experiments on partial-complementary label learning underscore the flexibility of our uniform treatment in managing diverse supervision scenarios.",
        "_bibtex": "@inproceedings{\nliu2024learning,\ntitle={Learning with Partial-Label and Unlabeled Data: A Uniform Treatment for Supervision Redundancy and Insufficiency},\nauthor={Yangfan Liu and Jiaqi Lv and Xin Geng and Ning Xu},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=LmzsgSDkWs}\n}"
    },
    {
        "title": "Truly No-Regret Learning in Constrained MDPs",
        "authorids": [
            "~Adrian_M\u00fcller2",
            "~Pragnya_Alatur1",
            "~Volkan_Cevher1",
            "~Giorgia_Ramponi1",
            "~Niao_He3"
        ],
        "abstract": "Constrained Markov decision processes (CMDPs) are a common way to model safety constraints in reinforcement learning. State-of-the-art methods for efficiently solving CMDPs are based on primal-dual algorithms. For these algorithms, all currently known regret bounds allow for *error cancellations* --- one can compensate for a constraint violation in one round with a strict constraint satisfaction in another. This makes the online learning process unsafe since it only guarantees safety for the final (mixture) policy but not during learning. As Efroni et al. (2020) pointed out, it is an open question whether primal-dual algorithms can provably achieve sublinear regret if we do not allow error cancellations. In this paper, we give the first affirmative answer. We first generalize a result on last-iterate convergence of regularized primal-dual schemes to CMDPs with multiple constraints. Building upon this insight, we propose a model-based primal-dual algorithm to learn in an unknown CMDP. We prove that our algorithm achieves sublinear regret without error cancellations.",
        "_bibtex": "@inproceedings{\nm{\\\"u}ller2024truly,\ntitle={Truly No-Regret Learning in Constrained {MDP}s},\nauthor={Adrian M{\\\"u}ller and Pragnya Alatur and Volkan Cevher and Giorgia Ramponi and Niao He},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=hrWte3nlzr}\n}"
    },
    {
        "title": "How Deep Networks Learn Sparse and Hierarchical Data: the Sparse Random Hierarchy Model",
        "authorids": [
            "~Umberto_Maria_Tomasini1",
            "~Matthieu_Wyart2"
        ],
        "abstract": "Understanding what makes high-dimensional data learnable is a fundamental question in machine learning. On the one hand, it is believed that the success of deep learning lies in its ability to build a hierarchy of representations that become increasingly more abstract with depth, going from simple features like edges to more complex concepts. On the other hand, learning to be insensitive to invariances of the task, such as smooth transformations for image datasets, has been argued to be important for deep networks and it strongly correlates with their performance. In this work, we aim to explain this correlation and unify these two viewpoints. We show that by introducing sparsity to generative hierarchical models of data, the task acquires insensitivity to spatial transformations that are discrete versions of smooth transformations. In particular, we introduce the Sparse Random Hierarchy Model (SRHM), where we observe and rationalize that a hierarchical representation mirroring the hierarchical model is learnt precisely when such insensitivity is learnt, thereby explaining the strong correlation between the latter and performance. Moreover, we quantify how the sample complexity of CNNs learning the SRHM depends on both the sparsity and hierarchical structure of the task.",
        "_bibtex": "@inproceedings{\ntomasini2024how,\ntitle={How Deep Networks Learn Sparse and Hierarchical Data: the Sparse Random Hierarchy Model},\nauthor={Umberto Maria Tomasini and Matthieu Wyart},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=CtEWswTjUd}\n}"
    },
    {
        "title": "Position: Mission Critical \u2013 Satellite Data is a Distinct Modality in Machine Learning",
        "authorids": [
            "~Esther_Rolf1",
            "~Konstantin_Klemmer1",
            "~Caleb_Robinson1",
            "~Hannah_Kerner1"
        ],
        "abstract": "Satellite data has the potential to inspire a seismic shift for machine learning---one in which we rethink existing practices designed for traditional data modalities. As machine learning for satellite data (SatML) gains traction for its real-world impact, our field is at a crossroads. We can either continue applying ill-suited approaches, or we can initiate a new research agenda that centers around the unique characteristics and challenges of satellite data. This position paper argues that satellite data constitutes a distinct modality for machine learning research and that we must recognize it as such to advance the quality and impact of SatML research across theory, methods, and deployment. We outline research directions, critical discussion questions and actionable suggestions to transform SatML from merely an intriguing application area to a dedicated research discipline that helps move the needle on big challenges for machine learning and society.",
        "_bibtex": "@inproceedings{\nrolf2024position,\ntitle={Position: Mission Critical {\\textendash} Satellite Data is a Distinct Modality in Machine Learning},\nauthor={Esther Rolf and Konstantin Klemmer and Caleb Robinson and Hannah Kerner},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=PQ0ERKKYJu}\n}"
    },
    {
        "title": "Practical Performance Guarantees for Pipelined DNN Inference",
        "authorids": [
            "~Aaron_Archer1",
            "~Matthew_Fahrbach1",
            "~Kuikui_Liu1",
            "~Prakash_Prabhu1"
        ],
        "abstract": "We optimize pipeline parallelism for deep neural network (DNN) inference by partitioning model graphs into $k$ stages and minimizing the running time of the bottleneck stage, including communication. We give practical and effective algorithms for this NP-hard problem, but our emphasis is on tackling the practitioner's dilemma of deciding when a solution is good enough. To this end, we design novel mixed integer programming (MIP) relaxations for proving lower bounds. Applying these methods to a diverse testbed of 369 production models, for $k \\in \\\\{2, 4, 8, 16, 32, 64\\\\}$, we empirically show that these lower bounds are strong enough to be useful in practice. Our lower bounds are substantially stronger than standard combinatorial bounds. For example, evaluated via geometric means across a production testbed with $k = 16$ pipeline stages, our MIP formulations raise the lower bound from 0.4598 to 0.9452, expressed as a fraction of the best partition found. In other words, our improved lower bounds close the optimality gap by a factor of 9.855x.",
        "_bibtex": "@inproceedings{\narcher2024practical,\ntitle={Practical Performance Guarantees for Pipelined {DNN} Inference},\nauthor={Aaron Archer and Matthew Fahrbach and Kuikui Liu and Prakash Prabhu},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=S3xqyEaST9}\n}"
    },
    {
        "title": "Position: What makes an image realistic?",
        "authorids": [
            "~Lucas_Theis1"
        ],
        "abstract": "The last decade has seen tremendous progress in our ability to *generate* realistic-looking data, be it images, text, audio, or video. Here, we discuss the closely related problem of *quantifying* realism, that is, designing functions that can reliably tell realistic data from unrealistic data. This problem turns out to be significantly harder to solve and remains poorly understood, despite its prevalence in machine learning and recent breakthroughs in generative AI. Drawing on insights from algorithmic information theory, we discuss why this problem is challenging, why a good generative model alone is insufficient to solve it, and what a good solution would look like. In particular, we introduce the notion of a *universal critic*, which unlike adversarial critics does not require adversarial training. While universal critics are not immediately practical, they can serve both as a North Star for guiding practical implementations and as a tool for analyzing existing attempts to capture realism.",
        "_bibtex": "@inproceedings{\ntheis2024position,\ntitle={Position: What makes an image realistic?},\nauthor={Lucas Theis},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=a6366lEzbX}\n}"
    },
    {
        "title": "FAFE: Immune Complex Modeling with Geodesic Distance Loss on Noisy Group Frames",
        "authorids": [
            "~Ruidong_Wu1",
            "~Ruihan_Guo2",
            "~Rui_Wang1",
            "~Shitong_Luo1",
            "xuyue@helixon.com",
            "~Jiahan_Li2",
            "~Jianzhu_Ma2",
            "~qiang_liu4",
            "~Yunan_Luo1",
            "~Jian_Peng1"
        ],
        "abstract": "Despite the striking success of general protein folding models such as AlphaFold2 (AF2), the accurate computational modeling of antibody-antigen complexes remains a challenging task. In this paper, we first analyze AF2's primary loss function, known as the Frame Aligned Point Error (FAPE), and raise a previously overlooked issue that FAPE tends to face gradient vanishing problem on high-rotational-error targets. To address this fundamental limitation, we propose a novel geodesic loss called Frame Aligned Frame Error (FAFE, denoted as F2E to distinguish from FAPE), which enables the model to better optimize both the rotational and translational errors between two frames. We then prove that F2E can be reformulated as a group-aware geodesic loss, which translates the optimization of the residue-to-residue error to optimizing group-to-group geodesic frame distance. By fine-tuning AF2 with our proposed new loss function, we attain a correct rate of 52.3% (DockQ > 0.23) on an evaluation set and 43.8% correct rate on a subset with low homology, with improvement over AF2 by 182% and 100% respectively.",
        "_bibtex": "@inproceedings{\nwu2024fafe,\ntitle={{FAFE}: Immune Complex Modeling with Geodesic Distance Loss on Noisy Group Frames},\nauthor={Ruidong Wu and Ruihan Guo and Rui Wang and Shitong Luo and Yue Xu and Jiahan Li and Jianzhu Ma and qiang liu and Yunan Luo and Jian Peng},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=Lhb39btw16}\n}"
    },
    {
        "title": "Double Variance Reduction: A Smoothing Trick for Composite Optimization Problems without First-Order Gradient",
        "authorids": [
            "~Hao_Di2",
            "~Haishan_Ye2",
            "~Yueling_Zhang3",
            "~Xiangyu_Chang1",
            "~Guang_Dai1",
            "~Ivor_Tsang1"
        ],
        "abstract": "Variance reduction techniques are designed to decrease the sampling variance, thereby accelerating convergence rates of first-order (FO) and zeroth-order (ZO) optimization methods. However, in composite optimization problems, ZO methods encounter an additional variance called the coordinate-wise variance, which stems from the random gradient estimation. To reduce this variance, prior works require estimating all partial derivatives, essentially approximating FO information. This approach demands $\\mathcal{O}(d)$ function evaluations ($d$ is the dimension size), which incurs substantial computational costs and is prohibitive in high-dimensional scenarios. This paper proposes the Zeroth-order Proximal Double Variance Reduction ($\\texttt{ZPDVR}$) method, which utilizes the averaging trick to reduce both sampling and coordinate-wise variances. Compared to prior methods, $\\texttt{ZPDVR}$ relies solely on random gradient estimates, calls the stochastic zeroth-order oracle (SZO) in expectation $\\mathcal{O}(1)$ times per iteration, and achieves the optimal $\\mathcal{O}(d(n + \\kappa)\\log (\\frac{1}{\\epsilon}))$ SZO query complexity in the strongly convex and smooth setting, where $\\kappa$ represents the condition number and $\\epsilon$ is the desired accuracy. Empirical results validate $\\texttt{ZPDVR}$'s linear convergence and demonstrate its superior performance over other related methods.",
        "_bibtex": "@inproceedings{\ndi2024double,\ntitle={Double Variance Reduction: A Smoothing Trick for Composite Optimization Problems without First-Order Gradient},\nauthor={Hao Di and Haishan Ye and Yueling Zhang and Xiangyu Chang and Guang Dai and Ivor Tsang},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=e1jPdRJeo7}\n}"
    },
    {
        "title": "A Circuit Domain Generalization Framework for Efficient Logic Synthesis in Chip Design",
        "authorids": [
            "~Zhihai_Wang1",
            "lc.leichen@huawei.com",
            "~Jie_Wang1",
            "byq000324@mail.ustc.edu.cn",
            "li.xing2@huawei.com",
            "~Xijun_Li1",
            "~Mingxuan_Yuan1",
            "~Jianye_HAO1",
            "~Yongdong_Zhang2",
            "~Feng_Wu1"
        ],
        "abstract": "Logic Synthesis (LS) plays a vital role in chip design. A key task in LS is to simplify circuits---modeled by directed acyclic graphs (DAGs)---with functionality-equivalent transformations. To tackle this task, many LS heuristics apply transformations to subgraphs---rooted at each node on an input DAG---sequentially. However, we found that a large number of transformations are ineffective, which makes applying these heuristics highly time-consuming. In particular, we notice that the runtime of the Resub and Mfs2 heuristics often dominates the overall runtime of LS optimization processes. To address this challenge, we propose a novel data-driven LS heuristic paradigm, namely PruneX, to reduce ineffective transformations. The major challenge of developing PruneX is to learn models that well generalize to unseen circuits, i.e., the out-of-distribution (OOD) generalization problem. Thus, the major technical contribution of PruneX is the novel circuit domain generalization framework, which learns domain-invariant representations based on the transformation-invariant domain-knowledge. To the best of our knowledge, PruneX is the first approach to tackle the OOD problem in LS heuristics. We integrate PruneX with the aforementioned Resub and Mfs2 heuristics. Experiments demonstrate that PruneX significantly improves their efficiency while keeping comparable optimization performance on industrial and very large-scale circuits, achieving up to $3.1\\times$ faster runtime.",
        "_bibtex": "@inproceedings{\nwang2024a,\ntitle={A Circuit Domain Generalization Framework for Efficient Logic Synthesis in Chip Design},\nauthor={Zhihai Wang and Lei Chen and Jie Wang and Yinqi Bai and Xing Li and Xijun Li and Mingxuan Yuan and Jianye HAO and Yongdong Zhang and Feng Wu},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=1KemC8DNa0}\n}"
    },
    {
        "title": "Sharp Rates in Dependent Learning Theory: Avoiding Sample Size Deflation for the Square Loss",
        "authorids": [
            "~Ingvar_Ziemann1",
            "~Stephen_Tu1",
            "~George_J._Pappas1",
            "~Nikolai_Matni2"
        ],
        "abstract": "In this work, we study statistical learning with dependent data and square loss in a hypothesis class with tail decay in Orlicz space: $\\mathscr{F}\\subset L_{\\Psi_p}$. Our inquiry is motivated by the search for a sharp noise interaction term, or variance proxy, in learning with dependent (e.g. $\\beta$-mixing) data. Typical non-asymptotic results exhibit variance proxies that are deflated *multiplicatively* in the mixing time of the underlying covariates process. We show that whenever the topologies of $L^2$ and $\\Psi_p$ are comparable on our hypothesis class $\\mathscr{F}$, the empirical risk minimizer achieves a rate that only depends on the complexity of the class and second order statistics in its leading term. We refer to this as a *near mixing-free rate*, since direct dependence on mixing is relegated to an additive higher order term. Our approach, reliant on mixed tail generic chaining, allows us to obtain sharp, instance-optimal rates. Examples that satisfy our framework include for instance sub-Gaussian linear regression and bounded smoothness classes.",
        "_bibtex": "@inproceedings{\nziemann2024sharp,\ntitle={Sharp Rates in Dependent Learning Theory: Avoiding Sample Size Deflation for the Square Loss},\nauthor={Ingvar Ziemann and Stephen Tu and George J. Pappas and Nikolai Matni},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=DHtF8Y6PqS}\n}"
    },
    {
        "title": "Navigating Scaling Laws: Compute Optimality in Adaptive Model Training",
        "authorids": [
            "~Sotiris_Anagnostidis1",
            "~Gregor_Bachmann1",
            "~Imanol_Schlag3",
            "~Thomas_Hofmann1"
        ],
        "abstract": "In recent years, the state-of-the-art in deep learning has been dominated by very large models that have been pre-trained on vast amounts of data. The paradigm is very simple: investing more computational resources (optimally) leads to better performance, and even predictably so; neural scaling laws have been derived that accurately forecast the performance of a network for a desired level of compute. This leads to the notion of a 'compute-optimal' model, i.e. a model that allocates a given level of compute during training optimally to maximize performance. In this work, we extend the concept of optimality by allowing for an 'adaptive' model, i.e. a model that can change its shape during training. By doing so, we can design adaptive models that optimally traverse between the underlying scaling laws and outpace their `static' counterparts, leading to a significant reduction in the required compute to reach a given target performance. We show that our approach generalizes across modalities and different shape parameters.",
        "_bibtex": "@inproceedings{\nanagnostidis2024navigating,\ntitle={Navigating Scaling Laws: Compute Optimality in Adaptive Model Training},\nauthor={Sotiris Anagnostidis and Gregor Bachmann and Imanol Schlag and Thomas Hofmann},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=3KxPo62PYn}\n}"
    },
    {
        "title": "Pessimism Meets Risk: Risk-Sensitive Offline Reinforcement Learning",
        "authorids": [
            "~Dake_Zhang1",
            "~Boxiang_Lyu1",
            "~Shuang_Qiu2",
            "~mladen_kolar1",
            "~Tong_Zhang2"
        ],
        "abstract": "We study risk-sensitive reinforcement learning (RL), a crucial field due to its ability to enhance decision-making in scenarios where it is essential to manage uncertainty and minimize potential adverse outcomes. Particularly, our work focuses on applying the entropic risk measure to RL problems. While existing literature primarily investigates the online setting, there remains a large gap in understanding how to efficiently derive a near-optimal policy based on this risk measure using only a pre-collected dataset. We center on the linear Markov Decision Process (MDP) setting, a well-regarded theoretical framework that has yet to be examined from a risk-sensitive standpoint. In response, we introduce two provably sample-efficient algorithms. We begin by presenting a risk-sensitive pessimistic value iteration algorithm, offering a tight analysis by leveraging the structure of the risk-sensitive performance measure. To further improve the obtained bounds, we propose another pessimistic algorithm that utilizes variance information and reference-advantage decomposition, effectively improving both the dependence on the space dimension $d$ and the risk-sensitivity factor. To the best of our knowledge, we obtain the first provably efficient risk-sensitive offline RL algorithms.",
        "_bibtex": "@inproceedings{\nzhang2024pessimism,\ntitle={Pessimism Meets Risk: Risk-Sensitive Offline Reinforcement Learning},\nauthor={Dake Zhang and Boxiang Lyu and Shuang Qiu and mladen kolar and Tong Zhang},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=InUUQkExsw}\n}"
    },
    {
        "title": "Conformal prediction for multi-dimensional time series by ellipsoidal sets",
        "authorids": [
            "~Chen_Xu12",
            "~Hanyang_Jiang2",
            "~Yao_Xie2"
        ],
        "abstract": "Conformal prediction (CP) has been a popular method for uncertainty quantification because it is distribution-free, model-agnostic, and theoretically sound. For forecasting problems in supervised learning, most CP methods focus on building prediction intervals for univariate responses. In this work, we develop a sequential CP method called $\\texttt{MultiDimSPCI}$ that builds prediction $\\textit{regions}$ for a multivariate response, especially in the context of multivariate time series, which are not exchangeable. Theoretically, we estimate $\\textit{finite-sample}$ high-probability bounds on the conditional coverage gap. Empirically, we demonstrate that $\\texttt{MultiDimSPCI}$ maintains valid coverage on a wide range of multivariate time series while producing smaller prediction regions than CP and non-CP baselines.",
        "_bibtex": "@inproceedings{\nxu2024conformal,\ntitle={Conformal prediction for multi-dimensional time series by ellipsoidal sets},\nauthor={Chen Xu and Hanyang Jiang and Yao Xie},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=uN39Tt9P8b}\n}"
    },
    {
        "title": "Asymptotics of feature learning in two-layer networks after one gradient-step",
        "authorids": [
            "~Hugo_Cui1",
            "~Luca_Pesce1",
            "~Yatin_Dandi1",
            "~Florent_Krzakala1",
            "~Yue_Lu1",
            "~Lenka_Zdeborova1",
            "~Bruno_Loureiro1"
        ],
        "abstract": "In this manuscript, we investigate the problem of how two-layer neural networks learn features from data, and improve over the kernel regime, after being trained with a single gradient descent step. Leveraging the insight from (Ba et al., 2022), we model the trained network by a spiked Random Features (sRF) model. Further building on recent progress on Gaussian universality (Dandi et al., 2023), we provide an exact asymptotic description of the generalization error of the sRF in the high-dimensional limit where the number of samples, the width, and the input dimension grow at a proportional rate. The resulting characterization for sRFs also captures closely the learning curves of the original network model. This enables us to understand how adapting to the data is crucial for the network to efficiently learn non-linear functions in the direction of the gradient - where at initialization it can only express linear functions in this regime.",
        "_bibtex": "@inproceedings{\ncui2024asymptotics,\ntitle={Asymptotics of feature learning in two-layer networks after one gradient-step},\nauthor={Hugo Cui and Luca Pesce and Yatin Dandi and Florent Krzakala and Yue Lu and Lenka Zdeborova and Bruno Loureiro},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=EdRb84fiJY}\n}"
    },
    {
        "title": "Robust Optimization in Protein Fitness Landscapes Using Reinforcement Learning in Latent Space",
        "authorids": [
            "~Minji_Lee1",
            "~Luiz_Felipe_Vecchietti1",
            "~Hyunkyu_Jung1",
            "~Hyun_Joo_Ro1",
            "~Meeyoung_Cha2",
            "~Ho_Min_Kim1"
        ],
        "abstract": "Proteins are complex molecules responsible for different functions in nature. Enhancing the functionality of proteins and cellular fitness can significantly impact various industries. However, protein optimization using computational methods remains challenging, especially when starting from low-fitness sequences. We propose LatProtRL, an optimization method to efficiently traverse a latent space learned by an encoder-decoder leveraging a large protein language model. To escape local optima, our optimization is modeled as a Markov decision process using reinforcement learning acting directly in latent space. We evaluate our approach on two important fitness optimization tasks, demonstrating its ability to achieve comparable or superior fitness over baseline methods. Our findings and in vitro evaluation show that the generated sequences can reach high-fitness regions, suggesting a substantial potential of LatProtRL in lab-in-the-loop scenarios.",
        "_bibtex": "@inproceedings{\nlee2024robust,\ntitle={Robust Optimization in Protein Fitness Landscapes Using Reinforcement Learning in Latent Space},\nauthor={Minji Lee and Luiz Felipe Vecchietti and Hyunkyu Jung and Hyun Joo Ro and Meeyoung Cha and Ho Min Kim},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=0zbxwvJqwf}\n}"
    },
    {
        "title": "CLIF: Complementary Leaky Integrate-and-Fire Neuron for Spiking Neural Networks",
        "authorids": [
            "~Yulong_Huang2",
            "~Xiaopeng_LIN1",
            "~Hongwei_Ren2",
            "~Haotian_FU4",
            "~Yue_Zhou8",
            "~Zunchang_LIU2",
            "~biao_pan1",
            "~Bojun_Cheng1"
        ],
        "abstract": "Spiking neural networks (SNNs) are promising brain-inspired energy-efficient models. Compared to conventional deep Artificial Neural Networks (ANNs), SNNs exhibit superior efficiency and capability to process temporal information. However, it remains a challenge to train SNNs due to their undifferentiable spiking mechanism. The surrogate gradients method is commonly used to train SNNs, but often comes with an accuracy disadvantage over ANNs counterpart. We link the degraded accuracy to the vanishing of gradient on the temporal dimension through the analytical and experimental study of the training process of Leaky Integrate-and-Fire (LIF) Neuron-based SNNs. Moreover, we propose the Complementary Leaky Integrate-and-Fire (CLIF) Neuron. CLIF creates extra paths to facilitate the backpropagation in computing temporal gradient while keeping binary output. CLIF is hyperparameter-free and features broad applicability. Extensive experiments on a variety of datasets demonstrate CLIF's clear performance advantage over other neuron models. Furthermore, the CLIF's performance even slightly surpasses superior ANNs with identical network structure and training conditions. The code is available at https://github.com/HuuYuLong/Complementary-LIF.",
        "_bibtex": "@inproceedings{\nhuang2024clif,\ntitle={{CLIF}: Complementary Leaky Integrate-and-Fire Neuron for Spiking Neural Networks},\nauthor={Yulong Huang and Xiaopeng LIN and Hongwei Ren and Haotian FU and Yue Zhou and Zunchang LIU and biao pan and Bojun Cheng},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=yY6N89IlHa}\n}"
    },
    {
        "title": "One Meta-tuned Transformer is What You Need for Few-shot Learning",
        "authorids": [
            "~Xu_Yang10",
            "~Huaxiu_Yao1",
            "~Ying_Wei1"
        ],
        "abstract": "Pre-trained vision transformers have revolutionized few-shot image classification, and it has been recently demonstrated that the previous common practice of meta-learning in synergy with these pre-trained transformers still holds significance. In this work, we design a new framework centered exclusively on self-attention, called MetaFormer, which extends the vision transformers beyond patch token interactions to encompass relationships between samples and tasks simultaneously for further advancing their downstream task performance. Leveraging the intrinsical property of ViTs in handling local patch relationships, we propose Masked Sample Attention (MSA) to efficiently embed the sample relationships into the network, where an adaptive mask is attached for enhancing task-specific feature consistency and providing flexibility in switching between few-shot learning setups. To encapsulate task relationships while filtering out background noise, Patch-grained Task Attention (PTA) is designed to maintain a dynamic knowledge pool consolidating diverse patterns from historical tasks. MetaFormer demonstrates coherence and compatibility with off-the-shelf pre-trained vision transformers and shows significant improvements in both inductive and transductive few-shot learning scenarios, outperforming state-of-the-art methods by up to 8.77% and 6.25% on 12 in-domain and 10 cross-domain datasets, respectively.",
        "_bibtex": "@inproceedings{\nyang2024one,\ntitle={One Meta-tuned Transformer is What You Need for Few-shot Learning},\nauthor={Xu Yang and Huaxiu Yao and Ying Wei},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=01ahsMovBx}\n}"
    },
    {
        "title": "Mixtures of Experts Unlock Parameter Scaling for Deep RL",
        "abstract": "The recent rapid progress in (self) supervised learning models is in large part predicted by empirical scaling laws: a model's performance scales proportionally to its size. Analogous scaling laws remain elusive for reinforcement learning domains, however, where increasing the parameter count of a model often hurts its final performance. In this paper, we demonstrate that incorporating Mixture-of-Expert (MoE) modules, and in particular Soft MoEs (Puigcerver et al., 2023), into value-based networks results in more parameter-scalable models, evidenced by substantial performance increases across a variety of training regimes and model sizes. This work thus provides strong empirical evidence towards developing scaling laws for reinforcement learning.",
        "_bibtex": "@inproceedings{\nceron2024mixtures,\ntitle={Mixtures of Experts Unlock Parameter Scaling for Deep {RL}},\nauthor={Johan Samir Obando Ceron and Ghada Sokar and Timon Willi and Clare Lyle and Jesse Farebrother and Jakob Nicolaus Foerster and Gintare Karolina Dziugaite and Doina Precup and Pablo Samuel Castro},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=X9VMhfFxwn}\n}"
    },
    {
        "title": "On the Complexity of Finite-Sum Smooth Optimization under the Polyak\u2013\u0141ojasiewicz Condition",
        "abstract": "This paper considers the optimization problem of the form $\\min_{{\\bf x}\\in{\\mathbb R}^d} f({\\bf x})\\triangleq \\frac{1}{n}\\sum_{i=1}^n f_i({\\bf x})$, where $f(\\cdot)$ satisfies the Polyak\u2013\u0141ojasiewicz (PL) condition with parameter $\\mu$ and $\\{f_i(\\cdot)\\}_{i=1}^n$ is $L$-mean-squared smooth. We show that any gradient method requires at least $\\Omega(n+\\kappa\\sqrt{n}\\log(1/\\epsilon))$ incremental first-order oracle (IFO) calls to find an $\\epsilon$-suboptimal solution, where $\\kappa\\triangleq L/\\mu$ is the condition number of the problem. This result nearly matches upper bounds of IFO complexity for best-known first-order methods. We also study the problem of minimizing the PL function in the distributed setting such that the individuals $f_1(\\cdot),\\dots,f_n(\\cdot)$ are located on a connected network of $n$ agents. We provide lower bounds of $\\Omega(\\kappa/\\sqrt{\\gamma}\\log(1/\\epsilon))$, $\\Omega((\\kappa+\\tau\\kappa/\\sqrt{\\gamma})\\log(1/\\epsilon))$ and $\\Omega\\big(n+\\kappa\\sqrt{n}\\log(1/\\epsilon)\\big)$ for communication rounds, time cost and local first-order oracle calls respectively, where $\\gamma\\in(0,1]$ is the spectral gap of the mixing matrix associated with the network and $\\tau>0$ is the time cost of per communication round. Furthermore, we propose a decentralized first-order method that nearly matches above lower bounds in expectation.",
        "_bibtex": "@inproceedings{\nbai2024on,\ntitle={On the Complexity of Finite-Sum Smooth Optimization  under the Polyak{\\textendash}{\\L}ojasiewicz Condition},\nauthor={Yunyan Bai and Yuxing Liu and Luo Luo},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=leJGQCron2}\n}"
    },
    {
        "title": "Learning Exceptional Subgroups by End-to-End Maximizing KL-Divergence",
        "authorids": [
            "~Sascha_Xu1",
            "~Nils_Philipp_Walter1",
            "~Janis_Kalofolias1",
            "~Jilles_Vreeken2"
        ],
        "abstract": "Finding and describing sub-populations that are exceptional in terms of a target property has important applications in many scientific disciplines, from identifying disadvantaged demographic groups in census data to finding conductive molecules within gold nanoparticles. Current approaches to finding such subgroups require pre-discretized predictive variables, do not permit non-trivial target distributions, do not scale to large datasets, and struggle to find diverse results. To address these limitations, we propose SYFLOW, an end-to-end optimizable approach in which we leverage normalizing flows to model arbitrary target distributions and introduce a novel neural layer that results in easily interpretable subgroup descriptions. We demonstrate on synthetic data, real-world data, and via a case study, that SYFLOW reliably finds highly exceptional subgroups accompanied by insightful descriptions.",
        "_bibtex": "@inproceedings{\nxu2024learning,\ntitle={Learning Exceptional Subgroups by End-to-End Maximizing {KL}-Divergence},\nauthor={Sascha Xu and Nils Philipp Walter and Janis Kalofolias and Jilles Vreeken},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=AG45XqwPKU}\n}"
    },
    {
        "title": "Leveraging (Biased) Information: Multi-armed Bandits with Offline Data",
        "authorids": [
            "~Wang_Chi_Cheung1",
            "~Lixing_Lyu1"
        ],
        "abstract": "We leverage offline data to facilitate online learning in stochastic multi-armed bandits. The probability distributions that govern the offline data and the online rewards can be different. Without any non-trival upper bound on their difference, we show that no non-anticipatory policy can out-perform the UCB policy by (Auer et al. 2002), even in the presence of offline data. In complement, we propose an online policy MIN-UCB, which outperforms UCB when a non-trivial upper bound is given. MIN-UCB adaptively chooses to utilize the offline data when they are deemed informative, and to ignore them otherwise. MIN-UCB is shown to be tight in terms of both instance indepedent and dependent regret bounds. Finally, we corroborate the theoretical results with numerical experiments.",
        "_bibtex": "@inproceedings{\ncheung2024leveraging,\ntitle={Leveraging (Biased) Information: Multi-armed Bandits with Offline Data},\nauthor={Wang Chi Cheung and Lixing Lyu},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=WvIHbQhrTq}\n}"
    },
    {
        "title": "Learning Causal Relations from Subsampled Time Series with Two Time-Slices",
        "authorids": [
            "~Anpeng_Wu1",
            "~Haoxuan_Li6",
            "~Kun_Kuang1",
            "~Zhang_Keli1",
            "~Fei_Wu1"
        ],
        "abstract": "This paper studies the causal relations from subsampled time series, in which measurements are sparse and sampled at a coarser timescale than the causal timescale of the underlying system. In such data, because there are numerous missing time-slices (i.e., cross-sections at each time point) between two consecutive measurements, conventional causal discovery methods designed for standard time series data would produce significant errors. To learn causal relations from subsampled time series, a typical solution is to conduct different interventions and then make a comparison. However, full interventions are often expensive, unethical, or even infeasible, particularly in fields such as health and social science. In this paper, we first explore how readily available two-time-slices data can replace intervention data to improve causal ordering, and propose a novel Descendant Hierarchical Topology algorithm with Conditional Independence Test (DHT-CIT) to learn causal relations from subsampled time series using only two time-slices. Specifically, we develop a conditional independence criterion that can be applied iteratively to test each node from time series and identify all of its descendant nodes. Empirical results on both synthetic and real-world datasets demonstrate the superiority of our DHT-CIT algorithm.",
        "_bibtex": "@inproceedings{\nwu2024learning,\ntitle={Learning Causal Relations from Subsampled Time Series with Two Time-Slices},\nauthor={Anpeng Wu and Haoxuan Li and Kun Kuang and Zhang Keli and Fei Wu},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=60F0fVbknK}\n}"
    },
    {
        "title": "Equivariance via Minimal Frame Averaging for More Symmetries and Efficiency",
        "authorids": [
            "~Yuchao_Lin1",
            "~Jacob_Helwig1",
            "~Shurui_Gui1",
            "~Shuiwang_Ji1"
        ],
        "abstract": "We consider achieving equivariance in machine learning systems via frame averaging. Current frame averaging methods involve a costly sum over large frames or rely on sampling-based approaches that only yield approximate equivariance. Here, we propose Minimal Frame Averaging (MFA), a mathematical framework for constructing provably minimal frames that are exactly equivariant. The general foundations of MFA also allow us to extend frame averaging to more groups than previously considered, including the Lorentz group for describing symmetries in space-time, and the unitary group for complex-valued domains. Results demonstrate the efficiency and effectiveness of encoding symmetries via MFA across a diverse range of tasks, including $n$-body simulation, top tagging in collider physics, and relaxed energy prediction. Our code is available at https://github.com/divelab/MFA.",
        "_bibtex": "@inproceedings{\nlin2024equivariance,\ntitle={Equivariance via Minimal Frame Averaging for More Symmetries and Efficiency},\nauthor={Yuchao Lin and Jacob Helwig and Shurui Gui and Shuiwang Ji},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=guFsTBXsov}\n}"
    },
    {
        "title": "Dynamic Facility Location in High Dimensional Euclidean Spaces",
        "authorids": [
            "~Sayan_Bhattacharya2",
            "~Gramoz_Goranci1",
            "~Shaofeng_H.-C._Jiang1",
            "qianyi@stu.pku.edu.cn",
            "~Yubo_Zhang4"
        ],
        "abstract": "We study the facility location problem in the dynamic setting, where the goal is to efficiently process an intermixed sequence of point insertions and deletions while maintaining a high quality and stable solution. Although the problem has been studied in the context of general metrics and low-dimensional spaces, much remains unknown concerning dynamic facility location in high dimensional spaces. In this work, we present the first fully dynamic algorithm for facility location in high-dimensional spaces $\\mathbb{R}^{d}$. For any $c \\geq 1$, our algorithm achieves $O(c)$-approximation, supports point updates in $\\tilde{O}(\\mathrm{poly}(d)n^{1/c + o(1)})$ amortized time and incurs $O(1)$ amortized recourse. More generally, our result shows that despite the linear-time lower bound on the update time for general metrics, it is possible to achieve sub-linear update times for metric spaces that admit dynamic nearest neighbour oracles. Experiments on real datasets confirm that our algorithm achieves high-quality solutions with low running time, and incurs minimal recourse.",
        "_bibtex": "@inproceedings{\nbhattacharya2024dynamic,\ntitle={Dynamic Facility Location in High Dimensional Euclidean Spaces},\nauthor={Sayan Bhattacharya and Gramoz Goranci and Shaofeng H.-C. Jiang and Yi Qian and Yubo Zhang},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=rucbIsWoEV}\n}"
    },
    {
        "title": "What Will My Model Forget? Forecasting Forgotten Examples in Language Model Refinement",
        "authorids": [
            "~Xisen_Jin3",
            "~Xiang_Ren1"
        ],
        "abstract": "Language models deployed in the wild make errors. However, simply updating the model with the corrected error instances causes catastrophic forgetting---the updated model makes errors on instances learned during the instruction tuning or upstream training phase. Randomly replaying upstream data yields unsatisfactory performance and often comes with high variance and poor controllability. To this end, we try to forecast upstream examples that will be forgotten due to a model update for improved controllability of the replay process and interpretability. We train forecasting models given a collection of online learned examples and corresponding forgotten upstream pre-training examples. We propose a partially interpretable forecasting model based on the observation that changes in pre-softmax logit scores of pretraining examples resemble that of online learned examples, which performs decently on BART but fails on T5 models. We further show a black-box classifier based on inner products of example representations achieves better forecasting performance over a series of setups. Finally, we show that we reduce forgetting of upstream pretraining examples by replaying examples that are forecasted to be forgotten, demonstrating the practical utility of forecasting example forgetting.",
        "_bibtex": "@inproceedings{\njin2024what,\ntitle={What Will My Model Forget? Forecasting Forgotten Examples in Language Model Refinement},\nauthor={Xisen Jin and Xiang Ren},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=bzNwexOPWm}\n}"
    },
    {
        "title": "Defining Neural Network Architecture through Polytope Structures of Datasets",
        "authorids": [
            "~Sangmin_Lee3",
            "~Abbas_Mammadov1",
            "~Jong_Chul_Ye1"
        ],
        "abstract": "Current theoretical and empirical research in neural networks suggests that complex datasets require large network architectures for thorough classification, yet the precise nature of this relationship remains unclear. This paper tackles this issue by defining upper and lower bounds for neural network widths, which are informed by the polytope structure of the dataset in question. We also delve into the application of these principles to simplicial complexes and specific manifold shapes, explaining how the requirement for network width varies in accordance with the geometric complexity of the dataset. Moreover, we develop an algorithm to investigate a converse situation where the polytope structure of a dataset can be inferred from its corresponding trained neural networks. Through our algorithm, it is established that popular datasets such as MNIST, Fashion-MNIST, and CIFAR10 can be efficiently encapsulated using no more than two polytopes with a small number of faces.",
        "_bibtex": "@inproceedings{\nlee2024defining,\ntitle={Defining Neural Network Architecture through Polytope Structures of Datasets},\nauthor={Sangmin Lee and Abbas Mammadov and Jong Chul Ye},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=qXoqV40imX}\n}"
    },
    {
        "title": "Extending Test-Time Augmentation with Metamorphic Relations for Combinatorial Problems",
        "authorids": [
            "~Siwei_Wei1",
            "zhangxd20@ios.ac.cn",
            "~Zhiyang_Zhou3",
            "~Yan_Cai3"
        ],
        "abstract": "The application of machine learning methods to solve combinatorial problems has garnered considerable research interest. In this paper, we propose MAgg (**M**etamorphic **Agg**regation), a method to augment machine learning models for combinatorial problems at inference time using metamorphic relations. MAgg models metamorphic relations using directed graphs, which are then fed to a Graph Neural Network (GNN) model to improve the aggregation of predictions across transformed input instances. By incorporating metamorphic relations, MAgg essentially extends standard Test-Time Augmentation (TTA), eliminating the necessity of label-preserving transformations and expanding its applicability to a broader range of supervised learning tasks for combinatorial problems. We evaluate the proposed MAgg method on three mainstream machine learning tasks for combinatorial problems, namely Boolean Satisfiability Prediction (SAT), Decision Traveling Salesman Problem Satisfiability Prediction (Decision TSP), and Graph Edit Distance Estimation (GED). The evaluation result shows significant improvements over base models in all three tasks, corroborating the effectiveness and versatility of the proposed method.",
        "_bibtex": "@inproceedings{\nwei2024extending,\ntitle={Extending Test-Time Augmentation with Metamorphic Relations for Combinatorial Problems},\nauthor={Siwei Wei and Xudong Zhang and Zhiyang Zhou and Yan Cai},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=PNsdnl8blk}\n}"
    },
    {
        "title": "Bridging Data Gaps in Diffusion Models with Adversarial Noise-Based Transfer Learning",
        "authorids": [
            "~Xiyu_Wang2",
            "~Baijiong_Lin1",
            "~Daochang_Liu1",
            "~Ying-Cong_Chen1",
            "~Chang_Xu4"
        ],
        "abstract": "Diffusion Probabilistic Models (DPMs) show significant potential in image generation, yet their performance hinges on having access to large datasets. Previous works, like Generative Adversarial Networks (GANs), have tackled the limited data problem by transferring pre-trained models learned with sufficient data. However, those methods are hard to be utilized in DPMs since the distinct differences between DPM-based and GAN-based methods, showing in the unique iterative denoising process integral and the need for many timesteps with no-targeted noise in DPMs. In this paper, we propose a novel DPMs-based transfer learning method, ANT, to address the limited data problem. It includes two strategies: similarity-guided training, which boosts transfer with a classifier, and adversarial noise selection which adaptively chooses targeted noise based on the input image. Extensive experiments in the context of few-shot image generation tasks demonstrate that our method is not only efficient but also excels in terms of image quality and diversity when compared to existing GAN-based and DDPM-based methods.",
        "_bibtex": "@inproceedings{\nwang2024bridging,\ntitle={Bridging Data Gaps in Diffusion Models with Adversarial Noise-Based Transfer Learning},\nauthor={Xiyu Wang and Baijiong Lin and Daochang Liu and Ying-Cong Chen and Chang Xu},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=PpBs2iL0jv}\n}"
    },
    {
        "title": "Handling Heterogeneous Curvatures in Bandit LQR Control",
        "authorids": [
            "~Yu-Hu_Yan1",
            "~Jing_Wang32",
            "~Peng_Zhao1"
        ],
        "abstract": "We investigate online Linear Quadratic Regulator (LQR) with bandit feedback and semi-adversarial disturbances. Previous works assume costs with *homogeneous* curvatures (i.e., with a uniform strong convexity lower bound), which can be hard to satisfy in many real scenarios and prohibits adapting to true curvatures for better performance. In this paper, we initiate the study of bandit LQR control with *heterogeneous* cost curvatures, aiming to strengthen the algorithm's adaptivity. To achieve this, we reduce the problem to bandit convex optimization with memory via a ``with-history'' reduction to avoid hard-to-control truncation errors. Then we provide a novel analysis for an important *stability* term that appeared in both regret and memory, using *Newton decrement* developed in interior-point methods. The analysis enables us to guarantee memory-related terms introduced in the reduction and also provide a simplified analysis for handling heterogeneous curvatures in bandit convex optimization. Finally, we achieve interpolated guarantees that can not only recover existing bounds for convex and quadratic costs but also attain new implications for cases of corrupted and decaying quadraticity.",
        "_bibtex": "@inproceedings{\nyan2024handling,\ntitle={Handling Heterogeneous Curvatures in Bandit {LQR} Control},\nauthor={Yu-Hu Yan and Jing Wang and Peng Zhao},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=zWIS8I9G9B}\n}"
    },
    {
        "title": "Optimal Ridge Regularization for Out-of-Distribution Prediction",
        "authorids": [
            "~Pratik_Patil1",
            "~Jin-Hong_Du1",
            "~Ryan_Tibshirani2"
        ],
        "abstract": "We study the behavior of optimal ridge regularization and optimal ridge risk for out-of-distribution prediction, where the test distribution deviates arbitrarily from the train distribution. We establish general conditions that determine the sign of the optimal regularization level under covariate and regression shifts. These conditions capture the alignment between the covariance and signal structures in the train and test data and reveal stark differences compared to the in-distribution setting. For example, a negative regularization level can be optimal under covariate shift or regression shift, even when the training features are isotropic or the design is underparameterized. Furthermore, we prove that the optimally tuned risk is monotonic in the data aspect ratio, even in the out-of-distribution setting and when optimizing over negative regularization levels. In general, our results do not make any modeling assumptions for the train or the test distributions, except for moment bounds, and allow for arbitrary shifts and the widest possible range of (negative) regularization levels.",
        "_bibtex": "@inproceedings{\npatil2024optimal,\ntitle={Optimal Ridge Regularization for Out-of-Distribution Prediction},\nauthor={Pratik Patil and Jin-Hong Du and Ryan Tibshirani},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=bvPYroQgc3}\n}"
    },
    {
        "title": "Optimal Kernel Quantile Learning with Random Features",
        "authorids": [
            "~Caixing_Wang1",
            "~Xingdong_Feng1"
        ],
        "abstract": "The random feature (RF) approach is a well-established and efficient tool for scalable kernel methods, but existing literature has primarily focused on kernel ridge regression with random features (KRR-RF), which has limitations in handling heterogeneous data with heavy-tailed noises. This paper presents a generalization study of kernel quantile regression with random features (KQR-RF), which accounts for the non-smoothness of the check loss in KQR-RF by introducing a refined error decomposition and establishing a novel connection between KQR-RF and KRR-RF. Our study establishes the capacity-dependent learning rates for KQR-RF under mild conditions on the number of RFs, which are minimax optimal up to some logarithmic factors. Importantly, our theoretical results, utilizing a data-dependent sampling strategy, can be extended to cover the agnostic setting where the target quantile function may not precisely align with the assumed kernel space. By slightly modifying our assumptions, the capacity-dependent error analysis can also be applied to cases with Lipschitz continuous losses, enabling broader applications in the machine learning community. To validate our theoretical findings, simulated experiments and a real data application are conducted.",
        "_bibtex": "@inproceedings{\nwang2024optimal,\ntitle={Optimal Kernel Quantile Learning with Random Features},\nauthor={Caixing Wang and Xingdong Feng},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=KOW9ncAiRo}\n}"
    },
    {
        "title": "RICE: Breaking Through the Training Bottlenecks of Reinforcement Learning with Explanation",
        "authorids": [
            "~Zelei_Cheng1",
            "~Xian_Wu8",
            "~Jiahao_Yu1",
            "~Sabrina_Yang1",
            "~Gang_Wang13",
            "~Xinyu_Xing3"
        ],
        "abstract": "Deep reinforcement learning (DRL) is playing an increasingly important role in real-world applications. However, obtaining an optimally performing DRL agent for complex tasks, especially with sparse rewards, remains a significant challenge. The training of a DRL agent can be often trapped in a bottleneck without further progress. In this paper, we propose RICE, an innovative refining scheme for reinforcement learning that incorporates explanation methods to break through the training bottlenecks. The high-level idea of RICE is to construct a new initial state distribution that combines both the default initial states and critical states identified through explanation methods, thereby encouraging the agent to explore from the mixed initial states. Through careful design, we can theoretically guarantee that our refining scheme has a tighter sub-optimality bound. We evaluate RICE in various popular RL environments and real-world applications. The results demonstrate that RICE significantly outperforms existing refining schemes in enhancing agent performance.",
        "_bibtex": "@inproceedings{\ncheng2024rice,\ntitle={{RICE}: Breaking Through the Training Bottlenecks of Reinforcement Learning with Explanation},\nauthor={Zelei Cheng and Xian Wu and Jiahao Yu and Sabrina Yang and Gang Wang and Xinyu Xing},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=PKJqsZD5nQ}\n}"
    },
    {
        "title": "Prospective Side Information for Latent MDPs",
        "authorids": [
            "~Jeongyeol_Kwon1",
            "~Yonathan_Efroni2",
            "~Shie_Mannor2",
            "~Constantine_Caramanis1"
        ],
        "abstract": "In many interactive decision-making problems, there is contextual side information that remains fixed within the course of an interaction. This problem has been studied quite extensively under the assumption the context is fully observed, as well as in the opposing limit when the context is unobserved, a special type of POMDP also referred to as a Latent MDP (LMDP). In this work, we consider a class of decision problems that interpolates between the settings, namely, between the case the context is fully observed, and the case the context is unobserved. We refer to this class of decision problems as *LMDPs with prospective side information*. In such an environment an agent receives additional, weakly revealing, information on the latent context at the beginning of each episode. We show that, surprisingly, this problem is not captured by contemporary POMDP settings and is not solved by RL algorithms designed for partially observed environments. We then establish that any sample efficient algorithm must suffer at least $\\Omega(K^{2/3})$-regret, as opposed to standard $\\Omega(\\sqrt{K})$ lower bounds. We design an algorithm with a matching upper bound that depends only polynomially on the problem parameters. This establishes exponential improvement in the sample complexity relative to the existing LMDP lower bound, when prospective information is not given in prior work.",
        "_bibtex": "@inproceedings{\nkwon2024prospective,\ntitle={Prospective Side Information for Latent {MDP}s},\nauthor={Jeongyeol Kwon and Yonathan Efroni and Shie Mannor and Constantine Caramanis},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=p5FIjG9fbs}\n}"
    },
    {
        "title": "Dynamic Correlation Clustering in Sublinear Update Time",
        "authorids": [
            "~Vincent_Cohen-Addad1",
            "~Silvio_Lattanzi1",
            "~Andreas_Maggiori1",
            "~Nikos_Parotsidis1"
        ],
        "abstract": "We study the classic problem of correlation clustering in dynamic vertex streams. In this setting, vertices are either added or randomly deleted over time, and each vertex pair is connected by a positive or negative edge. The objective is to continuously find a partition which minimizes the sum of positive edges crossing clusters and negative edges within clusters. We present an algorithm that maintains an $O(1)$-approximation with $O(\\text{polylog} n)$ amortized update time. Prior to our work Behnezhad et al. in SODA 2023 achieved a $5$-approximation with $O(1)$ expected update time in edge streams which translates in vertex streams to an $O(D)$-update time where $D$ is the maximum possible degree. Finally we complement our theoretical analysis with experiments on real world data.",
        "_bibtex": "@inproceedings{\ncohen-addad2024dynamic,\ntitle={Dynamic Correlation Clustering in Sublinear Update Time},\nauthor={Vincent Cohen-Addad and Silvio Lattanzi and Andreas Maggiori and Nikos Parotsidis},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=3YG55Lbcnr}\n}"
    },
    {
        "title": "A Theoretical Analysis of Backdoor Poisoning Attacks in Convolutional Neural Networks",
        "authorids": [
            "~Boqi_Li2",
            "~Weiwei_Liu1"
        ],
        "abstract": "The rising threat of backdoor poisoning attacks (BPAs) on Deep Neural Networks (DNNs) has become a significant concern in recent years. In such attacks, the adversaries strategically target a specific class and generate a poisoned training set. The neural network (NN), well-trained on the poisoned training set, is able to predict any input with the trigger pattern as the targeted label, while maintaining accurate outputs for clean inputs. However, why the BPAs work remains less explored. To fill this gap, we employ a dirty-label attack and conduct a detailed analysis of BPAs in a two-layer convolutional neural network. We provide theoretical insights and results on the effectiveness of BPAs. Our experimental results on two real-world datasets validate our theoretical findings.",
        "_bibtex": "@inproceedings{\nli2024a,\ntitle={A Theoretical Analysis of Backdoor Poisoning Attacks in Convolutional Neural Networks},\nauthor={Boqi Li and Weiwei Liu},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=SfcB4cVvPz}\n}"
    },
    {
        "title": "Masked Face Recognition with Generative-to-Discriminative Representations",
        "authorids": [
            "~Shiming_Ge1",
            "guoweijia@iie.ac.cn",
            "lichenyu@iie.ac.cn",
            "~Zhang_Junzheng1",
            "liyong@iie.ac.cn",
            "~Dan_Zeng2"
        ],
        "abstract": "Masked face recognition is important for social good but challenged by diverse occlusions that cause insufficient or inaccurate representations. In this work, we propose a unified deep network to learn generative-to-discriminative representations for facilitating masked face recognition. To this end, we split the network into three modules and learn them on synthetic masked faces in a greedy module-wise pretraining manner. First, we leverage a generative encoder pretrained for face inpainting and finetune it to represent masked faces into category-aware descriptors. Attribute to the generative encoder's ability in recovering context information, the resulting descriptors can provide occlusion-robust representations for masked faces, mitigating the effect of diverse masks. Then, we incorporate a multi-layer convolutional network as a discriminative reformer and learn it to convert the category-aware descriptors into identity-aware vectors, where the learning is effectively supervised by distilling relation knowledge from off-the-shelf face recognition model. In this way, the discriminative reformer together with the generative encoder serves as the pretrained backbone, providing general and discriminative representations towards masked faces. Finally, we cascade one fully-connected layer following by one softmax layer into a feature classifier and finetune it to identify the reformed identity-aware vectors. Extensive experiments on synthetic and realistic datasets demonstrate the effectiveness of our approach in recognizing masked faces.",
        "_bibtex": "@inproceedings{\nge2024masked,\ntitle={Masked Face Recognition with Generative-to-Discriminative Representations},\nauthor={Shiming Ge and Weijia Guo and Chenyu Li and Zhang Junzheng and Yong Li and Dan Zeng},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=tya725xlZ3}\n}"
    },
    {
        "title": "No Dimensional Sampling Coresets for Classification",
        "authorids": [
            "~Meysam_Alishahi1",
            "~Jeff_M._Phillips1"
        ],
        "abstract": "We refine and generalize what is known about coresets for classification problems via the sensitivity sampling framework. Such coresets seek the smallest possible subsets of input data, so one can optimize a loss function on the coreset and ensure approximation guarantees with respect to the original data. Our analysis provides the first no dimensional coresets, so the size does not depend on the dimension. Moreover, our results are general, apply for distributional input and can use iid samples, so provide sample complexity bounds, and work for a variety of loss functions. A key tool we develop is a Radamacher complexity version of the main sensitivity sampling approach, which can be of independent interest.",
        "_bibtex": "@inproceedings{\nalishahi2024no,\ntitle={No Dimensional Sampling Coresets for Classification},\nauthor={Meysam Alishahi and Jeff M. Phillips},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=jS3CMHtYJD}\n}"
    },
    {
        "title": "Stereographic Spherical Sliced Wasserstein Distances",
        "authorids": [
            "~Huy_Tran3",
            "~Yikun_Bai2",
            "~Abihith_Kothapalli1",
            "~Ashkan_Shahbazi1",
            "~Xinran_Liu2",
            "~Rocio_P_Diaz_Martin1",
            "~Soheil_Kolouri1"
        ],
        "abstract": "Comparing spherical probability distributions is of great interest in various fields, including geology, medical domains, computer vision, and deep representation learning. The utility of optimal transport-based distances, such as the Wasserstein distance, for comparing probability measures has spurred active research in developing computationally efficient variations of these distances for spherical probability measures. This paper introduces a high-speed and highly parallelizable distance for comparing spherical measures using the stereographic projection and the generalized Radon transform, which we refer to as the Stereographic Spherical Sliced Wasserstein (S3W) distance. We carefully address the distance distortion caused by the stereographic projection and provide an extensive theoretical analysis of our proposed metric and its rotationally invariant variation. Finally, we evaluate the performance of the proposed metrics and compare them with recent baselines in terms of both speed and accuracy through a wide range of numerical studies, including gradient flows and self-supervised learning. Our code is available at https://github.com/mint-vu/s3wd.",
        "_bibtex": "@inproceedings{\ntran2024stereographic,\ntitle={Stereographic Spherical Sliced Wasserstein Distances},\nauthor={Huy Tran and Yikun Bai and Abihith Kothapalli and Ashkan Shahbazi and Xinran Liu and Rocio P Diaz Martin and Soheil Kolouri},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=vLtVGtEz5h}\n}"
    },
    {
        "title": "Faster Adaptive Decentralized Learning Algorithms",
        "authorids": [
            "~Feihu_Huang1",
            "~jianyu_zhao4"
        ],
        "abstract": "Decentralized learning recently has received increasing attention in machine learning due to its advantages in implementation simplicity and system robustness, data privacy. Meanwhile, the adaptive gradient methods show superior performances in many machine learning tasks such as training neural networks. Although some works focus on studying decentralized optimization algorithms with adaptive learning rates, these adaptive decentralized algorithms still suffer from high sample complexity. To fill these gaps, we propose a class of faster adaptive decentralized algorithms (i.e., AdaMDOS and AdaMDOF) for distributed nonconvex stochastic and finite-sum optimization, respectively. Moreover, we provide a solid convergence analysis framework for our methods. In particular, we prove that our AdaMDOS obtains a near-optimal sample complexity of $\\tilde{O}(\\epsilon^{-3})$ for finding an $\\epsilon$-stationary solution of nonconvex stochastic optimization. Meanwhile, our AdaMDOF obtains a near-optimal sample complexity of $O(\\sqrt{n}\\epsilon^{-2})$ for finding an $\\epsilon$-stationary solution of for nonconvex finite-sum optimization, where $n$ denotes the sample size. To the best of our knowledge, our AdaMDOF algorithm is the first adaptive decentralized algorithm for nonconvex finite-sum optimization. Some experimental results demonstrate efficiency of our algorithms.",
        "_bibtex": "@inproceedings{\nhuang2024faster,\ntitle={Faster Adaptive Decentralized Learning Algorithms},\nauthor={Feihu Huang and jianyu zhao},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=Dwc0RwiNI5}\n}"
    },
    {
        "title": "Minimax Optimality of Score-based Diffusion Models: Beyond the Density Lower Bound Assumptions",
        "authorids": [
            "~Kaihong_Zhang1",
            "~Heqi_Yin1",
            "~Feng_Liang1",
            "~Jingbo_Liu3"
        ],
        "abstract": "We study the asymptotic error of score-based diffusion model sampling in large-sample scenarios from a non-parametric statistics perspective. We show that a kernel-based score estimator achieves an optimal mean square error of $\\widetilde{O}\\left(n^{-1} t^{-\\frac{d+2}{2}}(t^{\\frac{d}{2}} \\vee 1)\\right)$ for the score function of $p_0*\\mathcal{N}(0,t\\boldsymbol{I}_d)$, where $n$ and $d$ represent the sample size and the dimension, $t$ is bounded above and below by polynomials of $n$, and $p_0$ is an arbitrary sub-Gaussian distribution. As a consequence, this yields an $\\widetilde{O}\\left(n^{-1/2} t^{-\\frac{d}{4}}\\right)$ upper bound for the total variation error of the distribution of the sample generated by the diffusion model under a mere sub-Gaussian assumption. If in addition, $p_0$ belongs to the nonparametric family of the $\\beta$-Sobolev space with $\\beta\\le 2$, by adopting an early stopping strategy, we obtain that the diffusion model is nearly (up to log factors) minimax optimal. This removes the crucial lower bound assumption on $p_0$ in previous proofs of the minimax optimality of the diffusion model for nonparametric families.",
        "_bibtex": "@inproceedings{\nzhang2024minimax,\ntitle={Minimax Optimality of Score-based Diffusion Models: Beyond the Density Lower Bound Assumptions},\nauthor={Kaihong Zhang and Heqi Yin and Feng Liang and Jingbo Liu},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=wTd7dogTsB}\n}"
    },
    {
        "title": "Memorization Through the Lens of Curvature of Loss Function Around Samples",
        "authorids": [
            "~Isha_Garg1",
            "~Deepak_Ravikumar1",
            "~Kaushik_Roy1"
        ],
        "abstract": "Deep neural networks are over-parameterized and easily overfit to and memorize the datasets that they train on. In the extreme case, it has been shown that networks can memorize a randomly labeled dataset. In this paper, we propose using the curvature of the loss function around each training sample, averaged over training epochs, as a measure of memorization of a sample. We show that this curvature metric effectively captures memorization statistics, both qualitatively and quantitatively in popular image datasets. We provide quantitative validation of the proposed metric against memorization scores released by Feldman & Zhang (2020). Further, experiments on mislabeled data detection show that corrupted samples are learned with high curvature and using curvature for identifying mislabelled examples outperforms existing approaches. Qualitatively, we find that high curvature samples correspond to long-tailed, mislabeled, or conflicting instances, indicating a likelihood of memorization. Notably, this analysis helps us find, to the best of our knowledge, a novel failure mode on the CIFAR100 and ImageNet datasets: that of duplicated images with differing labels.",
        "_bibtex": "@inproceedings{\ngarg2024memorization,\ntitle={Memorization Through the Lens of Curvature of Loss Function Around Samples},\nauthor={Isha Garg and Deepak Ravikumar and Kaushik Roy},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=WQbDS9RydY}\n}"
    },
    {
        "title": "Sparse and Structured Hopfield Networks",
        "authorids": [
            "~Saul_Jos\u00e9_Rodrigues_dos_Santos1",
            "~Vlad_Niculae2",
            "~Daniel_C_McNamee1",
            "~Andre_Martins1"
        ],
        "abstract": "Modern Hopfield networks have enjoyed recent interest due to their connection to attention in transformers. Our paper provides a unified framework for sparse Hopfield networks by establishing a link with Fenchel-Young losses. The result is a new family of Hopfield-Fenchel-Young energies whose update rules are end-to-end differentiable sparse transformations. We reveal a connection between loss margins, sparsity, and exact memory retrieval. We further extend this framework to structured Hopfield networks via the SparseMAP transformation, which can retrieve pattern associations instead of a single pattern. Experiments on multiple instance learning and text rationalization demonstrate the usefulness of our approach.",
        "_bibtex": "@inproceedings{\nsantos2024sparse,\ntitle={Sparse and Structured Hopfield Networks},\nauthor={Saul Jos{\\'e} Rodrigues dos Santos and Vlad Niculae and Daniel C McNamee and Andre Martins},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=OdPlFWExX1}\n}"
    },
    {
        "title": "Beyond Implicit Bias: The Insignificance of SGD Noise in Online Learning",
        "authorids": [
            "~Nikhil_Vyas1",
            "~Depen_Morwani1",
            "~Rosie_Zhao1",
            "~Gal_Kaplun1",
            "~Sham_M._Kakade1",
            "~Boaz_Barak2"
        ],
        "abstract": "The success of SGD in deep learning has been ascribed by prior works to the *implicit bias* induced by finite batch sizes (''SGD noise''). While prior works focused on *offline learning* (i.e., multiple-epoch training), we study the impact of SGD noise on *online* (i.e., single epoch) learning. Through an extensive empirical analysis of image and language data, we demonstrate that small batch sizes do *not* confer any implicit bias advantages in online learning. In contrast to offline learning, the benefits of SGD noise in online learning are strictly computational, facilitating more cost-effective gradient steps. This suggests that SGD in the online regime can be construed as taking noisy steps along the ''golden path'' of the noiseless *gradient descent* algorithm. We study this hypothesis and provide supporting evidence in loss and function space. Our findings challenge the prevailing understanding of SGD and offer novel insights into its role in online learning.",
        "_bibtex": "@inproceedings{\nvyas2024beyond,\ntitle={Beyond Implicit Bias: The Insignificance of {SGD} Noise in Online Learning},\nauthor={Nikhil Vyas and Depen Morwani and Rosie Zhao and Gal Kaplun and Sham M. Kakade and Boaz Barak},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=RiQbe8RwCe}\n}"
    },
    {
        "title": "Towards Theoretical Understanding of Learning Large-scale Dependent Data via Random Features",
        "authorids": [
            "~Chao_Wang39",
            "~Xin_Bing1",
            "~Xin_HE6",
            "~Caixing_Wang1"
        ],
        "abstract": "Random feature (RF) mapping is an attractive and powerful technique for solving large-scale nonparametric regression. Yet, the existing theoretical analysis crucially relies on the i.i.d. assumption that individuals in the data are independent and identically distributed. It is still unclear whether learning accuracy would be compromised when the i.i.d. assumption is violated. This paper aims to provide theoretical understanding of the kernel ridge regression (KRR) with RFs for large-scale dependent data. Specifically, we consider two types of data dependence structure, namely, the $\\tau$-mixing process with exponential decay coefficient, and that with polynomial decay coefficient. Theoretically, we prove that the kernel ridge estimator with RFs achieves the minimax optimality under the exponential decay scenario, but yields a sub-optimal result under the polynomial decay case. Our analysis further reveals how the decay rate of the $\\tau$-mixing coefficient impacts the learning accuracy of the kernel ridge estimator with RFs. Extensive numerical experiments on both synthetic and real examples further validate our theoretical findings and support the effectiveness of the KRR with RFs in dealing with dependent data.",
        "_bibtex": "@inproceedings{\nwang2024towards,\ntitle={Towards Theoretical Understanding of Learning Large-scale Dependent Data via Random Features},\nauthor={Chao Wang and Xin Bing and Xin HE and Caixing Wang},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=eY4jrFe6Qc}\n}"
    },
    {
        "title": "Automating the Selection of Proxy Variables of Unmeasured Confounders",
        "authorids": [
            "~Feng_Xie1",
            "~Zhengming_Chen2",
            "~Shanshan_Luo2",
            "~Wang_Miao1",
            "~Ruichu_Cai1",
            "~Zhi_Geng1"
        ],
        "abstract": "Recently, interest has grown in the use of proxy variables of unobserved confounding for inferring the causal effect in the presence of unmeasured confounders from observational data. One difficulty inhibiting the practical use is finding valid proxy variables of unobserved confounding to a target causal effect of interest. These proxy variables are typically justified by background knowledge. In this paper, we investigate the estimation of causal effects among multiple treatments and a single outcome, all of which are affected by unmeasured confounders, within a linear causal model, without prior knowledge of the validity of proxy variables. To be more specific, we first extend the existing proxy variable estimator, originally addressing a single unmeasured confounder, to accommodate scenarios where multiple unmeasured confounders exist between the treatments and the outcome. Subsequently, we present two different sets of precise identifiability conditions for selecting valid proxy variables of unmeasured confounders, based on the second-order statistics and higher-order statistics of the data, respectively. Moreover, we propose two data-driven methods for the selection of proxy variables and for the unbiased estimation of causal effects. Theoretical analysis demonstrates the correctness of our proposed algorithms. Experimental results on both synthetic and real-world data show the effectiveness of the proposed approach.",
        "_bibtex": "@inproceedings{\nxie2024automating,\ntitle={Automating the Selection of Proxy Variables of Unmeasured Confounders},\nauthor={Feng Xie and Zhengming Chen and Shanshan Luo and Wang Miao and Ruichu Cai and Zhi Geng},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=VuoB86HiCL}\n}"
    },
    {
        "title": "Code as Reward: Empowering Reinforcement Learning with VLMs",
        "authorids": [
            "~David_Venuto1",
            "~Mohammad_Sami_Nur_Islam1",
            "~Martin_Klissarov1",
            "~Doina_Precup1",
            "~Sherry_Yang1",
            "~Ankit_Anand4"
        ],
        "abstract": "Pre-trained Vision-Language Models (VLMs) are able to understand visual concepts, describe and decompose complex tasks into sub-tasks, and provide feedback on task completion. In this paper, we aim to leverage these capabilities to support the training of reinforcement learning (RL) agents. In principle, VLMs are well suited for this purpose, as they can naturally analyze image-based observations and provide feedback (reward) on learning progress. However, inference in VLMs is computationally expensive, so querying them frequently to compute rewards would significantly slowdown the training of an RL agent. To address this challenge, we propose a framework named Code as Reward (VLM-CaR). VLM-CaR produces dense reward functions from VLMs through code generation, thereby significantly reducing the computational burden of querying the VLM directly. We show that the dense rewards generated through our approach are very accurate across a diverse set of discrete and continuous environments, and can be more effective in training RL policies than the original sparse environment rewards.",
        "_bibtex": "@inproceedings{\nvenuto2024code,\ntitle={Code as Reward: Empowering Reinforcement Learning with {VLM}s},\nauthor={David Venuto and Mohammad Sami Nur Islam and Martin Klissarov and Doina Precup and Sherry Yang and Ankit Anand},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=6P88DMUDvH}\n}"
    },
    {
        "title": "EfficientZero V2: Mastering Discrete and Continuous Control with Limited Data",
        "authorids": [
            "~Shengjie_Wang2",
            "~Shaohuai_Liu1",
            "~Weirui_Ye1",
            "~Jiacheng_You1",
            "~Yang_Gao1"
        ],
        "abstract": "Sample efficiency remains a crucial challenge in applying Reinforcement Learning (RL) to real-world tasks. While recent algorithms have made significant strides in improving sample efficiency, none have achieved consistently superior performance across diverse domains. In this paper, we introduce EfficientZero V2, a general framework designed for sample-efficient RL algorithms. We have expanded the performance of EfficientZero to multiple domains, encompassing both continuous and discrete actions, as well as visual and low-dimensional inputs. With a series of improvements we propose, EfficientZero V2 outperforms the current state-of-the-art (SoTA) by a significant margin in diverse tasks under the limited data setting. EfficientZero V2 exhibits a notable advancement over the prevailing general algorithm, DreamerV3, achieving superior outcomes in 50 of 66 evaluated tasks across multiple benchmarks, including Atari 100k, Proprio Control, and Vision Control.",
        "_bibtex": "@inproceedings{\nwang2024efficientzero,\ntitle={EfficientZero V2: Mastering Discrete and Continuous Control with Limited Data},\nauthor={Shengjie Wang and Shaohuai Liu and Weirui Ye and Jiacheng You and Yang Gao},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=LHGMXcr6zx}\n}"
    },
    {
        "title": "Distributed High-Dimensional Quantile Regression: Estimation Efficiency and Support Recovery",
        "authorids": [
            "~Caixing_Wang1",
            "~Ziliang_Shen1"
        ],
        "abstract": "In this paper, we focus on distributed estimation and support recovery for high-dimensional linear quantile regression. Quantile regression is a popular alternative tool to the least squares regression for robustness against outliers and data heterogeneity. However, the non-smoothness of the check loss function poses big challenges to both computation and theory in the distributed setting. To tackle these problems, we transform the original quantile regression into the least-squares optimization. By applying a double-smoothing approach, we extend a previous Newton-type distributed approach without the restrictive independent assumption between the error term and covariates. An efficient algorithm is developed, which enjoys high computation and communication efficiency. Theoretically, the proposed distributed estimator achieves a near-oracle convergence rate and high support recovery accuracy after a constant number of iterations. Extensive experiments on synthetic examples and a real data application further demonstrate the effectiveness of the proposed method.",
        "_bibtex": "@inproceedings{\nwang2024distributed,\ntitle={Distributed High-Dimensional Quantile Regression: Estimation Efficiency and Support Recovery},\nauthor={Caixing Wang and Ziliang Shen},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=PDUQRBPkks}\n}"
    },
    {
        "title": "A Theory of Fault-Tolerant Learning",
        "authorids": [
            "~Changlong_Wu1",
            "~Yifan_Wang14",
            "~Ananth_Grama1"
        ],
        "abstract": "Developing machine learning models that account for potential faults encountered in real-world environments presents a fundamental challenge for mission-critical applications. In this paper, we introduce a novel theoretical framework grounded in learning theory for dealing with faults. In particular, we propose a framework called *fault-tolerant PAC learning*, aimed at identifying the most fault-tolerant models from a given hypothesis class (such as neural networks). We show that if faults occur randomly, fault-tolerant learning is equivalent to regular PAC learning. However, for *adversarial* faults, we show that the sample complexity of fault-tolerant PAC learning can grow linearly w.r.t. the number of perturbing functions induced by the faults, even for a hypothesis class with VC-dimension 1. We then provide a matching upper bound by restricting the number of perturbing functions. Finally, we show that the linear dependency on the number of perturbing functions can be substantially improved for *deletion faults* in neural networks. Our work provides a powerful formal framework and avenues for a number of future investigations on the precise characterization of fault-tolerant learning.",
        "_bibtex": "@inproceedings{\nwu2024a,\ntitle={A Theory of Fault-Tolerant Learning},\nauthor={Changlong Wu and Yifan Wang and Ananth Grama},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=ooh8tkXKyR}\n}"
    },
    {
        "title": "Faithfulness Measurable Masked Language Models",
        "authorids": [
            "~Andreas_Madsen1",
            "~Siva_Reddy1",
            "~Sarath_Chandar1"
        ],
        "abstract": "A common approach to explaining NLP models is to use importance measures that express which tokens are important for a prediction. Unfortunately, such explanations are often wrong despite being persuasive. Therefore, it is essential to measure their faithfulness. One such metric is if tokens are truly important, then masking them should result in worse model performance. However, token masking introduces out-of-distribution issues, and existing solutions that address this are computationally expensive and employ proxy models. Furthermore, other metrics are very limited in scope. This work proposes an inherently faithfulness measurable model that addresses these challenges. This is achieved using a novel fine-tuning method that incorporates masking, such that masking tokens become in-distribution by design. This differs from existing approaches, which are completely model-agnostic but are inapplicable in practice. We demonstrate the generality of our approach by applying it to 16 different datasets and validate it using statistical in-distribution tests. The faithfulness is then measured with 9 different importance measures. Because masking is in-distribution, importance measures that themselves use masking become consistently more faithful. Additionally, because the model makes faithfulness cheap to measure, we can optimize explanations towards maximal faithfulness; thus, our model becomes indirectly inherently explainable.",
        "_bibtex": "@inproceedings{\nmadsen2024faithfulness,\ntitle={Faithfulness Measurable Masked Language Models},\nauthor={Andreas Madsen and Siva Reddy and Sarath Chandar},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=tw1PwpuAuN}\n}"
    },
    {
        "title": "End-to-End Neuro-Symbolic Reinforcement Learning with Textual Explanations",
        "authorids": [
            "~Lirui_Luo1",
            "~Guoxi_Zhang1",
            "~Hongming_Xu2",
            "~Yaodong_Yang1",
            "~Cong_Fang1",
            "~Qing_Li1"
        ],
        "abstract": "Neuro-symbolic reinforcement learning (NS-RL) has emerged as a promising paradigm for explainable decision-making, characterized by the interpretability of symbolic policies. NS-RL entails structured state representations for tasks with visual observations, but previous methods cannot refine the structured states with rewards due to a lack of efficiency. Accessibility also remains an issue, as extensive domain knowledge is required to interpret symbolic policies. In this paper, we present a neuro-symbolic framework for jointly learning structured states and symbolic policies, whose key idea is to distill the vision foundation model into an efficient perception module and refine it during policy learning. Moreover, we design a pipeline to prompt GPT-4 to generate textual explanations for the learned policies and decisions, significantly reducing users' cognitive load to understand the symbolic policies. We verify the efficacy of our approach on nine Atari tasks and present GPT-generated explanations for policies and decisions.",
        "_bibtex": "@inproceedings{\nluo2024endtoend,\ntitle={End-to-End Neuro-Symbolic Reinforcement Learning with Textual Explanations},\nauthor={Lirui Luo and Guoxi Zhang and Hongming Xu and Yaodong Yang and Cong Fang and Qing Li},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=0P3kaNluGj}\n}"
    },
    {
        "title": "PriorBoost: An Adaptive Algorithm for Learning from Aggregate Responses",
        "authorids": [
            "~Adel_Javanmard1",
            "~Matthew_Fahrbach1",
            "~Vahab_Mirrokni2"
        ],
        "abstract": "This work studies algorithms for learning from aggregate responses. We focus on the construction of aggregation sets (called *bags* in the literature) for event-level loss functions. We prove for linear regression and generalized linear models (GLMs) that the optimal bagging problem reduces to one-dimensional size-constrained $k$-means clustering. Further, we theoretically quantify the advantage of using curated bags over random bags. We then propose the $\\texttt{PriorBoost}$ algorithm, which adaptively forms bags of samples that are increasingly homogeneous with respect to (unobserved) individual responses to improve model quality. We study label differential privacy for aggregate learning, and we also provide extensive experiments showing that $\\texttt{PriorBoost}$ regularly achieves optimal model quality for event-level predictions, in stark contrast to non-adaptive algorithms.",
        "_bibtex": "@inproceedings{\njavanmard2024priorboost,\ntitle={PriorBoost: An Adaptive Algorithm for Learning from Aggregate Responses},\nauthor={Adel Javanmard and Matthew Fahrbach and Vahab Mirrokni},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=qawwyKqOkj}\n}"
    },
    {
        "title": "InterpreTabNet: Distilling Predictive Signals from Tabular Data by Salient Feature Interpretation",
        "abstract": "Tabular data are omnipresent in various sectors of industries. Neural networks for tabular data such as TabNet have been proposed to make predictions while leveraging the attention mechanism for interpretability. However, the inferred attention masks are often dense, making it challenging to come up with rationales about the predictive signal. To remedy this, we propose InterpreTabNet, a variant of the TabNet model that models the attention mechanism as a latent variable sampled from a Gumbel-Softmax distribution. This enables us to regularize the model to learn distinct concepts in the attention masks via a KL Divergence regularizer. It prevents overlapping feature selection by promoting sparsity which maximizes the model's efficacy and improves interpretability to determine the important features when predicting the outcome. To assist in the interpretation of feature interdependencies from our model, we employ a large language model (GPT-4) and use prompt engineering to map from the learned feature mask onto natural language text describing the learned signal. Through comprehensive experiments on real-world datasets, we demonstrate that InterpreTabNet outperforms previous methods for interpreting tabular data while attaining competitive accuracy.",
        "_bibtex": "@inproceedings{\nsi2024interpretabnet,\ntitle={InterpreTabNet: Distilling Predictive Signals from Tabular Data by Salient Feature Interpretation},\nauthor={Jacob Yoke Hong Si and Wendy Yusi Cheng and Michael Cooper and Rahul Krishnan},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=or8BQ4ohGb}\n}"
    },
    {
        "title": "By Tying Embeddings You Are Assuming the Distributional Hypothesis",
        "authorids": [
            "~Francesco_Bertolotti1",
            "~Walter_Cazzola1"
        ],
        "abstract": "In this work, we analyze both theoretically and empirically the effect of tied input-output embeddings\u2014a popular technique that reduces the model size while often improving training. Interestingly, we found that this technique is connected to Harris (1954)\u2019s distributional hypothesis\u2014often portrayed by the famous Firth (1957)\u2019s quote \u201ca word is characterized by the company it keeps\u201d. Specifically, our findings indicate that words (or, more broadly, symbols) with similar semantics tend to be encoded in similar input embeddings, while words that appear in similar contexts are encoded in similar output embeddings (thus explaining the semantic space arising in input and output embedding of foundational language models). As a consequence of these findings, the tying of the input and output embeddings is encouraged only when the distributional hypothesis holds for the underlying data. These results also provide insight into the embeddings of foundation language models (which are known to be semantically organized). Further, we complement the theoretical findings with several experiments supporting the claims.",
        "_bibtex": "@inproceedings{\nbertolotti2024by,\ntitle={By Tying Embeddings You Are Assuming the Distributional Hypothesis},\nauthor={Francesco Bertolotti and Walter Cazzola},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=yyYMAprcAR}\n}"
    },
    {
        "title": "BayOTIDE: Bayesian Online Multivariate Time Series Imputation with Functional Decomposition",
        "authorids": [
            "~Shikai_Fang2",
            "~Qingsong_Wen2",
            "~Yingtao_Luo1",
            "~Shandian_Zhe1",
            "~Liang_Sun2"
        ],
        "abstract": "In real-world scenarios such as traffic and energy management, we frequently encounter large volumes of time-series data characterized by missing values, noise, and irregular sampling patterns. While numerous imputation methods have been proposed, the majority tend to operate within a local horizon, which involves dividing long sequences into batches of fixed-length segments for model training. This local horizon often leads to the overlooking of global trends and periodic patterns. More importantly, most methods assume the observations are sampled at regular timestamps, and fail to handle complex irregular sampled time series in various applications. Additionally, most existing methods are learned in an offline manner. Thus, it is not suitable for applications with rapidly arriving streaming data. To address these challenges, we propose BayOTIDE: Bayesian Online Multivariate Time series Imputation with functional decomposition. Our method conceptualizes multivariate time series as the weighted combination of groups of low-rank temporal factors with different patterns. We employ a suite of Gaussian Processes (GPs),each with a unique kernel, as functional priors to model these factors. For computational efficiency, we further convert the GPs into a state-space prior by constructing an equivalent stochastic differential equation (SDE), and developing a scalable algorithm for online inference. The proposed method can not only handle imputation over arbitrary timestamps, but also offer uncertainty quantification and interpretability for the downstream application. We evaluate our method on both synthetic and real-world datasets. We release the code at https://github.com/xuangu-fang/BayOTIDE.",
        "_bibtex": "@inproceedings{\nfang2024bayotide,\ntitle={Bay{OTIDE}: Bayesian Online Multivariate Time Series Imputation with Functional Decomposition},\nauthor={Shikai Fang and Qingsong Wen and Yingtao Luo and Shandian Zhe and Liang Sun},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=aGBpiEcB8z}\n}"
    },
    {
        "title": "ACM-MILP: Adaptive Constraint Modification via Grouping and Selection for Hardness-Preserving MILP Instance Generation",
        "authorids": [
            "~Ziao_Guo1",
            "~Yang_Li32",
            "~Chang_Liu7",
            "~Wenli_Ouyang1",
            "~Junchi_Yan2"
        ],
        "abstract": "Data plays a pivotal role in the development of both classic and learning-based methods for Mixed-Integer Linear Programming (MILP). However, the scarcity of data in real-world applications underscores the necessity for MILP instance generation methods. Currently, these methods primarily rely on iterating random single-constraint modifications, disregarding the underlying problem structure with constraint interrelations, thereby leading to compromised quality and solvability. In this paper, we propose ACM-MILP, a framework for MILP instance generation, to achieve adaptive constraint modification and constraint interrelation modeling. It employs an adaptive constraint selection mechanism based on probability estimation within the latent space to preserve instance characteristics. Meanwhile, it detects and groups strongly related constraints through community detection, enabling collective modifications that account for constraint dependencies. Experimental results show significant improvements in problem-solving hardness similarity under our framework. Additionally, in the downstream task, we showcase the efficacy of our generated instances for hyperparameter tuning. Source code is available: https://github.com/Thinklab-SJTU/ACM-MILP.",
        "_bibtex": "@inproceedings{\nguo2024acmmilp,\ntitle={{ACM}-{MILP}: Adaptive Constraint Modification via Grouping and Selection for Hardness-Preserving {MILP} Instance Generation},\nauthor={Ziao Guo and Yang Li and Chang Liu and Wenli Ouyang and Junchi Yan},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=qDAAMmGsGw}\n}"
    },
    {
        "title": "How Uniform Random Weights Induce Non-uniform Bias: Typical Interpolating Neural Networks Generalize with Narrow Teachers",
        "authorids": [
            "~Gon_Buzaglo1",
            "~Itamar_Harel1",
            "~Mor_Shpigel_Nacson1",
            "~Alon_Brutzkus1",
            "~Nathan_Srebro1",
            "~Daniel_Soudry1"
        ],
        "abstract": "A main theoretical puzzle is why over-parameterized Neural Networks (NNs) generalize well when trained to zero loss (i.e., so they interpolate the data). Usually, the NN is trained with Stochastic Gradient Descent (SGD) or one of its variants. However, recent empirical work examined the generalization of a random NN that interpolates the data: the NN was sampled from a seemingly uniform prior over the parameters, conditioned on that the NN perfectly classifying the training set. Interestingly, such a NN sample typically generalized as well as SGD-trained NNs. We prove that such a random NN interpolator typically generalizes well if there exists an underlying narrow ``teacher NN\" that agrees with the labels. Specifically, we show that such a `flat' prior over the NN parametrization induces a rich prior over the NN functions, due to the redundancy in the NN structure. In particular, this creates a bias towards simpler functions, which require less relevant parameters to represent --- enabling learning with a sample complexity approximately proportional to the complexity of the teacher (roughly, the number of non-redundant parameters), rather than the student's.",
        "_bibtex": "@inproceedings{\nbuzaglo2024how,\ntitle={How Uniform Random Weights Induce Non-uniform Bias: Typical Interpolating Neural Networks Generalize with Narrow Teachers},\nauthor={Gon Buzaglo and Itamar Harel and Mor Shpigel Nacson and Alon Brutzkus and Nathan Srebro and Daniel Soudry},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=3eHNvPHL9Z}\n}"
    },
    {
        "title": "Optimal Acceleration for Minimax and Fixed-Point Problems is Not Unique",
        "authorids": [
            "~TaeHo_Yoon1",
            "~Jaeyeon_Kim2",
            "~Jaewook_J._Suh1",
            "~Ernest_K._Ryu1"
        ],
        "abstract": "Recently, accelerated algorithms using the anchoring mechanism for minimax optimization and fixed-point problems have been proposed, and matching complexity lower bounds establish their optimality. In this work, we present the surprising observation that the optimal acceleration mechanism in minimax optimization and fixed-point problems is not unique. Our new algorithms achieve exactly the same worst-case convergence rates as existing anchor-based methods while using materially different acceleration mechanisms. Specifically, these new algorithms are dual to the prior anchor-based accelerated methods in the sense of H-duality. This finding opens a new avenue of research on accelerated algorithms since we now have a family of methods that empirically exhibit varied characteristics while having the same optimal worst-case guarantee.",
        "_bibtex": "@inproceedings{\nyoon2024optimal,\ntitle={Optimal Acceleration for Minimax and Fixed-Point Problems is Not Unique},\nauthor={TaeHo Yoon and Jaeyeon Kim and Jaewook J. Suh and Ernest K. Ryu},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=ZeF75iQcAc}\n}"
    },
    {
        "title": "Nash Learning from Human Feedback",
        "authorids": [
            "~Remi_Munos1",
            "~Michal_Valko1",
            "~Daniele_Calandriello1",
            "~Mohammad_Gheshlaghi_Azar1",
            "~Mark_Rowland1",
            "~Zhaohan_Daniel_Guo1",
            "~Yunhao_Tang1",
            "~Matthieu_Geist1",
            "~Thomas_Mesnard2",
            "~C\u00f4me_Fiegel1",
            "~Andrea_Michi1",
            "~Marco_Selvi1",
            "~Sertan_Girgin1",
            "~Nikola_Momchev1",
            "~Olivier_Bachem1",
            "~Daniel_J_Mankowitz2",
            "~Doina_Precup1",
            "~Bilal_Piot1"
        ],
        "abstract": "Reinforcement learning from human feedback (RLHF) has emerged as the main paradigm for aligning large language models (LLMs) with human preferences. Traditionally, RLHF involves the initial step of learning a reward model from pairwise human feedback, i.e., expressed as preferences between pairs of text generations. Subsequently, the LLM's policy is fine-tuned to maximize the reward through a reinforcement learning algorithm. In this study, we introduce an alternative pipeline for the fine-tuning of LLMs using pairwise human feedback. Our approach entails the initial learning of a pairwise preference model, which is conditioned on two inputs (instead of a single input in the case of a reward model) given a prompt, followed by the pursuit of a policy that consistently generates responses preferred over those generated by any competing policy, thus defining the Nash equilibrium of this preference model. We term this approach Nash learning from human feedback (NLHF). In the context of a tabular policy representation, we present a novel algorithmic solution, Nash-MD, founded on the principles of mirror descent. This algorithm produces a sequence of policies, with the last iteration converging to the regularized Nash equilibrium. Additionally, we explore parametric representations of policies and introduce gradient descent algorithms for deep-learning architectures. We illustrate the effectiveness of our approach by presenting experimental results on a text summarization task. We believe NLHF offers a compelling avenue for fine-tuning LLMs and enhancing the alignment of LLMs with human preferences.",
        "_bibtex": "@inproceedings{\nmunos2024nash,\ntitle={Nash Learning from Human Feedback},\nauthor={Remi Munos and Michal Valko and Daniele Calandriello and Mohammad Gheshlaghi  Azar and Mark Rowland and Zhaohan Daniel Guo and Yunhao Tang and Matthieu Geist and Thomas Mesnard and C{\\^o}me Fiegel and Andrea Michi and Marco Selvi and Sertan Girgin and Nikola Momchev and Olivier Bachem and Daniel J Mankowitz and Doina Precup and Bilal Piot},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=Y5AmNYiyCQ}\n}"
    },
    {
        "title": "Size-invariance Matters: Rethinking Metrics and Losses for Imbalanced Multi-object Salient Object Detection",
        "authorids": [
            "~Feiran_Li3",
            "~Qianqian_Xu2",
            "~Shilong_Bao1",
            "~Zhiyong_Yang1",
            "~Runmin_Cong1",
            "~Xiaochun_Cao3",
            "~Qingming_Huang1"
        ],
        "abstract": "This paper explores the size-invariance of evaluation metrics in Salient Object Detection (SOD), especially when multiple targets of diverse sizes co-exist in the same image. We observe that current metrics are size-sensitive, where larger objects are focused, and smaller ones tend to be ignored. We argue that the evaluation should be size-invariant because bias based on size is unjustified without additional semantic information. In pursuit of this, we propose a generic approach that evaluates each salient object separately and then combines the results, effectively alleviating the imbalance. We further develop an optimization framework tailored to this goal, achieving considerable improvements in detecting objects of different sizes. Theoretically, we provide evidence supporting the validity of our new metrics and present the generalization analysis of SOD. Extensive experiments demonstrate the effectiveness of our method.",
        "_bibtex": "@inproceedings{\nli2024sizeinvariance,\ntitle={Size-invariance Matters: Rethinking Metrics and Losses for Imbalanced Multi-object Salient Object Detection},\nauthor={Feiran Li and Qianqian Xu and Shilong Bao and Zhiyong Yang and Runmin Cong and Xiaochun Cao and Qingming Huang},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=4HCi7JGCZk}\n}"
    },
    {
        "title": "Closing the Gap: Achieving Global Convergence (Last Iterate) of Actor-Critic under Markovian Sampling with Neural Network Parametrization",
        "authorids": [
            "~Mudit_Gaur1",
            "~Amrit_Bedi1",
            "~Di_Wang1",
            "~Vaneet_Aggarwal1"
        ],
        "abstract": "The current state-of-the-art theoretical analysis of Actor-Critic (AC) algorithms significantly lags in addressing the practical aspects of AC implementations. This crucial gap needs bridging to bring the analysis in line with practical implementations of AC. To address this, we advocate for considering the MMCLG criteria: **M**ulti-layer neural network parametrization for actor/critic, **M**arkovian sampling, **C**ontinuous state-action spaces, the performance of the **L**ast iterate, and **G**lobal optimality. These aspects are practically significant and have been largely overlooked in existing theoretical analyses of AC algorithms. In this work, we address these gaps by providing the first comprehensive theoretical analysis of AC algorithms that encompasses all five crucial practical aspects (covers MMCLG criteria). We establish global convergence sample complexity bounds of $\\tilde{\\mathcal{O}}\\left( \\epsilon^{-3} \\right)$. We achieve this result through our novel use of the weak gradient domination property of MDP's and our unique analysis of the error in critic estimation.",
        "_bibtex": "@inproceedings{\ngaur2024closing,\ntitle={Closing the Gap: Achieving Global Convergence (Last Iterate) of Actor-Critic under Markovian Sampling with Neural Network Parametrization},\nauthor={Mudit Gaur and Amrit Bedi and Di Wang and Vaneet Aggarwal},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=rJxFvAs7pq}\n}"
    },
    {
        "title": "Vocabulary for Universal Approximation: A Linguistic Perspective of Mapping Compositions",
        "authorids": [
            "~Yongqiang_Cai1"
        ],
        "abstract": "In recent years, deep learning-based sequence modelings, such as language models, have received much attention and success, which pushes researchers to explore the possibility of transforming non-sequential problems into a sequential form. Following this thought, deep neural networks can be represented as composite functions of a sequence of mappings, linear or nonlinear, where each composition can be viewed as a word. However, the weights of linear mappings are undetermined and hence require an infinite number of words. In this article, we investigate the finite case and constructively prove the existence of a finite vocabulary $V$=$\\phi_i: \\mathbb{R}^d \\to \\mathbb{R}^d | i=1,...,n$ with $n=O(d^2)$ for the universal approximation. That is, for any continuous mapping $f: \\mathbb{R}^d \\to \\mathbb{R}^d$, compact domain $\\Omega$ and $\\varepsilon>0$, there is a sequence of mappings $\\phi_{i_1}, ..., \\phi_{i_m} \\in V, m \\in \\mathbb{Z}^+$, such that the composition $\\phi_{i_m} \\circ ... \\circ \\phi_{i_1} $ approximates $f$ on $\\Omega$ with an error less than $\\varepsilon$. Our results demonstrate an unusual approximation power of mapping compositions and motivate a novel compositional model for regular languages.",
        "_bibtex": "@inproceedings{\ncai2024vocabulary,\ntitle={Vocabulary for Universal Approximation: A Linguistic Perspective of Mapping Compositions},\nauthor={Yongqiang Cai},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=PnyYgWMMwj}\n}"
    },
    {
        "title": "Pricing with Contextual Elasticity and Heteroscedastic Valuation",
        "authorids": [
            "~Jianyu_Xu1",
            "~Yu-Xiang_Wang1"
        ],
        "abstract": "We study an online contextual dynamic pricing problem, where customers decide whether to purchase a product based on its features and price. We introduce a novel approach to modeling a customer's expected demand by incorporating feature-based price elasticity, which can be equivalently represented as a valuation with heteroscedastic noise. To solve the problem, we propose a computationally efficient algorithm called \"Pricing with Perturbation (PwP)\", which enjoys an $O(\\sqrt{dT\\log T})$ regret while allowing arbitrary adversarial input context sequences. We also prove a matching lower bound at $\\Omega(\\sqrt{dT})$ to show the optimality regarding $d$ and $T$ (up to $\\log T$ factors). Our results shed light on the relationship between contextual elasticity and heteroscedastic valuation, providing insights for effective and practical pricing strategies.",
        "_bibtex": "@inproceedings{\nxu2024pricing,\ntitle={Pricing with Contextual Elasticity and Heteroscedastic Valuation},\nauthor={Jianyu Xu and Yu-Xiang Wang},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=51gXk4BISH}\n}"
    },
    {
        "title": "QBMK: Quantum-based Matching Kernels for Un-attributed Graphs",
        "authorids": [
            "~Lu_Bai3",
            "cuilixin@cufe.edu.cn",
            "~Ming_Li15",
            "~Yue_Wang41",
            "~Edwin_Hancock1"
        ],
        "abstract": "In this work, we develop a new Quantum-based Matching Kernel (QBMK) for un-attributed graphs, by computing the kernel-based similarity between the quantum Shannon entropies of aligned vertices through the Continuous-time Quantum Walk (CTQW). The theoretical analysis reveals that the proposed QBMK kernel not only addresses the shortcoming of neglecting the structural correspondence information between graphs arising in existing R-convolution graph kernels, but also overcomes the problem of neglecting the structural differences between pairs of aligned vertices arising in existing vertex-based matching kernels. Moreover, the proposed QBMK kernel can simultaneously capture both global and local structural characteristics through the quantum Shannon entropies. Experimental evaluations on standard graph datasets demonstrate that the proposed QBMK kernel is able to outperform state-of-the-art graph kernels and graph deep learning approaches.",
        "_bibtex": "@inproceedings{\nbai2024qbmk,\ntitle={{QBMK}: Quantum-based Matching Kernels for Un-attributed Graphs},\nauthor={Lu Bai and Lixin Cui and Ming Li and Yue Wang and Edwin Hancock},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=PYDCwWvbG7}\n}"
    },
    {
        "title": "Sample-specific Masks for Visual Reprogramming-based Prompting",
        "authorids": [
            "~Chengyi_Cai2",
            "~Zesheng_Ye1",
            "~Lei_Feng1",
            "~Jianzhong_Qi1",
            "~Feng_Liu2"
        ],
        "abstract": "*Visual reprogramming* (VR) is a prompting technique that aims to re-purpose a pre-trained model (e.g., a classifier on ImageNet) to target tasks (e.g., medical data prediction) by learning a *small-scale pattern* added into input images instead of tuning considerable parameters within the model. The location of the pattern within input samples is usually determined by a pre-defined mask *shared across all samples*. In this paper, we show that the shared mask potentially limits VR's generalization and increases its approximation error due to the lack of sample-level adaptation. Motivated by this finding, we design a new framework for VR called *sample-specific multi-channel masks* (SMM). Specifically, SMM employs a lightweight ConvNet and patch-wise interpolation to generate sample-specific three-channel masks instead of a shared and pre-defined mask. Since we generate different masks for individual samples, SMM is theoretically shown to reduce approximation error for the target tasks compared with existing state-of-the-art VR methods. We also empirically demonstrate its performance gain on both ResNet and ViT. The success of SMM further highlights the broader applicability of VR in leveraging the latent knowledge of pre-trained models for various target tasks. Our code is available at https://github.com/tmlr-group/SMM.",
        "_bibtex": "@inproceedings{\ncai2024samplespecific,\ntitle={Sample-specific Masks for Visual Reprogramming-based Prompting},\nauthor={Chengyi Cai and Zesheng Ye and Lei Feng and Jianzhong Qi and Feng Liu},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=4sikyurTLX}\n}"
    },
    {
        "title": "Self-Alignment of Large Language Models via Monopolylogue-based Social Scene Simulation",
        "authorids": [
            "~Xianghe_Pang1",
            "~Shuo_Tang2",
            "~Rui_Ye1",
            "~Yuxin_Xiong1",
            "~Bolun_Zhang2",
            "~Yanfeng_Wang1",
            "~Siheng_Chen1"
        ],
        "abstract": "Aligning large language models (LLMs) with human values is imperative to mitigate potential adverse effects resulting from their misuse. Drawing from the sociological insight that acknowledging all parties' concerns is a key factor in shaping human values, this paper proposes a novel direction to align LLMs by themselves: social scene simulation. To achieve this, we present MATRIX, a novel social scene simulator that emulates realistic scenes around a user's input query, enabling the LLM to take social consequences into account before responding. MATRIX serves as a virtual rehearsal space, akin to a Monopolylogue, where the LLM performs diverse roles related to the query and practice by itself. To inject this alignment, we fine-tune the LLM with MATRIX-simulated data, ensuring adherence to human values without compromising inference speed. We theoretically show that the LLM with MATRIX outperforms existing methods under mild assumptions. Finally, extensive experiments validate that our method outperforms over 10 baselines across 4 benchmarks. As evidenced by 875 user ratings, our tuned 13B-size LLM exceeds GPT-4 in aligning with human values. See our project page at https://shuotang123.github.io/MATRIX.",
        "_bibtex": "@inproceedings{\npang2024selfalignment,\ntitle={Self-Alignment of Large Language Models via Monopolylogue-based Social Scene Simulation},\nauthor={Xianghe Pang and Shuo Tang and Rui Ye and Yuxin Xiong and Bolun Zhang and Yanfeng Wang and Siheng Chen},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=l7shXGuGBT}\n}"
    },
    {
        "title": "Learning Decision Trees and Forests with Algorithmic Recourse",
        "authorids": [
            "~Kentaro_Kanamori1",
            "~Takuya_Takagi1",
            "~Ken_Kobayashi1",
            "~Yuichi_Ike1"
        ],
        "abstract": "This paper proposes a new algorithm for learning accurate tree-based models while ensuring the existence of recourse actions. Algorithmic Recourse (AR) aims to provide a recourse action for altering the undesired prediction result given by a model. Typical AR methods provide a reasonable action by solving an optimization task of minimizing the required effort among executable actions. In practice, however, such actions do not always exist for models optimized only for predictive performance. To alleviate this issue, we formulate the task of learning an accurate classification tree under the constraint of ensuring the existence of reasonable actions for as many instances as possible. Then, we propose an efficient top-down greedy algorithm by leveraging the adversarial training techniques. We also show that our proposed algorithm can be applied to the random forest, which is known as a popular framework for learning tree ensembles. Experimental results demonstrated that our method successfully provided reasonable actions to more instances than the baselines without significantly degrading accuracy and computational efficiency.",
        "_bibtex": "@inproceedings{\nkanamori2024learning,\ntitle={Learning Decision Trees and Forests with Algorithmic Recourse},\nauthor={Kentaro Kanamori and Takuya Takagi and Ken Kobayashi and Yuichi Ike},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=blGpu9aGs6}\n}"
    },
    {
        "title": "On Stronger Computational Separations Between Multimodal and Unimodal Machine Learning",
        "authorids": [
            "~Ari_Karchmer1"
        ],
        "abstract": "Recently, multimodal machine learning has enjoyed huge empirical success (e.g. GPT-4). Motivated to develop theoretical justification for this empirical success, Lu (NeurIPS '23, ALT '24) introduces a theory of multimodal learning, and considers possible *separations* between theoretical models of multimodal and unimodal learning. In particular, Lu (ALT '24) shows a computational separation, which is relevant to *worst-case* instances of the learning task. In this paper, we give a stronger *average-case* computational separation, where for \"typical\" instances of the learning task, unimodal learning is computationally hard, but multimodal learning is easy. We then question how \"natural\" the average-case separation is. Would it be encountered in practice? To this end, we prove that under basic conditions, any given computational separation between average-case unimodal and multimodal learning tasks implies a corresponding cryptographic key agreement protocol. We suggest to interpret this as evidence that very strong *computational* advantages of multimodal learning may arise *infrequently* in practice, since they exist only for the \"pathological\" case of inherently cryptographic distributions. However, this does not apply to possible (super-polynomial) *statistical* advantages.",
        "_bibtex": "@inproceedings{\nkarchmer2024on,\ntitle={On Stronger Computational Separations Between Multimodal and Unimodal Machine Learning},\nauthor={Ari Karchmer},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=8Z2xWhuT6R}\n}"
    },
    {
        "title": "Efficient Precision and Recall Metrics for Assessing Generative Models using Hubness-aware Sampling",
        "authorids": [
            "~Yuanbang_Liang1",
            "~Jing_Wu3",
            "~Yu-Kun_Lai1",
            "~Yipeng_Qin1"
        ],
        "abstract": "Despite impressive results, deep generative models require massive datasets for training, and as dataset size increases, effective evaluation metrics like precision and recall (P&R) become computationally infeasible on commodity hardware. In this paper, we address this challenge by proposing efficient P&R (eP&R) metrics that give almost identical results as the original P&R but with much lower computational costs. Specifically, we identify two redundancies in the original P&R: i) redundancy in ratio computation and ii) redundancy in manifold inside/outside identification. We find both can be effectively removed via hubness-aware sampling, which extracts representative elements from synthetic/real image samples based on their hubness values, i.e., the number of times a sample becomes a k-nearest neighbor to others in the feature space. Thanks to the insensitivity of hubness-aware sampling to exact k-nearest neighbor (k-NN) results, we further improve the efficiency of our eP&R metrics by using approximate k-NN methods. Extensive experiments show that our eP&R matches the original P&R but is far more efficient in time and space. Our code is available at: https://github.com/Byronliang8/Hubness_Precision_Recall",
        "_bibtex": "@inproceedings{\nliang2024efficient,\ntitle={Efficient Precision and Recall Metrics for Assessing Generative Models using Hubness-aware Sampling},\nauthor={Yuanbang Liang and Jing Wu and Yu-Kun Lai and Yipeng Qin},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=jnps5YwNlU}\n}"
    },
    {
        "title": "Quasi-Monte Carlo Features for Kernel Approximation",
        "authorids": [
            "~Zhen_Huang7",
            "~Jiajin_Sun1",
            "~Yian_Huang1"
        ],
        "abstract": "Random features (Rahimi & Recht, 2007), based on Monte Carlo (MC) method, is one of the most popular approximation techniques to accelerate kernel methods. We show for a class of kernels, including Gaussian kernels, quasi-Monte Carlo (QMC) methods can be used in place of MC to improve the approximation error from $O_P(1/\\sqrt{M})$ to $O(1/M)$ (up to logarithmic factors), for estimating both the kernel function itself and the associated integral operator, where $M$ is the number of features being used. Furthermore, we demonstrate the advantage of QMC features in the case of kernel ridge regression, where theoretically, fewer random features suffice to guarantee the same convergence rate of the excess risk. In practice, the QMC kernel approximation approach is easily implementable and shows superior performance, as supported by the empirical evidence provided in the paper.",
        "_bibtex": "@inproceedings{\nhuang2024quasimonte,\ntitle={Quasi-Monte Carlo Features for Kernel Approximation},\nauthor={Zhen Huang and Jiajin Sun and Yian Huang},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=gSMUjrkRRk}\n}"
    },
    {
        "title": "Agnostic Sample Compression Schemes for Regression",
        "authorids": [
            "~Idan_Attias1",
            "~Steve_Hanneke1",
            "~Aryeh_Kontorovich1",
            "~Menachem_Sadigurschi1"
        ],
        "abstract": "We obtain the first positive results for bounded sample compression in the agnostic regression setting with the $\\ell_p$ loss, where $p\\in [1,\\infty]$. We construct a generic approximate sample compression scheme for real-valued function classes exhibiting exponential size in the fat-shattering dimension but independent of the sample size. Notably, for linear regression, an approximate compression of size linear in the dimension is constructed. Moreover, for $\\ell_1$ and $\\ell_\\infty$ losses, we can even exhibit an efficient exact sample compression scheme of size linear in the dimension. We further show that for every other $\\ell_p$ loss, $p\\in (1,\\infty)$, there does not exist an exact agnostic compression scheme of bounded size. This refines and generalizes a negative result of David, Moran, and Yehudayoff (2016) for the $\\ell_2$ loss. We close by posing general open questions: for agnostic regression with $\\ell_1$ loss, does every function class admit an exact compression scheme of polynomial size in the pseudo-dimension? For the $\\ell_2$ loss, does every function class admit an approximate compression scheme of polynomial size in the fat-shattering dimension? These questions generalize Warmuth's classic sample compression conjecture for realizable-case classification (Warmuth, 2003).",
        "_bibtex": "@inproceedings{\nattias2024agnostic,\ntitle={Agnostic Sample Compression Schemes for Regression},\nauthor={Idan Attias and Steve Hanneke and Aryeh Kontorovich and Menachem Sadigurschi},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=71ktaA3ihI}\n}"
    },
    {
        "title": "Behavior Generation with Latent Actions",
        "authorids": [
            "~Seungjae_Lee2",
            "~Yibin_Wang1",
            "~Haritheja_Etukuru1",
            "~H._Jin_Kim1",
            "~Nur_Muhammad_Mahi_Shafiullah1",
            "~Lerrel_Pinto1"
        ],
        "abstract": "Generative modeling of complex behaviors from labeled datasets has been a longstanding problem in decision-making. Unlike language or image generation, decision-making requires modeling actions \u2013 continuous-valued vectors that are multimodal in their distribution, potentially drawn from uncurated sources, where generation errors can compound in sequential prediction. A recent class of models called Behavior Transformers (BeT) addresses this by discretizing actions using k-means clustering to capture different modes. However, k-means struggles to scale for high-dimensional action spaces or long sequences, and lacks gradient information, and thus BeT suffers in modeling long-range actions. In this work, we present Vector-Quantized Behavior Transformer (VQ-BeT), a versatile model for behavior generation that handles multimodal action prediction, conditional generation, and partial observations. VQ-BeT augments BeT by tokenizing continuous actions with a hierarchical vector quantization module. Across seven environments including simulated manipulation, autonomous driving, and robotics, VQ-BeT improves on state-of-the-art models such as BeT and Diffusion Policies. Importantly, we demonstrate VQ-BeT\u2019s improved ability to capture behavior modes while accelerating inference speed 5\u00d7 over Diffusion Policies. Videos can be found https://sjlee.cc/vq-bet/",
        "_bibtex": "@inproceedings{\nlee2024behavior,\ntitle={Behavior Generation with Latent Actions},\nauthor={Seungjae Lee and Yibin Wang and Haritheja Etukuru and H. Jin Kim and Nur Muhammad Mahi Shafiullah and Lerrel Pinto},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=hoVwecMqV5}\n}"
    },
    {
        "title": "Individual Fairness in Graph Decomposition",
        "authorids": [
            "~Kamesh_Munagala2",
            "~Govind_S._Sankar1"
        ],
        "abstract": "In this paper, we consider classic randomized low diameter decomposition procedures for planar graphs that obtain connected clusters that are cohesive in that close by pairs of nodes are assigned to the same cluster with high probability. We consider the additional aspect of *individual fairness* -- pairs of nodes at comparable distances should be separated with comparable probability. We show that classic decomposition procedures do not satisfy this property. We present novel algorithms that achieve various trade-offs between this property and additional desiderata of connectivity of the clusters and optimality in number of clusters. We show that our individual fairness bounds may be difficult to improve by tying the improvement to resolving a major open question in metric embeddings. We finally show the efficacy of our algorithms on real planar networks modeling Congressional redistricting.",
        "_bibtex": "@inproceedings{\nmunagala2024individual,\ntitle={Individual Fairness in Graph Decomposition},\nauthor={Kamesh Munagala and Govind S. Sankar},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=8f8SI9X9ox}\n}"
    },
    {
        "title": "Position: Amazing Things Come From Having Many Good Models",
        "authorids": [
            "~Cynthia_Rudin1",
            "~Chudi_Zhong1",
            "~Lesia_Semenova1",
            "~Margo_Seltzer1",
            "~Ronald_Parr1",
            "~Jiachang_Liu1",
            "~Srikar_Katta1",
            "~Jon_Donnelly1",
            "~Harry_Chen2",
            "~Zachery_Boner1"
        ],
        "abstract": "The *Rashomon Effect*, coined by Leo Breiman, describes the phenomenon that there exist many equally good predictive models for the same dataset. This phenomenon happens for many real datasets and when it does, it sparks both magic and consternation, but mostly magic. In light of the Rashomon Effect, this perspective piece proposes reshaping the way we think about machine learning, particularly for tabular data problems in the nondeterministic (noisy) setting. We address how the Rashomon Effect impacts (1) the existence of simple-yet-accurate models, (2) flexibility to address user preferences, such as fairness and monotonicity, without losing performance, (3) uncertainty in predictions, fairness, and explanations, (4) reliable variable importance, (5) algorithm choice, specifically, providing advanced knowledge of which algorithms might be suitable for a given problem, and (6) public policy. We also discuss a theory of when the Rashomon Effect occurs and why. Our goal is to illustrate how the Rashomon Effect can have a massive impact on the use of machine learning for complex problems in society.",
        "_bibtex": "@inproceedings{\nrudin2024position,\ntitle={Position: Amazing Things Come From Having Many Good Models},\nauthor={Cynthia Rudin and Chudi Zhong and Lesia Semenova and Margo Seltzer and Ronald Parr and Jiachang Liu and Srikar Katta and Jon Donnelly and Harry Chen and Zachery Boner},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=oFDFGd9Age}\n}"
    },
    {
        "title": "The Perception-Robustness Tradeoff in Deterministic Image Restoration",
        "authorids": [
            "~Guy_Ohayon1",
            "~Tomer_Michaeli1",
            "~Michael_Elad1"
        ],
        "abstract": "We study the behavior of deterministic methods for solving inverse problems in imaging. These methods are commonly designed to achieve two goals: (1) attaining high perceptual quality, and (2) generating reconstructions that are consistent with the measurements. We provide a rigorous proof that the better a predictor satisfies these two requirements, the larger its Lipschitz constant must be, regardless of the nature of the degradation involved. In particular, to approach perfect perceptual quality and perfect consistency, the Lipschitz constant of the model must grow to infinity. This implies that such methods are necessarily more susceptible to adversarial attacks. We demonstrate our theory on single image super-resolution algorithms, addressing both noisy and noiseless settings. We also show how this undesired behavior can be leveraged to explore the posterior distribution, thereby allowing the deterministic model to imitate stochastic methods.",
        "_bibtex": "@inproceedings{\nohayon2024the,\ntitle={The Perception-Robustness Tradeoff in Deterministic Image Restoration},\nauthor={Guy Ohayon and Tomer Michaeli and Michael Elad},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=jQA5iutPzd}\n}"
    },
    {
        "title": "Sparse is Enough in Fine-tuning Pre-trained Large Language Models",
        "authorids": [
            "~Weixi_Song2",
            "~Zuchao_Li1",
            "~Lefei_Zhang1",
            "~hai_zhao1",
            "~Bo_Du3"
        ],
        "abstract": "With the prevalence of pre-training-fine-tuning paradigm, how to efficiently adapt the pre-trained model to the downstream tasks has been an intriguing issue. $\\textbf{P}$arameter-$\\textbf{E}$fficient $\\textbf{F}$ine-$\\textbf{T}$uning(PEFT) methods have been proposed  for low-cost adaptation. Although PEFT has demonstrated effectiveness and been widely applied, the underlying principles are still unclear. In this paper, we adopt the PAC-Bayesian generalization error bound, viewing pre-training as a shift of prior distribution which leads to a tighter bound for generalization error. We validate this shift from the perspectives of oscillations in the loss landscape and the quasi-sparsity in gradient distribution. Based on this, we propose a gradient-based sparse fine-tuning algorithm, named $\\textbf{S}$parse $\\textbf{I}$ncrement $\\textbf{F}$ine-$\\textbf{T}$uning(SIFT), and validate its effectiveness on a range of tasks including the GLUE Benchmark and Instruction-tuning. The code is accessible at https://github.com/song-wx/SIFT/.",
        "_bibtex": "@inproceedings{\nsong2024sparse,\ntitle={Sparse is Enough in Fine-tuning Pre-trained Large Language Models},\nauthor={Weixi Song and Zuchao Li and Lefei Zhang and hai zhao and Bo Du},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=10hu2D3hAg}\n}"
    },
    {
        "title": "Position: The No Free Lunch Theorem, Kolmogorov Complexity, and the Role of Inductive Biases in Machine Learning",
        "authorids": [
            "~Micah_Goldblum1",
            "~Marc_Anton_Finzi1",
            "~Keefer_Rowan1",
            "~Andrew_Gordon_Wilson1"
        ],
        "abstract": "No free lunch theorems for supervised learning state that no learner can solve all problems or that all learners achieve exactly the same accuracy on average over a uniform distribution on learning problems. Accordingly, these theorems are often referenced in support of the notion that individual problems require specially tailored inductive biases. While virtually all uniformly sampled datasets have high complexity, real-world problems disproportionately generate low-complexity data, and we argue that neural network models share this same preference, formalized using Kolmogorov complexity. Notably, we show that architectures designed for a particular domain, such as computer vision, can compress datasets on a variety of seemingly unrelated domains. Our experiments show that pre-trained and even randomly initialized language models prefer to generate low-complexity sequences. Whereas no free lunch theorems seemingly indicate that individual problems require specialized learners, we explain how tasks that often require human intervention such as picking an appropriately sized model when labeled data is scarce or plentiful can be automated into a single learning algorithm. These observations justify the trend in deep learning of unifying seemingly disparate problems with an increasingly small set of machine learning models.",
        "_bibtex": "@inproceedings{\ngoldblum2024position,\ntitle={Position Paper: The No Free Lunch Theorem, Kolmogorov Complexity, and the Role of Inductive Biases in Machine Learning},\nauthor={Micah Goldblum and Marc Anton Finzi and Keefer Rowan and Andrew Gordon Wilson},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=EaJ7nqJ2Fa}\n}"
    },
    {
        "title": "Learning-Rate-Free Stochastic Optimization over Riemannian Manifolds",
        "authorids": [
            "~Daniel_Dodd1",
            "~Louis_Sharrock1",
            "~Christopher_Nemeth1"
        ],
        "abstract": "In recent years, interest in gradient-based optimization over Riemannian manifolds has surged. However, a significant challenge lies in the reliance on hyperparameters, especially the learning rate, which requires meticulous tuning by practitioners to ensure convergence at a suitable rate. In this work, we introduce innovative learning-rate-free algorithms for stochastic optimization over Riemannian manifolds, eliminating the need for hand-tuning and providing a more robust and user-friendly approach. We establish high probability convergence guarantees that are optimal, up to logarithmic factors, compared to the best-known optimally tuned rate in the deterministic setting. Our approach is validated through numerical experiments, demonstrating competitive performance against learning-rate-dependent algorithms.",
        "_bibtex": "@inproceedings{\ndodd2024learningratefree,\ntitle={Learning-Rate-Free Stochastic Optimization over Riemannian Manifolds},\nauthor={Daniel Dodd and Louis Sharrock and Christopher Nemeth},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=eY98MVffrD}\n}"
    },
    {
        "title": "TravelPlanner: A Benchmark for Real-World Planning with Language Agents",
        "authorids": [
            "~Jian_Xie3",
            "~Kai_Zhang10",
            "~Jiangjie_Chen1",
            "~Tinghui_Zhu1",
            "~Renze_Lou1",
            "~Yuandong_Tian1",
            "~Yanghua_Xiao1",
            "~Yu_Su2"
        ],
        "abstract": "Planning has been part of the core pursuit for artificial intelligence since its conception, but earlier AI agents mostly focused on constrained settings because many of the cognitive substrates necessary for human-level planning have been lacking. Recently, language agents powered by large language models (LLMs) have shown interesting capabilities such as tool use and reasoning. Are these language agents capable of planning in more complex settings that are out of the reach of prior AI agents? To advance this investigation, we propose TravelPlanner, a new planning benchmark that focuses on travel planning, a common real-world planning scenario. It provides a rich sandbox environment, various tools for accessing nearly four million data records, and 1,225 meticulously curated planning intents and reference plans. Comprehensive evaluations show that the current language agents are not yet capable of handling such complex planning tasks\u2014even GPT-4 only achieves a success rate of 0.6%. Language agents struggle to stay on task, use the right tools to collect information, or keep track of multiple constraints. However, we note that the mere possibility for language agents to tackle such a complex problem is in itself non-trivial progress. TravelPlanner provides a challenging yet meaningful testbed for future language agents.",
        "_bibtex": "@inproceedings{\nxie2024travelplanner,\ntitle={TravelPlanner: A Benchmark for Real-World Planning with Language Agents},\nauthor={Jian Xie and Kai Zhang and Jiangjie Chen and Tinghui Zhu and Renze Lou and Yuandong Tian and Yanghua Xiao and Yu Su},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=l5XQzNkAOe}\n}"
    },
    {
        "title": "Generalization in Kernel Regression Under Realistic Assumptions",
        "authorids": [
            "~Daniel_Barzilai1",
            "~Ohad_Shamir1"
        ],
        "abstract": "It is by now well-established that modern over-parameterized models seem to elude the bias-variance tradeoff and generalize well despite overfitting noise. Many recent works attempt to analyze this phenomenon in the relatively tractable setting of kernel regression. However, as we argue in detail, most past works on this topic either make unrealistic assumptions, or focus on a narrow problem setup. This work aims to provide a unified theory to upper bound the excess risk of kernel regression for nearly all common and realistic settings. When applied to common kernels, our results imply benign overfitting in high input dimensions, nearly tempered overfitting in fixed dimensions, and explicit convergence rates for regularized regression. As a by-product, we obtain time-dependent bounds for neural networks trained in the kernel regime. Our results rely on new relative perturbation bounds for the eigenvalues of kernel matrices, which may be of independent interest. These reveal a self-regularization phenomenon, whereby a heavy tail in the eigendecomposition of the kernel implicitly leads to good generalization.",
        "_bibtex": "@inproceedings{\nbarzilai2024generalization,\ntitle={Generalization in Kernel Regression Under Realistic Assumptions},\nauthor={Daniel Barzilai and Ohad Shamir},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=PY3bKuorBI}\n}"
    },
    {
        "title": "Locally Estimated Global Perturbations are Better than Local Perturbations for Federated Sharpness-aware Minimization",
        "authorids": [
            "~Ziqing_Fan1",
            "~Shengchao_Hu1",
            "~Jiangchao_Yao1",
            "~Gang_Niu1",
            "~Ya_Zhang1",
            "~Masashi_Sugiyama1",
            "~Yanfeng_Wang1"
        ],
        "abstract": "In federated learning (FL), the multi-step update and data heterogeneity among clients often lead to a loss landscape with sharper minima, degenerating the performance of the resulted global model. Prevalent federated approaches incorporate sharpness-aware minimization (SAM) into local training to mitigate this problem. However, the local loss landscapes may not accurately reflect the flatness of global loss landscape in heterogeneous environments; as a result, minimizing local sharpness and calculating perturbations on client data might not align the efficacy of SAM in FL with centralized training. To overcome this challenge, we propose FedLESAM, a novel algorithm that locally estimates the direction of global perturbation on client side as the difference between global models received in the previous active and current rounds. Besides the improved quality, FedLESAM also speed up federated SAM-based approaches since it only performs once backpropagation in each iteration. Theoretically, we prove a slightly tighter bound than its original FedSAM by ensuring consistent perturbation. Empirically, we conduct comprehensive experiments on four federated benchmark datasets under three partition strategies to demonstrate the superior performance and efficiency of FedLESAM.",
        "_bibtex": "@inproceedings{\nfan2024locally,\ntitle={Locally Estimated Global Perturbations are Better than Local Perturbations for Federated Sharpness-aware Minimization},\nauthor={Ziqing Fan and Shengchao Hu and Jiangchao Yao and Gang Niu and Ya Zhang and Masashi Sugiyama and Yanfeng Wang},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=6axTFAlzRV}\n}"
    },
    {
        "title": "Designing Decision Support Systems using Counterfactual Prediction Sets",
        "authorids": [
            "~Eleni_Straitouri1",
            "~Manuel_Gomez_Rodriguez1"
        ],
        "abstract": "Decision support systems for classification tasks are predominantly designed to predict the value of the ground truth labels. However, since their predictions are not perfect, these systems also need to make human experts understand when and how to use these predictions to update their own predictions. Unfortunately, this has been proven challenging. In this context, it has been recently argued that an alternative type of decision support systems may circumvent this challenge. Rather than providing a single label prediction, these systems provide a set of label prediction values constructed using a conformal predictor, namely a prediction set, and forcefully ask experts to predict a label value from the prediction set. However, the design and evaluation of these systems have so far relied on stylized expert models, questioning their promise. In this paper, we revisit the design of this type of systems from the perspective of online learning and develop a methodology that does not require, nor assumes, an expert model. Our methodology leverages the nested structure of the prediction sets provided by any conformal predictor and a natural counterfactual monotonicity assumption to achieve an exponential improvement in regret in comparison to vanilla bandit algorithms. We conduct a large-scale human subject study ($n = 2{,}751$) to compare our methodology to several competitive baselines. The results show that, for decision support systems based on prediction sets, limiting experts\u2019 level of agency leads to greater performance than allowing experts to always exercise their own agency.",
        "_bibtex": "@inproceedings{\nstraitouri2024designing,\ntitle={Designing Decision Support Systems using Counterfactual Prediction Sets},\nauthor={Eleni Straitouri and Manuel Gomez Rodriguez},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=rqyXubsBhH}\n}"
    },
    {
        "title": "FiT: Flexible Vision Transformer for Diffusion Model",
        "authorids": [
            "~Zeyu_Lu1",
            "~ZiDong_Wang2",
            "~Di_Huang6",
            "~Chengyue_Wu1",
            "~Xihui_Liu1",
            "~Wanli_Ouyang1",
            "~LEI_BAI1"
        ],
        "abstract": "In the context of this reality, existing diffusion models, such as Diffusion Transformers, often face challenges when processing image resolutions outside of their trained domain. To overcome this limitation, we present the Flexible Vision Transformer (FiT), a transformer architecture specifically designed for generating images with unrestricted resolutions and aspect ratios. Unlike traditional methods that perceive images as static-resolution grids, FiT conceptualizes images as sequences of dynamically-sized tokens. This perspective enables a flexible training strategy that effortlessly adapts to diverse aspect ratios during both training and inference phases, thus promoting resolution generalization and eliminating biases induced by image cropping. Enhanced by a meticulously adjusted network structure and the integration of training-free extrapolation techniques, FiT exhibits remarkable flexibility in resolution extrapolation generation. Comprehensive experiments demonstrate the exceptional performance of FiT across a broad range of resolutions. Repository available at https://github.com/whlzy/FiT.",
        "_bibtex": "@inproceedings{\nlu2024fit,\ntitle={FiT: Flexible Vision Transformer for Diffusion Model},\nauthor={Zeyu Lu and ZiDong Wang and Di Huang and Chengyue Wu and Xihui Liu and Wanli Ouyang and LEI BAI},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=jZVen2JguY}\n}"
    },
    {
        "title": "Refined Coreset Selection: Towards Minimal Coreset Size under Model Performance Constraints",
        "authorids": [
            "~Xiaobo_Xia1",
            "~Jiale_Liu2",
            "~Shaokun_Zhang2",
            "~Qingyun_Wu2",
            "~Hongxin_Wei1",
            "~Tongliang_Liu1"
        ],
        "abstract": "Coreset selection is powerful in reducing computational costs and accelerating data processing for deep learning algorithms. It strives to identify a small subset from large-scale data, so that training only on the subset practically performs on par with full data. Practitioners regularly desire to identify the smallest possible coreset in realistic scenes while maintaining comparable model performance, to minimize costs and maximize acceleration. Motivated by this desideratum, for the first time, we pose the problem of refined coreset selection, in which the minimal coreset size under model performance constraints is explored. Moreover, to address this problem, we propose an innovative method, which maintains optimization priority order over the model performance and coreset size, and efficiently optimizes them in the coreset selection procedure. Theoretically, we provide the convergence guarantee of the proposed method. Empirically, extensive experiments confirm its superiority compared with previous strategies, often yielding better model performance with smaller coreset sizes. The implementation is available at https://github.com/xiaoboxia/LBCS.",
        "_bibtex": "@inproceedings{\nxia2024refined,\ntitle={Refined Coreset Selection: Towards Minimal Coreset Size under Model Performance Constraints},\nauthor={Xiaobo Xia and Jiale Liu and Shaokun Zhang and Qingyun Wu and Hongxin Wei and Tongliang Liu},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=yb5xV8LFDq}\n}"
    },
    {
        "title": "Finite Volume Features, Global Geometry Representations, and Residual Training for Deep Learning-based CFD Simulation",
        "authorids": [
            "~Loh_Sher_En_Jessica1",
            "~Naheed_Anjum_Arafat1",
            "~Wei_Xian_Lim2",
            "~Wai_Lee_Chan1",
            "~Adams_Wai-Kin_Kong1"
        ],
        "abstract": "Computational fluid dynamics (CFD) simulation is an irreplaceable modelling step in many engineering designs, but it is often computationally expensive. Some graph neural network (GNN)-based CFD methods have been proposed. However, the current methods inherit the weakness of traditional numerical simulators, as well as ignore the cell characteristics in the mesh used in the finite volume method, a common method in practical CFD applications. Specifically, the input nodes in these GNN methods have very limited information about any object immersed in the simulation domain and its surrounding environment. Also, the cell characteristics of the mesh such as cell volume, face surface area, and face centroid are not included in the message-passing operations in the GNN methods. To address these weaknesses, this work proposes two novel geometric representations: Shortest Vector (SV) and Directional Integrated Distance (DID). Extracted from the mesh, the SV and DID provide global geometry perspective to each input node, thus removing the need to collect this information through message-passing. This work also introduces the use of Finite Volume Features (FVF) in the graph convolutions as node and edge attributes, enabling its message-passing operations to adjust to different nodes. Finally, this work is the first to demonstrate how residual training, with the availability of low-resolution data, can be adopted to improve the flow field prediction accuracy. Experimental results on two datasets with five different state-of-the-art GNN methods for CFD indicate that SV, DID, FVF and residual training can effectively reduce the predictive error of current GNN-based methods by as much as 41%. Our codes and datasets are available at https://github.com/toggled/FvFGeo.",
        "_bibtex": "@inproceedings{\njessica2024finite,\ntitle={Finite Volume Features, Global Geometry Representations, and Residual Training for Deep Learning-based {CFD} Simulation},\nauthor={Loh Sher En Jessica and Naheed Anjum Arafat and Wei Xian Lim and Wai Lee Chan and Adams Wai-Kin Kong},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=WzD4a5ufN8}\n}"
    },
    {
        "title": "Tight Partial Identification of Causal Effects with Marginal Distribution of Unmeasured Confounders",
        "authorids": [
            "~Zhiheng_Zhang1"
        ],
        "abstract": "Partial identification (PI) presents a significant challenge in causal inference due to the incomplete measurement of confounders. Given that obtaining auxiliary variables of confounders is not always feasible and relies on untestable assumptions, researchers are encouraged to explore the internal information of latent confounders without external assistance. However, these prevailing PI results often lack precise mathematical measurement from observational data or assume that the information pertaining to confounders falls within extreme scenarios. In our paper, we reassess the significance of the marginal confounder distribution in PI. We refrain from imposing additional restrictions on the marginal confounder distribution, such as entropy or mutual information. Instead, we establish the closed-form tight PI for any possible P(U) in the discrete case. Furthermore, we establish the if and only if criterion for discerning whether the marginal confounder information leads to non-vanilla PI regions. This reveals a fundamental negative result wherein the marginal confounder information minimally contributes to PI as the confounder\u2019s cardinality increases. Our theoretical findings are supported by experiments.",
        "_bibtex": "@inproceedings{\nzhang2024tight,\ntitle={Tight Partial Identification of Causal Effects with Marginal Distribution of Unmeasured Confounders},\nauthor={Zhiheng Zhang},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=jEWpcEyuUl}\n}"
    },
    {
        "title": "Concentration Inequalities for General Functions of Heavy-Tailed Random Variables",
        "authorids": [
            "~Shaojie_Li2",
            "~Yong_Liu7"
        ],
        "abstract": "Concentration inequalities play an essential role in the study of machine learning and high dimensional statistics. In this paper, we obtain unbounded analogues of the popular bounded difference inequality for functions of independent random variables with heavy-tailed distributions. The main results provide a general framework applicable to all heavy-tailed distributions with finite variance. To illustrate the strength of our results, we present applications to sub-exponential tails, sub-Weibull tails, and heavier polynomially decaying tails. Applied to some standard problems in statistical learning theory (vector valued concentration, Rademacher complexity, and algorithmic stability), we show that these inequalities allow an extension of existing results to heavy-tailed distributions up to finite variance.",
        "_bibtex": "@inproceedings{\nli2024concentration,\ntitle={Concentration Inequalities for General Functions of Heavy-Tailed Random Variables},\nauthor={Shaojie Li and Yong Liu},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=JHRvP84SQ5}\n}"
    },
    {
        "title": "Adaptive Proximal Gradient Methods Are Universal Without Approximation",
        "authorids": [
            "~Konstantinos_Oikonomidis1",
            "~Emanuel_Laude1",
            "~Puya_Latafat1",
            "themelis.andreas.822@m.kyushu-u.ac.jp",
            "~Panagiotis_Patrinos1"
        ],
        "abstract": "We show that adaptive proximal gradient methods for convex problems are not restricted to traditional Lipschitzian assumptions. Our analysis reveals that a class of linesearch-free methods is still convergent under mere local H\u00f6lder gradient continuity, covering in particular continuously differentiable semi-algebraic functions. To mitigate the lack of local Lipschitz continuity, popular approaches revolve around $\\varepsilon$-oracles and/or linesearch procedures. In contrast, we exploit plain H\u00f6lder inequalities not entailing any approximation, all while retaining the linesearch-free nature of adaptive schemes. Furthermore, we prove full sequence convergence without prior knowledge of local H\u00f6lder constants nor of the order of H\u00f6lder continuity. Numerical experiments make comparisons with baseline methods on diverse tasks from machine learning covering both the locally and the globally H\u00f6lder setting.",
        "_bibtex": "@inproceedings{\noikonomidis2024adaptive,\ntitle={Adaptive Proximal Gradient Methods Are Universal Without Approximation},\nauthor={Konstantinos Oikonomidis and Emanuel Laude and Puya Latafat and Andreas Themelis and Panagiotis Patrinos},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=SUxarNgrUT}\n}"
    },
    {
        "title": "Variational Learning is Effective for Large Deep Networks",
        "authorids": [
            "~Yuesong_Shen1",
            "~Nico_Daheim1",
            "~Bai_Cong1",
            "~Peter_Nickl1",
            "~Gian_Maria_Marconi1",
            "~Bazan_Clement_Emile_Marcel_Raoul1",
            "~Rio_Yokota1",
            "~Iryna_Gurevych1",
            "~Daniel_Cremers1",
            "~Mohammad_Emtiyaz_Khan1",
            "~Thomas_M\u00f6llenhoff1"
        ],
        "abstract": "We give extensive empirical evidence against the common belief that variational learning is ineffective for large neural networks. We show that an optimizer called Improved Variational Online Newton (IVON) consistently matches or outperforms Adam for training large networks such as GPT-2 and ResNets from scratch. IVON's computational costs are nearly identical to Adam but its predictive uncertainty is better. We show several new use cases of IVON where we improve finetuning and model merging in Large Language Models, accurately predict generalization error, and faithfully estimate sensitivity to data. We find overwhelming evidence that variational learning is effective. Code is available at https://github.com/team-approx-bayes/ivon.",
        "_bibtex": "@inproceedings{\nshen2024variational,\ntitle={Variational Learning is Effective for Large Deep Networks},\nauthor={Yuesong Shen and Nico Daheim and Bai Cong and Peter Nickl and Gian Maria Marconi and Bazan Clement Emile Marcel Raoul and Rio Yokota and Iryna Gurevych and Daniel Cremers and Mohammad Emtiyaz Khan and Thomas M{\\\"o}llenhoff},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=cXBv07GKvk}\n}"
    },
    {
        "title": "Improving Interpretation Faithfulness for Vision Transformers",
        "authorids": [
            "~Lijie_Hu1",
            "~Yixin_Liu4",
            "~Ninghao_Liu2",
            "~Mengdi_Huai1",
            "~Lichao_Sun1",
            "~Di_Wang1"
        ],
        "abstract": "Vision Transformers (ViTs) have achieved state-of-the-art performance for various vision tasks. One reason behind the success lies in their ability to provide plausible innate explanations for the behavior of neural architectures. However, ViTs suffer from issues with explanation faithfulness, as their focal points are fragile to adversarial attacks and can be easily changed with even slight perturbations on the input image. In this paper, we propose a rigorous approach to mitigate these issues by introducing Faithful ViTs (FViTs). Briefly speaking, an FViT should have the following two properties: (1) The top-$k$ indices of its self-attention vector should remain mostly unchanged under input perturbation, indicating stable explanations; (2) The prediction distribution should be robust to perturbations. To achieve this, we propose a new method called Denoised Diffusion Smoothing (DDS), which adopts randomized smoothing and diffusion-based denoising. We theoretically prove that processing ViTs directly with DDS can turn them into FViTs. We also show that Gaussian noise is nearly optimal for both $\\ell_2$ and $\\ell_\\infty$-norm cases. Finally, we demonstrate the effectiveness of our approach through comprehensive experiments and evaluations. Results show that FViTs are more robust against adversarial attacks while maintaining the explainability of attention, indicating higher faithfulness.",
        "_bibtex": "@inproceedings{\nhu2024improving,\ntitle={Improving Interpretation Faithfulness for Vision Transformers},\nauthor={Lijie Hu and Yixin Liu and Ninghao Liu and Mengdi Huai and Lichao Sun and Di Wang},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=YdwwWRX20q}\n}"
    },
    {
        "title": "High-Performance Temporal Reversible Spiking Neural Networks with $\\mathcal{O}(L)$ Training Memory and $\\mathcal{O}(1)$ Inference Cost",
        "authorids": [
            "~JiaKui_Hu1",
            "~Man_Yao1",
            "~Xuerui_Qiu1",
            "~Yuhong_Chou1",
            "~Yuxuan_Cai1",
            "~Ning_Qiao1",
            "~Yonghong_Tian1",
            "~Bo_XU10",
            "~Guoqi_Li1"
        ],
        "abstract": "Multi-timestep simulation of brain-inspired Spiking Neural Networks (SNNs) boost memory requirements during training and increase inference energy cost. Current training methods cannot simultaneously solve both training and inference dilemmas. This work proposes a novel Temporal Reversible architecture for SNNs (T-RevSNN) to jointly address the training and inference challenges by altering the forward propagation of SNNs. We turn off the temporal dynamics of most spiking neurons and design multi-level temporal reversible interactions at temporal turn-on spiking neurons, resulting in a $\\mathcal{O}(L)$ training memory. Combined with the temporal reversible nature, we redesign the input encoding and network organization of SNNs to achieve $\\mathcal{O}(1)$ inference energy cost. Then, we finely adjust the internal units and residual connections of the basic SNN block to ensure the effectiveness of sparse temporal information interaction. T-RevSNN achieves excellent accuracy on ImageNet, while the memory efficiency, training time acceleration and inference energy efficiency can be significantly improved by $8.6 \\times$, $2.0 \\times$ and $1.6 \\times$, respectively. This work is expected to break the technical bottleneck of significantly increasing memory cost and training time for large-scale SNNs while maintaining both high performance and low inference energy cost.",
        "_bibtex": "@inproceedings{\nhu2024highperformance,\ntitle={High-Performance Temporal Reversible Spiking Neural Networks with  \\${\\textbackslash}mathcal\\{O\\}(L)\\$ Training Memory and \\${\\textbackslash}mathcal\\{O\\}(1)\\$ Inference Cost},\nauthor={JiaKui Hu and Man Yao and Xuerui Qiu and Yuhong Chou and Yuxuan Cai and Ning Qiao and Yonghong Tian and Bo XU and Guoqi Li},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=s4h6nyjM9H}\n}"
    },
    {
        "title": "A Subquadratic Time Algorithm for Robust Sparse Mean Estimation",
        "authorids": [
            "~Ankit_Pensia1"
        ],
        "abstract": "We study the algorithmic problem of sparse mean estimation in the presence of adversarial outliers. Specifically, the algorithm observes a *corrupted* set of samples from $\\mathcal{N}(\\mu,\\mathbf{I}_d)$, where the unknown mean $\\mu \\in \\mathbb{R}^d$ is constrained to be $k$-sparse. A series of prior works has developed efficient algorithms for robust sparse mean estimation with sample complexity $\\mathrm{poly}(k,\\log d, 1/\\epsilon)$ and runtime $d^2 \\mathrm{poly}(k,\\log d,1/\\epsilon)$, where $\\epsilon$ is the fraction of contamination. In particular, the fastest runtime of existing algorithms is quadratic in the dimension, which can be prohibitive in high dimensions. This quadratic barrier in the runtime stems from the reliance of these algorithms on the sample covariance matrix, which is of size $d^2$. Our main contribution is an algorithm for robust sparse mean estimation which runs in _subquadratic_ time using $\\mathrm{poly}(k,\\log d,1/\\epsilon)$ samples. Our results build on algorithmic advances in detecting weak correlations, a generalized version of the light-bulb problem by Valiant (2015).",
        "_bibtex": "@inproceedings{\npensia2024a,\ntitle={A Subquadratic Time Algorithm for Robust Sparse Mean Estimation},\nauthor={Ankit Pensia},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=WSi4IiMaCx}\n}"
    },
    {
        "title": "Discrete Latent Perspective Learning for Segmentation and Detection",
        "authorids": [
            "~Deyi_Ji2",
            "~Feng_Zhao6",
            "~Lanyun_Zhu1",
            "~Wenwei_Jin3",
            "~Hongtao_Lu1",
            "~Jieping_Ye4"
        ],
        "abstract": "In this paper, we address the challenge of Perspective-Invariant Learning in machine learning and computer vision, which involves enabling a network to understand images from varying perspectives to achieve consistent semantic interpretation. While standard approaches rely on the labor-intensive collection of multi-view images or limited data augmentation techniques, we propose a novel framework, Discrete Latent Perspective Learning (DLPL), for latent multi-perspective fusion learning using conventional single-view images. DLPL comprises three main modules: Perspective Discrete Decomposition (PDD), Perspective Homography Transformation (PHT), and Perspective Invariant Attention (PIA), which work together to discretize visual features, transform perspectives, and fuse multi-perspective semantic information, respectively. DLPL is a universal perspective learning framework applicable to a variety of scenarios and vision tasks. Extensive experiments demonstrate that DLPL significantly enhances the network's capacity to depict images across diverse scenarios (daily photos, UAV, auto-driving) and tasks (detection, segmentation).",
        "_bibtex": "@inproceedings{\nji2024discrete,\ntitle={Discrete Latent Perspective Learning for Segmentation and Detection},\nauthor={Deyi Ji and Feng Zhao and Lanyun Zhu and Wenwei Jin and Hongtao Lu and Jieping Ye},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=VWCpm39peL}\n}"
    },
    {
        "title": "Best Arm Identification for Stochastic Rising Bandits",
        "authorids": [
            "~Marco_Mussi1",
            "~Alessandro_Montenegro1",
            "~Francesco_Trov\u00f21",
            "~Marcello_Restelli1",
            "~Alberto_Maria_Metelli2"
        ],
        "abstract": "Stochastic Rising Bandits (SRBs) model sequential decision-making problems in which the expected reward of the available options increases every time they are selected. This setting captures a wide range of scenarios in which the available options are learning entities whose performance improves (in expectation) over time (e.g., online best model selection). While previous works addressed the regret minimization problem, this paper focuses on the fixed-budget Best Arm Identification (BAI) problem for SRBs. In this scenario, given a fixed budget of rounds, we are asked to provide a recommendation about the best option at the end of the identification process. We propose two algorithms to tackle the above-mentioned setting, namely R-UCBE, which resorts to a UCB-like approach, and R-SR, which employs a successive reject procedure. Then, we prove that, with a sufficiently large budget, they provide guarantees on the probability of properly identifying the optimal option at the end of the learning process and on the simple regret. Furthermore, we derive a lower bound on the error probability, matched by our R-SR (up to constants), and illustrate how the need for a sufficiently large budget is unavoidable in the SRB setting. Finally, we numerically validate the proposed algorithms in both synthetic and realistic environments.",
        "_bibtex": "@inproceedings{\nmussi2024best,\ntitle={Best Arm Identification for Stochastic Rising Bandits},\nauthor={Marco Mussi and Alessandro Montenegro and Francesco Trov{\\`o} and Marcello Restelli and Alberto Maria Metelli},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=WwLtwPHmSM}\n}"
    },
    {
        "title": "Memoria: Resolving Fateful Forgetting Problem through Human-Inspired Memory Architecture",
        "authorids": [
            "~Sangjun_Park1",
            "~JinYeong_Bak2"
        ],
        "abstract": "Making neural networks remember over the long term has been a longstanding issue. Although several external memory techniques have been introduced, most focus on retaining recent information in the short term. Regardless of its importance, information tends to be fatefully forgotten over time. We present Memoria, a memory system for artificial neural networks, drawing inspiration from humans and applying various neuroscientific and psychological theories. The experimental results prove the effectiveness of Memoria in the diverse tasks of sorting, language modeling, and classification, surpassing conventional techniques. Engram analysis reveals that Memoria exhibits the primacy, recency, and temporal contiguity effects which are characteristics of human memory.",
        "_bibtex": "@inproceedings{\npark2024memoria,\ntitle={Memoria: Resolving Fateful Forgetting Problem through Human-Inspired Memory Architecture},\nauthor={Sangjun Park and JinYeong Bak},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=yTz0u4B8ug}\n}"
    },
    {
        "title": "Integrating Global Context Contrast and Local Sensitivity for Blind Image Quality Assessment",
        "abstract": "Blind Image Quality Assessment (BIQA) mirrors subjective made by human observers. Generally, humans favor comparing relative qualities over predicting absolute qualities directly. However, current BIQA models focus on mining the \"local\" context, i.e., the relationship between information among individual images and the absolute quality of the image, ignoring the \"global\" context of the relative quality contrast among different images in the training data. In this paper, we present the Perceptual Context and Sensitivity BIQA (CSIQA), a novel contrastive learning paradigm that seamlessly integrates \"global'' and \"local'' perspectives into the BIQA. Specifically, the CSIQA comprises two primary components: 1) A Quality Context Contrastive Learning module, which is equipped with different contrastive learning strategies to effectively capture potential quality correlations in the global context of the dataset. 2) A Quality-aware Mask Attention Module, which employs the random mask to ensure the consistency with visual local sensitivity, thereby improving the model's perception of local distortions. Extensive experiments on eight standard BIQA datasets demonstrate the superior performance to the state-of-the-art BIQA methods.",
        "_bibtex": "@inproceedings{\nli2024integrating,\ntitle={Integrating Global Context Contrast and Local Sensitivity for Blind Image Quality Assessment},\nauthor={XuDong Li and Runze Hu and Jingyuan Zheng and Yan Zhang and Shengchuan Zhang and Xiawu Zheng and Ke Li and Yunhang Shen and Yutao Liu and Pingyang Dai and Rongrong Ji},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=MRYS3Zb4iV}\n}"
    },
    {
        "title": "ERQ: Error Reduction for Post-Training Quantization of Vision Transformers",
        "authorids": [
            "~Yunshan_Zhong1",
            "~Jiawei_Hu4",
            "~You_Huang1",
            "~Yuxin_Zhang3",
            "~Rongrong_Ji5"
        ],
        "abstract": "Post-training quantization (PTQ) for vision transformers (ViTs) has garnered significant attention due to its efficiency in compressing models. However, existing methods typically overlook the intricate interdependence between quantized weight and activation, leading to considerable quantization error. In this paper, we propose ERQ, a two-step PTQ approach meticulously crafted to sequentially reduce the quantization error arising from activation and weight quantization. ERQ first introduces Activation quantization error reduction (Aqer) that strategically formulates the minimization of activation quantization error as a Ridge Regression problem, tackling it by updating weights with full-precision. Subsequently, ERQ introduces Weight quantization error reduction (Wqer) that adopts an iterative approach to mitigate the quantization error induced by weight quantization. In each iteration, an empirically derived, efficient proxy is employed to refine the rounding directions of quantized weights, coupled with a Ridge Regression solver to curtail weight quantization error. Experimental results attest to the effectiveness of our approach. Notably, ERQ surpasses the state-of-the-art GPTQ by 22.36% in accuracy for W3A4 ViT-S.",
        "_bibtex": "@inproceedings{\nzhong2024erq,\ntitle={{ERQ}: Error Reduction for Post-Training Quantization of Vision Transformers},\nauthor={Yunshan Zhong and Jiawei Hu and You Huang and Yuxin Zhang and Rongrong Ji},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=jKUWlgra9b}\n}"
    },
    {
        "title": "Towards Resource-friendly, Extensible and Stable Incomplete Multi-view Clustering",
        "authorids": [
            "~Shengju_Yu1",
            "~Zhibin_Dong1",
            "~Siwei_Wang4",
            "~Xinhang_Wan1",
            "~Yue_Liu10",
            "~Weixuan_Liang1",
            "~Pei_Zhang9",
            "~Wenxuan_Tu1",
            "~Xinwang_Liu1"
        ],
        "abstract": "Incomplete multi-view clustering (IMVC) methods typically encounter three drawbacks: (1) intense time and/or space overheads; (2) intractable hyper-parameters; (3) non-zero variance results. With these concerns in mind, we give a simple yet effective IMVC scheme, termed as ToRES. Concretely, instead of self-expression affinity, we manage to construct prototype-sample affinity for incomplete data so as to decrease the memory requirements. To eliminate hyper-parameters, besides mining complementary features among views by view-wise prototypes, we also attempt to devise cross-view prototypes to capture consensus features for jointly forming high-quality clustering representation. To avoid the variance, we successfully unify representation learning and clustering operation, and directly optimize the discrete cluster indicators from incomplete data. Then, for the resulting objective function, we provide two equivalent solutions from perspectives of feasible region partitioning and objective transformation. Many results suggest that ToRES exhibits advantages against 20 SOTA algorithms, even in scenarios with a higher ratio of incomplete data.",
        "_bibtex": "@inproceedings{\nyu2024towards,\ntitle={Towards Resource-friendly, Extensible and Stable Incomplete Multi-view  Clustering},\nauthor={Shengju Yu and Zhibin Dong and Siwei Wang and Xinhang Wan and Yue Liu and Weixuan Liang and Pei Zhang and Wenxuan Tu and Xinwang Liu},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=O45u81aby2}\n}"
    },
    {
        "title": "RIME: Robust Preference-based Reinforcement Learning with Noisy Preferences",
        "abstract": "Preference-based Reinforcement Learning (PbRL) circumvents the need for reward engineering by harnessing human preferences as the reward signal. However, current PbRL methods excessively depend on high-quality feedback from domain experts, which results in a lack of robustness. In this paper, we present RIME, a robust PbRL algorithm for effective reward learning from noisy preferences. Our method utilizes a sample selection-based discriminator to dynamically filter out noise and ensure robust training. To counteract the cumulative error stemming from incorrect selection, we suggest a warm start for the reward model, which additionally bridges the performance gap during the transition from pre-training to online training in PbRL. Our experiments on robotic manipulation and locomotion tasks demonstrate that RIME significantly enhances the robustness of the state-of-the-art PbRL method. Code is available at https://github.com/CJReinforce/RIME_ICML2024.",
        "_bibtex": "@inproceedings{\ncheng2024rime,\ntitle={{RIME}: Robust Preference-based Reinforcement Learning with Noisy Preferences},\nauthor={Jie Cheng and Gang Xiong and Xingyuan Dai and Qinghai Miao and Yisheng Lv and Fei-Yue Wang},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=BxAvcnlS8O}\n}"
    },
    {
        "title": "Towards Unified Multi-granularity Text Detection with Interactive Attention",
        "authorids": [
            "~Xingyu_Wan2",
            "~Chengquan_Zhang2",
            "~Pengyuan_Lyu1",
            "~Sen_Fan1",
            "~Zihan_Ni1",
            "~Kun_Yao1",
            "~Errui_Ding2",
            "~Jingdong_Wang1"
        ],
        "abstract": "Existing OCR engines or document image analysis systems typically rely on training separate models for text detection in varying scenarios and granularities, leading to significant computational complexity and resource demands. In this paper, we introduce \"Detect Any Text\" (DAT), an advanced paradigm that seamlessly unifies scene text detection, layout analysis, and document page detection into a cohesive, end-to-end model. This design enables DAT to efficiently manage text instances at different granularities, including *word*, *line*, *paragraph* and *page*. A pivotal innovation in DAT is the across-granularity interactive attention module, which significantly enhances the representation learning of text instances at varying granularities by correlating structural information across different text queries. As a result, it enables the model to achieve mutually beneficial detection performances across multiple text granularities. Additionally, a prompt-based segmentation module refines detection outcomes for texts of arbitrary curvature and complex layouts, thereby improving DAT's accuracy and expanding its real-world applicability. Experimental results demonstrate that DAT achieves state-of-the-art performances across a variety of text-related benchmarks, including multi-oriented/arbitrarily-shaped scene text detection, document layout analysis and page detection tasks.",
        "_bibtex": "@inproceedings{\nwan2024towards,\ntitle={Towards Unified Multi-granularity Text Detection with Interactive Attention},\nauthor={Xingyu Wan and Chengquan Zhang and Pengyuan Lyu and Sen Fan and Zihan Ni and Kun Yao and Errui Ding and Jingdong Wang},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=HaBVzgSdM7}\n}"
    },
    {
        "title": "An Efficient Maximal Ancestral Graph Listing Algorithm",
        "authorids": [
            "~Tian-Zuo_Wang1",
            "~Wen-Bo_Du1",
            "~Zhi-Hua_Zhou2"
        ],
        "abstract": "Maximal ancestral graph (MAG) is a prevalent graphical model to characterize causal relations in the presence of *latent variables* including latent confounders and selection variables. Given observational data, only a Markov equivalence class (MEC) of MAGs is identifiable if without some additional assumptions. Due to this fact, MAG listing, listing all the MAGs in the MEC, is usually demanded in many downstream tasks. To the best of our knowledge, there are no relevant methods for MAG listing other than brute force in the literature. In this paper, we propose the first brute-force-free MAG listing method, by determining the local structures of each vertex recursively. We provide the graphical characterization for each valid local transformation of a vertex, and present sound and complete rules to incorporate the valid local transformation in the presence of latent confounders and selection variables. Based on these components, our method can efficiently output all the MAGs in the MEC with no redundance, that is, every intermediate graph in the recursive process is necessary for the MAG listing task. The empirical analysis demonstrates the superiority of our proposed method on efficiency and effectiveness.",
        "_bibtex": "@inproceedings{\nwang2024an,\ntitle={An Efficient Maximal Ancestral Graph Listing Algorithm},\nauthor={Tian-Zuo Wang and Wen-Bo Du and Zhi-Hua Zhou},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=MZkqjV4FRT}\n}"
    },
    {
        "title": "Transolver: A Fast Transformer Solver for PDEs on General Geometries",
        "authorids": [
            "~Haixu_Wu1",
            "~Huakun_Luo1",
            "~Haowen_Wang4",
            "~Jianmin_Wang1",
            "~Mingsheng_Long5"
        ],
        "abstract": "Transformers have empowered many milestones across various fields and have recently been applied to solve partial differential equations (PDEs). However, since PDEs are typically discretized into large-scale meshes with complex geometries, it is challenging for Transformers to capture intricate physical correlations directly from massive individual points. Going beyond superficial and unwieldy meshes, we present Transolver based on a more foundational idea, which is learning intrinsic physical states hidden behind discretized geometries. Specifically, we propose a new Physics-Attention to adaptively split the discretized domain into a series of learnable slices of flexible shapes, where mesh points under similar physical states will be ascribed to the same slice. By calculating attention to physics-aware tokens encoded from slices, Transovler can effectively capture intricate physical correlations under complex geometrics, which also empowers the solver with endogenetic geometry-general modeling capacity and can be efficiently computed in linear complexity. Transolver achieves consistent state-of-the-art with 22% relative gain across six standard benchmarks and also excels in large-scale industrial simulations, including car and airfoil designs. Code is available at https://github.com/thuml/Transolver.",
        "_bibtex": "@inproceedings{\nwu2024transolver,\ntitle={Transolver: A Fast Transformer Solver for {PDE}s on General Geometries},\nauthor={Haixu Wu and Huakun Luo and Haowen Wang and Jianmin Wang and Mingsheng Long},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=Ywl6pODXjB}\n}"
    },
    {
        "title": "Revisiting the Power of Prompt for Visual Tuning",
        "authorids": [
            "~Yuzhu_Wang1",
            "~Lechao_Cheng2",
            "~Chaowei_Fang3",
            "~Dingwen_Zhang1",
            "~Manni_Duan2",
            "~Meng_Wang2"
        ],
        "abstract": "Visual prompt tuning (VPT) is a promising solution incorporating learnable prompt tokens to customize pre-trained models for downstream tasks. However, VPT and its variants often encounter challenges like prompt initialization, prompt length, and subpar performance in self-supervised pretraining, hindering successful contextual adaptation. This study commences by exploring the correlation evolvement between prompts and patch tokens during proficient training. Inspired by the observation that the prompt tokens tend to share high mutual information with patch tokens, we propose initializing prompts with downstream token prototypes. The strategic initialization, a stand-in for the previous initialization, substantially improves performance. To refine further, we optimize token construction with a streamlined pipeline that maintains excellent performance with almost no increase in computational expenses compared to VPT. Exhaustive experiments show our proposed approach outperforms existing methods by a remarkable margin. For instance, after MAE pre-training, our method improves accuracy by up to 10%$\\sim$30% compared to VPT, and outperforms Full fine-tuning 19 out of 24 cases while using less than 0.4% of learnable parameters. Besides, the experimental results demonstrate the proposed SPT is robust to prompt lengths and scales well with model capacity and training data size. We finally provide an insightful exploration into the amount of target data facilitating the adaptation of pre-trained models to downstream tasks. The code is available at https://github.com/WangYZ1608/Self-Prompt-Tuning.",
        "_bibtex": "@inproceedings{\nwang2024revisiting,\ntitle={Revisiting the Power of Prompt for Visual Tuning},\nauthor={Yuzhu Wang and Lechao Cheng and Chaowei Fang and Dingwen Zhang and Manni Duan and Meng Wang},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=2Y93PtAqCl}\n}"
    },
    {
        "title": "Realistic Unsupervised CLIP Fine-tuning with Universal Entropy Optimization",
        "authorids": [
            "~Jian_Liang1",
            "~Lijun_Sheng1",
            "~Zhengbo_Wang1",
            "~Ran_He1",
            "~Tieniu_Tan1"
        ],
        "abstract": "The emergence of vision-language models, such as CLIP, has spurred a significant research effort towards their application for downstream supervised learning tasks. Although some previous studies have explored the unsupervised fine-tuning of CLIP, they often rely on prior knowledge in the form of class names associated with ground truth labels. This paper explores a realistic unsupervised fine-tuning scenario, considering the presence of out-of-distribution samples from unknown classes within the unlabeled data. In particular, we focus on simultaneously enhancing out-of-distribution detection and the recognition of instances associated with known classes. To tackle this problem, we present a simple, efficient, and effective approach called Universal Entropy Optimization (UEO). UEO leverages sample-level confidence to approximately minimize the conditional entropy of confident instances and maximize the marginal entropy of less confident instances. Apart from optimizing the textual prompt, UEO incorporates optimization of channel-wise affine transformations within the visual branch of CLIP. Extensive experiments across 15 domains and 4 different types of prior knowledge validate the effectiveness of UEO compared to baseline methods. The code is at https://github.com/tim-learn/UEO.",
        "_bibtex": "@inproceedings{\nliang2024realistic,\ntitle={Realistic Unsupervised {CLIP} Fine-tuning with Universal Entropy Optimization},\nauthor={Jian Liang and Lijun Sheng and Zhengbo Wang and Ran He and Tieniu Tan},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=XxCfToC9pJ}\n}"
    },
    {
        "title": "Position: Levels of AGI for Operationalizing Progress on the Path to AGI",
        "authorids": [
            "~Meredith_Ringel_Morris1",
            "~Jascha_Sohl-Dickstein2",
            "~Noah_Fiedel1",
            "~Tris_Warkentin1",
            "~Allan_Dafoe1",
            "~Aleksandra_Faust1",
            "~Clement_Farabet2",
            "~Shane_Legg1"
        ],
        "abstract": "We propose a framework for classifying the capabilities and behavior of Artificial General Intelligence (AGI) models and their precursors. This framework introduces levels of AGI performance, generality, and autonomy, providing a common language to compare models, assess risks, and measure progress along the path to AGI. To develop our framework, we analyze existing definitions of AGI, and distill six principles that a useful ontology for AGI should satisfy. With these principles in mind, we propose \u201cLevels of AGI\u201d based on depth (performance) and breadth (generality) of capabilities, and reflect on how current systems fit into this ontology. We discuss the challenging requirements for future benchmarks that quantify the behavior and capabilities of AGI models against these levels. Finally, we discuss how these levels of AGI interact with deployment considerations such as autonomy and risk, and emphasize the importance of carefully selecting Human-AI Interaction paradigms for responsible and safe deployment of highly capable AI systems.",
        "_bibtex": "@inproceedings{\nmorris2024position,\ntitle={Position: Levels of {AGI} for Operationalizing Progress on the Path to {AGI}},\nauthor={Meredith Ringel Morris and Jascha Sohl-Dickstein and Noah Fiedel and Tris Warkentin and Allan Dafoe and Aleksandra Faust and Clement Farabet and Shane Legg},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=0ofzEysK2D}\n}"
    },
    {
        "title": "Novel Spectral Algorithms for the Partial Credit Model",
        "authorids": [
            "~Duc_Nguyen3",
            "~Anderson_Ye_Zhang1"
        ],
        "abstract": "The Partial Credit Model (PCM) of Andrich (1978) and Masters (1982) is a fundamental model within the psychometric literature with wide-ranging modern applications. It models the integer-valued response that a subject gives to an item where there is a natural notion of monotonic progress between consecutive response values, such as partial scores on a test and customer ratings of a product. In this paper, we introduce a novel, time-efficient and accurate statistical spectral algorithm for inference under the PCM model. We complement our algorithmic contribution with in-depth non-asymptotic statistical analysis, the first of its kind in the literature. We show that the spectral algorithm enjoys the optimal error guarantee under three different metrics, all under reasonable sampling assumptions. We leverage the efficiency of the spectral algorithm to propose a novel EM-based algorithm for learning mixtures of PCMs. We perform comprehensive experiments on synthetic and real-life datasets covering education testing, recommendation systems, and financial investment applications. We show that the proposed spectral algorithm is competitive with previously introduced algorithms in terms of accuracy while being orders of magnitude faster.",
        "_bibtex": "@inproceedings{\nnguyen2024novel,\ntitle={Novel Spectral Algorithms for the Partial Credit Model},\nauthor={Duc Nguyen and Anderson Ye Zhang},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=eW0pZmziBH}\n}"
    },
    {
        "title": "Domain Generalisation via Imprecise Learning",
        "authorids": [
            "~Anurag_Singh3",
            "~Siu_Lun_Chau1",
            "~Shahine_Bouabid1",
            "~Krikamol_Muandet1"
        ],
        "abstract": "Out-of-distribution (OOD) generalisation is challenging because it involves not only learning from empirical data, but also deciding among various notions of generalisation, e.g. optimise based on the average-case risk, worst-case risk, or interpolations thereof. While this decision should in principle be decided by the model operator like medical doctors in practice, this information might not always be available at training time. This situation leads to arbitrary commitments to specific generalisation strategies by machine learners due to these deployment uncertainties. We introduce the Imprecise Domain Generalisation framework to mitigate this, featuring an imprecise risk optimisation that allows learners to stay imprecise by optimising against a continuous spectrum of generalisation strategies during training, and a model framework that allows operators to specify their generalisation preference at deployment. Our work, supported by theoretical and empirical evidence, showcases the benefits of integrating imprecision into domain generalisation.",
        "_bibtex": "@inproceedings{\nsingh2024domain,\ntitle={Domain Generalisation via Imprecise Learning},\nauthor={Anurag Singh and Siu Lun Chau and Shahine Bouabid and Krikamol Muandet},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=yFUdZfbEme}\n}"
    },
    {
        "title": "Auto-Encoding Morph-Tokens for Multimodal LLM",
        "authorids": [
            "~Kaihang_Pan1",
            "~Siliang_Tang1",
            "~Juncheng_Li3",
            "~Zhaoyu_Fan1",
            "~Wei_Chow1",
            "~Shuicheng_YAN3",
            "~Tat-Seng_Chua2",
            "~Yueting_Zhuang1",
            "~Hanwang_Zhang3"
        ],
        "abstract": "For multimodal LLMs, the synergy of visual comprehension (textual output) and generation (visual output) presents an ongoing challenge. This is due to a conflicting objective: for comprehension, an MLLM needs to abstract the visuals; for generation, it needs to preserve the visuals as much as possible. Thus, the objective is a dilemma for visual-tokens. To resolve the conflict, we propose encoding images into morph-tokens to serve a dual purpose: for comprehension, they act as visual prompts instructing MLLM to generate texts; for generation, they take on a different, non-conflicting role as complete visual-tokens for image reconstruction, where the missing visual cues are recovered by the MLLM. Extensive experiments show that morph-tokens can achieve a new SOTA for multimodal comprehension and generation simultaneously. Our project is available at https://github.com/DCDmllm/MorphTokens.",
        "_bibtex": "@inproceedings{\npan2024autoencoding,\ntitle={Auto-Encoding Morph-Tokens for Multimodal {LLM}},\nauthor={Kaihang Pan and Siliang Tang and Juncheng Li and Zhaoyu Fan and Wei Chow and Shuicheng YAN and Tat-Seng Chua and Yueting Zhuang and Hanwang Zhang},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=U97MIrs35l}\n}"
    }
]