[
    {
        "title": "SaNN: Simple Yet Powerful Simplicial-aware Neural Networks",
        "authorids": [
            "~Sravanthi_Gurugubelli1",
            "~Sundeep_Prabhakar_Chepuri1"
        ],
        "keywords": [
            "Graph Neural Networks",
            "Higher-order Representation Learning",
            "Simplicial Complexes",
            "Simplicial Neural Networks",
            "Weisfeiler-Lehman Isomorphism Test"
        ],
        "abstract": "Simplicial neural networks (SNNs) are deep models for higher-order graph representation learning. SNNs learn low-dimensional embeddings of simplices in a simplicial complex by aggregating features of their respective upper, lower, boundary, and coboundary adjacent simplices. The aggregation in SNNs is carried out during training. Since the number of simplices of various orders in a simplicial complex is significantly large, the memory and training-time requirement in SNNs is enormous. In this work, we propose a scalable simplicial-aware neural network (SaNN) model with a constant run-time and memory requirements independent of the size of the simplicial complex and the density of interactions in it. SaNN is based on pre-aggregated simplicial-aware features as inputs to a neural network, so it has a strong simplicial-structural inductive bias. We provide theoretical conditions under which SaNN is provably more powerful than the Weisfeiler-Lehman (WL) graph isomorphism test and as powerful as the simplicial Weisfeiler-Lehman (SWL) test. We also show that SaNN is permutation and orientation equivariant and satisfies simplicial-awareness of the highest order in a simplicial complex. We demonstrate via numerical experiments that despite being computationally economical, the proposed model achieves state-of-the-art performance in predicting trajectories,  simplicial closures, and classifying graphs.",
        "_bibtex": "@inproceedings{\ngurugubelli2024sann,\ntitle={Sa{NN}: Simple Yet Powerful Simplicial-aware Neural Networks},\nauthor={Sravanthi Gurugubelli and Sundeep Prabhakar Chepuri},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=eUgS9Ig8JG}\n}"
    },
    {
        "title": "Beyond Memorization: Violating Privacy via Inference with Large Language Models",
        "authorids": [
            "~Robin_Staab1",
            "~Mark_Vero1",
            "~Mislav_Balunovic1",
            "~Martin_Vechev1"
        ],
        "keywords": [
            "Privacy",
            "Large Language Models"
        ],
        "abstract": "Current privacy research on large language models (LLMs) primarily focuses on the issue of extracting memorized training data. At the same time, models\u2019 inference capabilities have increased drastically. This raises the key question of whether current LLMs could violate individuals\u2019 privacy by inferring personal attributes from text given at inference time. In this work, we present the first comprehensive study on the capabilities of pretrained LLMs to infer personal attributes from text. We construct a dataset consisting of real Reddit profiles, and show that current LLMs can infer a wide range of personal attributes (e.g., location, income, sex), achieving up to 85% top-1 and 95% top-3 accuracy at a fraction of the cost (100x) and time (240x) required by humans. As people increasingly interact with LLM-powered chatbots across all aspects of life, we also explore the emerging threat of privacy-invasive chatbots trying to extract personal information through seemingly benign questions. Finally, we show that common mitigations, i.e., text anonymization and model alignment, are currently ineffective at protecting user privacy against LLM inference. Our findings highlight that current LLMs can infer personal data at a previously unattainable scale. In the absence of working defenses, we advocate for a broader discussion around LLM privacy implications beyond memorization, striving for stronger and wider privacy protection.",
        "_bibtex": "@inproceedings{\nstaab2024beyond,\ntitle={Beyond Memorization: Violating Privacy via Inference with Large Language Models},\nauthor={Robin Staab and Mark Vero and Mislav Balunovic and Martin Vechev},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=kmn0BhQk7p}\n}"
    },
    {
        "title": "Controlled Text Generation via Language Model Arithmetic",
        "authorids": [
            "~Jasper_Dekoninck1",
            "~Marc_Fischer1",
            "~Luca_Beurer-Kellner1",
            "~Martin_Vechev1"
        ],
        "keywords": [
            "Controlled text generation",
            "LLM",
            "Natural Language Processing"
        ],
        "abstract": "As Large Language Models (LLMs) are deployed more widely, customization with respect to vocabulary, style, and character becomes more important. In this work, we introduce model arithmetic, a novel inference framework for composing and biasing LLMs without the need for model (re)training or highly specific datasets. In addition, the framework allows for more precise control of generated text than direct prompting and prior controlled text generation (CTG) techniques. Using model arithmetic, we can express prior CTG techniques as simple formulas and naturally extend them to new and more effective formulations. Further, we show that speculative sampling, a technique for efficient LLM sampling, extends to our setting. This enables highly efficient text generation with multiple composed models with only marginal overhead over a single model. Our empirical evaluation demonstrates that model arithmetic allows fine-grained control of generated text while outperforming state-of-the-art on the task of toxicity reduction. We release an open source easy-to-use implementation of our framework at https://github.com/eth-sri/language-model-arithmetic.",
        "_bibtex": "@inproceedings{\ndekoninck2024controlled,\ntitle={Controlled Text Generation via Language Model Arithmetic},\nauthor={Jasper Dekoninck and Marc Fischer and Luca Beurer-Kellner and Martin Vechev},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=SLw9fp4yI6}\n}"
    },
    {
        "title": "Consistency Training with Learnable Data Augmentation for Graph Anomaly Detection with Limited Supervision",
        "authorids": [
            "~Nan_Chen6",
            "~Zemin_Liu1",
            "~Bryan_Hooi1",
            "~Bingsheng_He1",
            "~Rizal_Fathony1",
            "~Jun_Hu3",
            "~Jia_Chen2"
        ],
        "keywords": [
            "Graph anomaly detection",
            "consistency training",
            "learnable data augmentation"
        ],
        "abstract": "Graph Anomaly Detection (GAD) has surfaced as a significant field of research, predominantly due to its substantial influence in production environments. Although existing approaches for node anomaly detection have shown effectiveness, they have yet to fully address two major challenges: operating in settings with limited supervision and managing class imbalance effectively. In response to these challenges, we propose a novel model, ConsisGAD, which is tailored for GAD in scenarios characterized by limited supervision and is anchored in the principles of consistency training. Under limited supervision, ConsisGAD effectively leverages the abundance of unlabeled data for consistency training by incorporating a novel learnable data augmentation mechanism, thereby introducing controlled noise into the dataset. Moreover, ConsisGAD takes advantage of the variance in homophily distribution between normal and anomalous nodes to craft a simplified GNN backbone, enhancing its capability to distinguish effectively between these two classes. Comprehensive experiments on several benchmark datasets validate the superior performance of ConsisGAD in comparison to state-of-the-art baselines. Our code is available at https://github.com/Xtra-Computing/ConsisGAD.",
        "_bibtex": "@inproceedings{\nchen2024consistency,\ntitle={Consistency Training with Learnable Data Augmentation for Graph Anomaly Detection with Limited Supervision},\nauthor={Nan Chen and Zemin Liu and Bryan Hooi and Bingsheng He and Rizal Fathony and Jun Hu and Jia Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=elMKXvhhQ9}\n}"
    },
    {
        "title": "Symmetric Mean-field Langevin Dynamics for Distributional Minimax Problems",
        "authorids": [
            "~Juno_Kim1",
            "~Kakei_Yamamoto1",
            "~Kazusato_Oko1",
            "~Zhuoran_Yang1",
            "~Taiji_Suzuki1"
        ],
        "keywords": [
            "mean-field Langevin dynamics",
            "minimax optimization",
            "zero-sum games",
            "Markov games"
        ],
        "abstract": "In this paper, we extend mean-field Langevin dynamics to minimax optimization over probability distributions for the first time with symmetric and provably convergent updates. We propose \\emph{mean-field Langevin averaged gradient} (MFL-AG), a single-loop algorithm that implements gradient descent ascent in the distribution spaces with a novel weighted averaging, and establish average-iterate convergence to the mixed Nash equilibrium. We also study both time and particle discretization regimes and prove a new uniform-in-time propagation of chaos result which accounts for the dependency of the particle interactions on all previous distributions. Furthermore, we propose \\emph{mean-field Langevin anchored best response} (MFL-ABR), a symmetric double-loop algorithm based on best response dynamics with linear last-iterate convergence. Finally, we study applications to zero-sum Markov games and conduct simulations demonstrating long-term optimality.",
        "_bibtex": "@inproceedings{\nkim2024symmetric,\ntitle={Symmetric Mean-field Langevin Dynamics for Distributional Minimax Problems},\nauthor={Juno Kim and Kakei Yamamoto and Kazusato Oko and Zhuoran Yang and Taiji Suzuki},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=YItWKZci78}\n}"
    },
    {
        "title": "Generalized Policy Iteration using Tensor Approximation for Hybrid Control",
        "authorids": [
            "~Suhan_Shetty1",
            "~Teng_Xue1",
            "~Sylvain_Calinon1"
        ],
        "keywords": [
            "Optimal Control",
            "Hybrid Actions",
            "Robotics",
            "Approximate Dynamic Programming",
            "Tensor Approximation"
        ],
        "abstract": "Control of dynamic systems involving hybrid actions is a challenging task in robotics.  To address this, we present a novel algorithm called Generalized Policy Iteration using Tensor Train (TTPI) that belongs to the class of Approximate Dynamic Programming (ADP). We use a low-rank tensor approximation technique called Tensor Train (TT) to approximate the state-value and advantage function which enables us to efficiently handle hybrid systems. We demonstrate the superiority of our approach over previous baselines for some benchmark problems with hybrid action spaces. Additionally, the robustness and generalization of the policy for hybrid systems are showcased through a real-world robotics experiment involving a non-prehensile manipulation task which is considered to be a highly challenging control problem.",
        "_bibtex": "@inproceedings{\nshetty2024generalized,\ntitle={Generalized Policy Iteration using Tensor Approximation for Hybrid Control},\nauthor={Suhan Shetty and Teng Xue and Sylvain Calinon},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=csukJcpYDe}\n}"
    },
    {
        "title": "Generalization error of spectral algorithms",
        "authorids": [
            "~Maksim_Velikanov1",
            "~Maxim_Panov1",
            "~Dmitry_Yarotsky1"
        ],
        "keywords": [
            "gradient descent",
            "kernel ridge regression",
            "optimal algorithm",
            "generalization",
            "asymptotic error rates",
            "power-laws"
        ],
        "abstract": "The asymptotically precise estimation of the generalization of kernel methods has recently received attention due to the parallels between neural networks and their associated kernels. However, prior works derive such estimates for training by kernel ridge regression (KRR), whereas neural networks are typically trained with gradient descent (GD). In the present work, we consider the training of kernels with a family of \\emph{spectral algorithms} specified by profile $h(\\lambda)$, and including KRR and GD as special cases. Then, we derive the generalization error as a functional of learning profile $h(\\lambda)$ for two data models: high-dimensional Gaussian and low-dimensional translation-invariant model. \nUnder power-law assumptions on the spectrum of the kernel and target, we use our framework to (i) give full loss asymptotics for both noisy and noiseless observations (ii) show that the loss localizes on certain spectral scales, giving a new perspective on the KRR saturation phenomenon (iii) conjecture, and demonstrate for the considered data models, the universality of the loss w.r.t. non-spectral details of the problem, but only in case of noisy observation.",
        "_bibtex": "@inproceedings{\nvelikanov2024generalization,\ntitle={Generalization error of spectral algorithms},\nauthor={Maksim Velikanov and Maxim Panov and Dmitry Yarotsky},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3SJE1WLB4M}\n}"
    },
    {
        "title": "Debiased Collaborative Filtering with Kernel-Based Causal Balancing",
        "authorids": [
            "~Haoxuan_Li6",
            "~Chunyuan_Zheng1",
            "~Yanghao_Xiao1",
            "~Peng_Wu5",
            "~Zhi_Geng1",
            "~Xu_Chen13",
            "~Peng_Cui1"
        ],
        "keywords": [
            "Recommender System",
            "Causal Inference",
            "Bias",
            "Debias",
            "Balancing"
        ],
        "abstract": "Collaborative filtering builds personalized models from the collected user feedback. However, the collected data is observational rather than experimental, leading to various biases in the data, which can significantly affect the learned model. To address this issue, many studies have focused on propensity-based methods to combat the selection bias by reweighting the sample loss, and demonstrate that\nbalancing is important for debiasing both theoretically and empirically. However, there are two questions that still need to be addressed: which function class should be balanced and how to effectively balance that function class? In this paper, we first perform theoretical analysis to show the effect of balancing finite-dimensional function classes on the bias of IPS and DR methods, and based on this, we propose a universal kernel-based balancing method to balance functions on the reproducing kernel Hilbert space. In addition, we propose a novel adaptive causal balancing method during the alternating update between unbiased evaluation and training of the prediction model. Specifically, the prediction loss of the model is projected in the kernel-based covariate function space, and the projection coefficients are used to determine which functions should be prioritized for balancing to reduce the estimation bias. We conduct extensive experiments on three real-world datasets to demonstrate the effectiveness of the proposed approach.",
        "_bibtex": "@inproceedings{\nli2024debiased,\ntitle={Debiased Collaborative Filtering with Kernel-based Causal Balancing},\nauthor={Haoxuan Li and Yanghao Xiao and Chunyuan Zheng and Peng Wu and Zhi Geng and Xu Chen and Peng Cui},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Ffjc8ApSbt}\n}"
    },
    {
        "title": "The Effective Horizon Explains Deep RL Performance in Stochastic Environments",
        "authorids": [
            "~Cassidy_Laidlaw1",
            "~Banghua_Zhu1",
            "~Stuart_Russell1",
            "~Anca_Dragan1"
        ],
        "keywords": [
            "reinforcement learning",
            "effective horizon",
            "RL theory",
            "theory of reinforcement learning",
            "instance-dependent bounds",
            "empirical validation of theory"
        ],
        "abstract": "Reinforcement learning (RL) theory has largely focused on proving minimax sample complexity bounds. These require strategic exploration algorithms that use relatively limited function classes for representing the policy or value function. Our goal is to explain why deep RL algorithms often perform well in practice, despite using random exploration and much more expressive function classes like neural networks. Our work arrives at an explanation by showing that many stochastic MDPs can be solved by performing only a few steps of value iteration on the random policy\u2019s Q function and then acting greedily. When this is true, we find that it is possible to separate the exploration and learning components of RL, making it much easier to analyze. We introduce a new RL algorithm, SQIRL, that iteratively learns a near-optimal policy by exploring randomly to collect rollouts and then performing a limited number of steps of fitted-Q iteration over those roll- outs. We find that any regression algorithm that satisfies basic in-distribution generalization properties can be used in SQIRL to efficiently solve common MDPs. This can explain why deep RL works with complex function approximators like neural networks, since it is empirically established that neural networks generalize well in-distribution. Furthermore, SQIRL explains why random exploration works well in practice, since we show many environments can be solved by effectively estimating the random policy\u2019s Q-function and then applying zero or a few steps of value iteration. We leverage SQIRL to derive instance-dependent sample complexity bounds for RL that are exponential only in an \u201ceffective horizon\u201d of lookahead\u2014which is typically much smaller than the full horizon\u2014and on the complexity of the class used for function approximation. Empirically, we also find that SQIRL performance strongly correlates with PPO and DQN performance in a variety of stochastic environments, supporting that our theoretical analysis is predictive of practical performance. Our code and data are available at https://github.com/cassidylaidlaw/effective-horizon.",
        "_bibtex": "@inproceedings{\nlaidlaw2024the,\ntitle={The Effective Horizon Explains Deep {RL} Performance in Stochastic Environments},\nauthor={Cassidy Laidlaw and Banghua Zhu and Stuart Russell and Anca Dragan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5ES5Hdlbxw}\n}"
    },
    {
        "title": "Selective Visual Representations Improve Convergence and Generalization for Embodied AI",
        "authorids": [
            "~Ainaz_Eftekhar1",
            "~Kuo-Hao_Zeng3",
            "~Jiafei_Duan1",
            "~Ali_Farhadi3",
            "~Aniruddha_Kembhavi1",
            "~Ranjay_Krishna1"
        ],
        "keywords": [
            "Embodied-AI",
            "Task-conditioned Representations",
            "Visual Navigation",
            "Reinforcement Learning"
        ],
        "abstract": "Embodied AI models often employ off the shelf vision backbones like CLIP to encode their visual observations. Although such general purpose representations encode rich syntactic and semantic information about the scene, much of this information is often irrelevant to the specific task at hand. This introduces noise within the learning process and distracts the agent's focus from task-relevant visual cues.\nInspired by selective attention in humans\u2014the process through which people filter their perception based on their experiences, knowledge, and the task at hand\u2014we introduce a parameter-efficient approach to filter visual stimuli for embodied AI.\nOur approach induces a task-conditioned bottleneck using a small learnable codebook module. This codebook is trained jointly to optimize task reward and acts as a task-conditioned selective filter over the visual observation.\nOur experiments showcase state-of-the-art performance for object goal navigation and object displacement across $5$ benchmarks, ProcTHOR, ArchitecTHOR, RoboTHOR, AI2-iTHOR, and ManipulaTHOR. The filtered representations produced by the codebook are also able generalize better and converge faster when adapted to other simulation environments such as Habitat. Our qualitative analyses show that agents explore their environments more effectively and their representations retain task-relevant information like target object recognition while ignoring superfluous information about other objects.",
        "_bibtex": "@inproceedings{\neftekhar2024selective,\ntitle={Selective Visual Representations Improve Convergence and Generalization for Embodied {AI}},\nauthor={Ainaz Eftekhar and Kuo-Hao Zeng and Jiafei Duan and Ali Farhadi and Aniruddha Kembhavi and Ranjay Krishna},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=kC5nZDU5zf}\n}"
    },
    {
        "title": "Improving Generalization of Alignment with Human Preferences through Group Invariant Learning",
        "authorids": [
            "~Rui_Zheng1",
            "~Wei_Shen12",
            "~Yuan_Hua2",
            "~Wenbin_Lai1",
            "~Shihan_Dou1",
            "~Yuhao_Zhou3",
            "~Zhiheng_Xi1",
            "~Xiao_Wang12",
            "~Haoran_Huang1",
            "~Tao_Gui1",
            "~Qi_Zhang8",
            "~Xuanjing_Huang1"
        ],
        "keywords": [
            "alignment",
            "language model",
            "invariant learning"
        ],
        "abstract": "The success of AI assistants based on language models (LLMs) hinges crucially on Reinforcement Learning from Human Feedback (RLHF), which enables the generation of responses more aligned with human preferences. \nAs universal AI assistants, there's a growing expectation for them to perform consistently across various domains. \nHowever, previous work shows that Reinforcement Learning (RL) often exploits shortcuts to attain high rewards and overlooks challenging samples.\nThis focus on quick reward gains undermines both the stability in training and the model's ability to generalize to new, unseen data.\nIn this work, we propose a novel approach that can learn a consistent policy via RL across various data groups or domains. \nGiven the challenges associated with acquiring group annotations, our method automatically classifies data into different groups, deliberately maximizing performance variance.\nThen, we optimize the policy to perform well on challenging groups. \nLastly, leveraging the established groups, our approach adaptively adjusts the exploration space, allocating more learning capacity to more challenging data and preventing the model from over-optimizing on simpler data. Experimental results indicate that our approach significantly enhances training stability and model generalization.",
        "_bibtex": "@inproceedings{\nzheng2024improving,\ntitle={Improving Generalization of Alignment with Human Preferences through Group Invariant Learning},\nauthor={Rui Zheng and Wei Shen and Yuan Hua and Wenbin Lai and Shihan Dou and Yuhao Zhou and Zhiheng Xi and Xiao Wang and Haoran Huang and Tao Gui and Qi Zhang and Xuanjing Huang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=fwCoLe3TAX}\n}"
    },
    {
        "title": "PINNACLE: PINN Adaptive ColLocation and Experimental points selection",
        "authorids": [
            "~Gregory_Kang_Ruey_Lau1",
            "~Apivich_Hemachandra1",
            "~See-Kiong_Ng1",
            "~Bryan_Kian_Hsiang_Low1"
        ],
        "keywords": [
            "Physics-informed Neural Networks",
            "PINNs",
            "adaptive training points selection"
        ],
        "abstract": "Physics-Informed Neural Networks (PINNs), which incorporate PDEs as soft constraints, train with a composite loss function that contains multiple training point types: different types of collocation points chosen during training to enforce each PDE and initial/boundary conditions, and experimental points which are usually costly to obtain via experiments or simulations. Training PINNs using this loss function is challenging as it typically requires selecting large numbers of points of different types, each with different training dynamics. Unlike past works that focused on the selection of either collocation or experimental points, this work introduces PINN Adaptive ColLocation and Experimental points selection (PINNACLE), the first algorithm that jointly optimizes the selection of all training point types, while automatically adjusting the proportion of collocation point types as training progresses. PINNACLE uses information on the interactions among training point types, which had not been considered before, based on an analysis of PINN training dynamics via the Neural Tangent Kernel (NTK). We theoretically show that the criterion used by PINNACLE is related to the PINN generalization error, and empirically demonstrate that PINNACLE is able to outperform existing point selection methods for forward, inverse, and transfer learning problems.",
        "_bibtex": "@inproceedings{\nlau2024pinnacle,\ntitle={{PINNACLE}: {PINN} Adaptive ColLocation and Experimental points selection},\nauthor={Gregory Kang Ruey Lau and Apivich Hemachandra and See-Kiong Ng and Bryan Kian Hsiang Low},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=GzNaCp6Vcg}\n}"
    },
    {
        "title": "Learning to Relax: Setting Solver Parameters Across a Sequence of Linear System Instances",
        "authorids": [
            "~Mikhail_Khodak1",
            "~Edmond_Chow1",
            "~Maria_Florina_Balcan1",
            "~Ameet_Talwalkar1"
        ],
        "keywords": [
            "scientific computing",
            "data-driven algorithm design",
            "online learning",
            "multi-armed bandits",
            "contextual bandits",
            "numerical analysis",
            "learning-augmented algorithms",
            "algorithms with predictions"
        ],
        "abstract": "Solving a linear system ${\\bf Ax}={\\bf b}$ is a fundamental scientific computing primitive for which numerous solvers and preconditioners have been developed. \n\tThese come with parameters whose optimal values depend on the system being solved and are often impossible or too expensive to identify;\n\tthus in practice sub-optimal heuristics are used.\n\tWe consider the common setting in which many related linear systems need to be solved, e.g. during a single numerical simulation.\n\tIn this scenario, can we sequentially choose parameters that attain a near-optimal overall number of iterations, without extra matrix computations?\n\tWe answer in the affirmative for Successive Over-Relaxation (SOR), a standard solver whose parameter $\\omega$ has a strong impact on its runtime.\n\tFor this method, we prove that a bandit online learning algorithm\u2014using only the number of iterations as feedback\u2014can select parameters for a sequence of instances such that the overall cost approaches that of the best fixed $\\omega$ as the sequence length increases.\n\tFurthermore, when given additional structural information, we show that a _contextual_ bandit method asymptotically achieves the performance of the _instance-optimal_ policy, which selects the best $\\omega$ for each instance.\n\tOur work provides the first learning-theoretic treatment of high-precision linear system solvers and the first end-to-end guarantees for data-driven scientific computing, demonstrating theoretically the potential to speed up numerical methods using well-understood learning algorithms.",
        "_bibtex": "@inproceedings{\nkhodak2024learning,\ntitle={Learning to Relax: Setting Solver Parameters Across a Sequence of Linear System Instances},\nauthor={Mikhail Khodak and Edmond Chow and Maria Florina Balcan and Ameet Talwalkar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5t57omGVMw}\n}"
    },
    {
        "title": "Rotation Has Two Sides: Evaluating Data Augmentation for Deep One-class Classification",
        "authorids": [
            "~Guodong_Wang3",
            "~Yunhong_Wang1",
            "~Xiuguo_Bao3",
            "~Di_Huang4"
        ],
        "keywords": [
            "self-supervised learning",
            "deep one-class cilassification"
        ],
        "abstract": "One-class classification (OCC) involves predicting whether a new data is normal or anomalous based solely on the data from a single class during training. Various attempts have been made to learn suitable representations for OCC within a self-supervised framework. Notably, discriminative methods that use geometric visual transformations, such as rotation, to generate pseudo-anomaly samples have exhibited impressive detection performance. Although rotation is commonly viewed as a distribution-shifting transformation and is widely used in the literature, the cause of its effectiveness remains a mystery. In this study, we are the first to make a surprising observation: there exists a strong linear relationship (Pearson's Correlation, $r > 0.9$) between the accuracy of rotation prediction and the performance of OCC. This suggests that a classifier that effectively distinguishes different rotations is more likely to excel in OCC, and vice versa. The root cause of this phenomenon can be attributed to the transformation bias in the dataset, where representations learned from transformations already present in the dataset tend to be less effective, making it essential to accurately estimate the transformation distribution before utilizing pretext tasks involving these transformations for reliable self-supervised representation learning. To the end, we propose a novel two-stage method to estimate the transformation distribution within the dataset. In the first stage, we learn general representations through standard contrastive pre-training. In the second stage, we select potentially semantics-preserving samples from the entire augmented dataset, which includes all rotations, by employing density matching with the provided reference distribution. By sorting samples based on semantics-preserving versus shifting transformations, we achieve improved performance on OCC benchmarks.",
        "_bibtex": "@inproceedings{\nwang2024rotation,\ntitle={Rotation Has Two Sides: Evaluating Data Augmentation for Deep One-class Classification},\nauthor={Guodong Wang and Yunhong Wang and Xiuguo Bao and Di Huang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Ad81awoBVS}\n}"
    },
    {
        "title": "Realistic Evaluation of Semi-supervised Learning Algorithms in Open Environments",
        "authorids": [
            "~Lin-Han_Jia1",
            "~Lan-Zhe_Guo2",
            "~Zhi_Zhou2",
            "~Yu-Feng_Li1"
        ],
        "keywords": [
            "Semi-Supervised Learning; Robustness; Open Environments"
        ],
        "abstract": "Semi-supervised learning (SSL) is a powerful paradigm for leveraging unlabeled data and has been proven to be successful across various tasks. Conventional SSL studies typically assume close environment scenarios where labeled and unlabeled examples are independently sampled from the same distribution. However, real-world tasks often involve open environment scenarios where the data distribution, label space, and feature space could differ between labeled and unlabeled data. This inconsistency introduces robustness challenges for SSL algorithms. In this paper, we first propose several robustness metrics for SSL based on the Robustness Analysis Curve (RAC), secondly, we establish a theoretical framework for studying the generalization performance and robustness of SSL algorithms in open environments, thirdly, we re-implement widely adopted SSL algorithms within a unified SSL toolkit and evaluate their performance on proposed open environment SSL benchmarks, including both image, text, and tabular datasets. By investigating the empirical and theoretical results, insightful discussions on enhancing the robustness of SSL algorithms in open environments are presented. The re-implementation and benchmark datasets are all publicly available. More details can be found at https://ygzwqzd.github.io/Robust-SSL-Benchmark.",
        "_bibtex": "@inproceedings{\njia2024realistic,\ntitle={Realistic Evaluation of Semi-supervised Learning Algorithms in Open Environments},\nauthor={Lin-Han Jia and Lan-Zhe Guo and Zhi Zhou and Yu-Feng Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=RvUVMjfp8i}\n}"
    },
    {
        "title": "Efficient Inverse Multiagent Learning",
        "authorids": [
            "~Denizalp_Goktas1",
            "~Amy_Greenwald1",
            "~Sadie_Zhao1",
            "~Alec_Koppel1",
            "~Sumitra_Ganesh1"
        ],
        "keywords": [
            "Inverse Game Theory",
            "Inverse Multiagent Reinforcement Learning"
        ],
        "abstract": "In this paper, we study inverse game theory (resp. inverse multiagent learning) in\nwhich the goal is to find parameters of a game\u2019s payoff functions for which the\nexpected (resp. sampled) behavior is an equilibrium. We formulate these problems\nas generative-adversarial (i.e., min-max) optimization problems, which we develop\npolynomial-time algorithms to solve, the former of which relies on an exact first-\norder oracle, and the latter, a stochastic one. We extend our approach to solve\ninverse multiagent simulacral learning in polynomial time and number of samples.\nIn these problems, we seek a simulacrum, meaning parameters and an associated\nequilibrium that replicate the given observations in expectation. We find that our\napproach outperforms the widely-used ARIMA method in predicting prices in\nSpanish electricity markets based on time-series data.",
        "_bibtex": "@inproceedings{\ngoktas2024efficient,\ntitle={Efficient Inverse Multiagent Learning},\nauthor={Denizalp Goktas and Amy Greenwald and Sadie Zhao and Alec Koppel and Sumitra Ganesh},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=JzvIWvC9MG}\n}"
    },
    {
        "title": "On the Role of Discrete Tokenization in Visual Representation Learning",
        "authorids": [
            "~Tianqi_Du1",
            "~Yifei_Wang1",
            "~Yisen_Wang1"
        ],
        "keywords": [
            "Self-supervised learning",
            "Masked image modeling",
            "Discrete visual token"
        ],
        "abstract": "In the realm of self-supervised learning (SSL), masked image modeling (MIM) has gained popularity alongside contrastive learning methods. MIM involves reconstructing masked regions of input images using their unmasked portions. A notable subset of MIM methodologies employs discrete tokens as the reconstruction target, but the theoretical underpinnings of this choice remain underexplored. In this paper, we explore the role of these discrete tokens, aiming to unravel their benefits and limitations. Building upon the connection between MIM and contrastive learning, we provide a comprehensive theoretical understanding on how discrete tokenization affects the model's generalization capabilities. Furthermore, we propose a novel metric named TCAS, which is specifically designed to assess the effectiveness of discrete tokens within the MIM framework. Inspired by this metric, we contribute an innovative tokenizer design and propose a corresponding MIM method named ClusterMIM. It demonstrates superior performance on a variety of benchmark datasets and ViT backbones. Code is available at \\url{https://github.com/PKU-ML/ClusterMIM}.",
        "_bibtex": "@inproceedings{\ndu2024on,\ntitle={On the Role of Discrete Tokenization in Visual Representation Learning},\nauthor={Tianqi Du and Yifei Wang and Yisen Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=WNLAkjUm19}\n}"
    },
    {
        "title": "The Consensus Game: Language Model Generation via Equilibrium Search",
        "authorids": [
            "~Athul_Paul_Jacob1",
            "~Yikang_Shen1",
            "~Gabriele_Farina1",
            "~Jacob_Andreas1"
        ],
        "keywords": [
            "language models",
            "decoding",
            "planning",
            "game theory"
        ],
        "abstract": "When applied to question answering and other text generation tasks, language models (LMs) may be queried generatively (by sampling answers from their output distribution) or discriminatively (by using them to score or rank a set of candidate answers). These procedures sometimes yield very different predictions. How do we reconcile mutually incompatible scoring procedures to obtain coherent LM predictions? We introduce a new, a training-free, game-theoretic procedure for language model decoding. Our approach casts language model decoding as a regularized imperfect-information sequential signaling game\u2014which we term the concensus game\u2014in which a generator seeks to communicate an abstract correctness parameter using natural language sentences to a discriminator. We develop computational procedures for finding approximate equilibria of this game, resulting in a decoding algorithm we call equilibrium-ranking. Applied to a large number of tasks (including reading comprehension, commonsense reasoning, mathematical problem-solving, and assistive dialog), equilibrium-ranking consistently improves performance over existing LM decoding procedures. These improvements are sometimes substantial\u2014on multiple benchmarks, we observe that applying equilibrium-ranking to LLaMA-7B outperforms the much larger LLaMA-65B and PaLM-540B models.",
        "_bibtex": "@inproceedings{\njacob2024the,\ntitle={The Consensus Game: Language Model Generation via Equilibrium Search},\nauthor={Athul Paul Jacob and Yikang Shen and Gabriele Farina and Jacob Andreas},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=n9xeGcI4Yg}\n}"
    },
    {
        "title": "AMAGO: Scalable In-Context Reinforcement Learning for Adaptive Agents",
        "authorids": [
            "~Jake_Grigsby1",
            "~Linxi_Fan2",
            "~Yuke_Zhu1"
        ],
        "keywords": [
            "Meta-RL",
            "Generalization",
            "Long-Term Memory",
            "Transformers"
        ],
        "abstract": "We introduce AMAGO, an in-context Reinforcement Learning (RL) agent that uses sequence models to tackle the challenges of generalization, long-term memory, and meta-learning. Recent works have shown that off-policy learning can make in-context RL with recurrent policies viable. Nonetheless, these approaches require extensive tuning and limit scalability by creating key bottlenecks in agents' memory capacity, planning horizon, and model size. AMAGO revisits and redesigns the off-policy in-context approach to successfully train long-sequence Transformers over entire rollouts in parallel with end-to-end RL. Our agent is scalable and applicable to a wide range of problems, and we demonstrate its strong performance empirically in meta-RL and long-term memory domains. AMAGO's focus on sparse rewards and off-policy data also allows in-context learning to extend to goal-conditioned problems with challenging exploration. When combined with a multi-goal hindsight relabeling scheme, AMAGO can solve a previously difficult category of open-world domains, where agents complete many possible instructions in procedurally generated environments.",
        "_bibtex": "@inproceedings{\ngrigsby2024amago,\ntitle={{AMAGO}: Scalable In-Context Reinforcement Learning for Adaptive Agents},\nauthor={Jake Grigsby and Linxi Fan and Yuke Zhu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=M6XWoEdmwf}\n}"
    },
    {
        "title": "PILOT: An $\\mathcal{O}(1/K)$-Convergent Approach for Policy Evaluation with Nonlinear Function Approximation",
        "authorids": [
            "~Zhuqing_Liu2",
            "~Xin_Zhang16",
            "~Jia_Liu1",
            "~Zhengyuan_Zhu1",
            "~Songtao_Lu1"
        ],
        "keywords": [
            "min-max optimization",
            "adaptive batch size",
            "policy evaluation."
        ],
        "abstract": "Learning an accurate value function for a given policy is a critical step in solving reinforcement learning (RL) problems. So far, however, the convergence speed and sample complexity performances of most existing policy evaluation algorithms remain unsatisfactory, particularly with non-linear function approximation. This challenge motivates us to develop a new path-integrated primal-dual stochastic gradient (PILOT) method, that is able to achieve a fast convergence speed for RL policy evaluation with nonlinear function approximation. To further alleviate the periodic full gradient evaluation requirement, we further propose an enhanced method with an adaptive-batch adjustment called PILOT$^+$. The main advantages of our methods include: i) PILOT allows the use of {\\em{constant}} step sizes and achieves the $\\mathcal{O}(1/K)$ convergence rate to first-order stationary points of non-convex policy evaluation problems; ii) PILOT is a generic {\\em{single}}-timescale algorithm that is also applicable for solving a large class of non-convex strongly-concave minimax optimization problems; iii) By adaptively adjusting the batch size via historical stochastic gradient information, PILOT$^+$ is more sample-efficient empirically without loss of theoretical convergence rate. Our extensive numerical experiments verify our theoretical findings and showcase the high efficiency of the proposed PILOT and PILOT$^+$ algorithms compared with the state-of-the-art methods.",
        "_bibtex": "@inproceedings{\nliu2024pilot,\ntitle={{PILOT}: An \\${\\textbackslash}mathcal\\{O\\}(1/K)\\$-Convergent Approach for Policy Evaluation with Nonlinear Function Approximation},\nauthor={Zhuqing Liu and Xin Zhang and Jia Liu and Zhengyuan Zhu and Songtao Lu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=OkHHJcMroY}\n}"
    },
    {
        "title": "Confronting Reward Model Overoptimization with Constrained RLHF",
        "authorids": [
            "~Ted_Moskovitz1",
            "~Aaditya_K_Singh1",
            "~DJ_Strouse1",
            "~Tuomas_Sandholm1",
            "~Ruslan_Salakhutdinov1",
            "~Anca_Dragan1",
            "~Stephen_Marcus_McAleer1"
        ],
        "keywords": [
            "rlhf",
            "overoptimization",
            "constrained RL"
        ],
        "abstract": "Large language models are typically aligned with human preferences by optimizing reward models (RMs) fitted to human feedback. However, human preferences are multi-faceted, and it is increasingly common to derive reward from a composition of simpler reward models which each capture a different aspect of language quality. This itself presents a challenge, as it is difficult to appropriately weight these component RMs when combining them. Compounding this difficulty, because any RM is only a proxy for human evaluation, this process is vulnerable to *overoptimization*, wherein past a certain point, accumulating higher reward is associated with worse human ratings. In this paper, we perform the first study on overoptimization in composite RMs, showing that correlation between component RMs has a significant effect on the locations of these points. We then introduce an approach to solve this issue using constrained reinforcement learning as a means of preventing the agent from exceeding each RM's threshold of usefulness. Our method addresses the problem of weighting component RMs by learning dynamic weights, naturally given by the Lagrange multipliers. As a result, each RM stays within the range at which it is an effective proxy, improving evaluation performance. Finally, we introduce an adaptive method using gradient-free optimization to identify and optimize towards these points during a single run.",
        "_bibtex": "@inproceedings{\nmoskovitz2024confronting,\ntitle={Confronting Reward Model Overoptimization with Constrained {RLHF}},\nauthor={Ted Moskovitz and Aaditya K Singh and DJ Strouse and Tuomas Sandholm and Ruslan Salakhutdinov and Anca Dragan and Stephen Marcus McAleer},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=gkfUvn0fLU}\n}"
    },
    {
        "title": "LiDAR: Sensing Linear Probing Performance in Joint Embedding SSL Architectures",
        "authorids": [
            "~Vimal_Thilak2",
            "~Chen_Huang6",
            "~Omid_Saremi1",
            "~Laurent_Dinh1",
            "~Hanlin_Goh2",
            "~Preetum_Nakkiran1",
            "~Joshua_M._Susskind1",
            "~Etai_Littwin1"
        ],
        "keywords": [
            "Self Supervised Learning",
            "Joint Embedding Architectures"
        ],
        "abstract": "Joint embedding (JE) architectures have emerged as a promising avenue for ac-\nquiring transferable data representations. A key obstacle to using JE methods,\nhowever, is the inherent challenge of evaluating learned representations without\naccess to a downstream task, and an annotated dataset. Without efficient and re-\nliable evaluation, it is difficult to iterate on architectural and training choices for\nJE methods. In this paper, we introduce LiDAR (Linear Discriminant Analysis\nRank), a metric designed to measure the quality of representations within JE archi-\ntectures. Our metric addresses several shortcomings of recent approaches based\non feature covariance rank by discriminating between informative and uninforma-\ntive features. In essence, LiDAR quantifies the rank of the Linear Discriminant\nAnalysis (LDA) matrix associated with the surrogate SSL task\u2014a measure that\nintuitively captures the information content as it pertains to solving the SSL task.\nWe empirically demonstrate that LiDAR significantly surpasses naive rank based\napproaches in its predictive power of optimal hyperparameters. Our proposed cri-\nterion presents a more robust and intuitive means of assessing the quality of rep-\nresentations within JE architectures, which we hope facilitates broader adoption\nof these powerful techniques in various domains.",
        "_bibtex": "@inproceedings{\nthilak2024lidar,\ntitle={Li{DAR}: Sensing Linear Probing Performance in Joint Embedding {SSL} Architectures},\nauthor={Vimal Thilak and Chen Huang and Omid Saremi and Laurent Dinh and Hanlin Goh and Preetum Nakkiran and Joshua M. Susskind and Etai Littwin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=f3g5XpL9Kb}\n}"
    },
    {
        "title": "Improved Efficiency Based on Learned Saccade and Continuous Scene Reconstruction From Foveated Visual Sampling",
        "authorids": [
            "~Jiayang_Liu2",
            "~Yiming_Bu1",
            "~Daniel_Tso1",
            "~Qinru_Qiu1"
        ],
        "keywords": [
            "Biological inspired high performance energy efficient vision system",
            "data efficient training",
            "energy saving sensoring",
            "learned saccade",
            "reinforcement learning",
            "foveated visual sampling",
            "continuous scene reconstruction."
        ],
        "abstract": "High accuracy, low latency and high energy efficiency represent a set of contradictory goals when searching for  system solutions for image classification and detection. While high-quality images naturally result in more precise detection and classification, they also result in a heavier computational workload for imaging and processing, reduce camera refresh rates, and increase the volume of data communication between the camera and processor. Taking inspiration from the foveal-peripheral sampling mechanism, saccade mechanism observed in the human visual system and the filling-in phenomena of brain, we have developed an active scene reconstruction architecture based on multiple foveal views. This model stitches together information from foveal and peripheral vision, which are sampled from multiple glances. Assisted by a reinforcement learning-based saccade mechanism, our model reduces the required input pixels by over 90\\% per frame while maintaining the same level of performance in image recognition as with the original images. We evaluated the effectiveness of our model using the GTSRB dataset and the ImageNet dataset. Using an equal number of input pixels, our study demonstrates a 5\\% higher image recognition accuracy compared to state-of-the-art foveal-peripheral vision systems. Furthermore, we demonstrate that our foveal sampling/saccadic scene reconstruction model exhibits significantly lower complexity and higher data efficiency during the training phase compared to existing approaches.",
        "_bibtex": "@inproceedings{\nliu2024improved,\ntitle={Improved Efficiency Based on Learned Saccade and Continuous Scene Reconstruction From Foveated Visual Sampling},\nauthor={Jiayang Liu and Yiming Bu and Daniel Tso and Qinru Qiu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=lOwkOIUJtx}\n}"
    },
    {
        "title": "Overthinking the Truth: Understanding how Language Models Process False Demonstrations",
        "authorids": [
            "~Danny_Halawi1",
            "~Jean-Stanislas_Denain1",
            "~Jacob_Steinhardt1"
        ],
        "keywords": [
            "Mechanistic Interpretability",
            "AI Safety",
            "Interpretability",
            "Science of ML",
            "few-shot learning",
            "Large Language Models"
        ],
        "abstract": "Modern language models can imitate complex patterns through few-shot learning, enabling them to complete challenging tasks without fine-tuning. However, imitation can also lead models to reproduce inaccuracies or harmful content if present in the context. We study harmful imitation through the lens of a model\u2019s internal representations, and identify two related phenomena: overthinking and false induction heads. The first phenomenon, overthinking, appears when we decode predictions from intermediate layers, given correct vs. incorrect few-shot demonstrations. At early layers, both demonstrations induce similar model behavior, but the behavior diverges sharply at some \u201ccritical layer\u201d, after which the accuracy given incorrect demonstrations progressively decreases. The second phenomenon, false induction heads, are a possible mechanistic cause of overthinking: these are heads in late layers that attend to and copy false information from previous demonstrations, and whose ablation reduces overthinking. Beyond scientific understanding, our results suggest that studying intermediate model computations could be a promising avenue for understanding and guarding against harmful model behaviors.",
        "_bibtex": "@inproceedings{\nhalawi2024overthinking,\ntitle={Overthinking the Truth: Understanding how Language Models Process False Demonstrations},\nauthor={Danny Halawi and Jean-Stanislas Denain and Jacob Steinhardt},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Tigr1kMDZy}\n}"
    },
    {
        "title": "MT-Ranker: Reference-free machine translation evaluation by inter-system ranking",
        "authorids": [
            "~Ibraheem_Muhammad_Moosa1",
            "~Rui_Zhang7",
            "~Wenpeng_Yin1"
        ],
        "keywords": [
            "Machine Translation Evaluation"
        ],
        "abstract": "Traditionally, Machine Translation (MT) Evaluation has been treated as a regression problem -- producing an absolute translation-quality score. This approach has two limitations: i) the scores lack interpretability, and human annotators struggle with giving consistent scores; ii) most scoring methods are based on (reference, translation) pairs, limiting their applicability in real-world scenarios where references are absent. In practice, we often care about whether a new MT system is better or worse than some competitors. In addition, reference-free MT evaluation is increasingly practical and necessary. Unfortunately, these two practical considerations have yet to be jointly explored. In this work, we formulate the reference-free MT evaluation into a pairwise ranking problem. Given the source sentence and a pair of translations, our system predicts which translation is better. In addition to proposing this new formulation, we further show that this new paradigm can demonstrate superior correlation with human judgments by merely using indirect supervision from natural language inference and weak supervision from our synthetic data. In the context of reference-free evaluation, MT-Ranker, trained without any human annotations, achieves state-of-the-art results on the WMT Shared Metrics Task benchmarks DARR20, MQM20, and MQM21. On a more challenging benchmark, ACES, which contains fine-grained evaluation criteria such as addition, omission, and mistranslation errors, MT-Ranker marks state-of-the-art against reference-free as well as reference-based baselines.",
        "_bibtex": "@inproceedings{\nmoosa2024mtranker,\ntitle={{MT}-Ranker: Reference-free machine translation evaluation by inter-system ranking},\nauthor={Ibraheem Muhammad Moosa and Rui Zhang and Wenpeng Yin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Rry1SeSOQL}\n}"
    },
    {
        "title": "MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning",
        "authorids": [
            "~Zayne_Rea_Sprague1",
            "~Xi_Ye2",
            "~Kaj_Bostrom1",
            "~Swarat_Chaudhuri1",
            "~Greg_Durrett1"
        ],
        "keywords": [
            "Large Language Models",
            "Chain-of-Thought",
            "Textual Reasoning"
        ],
        "abstract": "While large language models (LLMs) equipped with techniques like chain-of-thought prompting have demonstrated impressive capabilities, they still fall short in their ability to reason robustly in complex settings. However, evaluating LLM reasoning is challenging because system capabilities continue to grow while benchmark datasets for tasks like logical deduction have remained static. We introduce MuSR, a dataset for evaluating language models on multistep soft reasoning tasks specified in a natural language narrative. This dataset has two crucial features. First, it is created through a novel neurosymbolic synthetic-to-natural generation algorithm, enabling the construction of complex reasoning instances that challenge GPT-4 (e.g., murder mysteries roughly 1000 words in length) and which can be scaled further as more capable LLMs are released. Second, our data instances are free text narratives corresponding to real-world domains of reasoning; this makes it simultaneously much more challenging than other synthetically-crafted benchmarks while remaining realistic and tractable for human annotators to solve with high accuracy. We evaluate a range of LLMs and prompting techniques on this dataset and characterize the gaps that remain for techniques like chain-of-thought to perform robust reasoning.",
        "_bibtex": "@inproceedings{\nsprague2024musr,\ntitle={Mu{SR}: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning},\nauthor={Zayne Rea Sprague and Xi Ye and Kaj Bostrom and Swarat Chaudhuri and Greg Durrett},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=jenyYQzue1}\n}"
    },
    {
        "title": "Harnessing Density Ratios for Online Reinforcement Learning",
        "authorids": [
            "~Philip_Amortila1",
            "~Dylan_J_Foster1",
            "~Nan_Jiang2",
            "~Ayush_Sekhari1",
            "~Tengyang_Xie1"
        ],
        "keywords": [
            "reinforcement learning theory",
            "online RL",
            "offline RL",
            "hybrid RL",
            "density ratio",
            "marginalized importance weight",
            "weight function",
            "general function approximation"
        ],
        "abstract": "The theories of offline and online reinforcement learning, despite having evolved in parallel, have begun to show signs of the possibility for a unification, with algorithms and analysis techniques for one setting often having natural counterparts in the other. However, the notion of *density ratio modeling*, an emerging paradigm in offline RL, has been largely absent from online RL, perhaps for good reason: the very existence and boundedness of density ratios relies on access to an exploratory dataset with good coverage, but the core challenge in online RL is to collect such a dataset without having one to start.\n\nIn this work we show---perhaps surprisingly---that density ratio-based algorithms have online counterparts.  Assuming only the existence of an exploratory distribution with good coverage, a structural condition known as *coverability* (Xie et al., 2023), we give a new algorithm (GLOW) that uses density ratio realizability and value function realizability to perform sample-efficient online exploration. GLOW addresses unbounded density ratios via careful use of truncation, and combines this with optimism to guide exploration. GLOW is computationally inefficient; we complement it with a more efficient counterpart, HyGLOW, for the Hybrid RL setting (Song et al., 2023) wherein online RL is augmented with additional offline data. HyGLOW is derived as a special case of a more general meta-algorithm that provides a provable black-box reduction from hybrid RL to offline RL, which may be of independent interest.",
        "_bibtex": "@inproceedings{\namortila2024harnessing,\ntitle={Harnessing Density Ratios for Online Reinforcement Learning},\nauthor={Philip Amortila and Dylan J Foster and Nan Jiang and Ayush Sekhari and Tengyang Xie},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=THJEa8adBn}\n}"
    },
    {
        "title": "Predictive, scalable and interpretable knowledge tracing on structured domains",
        "authorids": [
            "~Hanqi_Zhou1",
            "~Robert_Bamler1",
            "~Charley_M_Wu1",
            "~\u00c1lvaro_Tejero-Cantero1"
        ],
        "keywords": [
            "knowledge tracing",
            "interpretable representations",
            "knowledge graphs",
            "probabilistic models",
            "variational inference",
            "continual learning"
        ],
        "abstract": "Intelligent tutoring systems optimize the selection and timing of learning materials to enhance understanding and long-term retention. This requires estimates of both the learner's progress (\"knowledge tracing\"; KT), and the prerequisite structure of the learning domain (\"knowledge mapping\"). While recent deep learning models achieve high KT accuracy, they do so at the expense of the interpretability of psychologically-inspired models. In this work, we present a solution to this trade-off. PSI-KT is a hierarchical generative approach that explicitly models how both individual cognitive traits and the prerequisite structure of knowledge influence learning dynamics, thus achieving interpretability by design. Moreover, by using scalable Bayesian inference, PSI-KT targets the real-world need for efficient personalization even with a growing body of learners and interaction data. Evaluated on three datasets from online learning platforms, PSI-KT achieves superior multi-step **p**redictive accuracy and **s**calable inference in continual-learning settings, all while providing **i**nterpretable representations of learner-specific traits and the prerequisite structure of knowledge that causally supports learning. In sum, predictive, scalable and interpretable knowledge tracing with solid knowledge mapping lays a key foundation for effective personalized learning to make education accessible to a broad, global audience.",
        "_bibtex": "@inproceedings{\nzhou2024predictive,\ntitle={Predictive, scalable and interpretable knowledge tracing on structured domains},\nauthor={Hanqi Zhou and Robert Bamler and Charley M Wu and {\\'A}lvaro Tejero-Cantero},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=NgaLU2fP5D}\n}"
    },
    {
        "title": "From Bricks to Bridges: Product of Invariances to Enhance Latent Space Communication",
        "authorids": [
            "~Irene_Cannistraci1",
            "~Luca_Moschella1",
            "~Marco_Fumero1",
            "~Valentino_Maiorca1",
            "~Emanuele_Rodol\u00e01"
        ],
        "keywords": [
            "invariance",
            "latent space",
            "latent comunication",
            "zero-shot stitching",
            "representation learning",
            "relative representation"
        ],
        "abstract": "It has been observed that representations learned by distinct neural networks conceal structural similarities when the models are trained under similar inductive biases. From a geometric perspective, identifying the classes of transformations and the related invariances that connect these representations is fundamental to unlocking applications, such as merging, stitching, and reusing different neural modules. However, estimating task-specific transformations a priori can be challenging and expensive due to several factors (e.g., weights initialization, training hyperparameters, or data modality). To this end, we introduce a versatile method to directly incorporate a set of invariances into the representations, constructing a product space of invariant components on top of the latent representations without requiring prior knowledge about the optimal invariance to infuse. We validate our solution on classification and reconstruction tasks, observing consistent latent similarity and downstream performance improvements in a zero-shot stitching setting. The experimental analysis comprises three modalities (vision, text, and graphs), twelve pretrained foundational models, nine benchmarks, and several architectures trained from scratch.",
        "_bibtex": "@inproceedings{\ncannistraci2024from,\ntitle={From Bricks to Bridges: Product of Invariances to Enhance Latent Space Communication},\nauthor={Irene Cannistraci and Luca Moschella and Marco Fumero and Valentino Maiorca and Emanuele Rodol{\\`a}},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=vngVydDWft}\n}"
    },
    {
        "title": "Proximal Policy Gradient Arborescence for Quality Diversity Reinforcement Learning",
        "authorids": [
            "~Sumeet_Batra1",
            "~Bryon_Tjanaka1",
            "~Matthew_Christopher_Fontaine1",
            "~Aleksei_Petrenko1",
            "~Stefanos_Nikolaidis1",
            "~Gaurav_S._Sukhatme1"
        ],
        "keywords": [
            "Reinforcement Learning",
            "Quality Diversity",
            "Robotics",
            "Machine Learning",
            "Evolution Strategies"
        ],
        "abstract": "Training generally capable agents that thoroughly explore their environment and\nlearn new and diverse skills is a long-term goal of robot learning. Quality Diversity\nReinforcement Learning (QD-RL) is an emerging research area that blends the\nbest aspects of both fields \u2013 Quality Diversity (QD) provides a principled form\nof exploration and produces collections of behaviorally diverse agents, while\nReinforcement Learning (RL) provides a powerful performance improvement\noperator enabling generalization across tasks and dynamic environments. Existing\nQD-RL approaches have been constrained to sample efficient, deterministic off-\npolicy RL algorithms and/or evolution strategies and struggle with highly stochastic\nenvironments. In this work, we, for the first time, adapt on-policy RL, specifically\nProximal Policy Optimization (PPO), to the Differentiable Quality Diversity (DQD)\nframework and propose several changes that enable efficient optimization and\ndiscovery of novel skills on high-dimensional, stochastic robotics tasks. Our new\nalgorithm, Proximal Policy Gradient Arborescence (PPGA), achieves state-of-\nthe-art results, including a 4x improvement in best reward over baselines on the\nchallenging humanoid domain.",
        "_bibtex": "@inproceedings{\nbatra2024proximal,\ntitle={Proximal Policy Gradient Arborescence for Quality Diversity Reinforcement Learning},\nauthor={Sumeet Batra and Bryon Tjanaka and Matthew Christopher Fontaine and Aleksei Petrenko and Stefanos Nikolaidis and Gaurav S. Sukhatme},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TFKIfhvdmZ}\n}"
    },
    {
        "title": "Memorization Capacity of Multi-Head Attention in Transformers",
        "authorids": [
            "~Sadegh_Mahdavi1",
            "~Renjie_Liao1",
            "~Christos_Thrampoulidis1"
        ],
        "keywords": [
            "Learning Theory",
            "Expressivity",
            "Multi-Head Attention",
            "Transformers"
        ],
        "abstract": "Transformers have become the go-to architecture for language and vision tasks, yet their theoretical properties, especially memorization capacity, remain elusive. This paper investigates the memorization abilities of multi-head attention mechanisms, examining how many example sequences they can memorize, as a function of the number of heads and sequence length. Motivated by experimental findings on vision transformers, we introduce novel assumptions about the linear independence of input data, distinct from the commonly used general-position assumption. Under these assumptions, we demonstrate that an attention layer with $H$ heads, dimension $d$, and context size $n < d,$ featuring $\\Theta(Hd^2)$ parameters, can memorize $\\Omega(Hn)$ examples. Our analysis sheds light on how different attention heads handle various example sequences, aided by the softmax operator\u2019s saturation property. We validate our findings through experiments on synthetic data.",
        "_bibtex": "@inproceedings{\nmahdavi2024memorization,\ntitle={Memorization Capacity of Multi-Head Attention in Transformers},\nauthor={Sadegh Mahdavi and Renjie Liao and Christos Thrampoulidis},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MrR3rMxqqv}\n}"
    },
    {
        "title": "Circuit Component Reuse Across Tasks in Transformer Language Models",
        "authorids": [
            "~Jack_Merullo2",
            "~Carsten_Eickhoff1",
            "~Ellie_Pavlick1"
        ],
        "keywords": [
            "interpretability",
            "llms",
            "mechanistic interpretability",
            "circuit"
        ],
        "abstract": "Recent work in mechanistic interpretability has shown that behaviors in language models can be successfully reverse-engineered through circuit analysis. A common criticism, however, is that each circuit is task-specific, and thus such analysis cannot contribute to understanding the models at a higher level. In this work, we present evidence that insights (both low-level findings about specific heads and higher-level findings about general algorithms) can indeed generalize across tasks. Specifically, we study the circuit discovered in (Wang, 2022) for the Indirect Object Identification (IOI) task and 1.) show that it reproduces on a larger GPT2 model, and 2.) that it is mostly reused to solve a seemingly different task: Colored Objects (Ippolito & Callison-Burch, 2023). We provide evidence that the process underlying both tasks is functionally very similar, and contains about a 78% overlap in in-circuit attention heads. We further present a proof-of-concept intervention experiment, in which we adjust four attention heads in middle layers in order to \u2018repair\u2019 the Colored Objects circuit and make it behave like the IOI circuit. In doing so, we boost accuracy from 49.6% to 93.7% on the Colored Objects task and explain most sources of error. The intervention affects downstream attention heads in specific ways predicted by their interactions in the IOI circuit, indicating that this subcircuit behavior is invariant to the different task inputs. Overall, our results provide evidence that it may yet be possible to explain large language models' behavior in terms of a relatively small number of interpretable task-general algorithmic building blocks and computational components.",
        "_bibtex": "@inproceedings{\nmerullo2024circuit,\ntitle={Circuit Component Reuse Across Tasks in Transformer Language Models},\nauthor={Jack Merullo and Carsten Eickhoff and Ellie Pavlick},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=fpoAYV6Wsk}\n}"
    },
    {
        "title": "Likelihood Training of Cascaded Diffusion Models via Hierarchical Volume-preserving Maps",
        "authorids": [
            "~Henry_Li2",
            "~Ronen_Basri1",
            "~Yuval_Kluger1"
        ],
        "keywords": [
            "likelihood-based modeling",
            "diffusion modeling",
            "density estimation"
        ],
        "abstract": "Cascaded models are multi-scale generative models with a marked capacity for producing perceptually impressive samples at high resolutions. In this work, we show that they can also be excellent likelihood models, so long as we overcome a fundamental difficulty with probabilistic multi-scale models: the intractability of the likelihood function. Chiefly, in cascaded models each intermediary scale introduces extraneous variables that cannot be tractably marginalized out for likelihood evaluation. This issue vanishes by modeling the diffusion process on latent spaces induced by a class of transformations we call hierarchical volume-preserving maps, which decompose spatially structured data in a hierarchical fashion without introducing local distortions in the latent space. We demonstrate that two such maps are well-known in the literature for multiscale modeling: Laplacian pyramids and wavelet transforms. Not only do such reparameterizations allow the likelihood function to be directly expressed as a joint likelihood over the scales, we show that the Laplacian pyramid and wavelet transform also produces significant improvements to the state-of-the-art on a selection of benchmarks in likelihood modeling, including density estimation, lossless compression, and out-of-distribution detection. Investigating the theoretical basis of our empirical gains we uncover deep connections to score matching under the Earth Mover's Distance (EMD), which is a well-known surrogate for perceptual similarity.",
        "_bibtex": "@inproceedings{\nli2024likelihood,\ntitle={Likelihood Training of Cascaded Diffusion Models via Hierarchical Volume-preserving Maps},\nauthor={Henry Li and Ronen Basri and Yuval Kluger},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=sojpn00o8z}\n}"
    },
    {
        "title": "Empirical Analysis of Model Selection for Heterogeneous Causal Effect Estimation",
        "authorids": [
            "~Divyat_Mahajan1",
            "~Ioannis_Mitliagkas1",
            "~Brady_Neal2",
            "~Vasilis_Syrgkanis1"
        ],
        "keywords": [
            "Heterogeneous Treatment Effect Estimation",
            "Conditional Average Treatment Effect",
            "Causal Inference",
            "Model Selection"
        ],
        "abstract": "We study the problem of model selection in causal inference, specifically for conditional average treatment effect (CATE) estimation. Unlike machine learning, there is no perfect analogue of cross-validation for model selection as we do not observe the counterfactual potential outcomes. Towards this, a variety of surrogate metrics have been proposed for CATE model selection that use only observed data. However, we do not have a good understanding regarding their effectiveness due to limited comparisons in prior studies. We conduct an extensive empirical analysis to benchmark the surrogate model selection metrics introduced in the literature, as well as the novel ones introduced in this work. We ensure a fair comparison by tuning the hyperparameters associated with these metrics via AutoML, and provide more detailed trends by incorporating realistic datasets via generative modeling. Our analysis suggests novel model selection strategies based on careful hyperparameter selection of CATE estimators and causal ensembling.",
        "_bibtex": "@inproceedings{\nmahajan2024empirical,\ntitle={Empirical Analysis of Model Selection for Heterogeneous Causal Effect Estimation},\nauthor={Divyat Mahajan and Ioannis Mitliagkas and Brady Neal and Vasilis Syrgkanis},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=yuy6cGt3KL}\n}"
    },
    {
        "title": "Confidential-DPproof: Confidential Proof of Differentially Private Training",
        "authorids": [
            "~Ali_Shahin_Shamsabadi1",
            "~Gefei_Tan1",
            "~Tudor_Ioan_Cebere1",
            "~Aur\u00e9lien_Bellet1",
            "~Hamed_Haddadi1",
            "~Nicolas_Papernot1",
            "~Xiao_Wang11",
            "~Adrian_Weller1"
        ],
        "keywords": [
            "privacy auditing",
            "zero knowledge proof",
            "differentially private training"
        ],
        "abstract": "Post hoc privacy auditing techniques can be used to test the privacy guarantees of a model, but come with several limitations: (i) they can only establish lower bounds on the privacy loss, (ii) the intermediate model updates and some data must be shared with the auditor to get a better approximation of the privacy loss, and (iii) the auditor typically faces a steep computational cost to run a large number of attacks. In this paper, we propose to proactively generate a cryptographic certificate of privacy during training to forego such auditing limitations. We introduce Confidential-DPproof , a framework for Confidential Proof of Differentially Private Training, which enhances training with a certificate of the $(\\varepsilon,\\delta)$-DP guarantee achieved. To obtain this certificate without revealing information about the training data or model, we design a customized zero-knowledge proof protocol tailored to the requirements introduced by differentially private training, including random noise addition and privacy amplification by subsampling. In experiments on CIFAR-10, Confidential-DPproof trains a model achieving state-of-the-art $91$% test accuracy with a certified privacy guarantee of $(\\varepsilon=0.55,\\delta=10^{-5})$-DP in approximately 100 hours.",
        "_bibtex": "@inproceedings{\nshamsabadi2024confidentialdpproof,\ntitle={Confidential-{DP}proof: Confidential Proof of Differentially Private Training},\nauthor={Ali Shahin Shamsabadi and Gefei Tan and Tudor Ioan Cebere and Aur{\\'e}lien Bellet and Hamed Haddadi and Nicolas Papernot and Xiao Wang and Adrian Weller},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=PQY2v6VtGe}\n}"
    },
    {
        "title": "In-Context Pretraining: Language Modeling Beyond Document Boundaries",
        "authorids": [
            "~Weijia_Shi1",
            "~Sewon_Min1",
            "~Maria_Lomeli2",
            "~Chunting_Zhou1",
            "~Margaret_Li1",
            "~Xi_Victoria_Lin1",
            "~Noah_A._Smith2",
            "~Luke_Zettlemoyer1",
            "~Wen-tau_Yih1",
            "~Mike_Lewis1"
        ],
        "keywords": [
            "Large Language Models"
        ],
        "abstract": "Language models are currently trained to predict tokens given document prefixes, enabling them to zero shot long form generation and prompting-style tasks which can be reduced to document completion. We instead present IN-CONTEXT PRETRAINING, a new approach where language models are trained on a sequence of related documents, thereby explicitly encouraging them to read and reason across document boundaries. Our approach builds on the fact that current pipelines train by concatenating random sets of shorter documents to create longer context windows; this improves efficiency even though the prior documents provide no signal for predicting the next document. Given this fact, we can do IN-CONTEXT PRETRAINING by simply changing the document ordering so that each context contains related documents, and directly applying existing pretraining pipelines. However, this document sorting problem is challenging. There are billions of documents and we would like the sort to maximize contextual similarity for every document without repeating any data. To do this, we introduce approximate algorithms for finding related documents with efficient nearest neighbor search and constructing coherent batches with a graph cover algorithm. Our experiments show IN-CONTEXT PRETRAINING offers a scalable and simple approach to significantly enhance LM performance: we see notable improvements in tasks that require more complex contextual reasoning, including in-context learning (+8%), reading comprehension (+15%), faithfulness to previous contexts (+16%), long-context reasoning (+5%), and retrieval augmentation (+9%).",
        "_bibtex": "@inproceedings{\nshi2024incontext,\ntitle={In-Context Pretraining: Language Modeling Beyond Document Boundaries},\nauthor={Weijia Shi and Sewon Min and Maria Lomeli and Chunting Zhou and Margaret Li and Xi Victoria Lin and Noah A. Smith and Luke Zettlemoyer and Wen-tau Yih and Mike Lewis},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=LXVswInHOo}\n}"
    },
    {
        "title": "What's In My Big Data?",
        "authorids": [
            "~Yanai_Elazar1",
            "~Akshita_Bhagia1",
            "~Ian_Helgi_Magnusson1",
            "~Abhilasha_Ravichander2",
            "~Dustin_Schwenk1",
            "~Alane_Suhr1",
            "~Evan_Pete_Walsh1",
            "~Dirk_Groeneveld1",
            "~Luca_Soldaini1",
            "~Sameer_Singh1",
            "~Hannaneh_Hajishirzi1",
            "~Noah_A._Smith2",
            "~Jesse_Dodge1"
        ],
        "keywords": [
            "nlp",
            "dataset",
            "analaysis",
            "data-statistics",
            "data-quality",
            "PII"
        ],
        "abstract": "Large text corpora are the backbone of language models.\nHowever, we have a limited understanding of the content of these corpora, including general statistics, quality, social factors, and inclusion of evaluation data (contamination).\nIn this work, we propose What's In My Big Data? (WIMBD), a platform and a set of sixteen analyses that allow us to reveal and compare the contents of large text corpora. WIMBD builds on two basic capabilities---count and search---*at scale*, which allows us to analyze more than 35 terabytes on a standard compute node. \nWe apply WIMBD to ten different corpora used to train popular language models, including *C4*, *The Pile*, and *RedPajama*.\nOur analysis uncovers several surprising and previously undocumented findings about these corpora, including the high prevalence of duplicate, synthetic, and low-quality content, personally identifiable information, toxic language, and benchmark contamination. \nFor instance, we find that about 50% of the documents in *RedPajama* and *LAION-2B-en* are duplicates. In addition, several datasets used for benchmarking models trained on such corpora are contaminated with respect to important benchmarks, including the Winograd Schema Challenge and parts of GLUE and SuperGLUE.\nWe open-source WIMBD's code and artifacts to provide a standard set of evaluations for new text-based corpora and to encourage more analyses and transparency around them.",
        "_bibtex": "@inproceedings{\nelazar2024whats,\ntitle={What's In My Big Data?},\nauthor={Yanai Elazar and Akshita Bhagia and Ian Helgi Magnusson and Abhilasha Ravichander and Dustin Schwenk and Alane Suhr and Evan Pete Walsh and Dirk Groeneveld and Luca Soldaini and Sameer Singh and Hannaneh Hajishirzi and Noah A. Smith and Jesse Dodge},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=RvfPnOkPV4}\n}"
    },
    {
        "title": "On Diffusion Modeling for Anomaly Detection",
        "authorids": [
            "~Victor_Livernoche1",
            "~Vineet_Jain1",
            "~Yashar_Hezaveh1",
            "~Siamak_Ravanbakhsh1"
        ],
        "keywords": [
            "Diffusion based models",
            "Anomaly detection",
            "Probabilistic Inference"
        ],
        "abstract": "Known for their impressive performance in generative modeling, diffusion models are attractive candidates for density-based anomaly detection. This paper investigates different variations of diffusion modeling for unsupervised and semi-supervised anomaly detection. In particular, we find that Denoising Diffusion Probability Models (DDPM) are performant on anomaly detection benchmarks yet computationally expensive. By simplifying DDPM in application to anomaly detection, we are naturally led to an alternative approach called Diffusion Time Estimation (DTE). DTE estimates the distribution over diffusion time for a given input and uses the mode or mean of this distribution as the anomaly score. We derive an analytical form for this density and leverage a deep neural network to improve inference efficiency. Through empirical evaluations on the ADBench benchmark, we demonstrate that all diffusion-based anomaly detection methods perform competitively for both semi-supervised and unsupervised settings. Notably, DTE achieves orders of magnitude faster inference time than DDPM, while outperforming it on this benchmark. These results establish diffusion-based anomaly detection as a scalable alternative to traditional methods and recent deep-learning techniques for standard unsupervised and semi-supervised anomaly detection settings.",
        "_bibtex": "@inproceedings{\nlivernoche2024on,\ntitle={On Diffusion Modeling for Anomaly Detection},\nauthor={Victor Livernoche and Vineet Jain and Yashar Hezaveh and Siamak Ravanbakhsh},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=lR3rk7ysXz}\n}"
    },
    {
        "title": "Social Reward: Evaluating and Enhancing Generative AI through Million-User Feedback from an Online Creative Community",
        "authorids": [
            "~Arman_Isajanyan1",
            "~Artur_Shatveryan1",
            "~David_Kocharian1",
            "~Zhangyang_Wang1",
            "~Humphrey_Shi1"
        ],
        "keywords": [
            "human feedback",
            "text to image",
            "generative AI",
            "image quality scoring"
        ],
        "abstract": "Social reward as a form of community recognition provides a strong source of\nmotivation for users of online platforms to actively engage and contribute with\ncontent to accumulate peers approval. In the realm of text-conditioned image\nsynthesis, the recent surge in progress has ushered in a collaborative era where\nusers and AI systems coalesce to refine visual creations. This co-creative pro-\ncess in the landscape of online social networks empowers users to craft original\nvisual artworks seeking for community validation. Nevertheless, assessing these\nmodels in the context of collective community preference introduces distinct chal-\nlenges. Existing evaluation methods predominantly center on limited size user\nstudies guided by image quality and alignment with prompts. This work pio-\nneers a paradigm shift, unveiling Social Reward - an innovative reward modeling\nframework that leverages implicit feedback from social network users engaged\nin creative editing of generated images. We embark on an extensive journey of\ndataset curation and refinement, drawing from Picsart: an online visual creation\nand editing platform, yielding a first million-user-scale dataset of implicit human\npreferences for user-generated visual art named Picsart Image-Social. Our anal-\nysis exposes the shortcomings of current metrics in modeling community creative\npreference of text-to-image models\u2019 outputs, compelling us to introduce a novel\npredictive model explicitly tailored to address these limitations. Rigorous quan-\ntitative experiments and user study show that our Social Reward model aligns\nbetter with social popularity than existing metrics. Furthermore, we utilize So-\ncial Reward to fine-tune text-to-image models, yielding images that are more fa-\nvored by not only Social Reward, but also other established metrics. These find-\nings highlight the relevance and effectiveness of Social Reward in assessing com-\nmunity appreciation for AI-generated artworks, establishing a closer alignment\nwith users\u2019 creative goals: creating popular visual art. Codes can be accessed at\nhttps://github.com/Picsart-AI-Research/Social-Reward",
        "_bibtex": "@inproceedings{\nisajanyan2024social,\ntitle={Social Reward: Evaluating and Enhancing Generative {AI} through Million-User Feedback from an Online Creative Community},\nauthor={Arman Isajanyan and Artur Shatveryan and David Kocharian and Zhangyang Wang and Humphrey Shi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tjn2YZSHUv}\n}"
    },
    {
        "title": "Role of Locality and Weight Sharing in Image-Based Tasks: A Sample Complexity Separation between CNNs, LCNs, and FCNs",
        "authorids": [
            "~Aakash_Lahoti1",
            "~Stefani_Karp1",
            "~Ezra_Winston1",
            "~Aarti_Singh1",
            "~Yuanzhi_Li1"
        ],
        "keywords": [
            "Deep Learning Theory",
            "Sample Complexity",
            "Convolutional Neural Networks"
        ],
        "abstract": "Vision tasks are characterized by the properties of locality and translation invariance. \n    The superior performance of convolutional neural networks (CNNs) on these tasks is widely attributed to the inductive bias of locality and weight sharing baked into their architecture.\n    Existing attempts to quantify the statistical benefits of these biases in CNNs over locally connected convolutional neural networks (LCNs) and fully connected neural networks (FCNs) fall into one of the following categories: either they disregard the optimizer and only provide uniform convergence upper bounds with no separating lower bounds, \n    or they consider simplistic tasks that do not truly mirror the locality and translation invariance as found in real-world vision tasks.\n    To address these deficiencies, we introduce the Dynamic Signal Distribution (DSD) classification task that models an image as consisting of $k$ patches, each of dimension $d$, and the label is determined by a $d$-sparse signal vector that can freely appear in any one of the $k$ patches. \n    On this task, for any orthogonally equivariant algorithm like gradient descent, we prove that CNNs require $\\tilde{O}(k+d)$ samples, whereas LCNs require $\\Omega(kd)$ samples, establishing the statistical advantages of weight sharing in translation invariant tasks. \n    Furthermore, LCNs need $\\tilde{O}(k(k+d))$ samples, compared to $\\Omega(k^2d)$ samples for FCNs, showcasing the benefits of locality in local tasks.\n    Additionally, we develop information theoretic tools for analyzing randomized algorithms, which may be of interest for statistical research.",
        "_bibtex": "@inproceedings{\nlahoti2024role,\ntitle={Role of Locality and Weight Sharing in Image-Based Tasks: A Sample Complexity Separation between {CNN}s, {LCN}s, and {FCN}s},\nauthor={Aakash Lahoti and Stefani Karp and Ezra Winston and Aarti Singh and Yuanzhi Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=AfnsTnYphT}\n}"
    },
    {
        "title": "Lion Secretly Solves a Constrained Optimization: As Lyapunov Predicts",
        "authorids": [
            "~Lizhang_Chen1",
            "~Bo_Liu13",
            "~Kaizhao_Liang1",
            "~qiang_liu4"
        ],
        "keywords": [
            "Lion",
            "Optimization",
            "Lyapunov Analysis"
        ],
        "abstract": "Lion (Evolved Sign Momentum), a new optimizer discovered through program search, has shown promising results in training large AI models. It achieves results comparable to AdamW but with greater memory efficiency. As what we can expect from the result of the random search, Lion blends a number of elements from existing algorithms, including signed momentum, decoupled weight decay,  Polayk and Nesterov momentum, but doesn't fit into any existing category of theoretically grounded optimizers. Thus, even though Lion appears to perform well as a general-purpose optimizer for a wide range of tasks, its theoretical basis remains uncertain. This absence of theoretical clarity limits opportunities to further enhance and expand Lion's efficacy. This work aims to demystify Lion. Using both continuous-time and discrete-time analysis, we demonstrate that Lion is a novel and theoretically grounded approach for minimizing a general loss function $f(x)$ while enforcing a bound constraint $||x||_\\infty \\leq 1/\\lambda$. Lion achieves this through the incorporation of decoupled weight decay, where $\\lambda$ represents the weight decay coefficient. Our analysis is facilitated by the development of a new Lyapunov function for the Lion updates. It applies to a wide range of Lion-$\\phi$ algorithms, where the  $sign(\\cdot)$ operator in Lion is replaced by the subgradient of a convex function $\\phi$, leading to the solution of the general composite optimization problem $\\min_x f(x) + \\phi^*(x)$. Our findings provide valuable insights into the dynamics of Lion and pave the way for further enhancements and extensions of Lion-related algorithms.",
        "_bibtex": "@inproceedings{\nchen2024lion,\ntitle={Lion Secretly Solves a Constrained Optimization: As Lyapunov Predicts},\nauthor={Lizhang Chen and Bo Liu and Kaizhao Liang and qiang liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=e4xS9ZarDr}\n}"
    },
    {
        "title": "Distributionally Robust Optimization with Bias and Variance Reduction",
        "authorids": [
            "~Ronak_Mehta2",
            "~Vincent_Roulet1",
            "~Krishna_Pillutla1",
            "~Zaid_Harchaoui1"
        ],
        "keywords": [
            "stochastic optimization",
            "convex optimization",
            "distributionally robust learning",
            "spectral risk measures",
            "incremental optimization"
        ],
        "abstract": "We consider the distributionally robust optimization (DRO) problem, wherein a learner optimizes the worst-case empirical risk achievable by reweighing the observed training examples. We present Prospect, a stochastic gradient-based algorithm that only requires tuning a single learning rate hyperparameter, and prove that it enjoys linear convergence for smooth regularized losses. This contrasts with previous algorithms that either require tuning multiple hyperparameters or potentially fail to converge due to biased gradient estimates or inadequate regularization. Empirically, we show that Prospect can converge 2-3x faster than baselines such as SGD and stochastic saddle-point methods on distribution shift and fairness benchmarks spanning tabular, vision, and language domains.",
        "_bibtex": "@inproceedings{\nmehta2024distributionally,\ntitle={Distributionally Robust Optimization with Bias and Variance Reduction},\nauthor={Ronak Mehta and Vincent Roulet and Krishna Pillutla and Zaid Harchaoui},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TTrzgEZt9s}\n}"
    },
    {
        "title": "A Benchmark for Learning to Translate a New Language from One Grammar Book",
        "authorids": [
            "~Garrett_Tanzer1",
            "~Mirac_Suzgun1",
            "~Eline_Visser1",
            "~Dan_Jurafsky1",
            "~Luke_Melas-Kyriazi1"
        ],
        "keywords": [
            "low-resource languages",
            "indigenous languages",
            "endangered languages",
            "long context",
            "field linguistics",
            "unseen tasks",
            "large language models",
            "machine translation",
            "benchmark"
        ],
        "abstract": "Large language models (LLMs) can perform impressive feats with in-context learning or lightweight finetuning. It is natural to wonder how well these models adapt to genuinely new tasks, but how does one find tasks that are unseen in internet-scale training sets? We turn to a field that is explicitly motivated and bottlenecked by a scarcity of web data: low-resource languages. In this paper, we introduce MTOB (Machine Translation from One Book), a benchmark for learning to translate between English and Kalamang\u2014a language with less than 200 speakers and therefore virtually no presence on the web\u2014using several hundred pages of field linguistics reference materials. This task framing is novel in that it asks a model to learn a language from a single human-readable book of grammar explanations, rather than a large mined corpus of in-domain data, more akin to L2 language learning than L1 language acquisition. We demonstrate that baselines using current LLMs are promising but fall short of human performance, achieving 44.7 chrF on Kalamang to English translation and 45.8 chrF on English to Kalamang translation, compared to 51.6 and 57.0 chrF by a human who learned Kalamang from the same reference materials. We hope that MTOB will help measure LLM capabilities along a new dimension, and that the methods developed to solve it could help expand access to language technology for underserved communities by leveraging qualitatively different kinds of data than traditional machine translation.",
        "_bibtex": "@inproceedings{\ntanzer2024a,\ntitle={A Benchmark for Learning to Translate a New Language from One Grammar Book},\nauthor={Garrett Tanzer and Mirac Suzgun and Eline Visser and Dan Jurafsky and Luke Melas-Kyriazi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tbVWug9f2h}\n}"
    },
    {
        "title": "Improving Offline RL by Blending Heuristics",
        "authorids": [
            "~Sinong_Geng1",
            "~Aldo_Pacchiano1",
            "~Andrey_Kolobov1",
            "~Ching-An_Cheng1"
        ],
        "keywords": [
            "offline RL",
            "heuristic",
            "RL",
            "MDP",
            "sequential decision-making"
        ],
        "abstract": "We propose **H**e**u**ristic **Bl**ending (HUBL), a simple performance-improving technique for a broad class of offline RL algorithms based on value bootstrapping. HUBL modifies the Bellman operators used in these algorithms, partially replacing the bootstrapped values with heuristic ones that are estimated with Monte-Carlo returns. For trajectories with higher returns, HUBL relies more on the heuristic values and less on bootstrapping; otherwise, it leans more heavily on bootstrapping. HUBL is very easy to combine with many existing offline RL implementations by relabeling the offline datasets with adjusted rewards and discount factors. We derive a theory that explains HUBL's effect on offline RL as reducing offline RL's complexity and thus increasing its finite-sample performance.  Furthermore, we empirically demonstrate that HUBL consistently improves the policy quality of four state-of-the-art bootstrapping-based offline RL algorithms (ATAC, CQL, TD3+BC, and IQL), by 9% on average over 27 datasets of the D4RL and Meta-World benchmarks.",
        "_bibtex": "@inproceedings{\ngeng2024improving,\ntitle={Improving Offline {RL} by Blending Heuristics},\nauthor={Sinong Geng and Aldo Pacchiano and Andrey Kolobov and Ching-An Cheng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MCl0TLboP1}\n}"
    },
    {
        "title": "Decision ConvFormer: Local Filtering in MetaFormer is Sufficient for Decision Making",
        "authorids": [
            "~Jeonghye_Kim1",
            "~Suyoung_Lee4",
            "~Woojun_Kim1",
            "~Youngchul_Sung1"
        ],
        "keywords": [
            "MetaFormer",
            "Convolution",
            "Reinforcement Learning",
            "Representation Learning"
        ],
        "abstract": "The recent success of Transformer in natural language processing has sparked its use in various domains. In offline reinforcement learning (RL), Decision Transformer (DT) is emerging as a promising model based on Transformer. However, we discovered that the attention module of DT is not appropriate to capture the inherent local dependence pattern in trajectories of RL modeled as a Markov decision process. To overcome the limitations of DT, we propose a novel action sequence predictor, named Decision ConvFormer (DC), based on the architecture of MetaFormer, which is a general structure to process multiple entities in parallel and understand the interrelationship among the multiple entities. DC employs local convolution filtering as the token mixer and can effectively capture the inherent local associations of the RL dataset. In extensive experiments, DC achieved state-of-the-art performance across various standard RL benchmarks while requiring fewer resources. Furthermore, we show that DC better understands the underlying meaning in data and exhibits enhanced generalization capability.",
        "_bibtex": "@inproceedings{\nkim2024decision,\ntitle={Decision ConvFormer: Local Filtering in MetaFormer is Sufficient for Decision Making},\nauthor={Jeonghye Kim and Suyoung Lee and Woojun Kim and Youngchul Sung},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=af2c8EaKl8}\n}"
    },
    {
        "title": "How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?",
        "authorids": [
            "~Jingfeng_Wu1",
            "~Difan_Zou1",
            "~Zixiang_Chen1",
            "~Vladimir_Braverman1",
            "~Quanquan_Gu1",
            "~Peter_Bartlett1"
        ],
        "keywords": [
            "in-context learning",
            "linear regression",
            "ridge regression",
            "Bayes optimality"
        ],
        "abstract": "Transformers pretrained on diverse tasks exhibit remarkable in-context learning (ICL) capabilities, enabling them to solve unseen tasks solely based on input contexts without adjusting model parameters. In this paper, we study ICL in one of its simplest setups: pretraining a single-layer linear attention model for linear regression with a Gaussian prior. We establish a statistical task complexity bound for the attention model pretraining, showing that effective pretraining only requires a small number of independent tasks. Furthermore, we prove that the pretrained model closely matches the Bayes optimal algorithm, i.e., optimally tuned ridge regression, by achieving nearly Bayes optimal risk on unseen tasks under a fixed context length. These theoretical findings complement prior experimental research and shed light on the statistical foundations of ICL.",
        "_bibtex": "@inproceedings{\nwu2024how,\ntitle={How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?},\nauthor={Jingfeng Wu and Difan Zou and Zixiang Chen and Vladimir Braverman and Quanquan Gu and Peter Bartlett},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=vSh5ePa0ph}\n}"
    },
    {
        "title": "Tool-Augmented Reward Modeling",
        "authorids": [
            "~Lei_Li18",
            "~Yekun_Chai1",
            "~Shuohuan_Wang1",
            "~Yu_Sun13",
            "~Hao_Tian1",
            "~Ningyu_Zhang1",
            "~Hua_Wu4"
        ],
        "keywords": [
            "Reward Model",
            "Large Language Model",
            "Tool Learning",
            "Augmented Language Model"
        ],
        "abstract": "Reward modeling (*a.k.a.*, preference modeling) is instrumental for aligning large language models with human preferences, particularly within the context of reinforcement learning from human feedback (RLHF). While conventional reward models (RMs) have exhibited remarkable scalability, they oft struggle with fundamental functionality such as arithmetic computation, code execution, and factual lookup. In this paper, we propose a tool-augmented preference modeling approach, named Themis, to address these limitations by empowering RMs with access to external environments, including calculators and search engines. This approach not only fosters synergy between tool utilization and reward grading but also enhances interpretive capacity and scoring reliability. Our study delves into the integration of external tools into RMs, enabling them to interact with diverse external sources and construct task-specific tool engagement and reasoning traces in an autoregressive manner. We validate our approach across a wide range of domains, incorporating seven distinct external tools. Our experimental results demonstrate a noteworthy overall improvement of 17.7% across eight tasks in preference ranking. Furthermore, our approach outperforms Gopher 280B by 7.3% on TruthfulQA task in zero-shot evaluation. In human evaluations, RLHF trained with Themis attains an average win rate of 32% when compared to baselines across four distinct tasks. Additionally, we provide a comprehensive collection of tool-related RM datasets, incorporating data from seven distinct tool APIs, totaling 15,000 instances. We have made the code, data, and model checkpoints publicly available to facilitate and inspire further research advancements (https://github.com/ernie-research/Tool-Augmented-Reward-Model).",
        "_bibtex": "@inproceedings{\nli2024toolaugmented,\ntitle={Tool-Augmented Reward Modeling},\nauthor={Lei Li and Yekun Chai and Shuohuan Wang and Yu Sun and Hao Tian and Ningyu Zhang and Hua Wu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=d94x0gWTUX}\n}"
    },
    {
        "title": "Reward-Consistent Dynamics Models are Strongly Generalizable for Offline Reinforcement Learning",
        "authorids": [
            "~Fan-Ming_Luo1",
            "~Tian_Xu2",
            "~Xingchen_Cao1",
            "~Yang_Yu5"
        ],
        "keywords": [
            "model-based offline reinforcement learning",
            "dynamics reward",
            "reward-consistent dynamics model learning"
        ],
        "abstract": "Learning a precise dynamics model can be crucial for offline reinforcement learning, which, unfortunately, has been found to be quite challenging. Dynamics models that are learned by fitting historical transitions often struggle to generalize to unseen transitions. In this study, we identify a hidden but pivotal factor termed dynamics reward that remains consistent across transitions, offering a pathway to better generalization. Therefore, we propose the idea of reward-consistent dynamics models: any trajectory generated by the dynamics model should maximize the dynamics reward derived from the data. We implement this idea as the MOREC (Model-based Offline reinforcement learning with Reward Consistency) method, which can be seamlessly integrated into previous offline model-based reinforcement learning (MBRL) methods. MOREC learns a generalizable dynamics reward function from offline data, which is subsequently employed as a transition filter in any offline MBRL method: when generating transitions, the dynamics model generates a batch of transitions and selects the one with the highest dynamics reward value. On a synthetic task, we visualize that MOREC has a strong generalization ability and can surprisingly recover some distant unseen transitions. On 21 offline tasks in D4RL and NeoRL benchmarks, MOREC improves the previous state-of-the-art performance by a significant margin, i.e., 4.6\\% on D4RL tasks and 25.9\\% on NeoRL tasks. Notably, MOREC is the first method that can achieve above 95\\% online RL performance in 6 out of 12 D4RL tasks and 3 out of 9 NeoRL tasks. Code is available at https://github.com/polixir/morec.",
        "_bibtex": "@inproceedings{\nluo2024rewardconsistent,\ntitle={Reward-Consistent Dynamics Models are Strongly Generalizable for Offline Reinforcement Learning},\nauthor={Fan-Ming Luo and Tian Xu and Xingchen Cao and Yang Yu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=GSBHKiw19c}\n}"
    },
    {
        "title": "Towards Optimal Regret in Adversarial Linear MDPs with Bandit Feedback",
        "authorids": [
            "~Haolin_Liu8",
            "~Chen-Yu_Wei1",
            "~Julian_Zimmert1"
        ],
        "keywords": [
            "adversarial MDPs",
            "policy optimization",
            "bandit feedback"
        ],
        "abstract": "We study online reinforcement learning in linear Markov decision processes with adversarial losses and bandit feedback. We introduce two algorithms that achieve improved regret performance compared to existing approaches. The first algorithm, although computationally inefficient, achieves a regret of $\\widetilde{O}(\\sqrt{K})$ without relying on simulators, where $K$ is the number of episodes. This is the first rate-optimal result in the considered setting. The second algorithm is computationally efficient and achieves a regret of  $\\widetilde{O}(K^{\\frac{3}{4}})$ . These results significantly improve over the prior state-of-the-art: a computationally inefficient algorithm by Kong et al. (2023) with $\\widetilde{O}(K^{\\frac{4}{5}}+1/\\lambda_{\\min})$ regret, and a computationally efficient algorithm by Sherman et al. (2023b) with $\\widetilde{O}(K^{\\frac{6}{7}})$ regret.",
        "_bibtex": "@inproceedings{\nliu2024towards,\ntitle={Towards Optimal Regret in Adversarial Linear {MDP}s with Bandit Feedback},\nauthor={Haolin Liu and Chen-Yu Wei and Julian Zimmert},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=6yv8UHVJn4}\n}"
    },
    {
        "title": "Dual RL: Unification and New Methods for Reinforcement and Imitation Learning",
        "authorids": [
            "~Harshit_Sikchi1",
            "~Qinqing_Zheng1",
            "~Amy_Zhang1",
            "~Scott_Niekum1"
        ],
        "keywords": [
            "Robot Learning",
            "Offline Imitation Learning",
            "Offline Reinforcement Learning",
            "Deep Reinforcement Learning"
        ],
        "abstract": "The goal of reinforcement learning (RL) is to find a policy that maximizes the expected cumulative return. It has been shown that this objective can be represented as an optimization problem of state-action visitation distribution under linear constraints. The dual problem of this formulation, which we refer to as *dual RL*, is unconstrained and easier to optimize. In this work, we first cast several state-of-the-art offline RL and offline imitation learning (IL) algorithms as instances of dual RL approaches with shared structures. Such unification allows us to identify the root cause of the shortcomings of prior methods. For offline IL, our analysis shows that prior methods are based on a restrictive coverage assumption that greatly limits their performance in practice. To fix this limitation, we propose a new discriminator-free method ReCOIL that learns to imitate from arbitrary off-policy data to obtain near-expert performance. For offline RL, our analysis frames a recent offline RL method XQL in the dual framework, and we further propose a new method $f$-DVL that provides alternative choices to the Gumbel regression loss that fixes the known training instability issue of XQL. The performance improvements by both of our proposed methods, ReCOIL and $f$-DVL, in IL and RL are validated on an extensive suite of simulated robot locomotion and manipulation tasks.",
        "_bibtex": "@inproceedings{\nsikchi2024dual,\ntitle={Dual {RL}: Unification and New Methods for Reinforcement and Imitation Learning},\nauthor={Harshit Sikchi and Qinqing Zheng and Amy Zhang and Scott Niekum},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xt9Bu66rqv}\n}"
    },
    {
        "title": "Out-Of-Domain Unlabeled Data Improves Generalization",
        "authorids": [
            "~seyed_amir_hossein_saberi1",
            "~Amir_Najafi1",
            "~Alireza_Heidari2",
            "~Mohammad_Hosein_Movasaghinia1",
            "~Abolfazl_Motahari1",
            "~Babak_Khalaj1"
        ],
        "keywords": [
            "Out-of-domain data",
            "Semi-supervised learing",
            "learning theory",
            "generalization bound",
            "adversarial robustness"
        ],
        "abstract": "We propose a novel framework for incorporating unlabeled data into semi-supervised classification problems, where scenarios involving the minimization of either i) adversarially robust or ii) non-robust loss functions have been considered. Notably, we allow the unlabeled samples to deviate slightly (in total variation sense) from the in-domain distribution. The core idea behind our framework is to combine Distributionally Robust Optimization (DRO) with self-supervised training. As a result, we also leverage efficient polynomial-time algorithms for the training stage. From a theoretical standpoint, we apply our framework on the classification problem of a mixture of two Gaussians in $\\mathbb{R}^d$, where in addition to the $m$ independent and labeled samples from the true distribution, a set of $n$ (usually with $n\\gg m$) out of domain and unlabeled samples are gievn as well. Using only the labeled data, it is known that the generalization error can be bounded by $\\propto\\left(d/m\\right)^{1/2}$. However, using our method on both isotropic and non-isotropic Gaussian mixture models, one can derive a new set of analytically explicit and non-asymptotic bounds which show substantial improvement on the generalization error compared ERM. Our results underscore two significant insights: 1) out-of-domain samples, even when unlabeled, can be harnessed to narrow the generalization gap, provided that the true data distribution adheres to a form of the \"cluster assumption\", and 2) the semi-supervised learning paradigm can be regarded as a special case of our framework when there are no distributional shifts. We validate our claims through experiments conducted on a variety of synthetic and real-world datasets.",
        "_bibtex": "@inproceedings{\nsaberi2024outofdomain,\ntitle={Out-Of-Domain Unlabeled Data Improves Generalization},\nauthor={seyed amir hossein saberi and Amir Najafi and Alireza Heidari and Mohammad Hosein Movasaghinia and Abolfazl Motahari and Babak Khalaj},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Bo6GpQ3B9a}\n}"
    },
    {
        "title": "Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation",
        "authorids": [
            "~Yangsibo_Huang2",
            "~Samyak_Gupta1",
            "~Mengzhou_Xia1",
            "~Kai_Li8",
            "~Danqi_Chen1"
        ],
        "keywords": [
            "Large Language Model",
            "Alignment",
            "Attack"
        ],
        "abstract": "The rapid progress in open-source large language models (LLMs) is significantly advancing AI development. Extensive efforts have been made before model release to align their behavior with human values, with the primary goal of ensuring their helpfulness and harmlessness. However, even carefully aligned models can be manipulated maliciously, leading to unintended behaviors, known as ``jailbreaks\". These jailbreaks are typically triggered by specific text inputs, often referred to as adversarial prompts. In this work, we propose the generation exploitation attack, an extremely simple approach that disrupts model alignment by only manipulating variations of decoding methods. By exploiting different generation strategies, including varying decoding hyper-parameters and sampling methods, we increase the attack success rate from $0\\%$ to more than $95\\%$ across 11 language models including LLaMA2, Vicuna, Falcon, and MPT families, outperforming state-of-the-art attacks with $30\\times$ lower computational cost. Finally, we propose an effective alignment method that explores diverse generation strategies, which can reasonably reduce the attack success rate under our attack. Altogether, our study underscores a major failure in current safety evaluation and alignment procedures for open-source LLMs, strongly advocating for more comprehensive red teaming and better alignment before releasing such models.",
        "_bibtex": "@inproceedings{\nhuang2024catastrophic,\ntitle={Catastrophic Jailbreak of Open-source {LLM}s via Exploiting Generation},\nauthor={Yangsibo Huang and Samyak Gupta and Mengzhou Xia and Kai Li and Danqi Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=r42tSSCHPh}\n}"
    },
    {
        "title": "PolyGCL: GRAPH CONTRASTIVE LEARNING via Learnable Spectral Polynomial Filters",
        "authorids": [
            "~Jingyu_Chen4",
            "~Runlin_Lei1",
            "~Zhewei_Wei1"
        ],
        "keywords": [
            "Graph Contrastive Learning",
            "Spectral Graph Neural Networks",
            "Polynomial Filter",
            "Heterophilic Graph Representation Learning"
        ],
        "abstract": "Recently, Graph Contrastive Learning (GCL) has achieved significantly superior performance in self-supervised graph representation learning. \nHowever, the existing GCL technique has inherent smooth characteristics because of its low-pass GNN encoder and objective based on homophily assumption, which poses a challenge when applying it to heterophilic graphs.\nIn supervised learning tasks, spectral GNNs with polynomial approximation excel in both homophilic and heterophilic settings by adaptively fitting graph filters of arbitrary shapes. \nYet, their applications in unsupervised learning are rarely explored.\nBased on the above analysis, a natural question arises: Can we incorporate the excellent properties of spectral polynomial filters into graph contrastive learning?\nIn this paper, we address the question by studying the necessity of introducing high-pass information for heterophily from a spectral perspective.\nWe propose PolyGCL, a GCL pipeline that utilizes polynomial filters to achieve contrastive learning between the low-pass and high-pass views.\nSpecifically, PolyGCL utilizes polynomials with learnable filter functions to generate different spectral views and an objective that incorporates high-pass information through a linear combination. \nWe theoretically prove that PolyGCL outperforms previous GCL paradigms when applied to graphs with varying levels of homophily.\nWe conduct extensive experiments on both synthetic and real-world datasets, which demonstrate the promising performance of PolyGCL on homophilic and heterophilic graphs.",
        "_bibtex": "@inproceedings{\nchen2024polygcl,\ntitle={Poly{GCL}: {GRAPH} {CONTRASTIVE} {LEARNING} via Learnable Spectral Polynomial Filters},\nauthor={Jingyu Chen and Runlin Lei and Zhewei Wei},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=y21ZO6M86t}\n}"
    },
    {
        "title": "Solving Homogeneous and Heterogeneous Cooperative Tasks with Greedy Sequential Execution",
        "authorids": [
            "~Shanqi_Liu1",
            "~Dong_Xing1",
            "~Pengjie_Gu1",
            "~Xinrun_Wang1",
            "~Bo_An2",
            "~Yong_Liu11"
        ],
        "keywords": [
            "Multi-Agent Cooperation",
            "Credit Assignment",
            "Homogeneous and Heterogeneous Cooperative Tasks"
        ],
        "abstract": "Cooperative multi-agent reinforcement learning (MARL) is extensively used for solving complex cooperative tasks, and value decomposition methods are a prevalent approach for this domain. However, these methods have not been successful in addressing both homogeneous and heterogeneous tasks simultaneously which is a crucial aspect for the practical application of cooperative agents. \nOn one hand, value decomposition methods demonstrate superior performance in homogeneous tasks. Nevertheless, they tend to produce agents with similar policies, which is unsuitable for heterogeneous tasks. On the other hand, solutions based on personalized observation or assigned roles are well-suited for heterogeneous tasks. However, they often lead to a trade-off situation where the agent's performance in homogeneous scenarios is negatively affected due to the aggregation of distinct policies. An alternative approach is to adopt sequential execution policies, which offer a flexible form for learning both types of tasks. However, learning sequential execution policies poses challenges in terms of credit assignment, and the limited information about subsequently executed agents can lead to sub-optimal solutions, which is known as the relative over-generalization problem. To tackle these issues, this paper proposes Greedy Sequential Execution (GSE) as a solution to learn the optimal policy that covers both scenarios. In the proposed GSE framework, we introduce an individual utility function into the framework of value decomposition to consider the complex interactions between agents. \nThis function is capable of representing both the homogeneous and heterogeneous optimal policies. Furthermore, we utilize greedy marginal contribution calculated by the utility function as the credit value of the sequential execution policy to address the credit assignment and relative over-generalization problem. We evaluated GSE in both homogeneous and heterogeneous scenarios. The results demonstrate that GSE achieves significant improvement in performance across multiple domains, especially in scenarios involving both homogeneous and heterogeneous tasks.",
        "_bibtex": "@inproceedings{\nliu2024solving,\ntitle={Solving Homogeneous and Heterogeneous Cooperative Tasks with Greedy Sequential Execution},\nauthor={Shanqi Liu and Dong Xing and Pengjie Gu and Xinrun Wang and Bo An and Yong Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=hB2hXtxIPH}\n}"
    },
    {
        "title": "Stabilizing Contrastive RL: Techniques for Robotic Goal Reaching from Offline Data",
        "authorids": [
            "~Chongyi_Zheng1",
            "~Benjamin_Eysenbach1",
            "~Homer_Rich_Walke1",
            "~Patrick_Yin1",
            "~Kuan_Fang3",
            "~Ruslan_Salakhutdinov1",
            "~Sergey_Levine1"
        ],
        "keywords": [
            "reinforcement learning",
            "self-supervised learning",
            "contrastive learning",
            "goal-conditioned RL",
            "offline RL",
            "robotics"
        ],
        "abstract": "Robotic systems that rely primarily on self-supervised learning have the potential to decrease the amount of human annotation and engineering effort required to learn control strategies. In the same way that prior robotic systems have leveraged self-supervised techniques from computer vision (CV) and natural language processing (NLP), our work builds on prior work showing that the reinforcement learning (RL) itself can be cast as a self-supervised problem: learning to reach any goal without human-specified rewards or labels. Despite the seeming appeal, little (if any) prior work has demonstrated how self-supervised RL methods can be practically deployed on robotic systems. By first studying a challenging simulated version of this task, we discover design decisions about architectures and hyperparameters that increase the success rate by $2 \\times$. These findings lay the groundwork for our main result: we demonstrate that a self-supervised RL algorithm based on contrastive learning can solve real-world, image-based robotic manipulation tasks, with tasks being specified by a single goal image provided after training.",
        "_bibtex": "@inproceedings{\nzheng2024stabilizing,\ntitle={Stabilizing Contrastive {RL}: Techniques for Robotic Goal Reaching from Offline Data},\nauthor={Chongyi Zheng and Benjamin Eysenbach and Homer Rich Walke and Patrick Yin and Kuan Fang and Ruslan Salakhutdinov and Sergey Levine},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Xkf2EBj4w3}\n}"
    },
    {
        "title": "Multi-View Causal Representation Learning with Partial Observability",
        "authorids": [
            "~Dingling_Yao1",
            "~Danru_Xu1",
            "~Sebastien_Lachapelle1",
            "~Sara_Magliacane1",
            "~Perouz_Taslakian1",
            "~Georg_Martius1",
            "~Julius_von_K\u00fcgelgen2",
            "~Francesco_Locatello1"
        ],
        "keywords": [
            "causal representation learning; identifiability"
        ],
        "abstract": "We present a unified framework for studying the identifiability of representations learned from simultaneously observed views, such as different data modalities. We allow a partially observed setting in which each view constitutes a nonlinear mixture of a subset of underlying latent variables, which can be causally related.\nWe prove that the information shared across all subsets of any number of views can be learned up to a smooth bijection using contrastive learning and a single encoder per view. \nWe also provide graphical criteria indicating which latent variables can be identified through a simple set of rules, which we refer to as identifiability algebra. Our general framework and theoretical results unify and extend several previous work on multi-view nonlinear ICA, disentanglement, and causal representation learning. We experimentally validate our claims on numerical, image, and multi-modal data sets. Further, we demonstrate that the performance of prior methods is recovered in different special cases of our setup. \nOverall, we find that access to multiple partial views offers unique opportunities for identifiable representation learning, enabling the discovery of latent structures from purely observational data.",
        "_bibtex": "@inproceedings{\nyao2024multiview,\ntitle={Multi-View Causal Representation Learning with Partial Observability},\nauthor={Dingling Yao and Danru Xu and Sebastien Lachapelle and Sara Magliacane and Perouz Taslakian and Georg Martius and Julius von K{\\\"u}gelgen and Francesco Locatello},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=OGtnhKQJms}\n}"
    },
    {
        "title": "CABINET: Content Relevance-based Noise Reduction for Table Question Answering",
        "authorids": [
            "~Sohan_Patnaik1",
            "~Heril_Changwal1",
            "~Milan_Aggarwal2",
            "~Sumit_Bhatia1",
            "~Yaman_Kumar1",
            "~Balaji_Krishnamurthy1"
        ],
        "keywords": [
            "Table Question Answering",
            "Large Language Models",
            "Noise Reduction",
            "Unsupervised Relevance Scoring",
            "Table Parsing",
            "Relevant Cell Highlighting"
        ],
        "abstract": "Table understanding capability of Large Language Models (LLMs) has been extensively studied through the task of question-answering (QA) over tables. Typically, only a small part of the whole table is relevant to derive the answer for a given question. The irrelevant parts act as noise and are distracting information, resulting in sub-optimal performance due to the vulnerability of LLMs to noise. To mitigate this, we propose CABINET (Content RelevAnce-Based NoIse ReductioN for TablE QuesTion-Answering) \u2013 a framework to enable LLMs to focus on relevant tabular data by suppressing extraneous information. CABINET comprises an Unsupervised Relevance Scorer (URS), trained differentially with the QA LLM, that weighs the table content based on its relevance to the input question before feeding it to the question answering LLM (QA LLM). To further aid the relevance scorer, CABINET employs a weakly supervised module that generates a parsing statement describing the criteria of rows and columns relevant to the question and highlights the content of corresponding table cells. CABINET significantly outperforms various tabular LLM baselines, as well as GPT3-based in-context learning methods, is more robust to noise, maintains outperformance on tables of varying sizes, and establishes new SoTA performance on WikiTQ, FeTaQA, and WikiSQL datasets. We release our code and datasets here.",
        "_bibtex": "@inproceedings{\npatnaik2024cabinet,\ntitle={{CABINET}: Content Relevance-based Noise Reduction for Table Question Answering},\nauthor={Sohan Patnaik and Heril Changwal and Milan Aggarwal and Sumit Bhatia and Yaman Kumar and Balaji Krishnamurthy},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=SQrHpTllXa}\n}"
    },
    {
        "title": "Safe RLHF: Safe Reinforcement Learning from Human Feedback",
        "authorids": [
            "~Josef_Dai1",
            "~Xuehai_Pan1",
            "~Ruiyang_Sun2",
            "~Jiaming_Ji2",
            "~Xinbo_Xu1",
            "~Mickel_Liu1",
            "~Yizhou_Wang1",
            "~Yaodong_Yang1"
        ],
        "keywords": [
            "Safe Reinforcement Learning",
            "Reinforcement Learning from Human Feedback",
            "Large Language Model",
            "AI Safety"
        ],
        "abstract": "With the development of large language models (LLMs), striking a balance between the performance and safety of AI systems has never been more critical. However, the inherent tension between the objectives of helpfulness and harmlessness presents a significant challenge during LLM training. To address this issue, we propose Safe Reinforcement Learning from Human Feedback (Safe RLHF), a novel algorithm for human value alignment. Safe RLHF explicitly decouples human preferences regarding helpfulness and harmlessness, effectively avoiding the crowd workers' confusion about the tension and allowing us to train separate reward and cost models. We formalize the safety concern of LLMs as an optimization task of maximizing the reward function while satisfying specified cost constraints. Leveraging the Lagrangian method to solve this constrained problem, Safe RLHF dynamically adjusts the balance between the two objectives during fine-tuning. Through a three-round fine-tuning using Safe RLHF, we demonstrate a superior ability to mitigate harmful responses while enhancing model performance compared to existing value-aligned algorithms. Experimentally, we fine-tuned the Alpaca-7B using Safe RLHF and aligned it with collected human preferences, significantly improving its helpfulness and harmlessness according to human evaluations.\n\nCode is available at https://github.com/PKU-Alignment/safe-rlhf.\n\n\nWarning: This paper contains example data that may be offensive or harmful.",
        "_bibtex": "@inproceedings{\ndai2024safe,\ntitle={Safe {RLHF}: Safe Reinforcement Learning from Human Feedback},\nauthor={Josef Dai and Xuehai Pan and Ruiyang Sun and Jiaming Ji and Xinbo Xu and Mickel Liu and Yizhou Wang and Yaodong Yang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TyFrPOKYXw}\n}"
    },
    {
        "title": "Benchmarking Algorithms for Federated Domain Generalization",
        "authorids": [
            "~Ruqi_Bai1",
            "~Saurabh_Bagchi1",
            "~David_I._Inouye1"
        ],
        "keywords": [
            "federated learning",
            "distributed learning",
            "domain generalization",
            "out-of-distribution generalization",
            "benchmarking",
            "data paritioning."
        ],
        "abstract": "While prior federated learning (FL) methods mainly consider client heterogeneity, we focus on the *Federated Domain Generalization (DG)* task, which introduces train-test heterogeneity in the FL context. Existing evaluations in this field are limited in terms of the scale of the clients and dataset diversity. Thus, we propose a Federated DG benchmark that aim to test the limits of current methods with high client heterogeneity, large numbers of clients, and diverse datasets. Towards this objective, we introduce a novel data partition method that allows us to distribute any domain dataset among few or many clients while controlling client heterogeneity. We then introduce and apply our methodology to evaluate 14 DG methods, which include centralized DG methods adapted to the FL context, FL methods that handle client heterogeneity, and methods designed specifically for Federated DG on 7 datasets. Our results suggest that, despite some progress, significant performance gaps remain in Federated DG, especially when evaluating with a large number of clients, high client heterogeneity, or more realistic datasets. Furthermore, our extendable benchmark code will be publicly released to aid in benchmarking future Federated DG approaches.",
        "_bibtex": "@inproceedings{\nbai2024benchmarking,\ntitle={Benchmarking Algorithms for Federated Domain Generalization},\nauthor={Ruqi Bai and Saurabh Bagchi and David I. Inouye},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=wprSv7ichW}\n}"
    },
    {
        "title": "CrossQ: Batch Normalization in Deep Reinforcement Learning for Greater Sample Efficiency and Simplicity",
        "authorids": [
            "~Aditya_Bhatt1",
            "~Daniel_Palenicek1",
            "~Boris_Belousov1",
            "~Max_Argus2",
            "~Artemij_Amiranashvili1",
            "~Thomas_Brox1",
            "~Jan_Peters3"
        ],
        "keywords": [
            "Deep Reinforcement Learning"
        ],
        "abstract": "Sample efficiency is a crucial problem in deep reinforcement learning. Recent algorithms, such as REDQ and DroQ, found a way to improve the sample efficiency by increasing the update-to-data (UTD) ratio to 20 gradient update steps on the critic per environment sample.\nHowever, this comes at the expense of a greatly increased computational cost. To reduce this computational burden, we introduce CrossQ:\nA lightweight algorithm for continuous control tasks that makes careful use of Batch Normalization and removes target networks to surpass the current state-of-the-art in sample efficiency while maintaining a low UTD ratio of 1. Notably, CrossQ does not rely on advanced bias-reduction schemes used in current methods. CrossQ's contributions are threefold: (1) it matches or surpasses current state-of-the-art methods in terms of sample efficiency, (2) it substantially reduces the computational cost compared to REDQ and DroQ, (3) it is easy to implement, requiring just a few lines of code on top of SAC.",
        "_bibtex": "@inproceedings{\nbhatt2024crossq,\ntitle={CrossQ: Batch Normalization in Deep Reinforcement Learning for Greater Sample Efficiency and Simplicity},\nauthor={Aditya Bhatt and Daniel Palenicek and Boris Belousov and Max Argus and Artemij Amiranashvili and Thomas Brox and Jan Peters},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=PczQtTsTIX}\n}"
    },
    {
        "title": "Blending Imitation and Reinforcement Learning for Robust Policy Improvement",
        "authorids": [
            "~Xuefeng_Liu2",
            "~Takuma_Yoneda1",
            "~Rick_Stevens1",
            "~Matthew_Walter1",
            "~Yuxin_Chen1"
        ],
        "keywords": [
            "imitation learning",
            "reinforcement learning",
            "multiple experts"
        ],
        "abstract": "While reinforcement learning (RL) has shown promising performance, its sample complexity continues to be a substantial hurdle, restricting its broader application across a variety of domains. Imitation learning (IL) utilizes oracles to improve sample efficiency, yet it is often constrained by the quality of the oracles deployed. To address the demand for robust policy improvement in real-world scenarios, we introduce a novel algorithm, Robust Policy Improvement (RPI), which actively interleaves between IL and RL based on an online estimate of their performance. RPI draws on the strengths of IL, using oracle queries to facilitate exploration\u2014an aspect that is notably challenging in sparse-reward RL\u2014particularly during the early stages of learning. As learning unfolds, RPI gradually transitions to RL, effectively treating the learned policy as an improved oracle. This algorithm is capable of learning from and improving upon a diverse set of black-box oracles. Integral to RPI are Robust Active Policy Selection (RAPS) and Robust Policy Gradient (RPG), both of which reason over whether to perform state-wise imitation from the oracles or learn from its own value function when the learner\u2019s performance surpasses that of the oracles in a specific state. Empirical evaluations and theoretical analysis validate that RPI excels in comparison to existing state-of-the-art methodologies, demonstrating superior performance across various benchmark domains.",
        "_bibtex": "@inproceedings{\nliu2024blending,\ntitle={Blending Imitation and Reinforcement Learning for Robust Policy Improvement},\nauthor={Xuefeng Liu and Takuma Yoneda and Rick Stevens and Matthew Walter and Yuxin Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=eJ0dzPJq1F}\n}"
    },
    {
        "title": "H-GAP: Humanoid Control with a Generalist Planner",
        "authorids": [
            "~zhengyao_jiang2",
            "~Yingchen_Xu2",
            "~Nolan_Wagener1",
            "~Yicheng_Luo1",
            "~Michael_Janner1",
            "~Edward_Grefenstette1",
            "~Tim_Rockt\u00e4schel1",
            "~Yuandong_Tian1"
        ],
        "keywords": [
            "Generative Modelling",
            "Humanoid Control",
            "Model Predictive Control",
            "Model-based Reinforcement Learning",
            "Offline Reinforcement Learning"
        ],
        "abstract": "Humanoid control is an important research challenge offering avenues for integration into human-centric infrastructures and enabling physics-driven humanoid animations.\nThe daunting challenges in this field stem from the difficulty of optimizing in high-dimensional action spaces and the instability introduced by the bipedal morphology of humanoids. \nHowever, the extensive collection of human motion-captured data and the derived datasets of humanoid trajectories, such as MoCapAct, paves the way to tackle these challenges. In this context, we present Humanoid Generalist Autoencoding Planner (H-GAP), a state-action trajectory generative model trained on humanoid trajectories derived from human motion-captured data, capable of adeptly handling downstream control tasks with Model Predictive Control (MPC).\nFor 56 degrees of freedom humanoid, we empirically demonstrate that H-GAP learns to represent and generate a wide range of motor behaviors. Further, without any learning from online interactions, it can also flexibly transfer these behaviours to solve novel downstream control tasks via planning. Notably, H-GAP excels established MPC baselines with access to the ground truth model, and is superior or comparable to offline RL methods trained for individual tasks.\nFinally, we do a series of empirical studies on the scaling properties of H-GAP, showing the potential for performance gains via additional data but not computing.",
        "_bibtex": "@inproceedings{\njiang2024hgap,\ntitle={H-{GAP}: Humanoid Control with a Generalist Planner},\nauthor={zhengyao jiang and Yingchen Xu and Nolan Wagener and Yicheng Luo and Michael Janner and Edward Grefenstette and Tim Rockt{\\\"a}schel and Yuandong Tian},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=LYG6tBlEX0}\n}"
    },
    {
        "title": "Unlocking the Power of Representations in Long-term Novelty-based Exploration",
        "authorids": [
            "~Alaa_Saade1",
            "~Steven_Kapturowski1",
            "~Daniele_Calandriello1",
            "~Charles_Blundell1",
            "~Pablo_Sprechmann1",
            "~Leopoldo_Sarra1",
            "~Oliver_Groth1",
            "~Michal_Valko1",
            "~Bilal_Piot1"
        ],
        "keywords": [
            "Deep RL",
            "exploration",
            "density estimation",
            "representation learning"
        ],
        "abstract": "We introduce Robust Exploration via Clustering-based Online Density Estimation (RECODE), a non-parametric method for novelty-based exploration that estimates visitation counts for clusters of states based on their similarity in a chosen embedding space. By adapting classical clustering to the nonstationary setting of Deep RL, RECODE can efficiently track state visitation counts over thousands of episodes. We further propose a novel generalization of the inverse dynamics loss, which leverages masked transformer architectures for multi-step prediction; which in conjunction with \\DETOCS achieves a new state-of-the-art in a suite of challenging 3D-exploration tasks in DM-Hard-8. RECODE also sets new state-of-the-art in hard exploration Atari games, and is the first agent to reach the end screen in \"Pitfall!\"",
        "_bibtex": "@inproceedings{\nsaade2024unlocking,\ntitle={Unlocking the Power of Representations in Long-term Novelty-based Exploration},\nauthor={Alaa Saade and Steven Kapturowski and Daniele Calandriello and Charles Blundell and Pablo Sprechmann and Leopoldo Sarra and Oliver Groth and Michal Valko and Bilal Piot},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=OwtMhMSybu}\n}"
    },
    {
        "title": "Accelerating Data Generation for Neural Operators via Krylov Subspace Recycling",
        "authorids": [
            "~Hong_Wang14",
            "~Zhongkai_Hao1",
            "~Jie_Wang1",
            "~Zijie_Geng1",
            "~Zhen_Wang30",
            "~Bin_Li8",
            "~Feng_Wu1"
        ],
        "keywords": [
            "AI4PDE; Neural Operator; Data Generation; Krylov Subspace"
        ],
        "abstract": "Learning neural operators for solving partial differential equations (PDEs) has attracted great attention due to its high inference efficiency.\nHowever, training such operators requires generating a substantial amount of labeled data, i.e., PDE problems together with their solutions.\nThe data generation process is exceptionally time-consuming, as it involves solving numerous systems of linear equations to obtain numerical solutions to the PDEs.\nMany existing methods solve these systems independently without considering their inherent similarities, resulting in extremely redundant computations.\nTo tackle this problem, we propose a novel method, namely **S**orting **K**rylov **R**ecycling (**SKR**), to boost the efficiency of solving these systems, thus significantly accelerating data generation for neural operators training.\nTo the best of our knowledge, SKR is the first attempt to address the time-consuming nature of data generation for learning neural operators.\nThe working horse of SKR is Krylov subspace recycling, a powerful technique for solving a series of interrelated systems by leveraging their inherent similarities.\nSpecifically, SKR employs a sorting algorithm to arrange these systems in a sequence, where adjacent systems exhibit high similarities.\nThen it equips a solver with Krylov subspace recycling to solve the systems sequentially instead of independently, thus effectively enhancing the solving efficiency.\nBoth theoretical analysis and extensive experiments demonstrate that SKR can significantly accelerate neural operator data generation, achieving a remarkable speedup of up to 13.9 times.",
        "_bibtex": "@inproceedings{\nwang2024accelerating,\ntitle={Accelerating Data Generation for Neural Operators via Krylov Subspace Recycling},\nauthor={Hong Wang and Zhongkai Hao and Jie Wang and Zijie Geng and Zhen Wang and Bin Li and Feng Wu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=UpgRVWexaD}\n}"
    },
    {
        "title": "Deep Orthogonal Hypersphere Compression for Anomaly Detection",
        "authorids": [
            "~Yunhe_Zhang1",
            "~Yan_Sun7",
            "~Jinyu_Cai2",
            "~Jicong_Fan2"
        ],
        "keywords": [
            "Anomaly Detection",
            "Deep Learning"
        ],
        "abstract": "Many well-known and effective anomaly detection methods assume that a reasonable decision boundary has a hypersphere shape, which however is difficult to obtain in practice and is not sufficiently compact, especially when the data are in high-dimensional spaces. In this paper, we first propose a novel deep anomaly detection model that improves the original hypersphere learning through an orthogonal projection layer, which ensures that the training data distribution is consistent with the hypersphere hypothesis, thereby increasing the true positive rate and decreasing the false negative rate. Moreover, we propose a bi-hypersphere compression method to obtain a hyperspherical shell that yields a more compact decision region than a hyperball, which is demonstrated theoretically and numerically.  The proposed methods are not confined to common datasets such as image and tabular data, but are also extended to a more challenging but promising scenario, graph-level anomaly detection, which learns graph representation with maximum mutual information between the substructure and global structure features while exploring orthogonal single- or bi-hypersphere anomaly decision boundaries. The numerical and visualization results on benchmark datasets demonstrate the superiority of our methods in comparison to many baselines and state-of-the-art methods.",
        "_bibtex": "@inproceedings{\nzhang2024deep,\ntitle={Deep Orthogonal Hypersphere Compression for Anomaly Detection},\nauthor={Yunhe Zhang and Yan Sun and Jinyu Cai and Jicong Fan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=cJs4oE4m9Q}\n}"
    },
    {
        "title": "On the Role of General Function Approximation in Offline Reinforcement Learning",
        "authorids": [
            "~Chenjie_Mao1",
            "~Qiaosheng_Zhang2",
            "~Zhen_Wang11",
            "~Xuelong_Li2"
        ],
        "keywords": [
            "reinforcement learning theory",
            "offline reinforcement learning",
            "general function approximation",
            "learnability",
            "minimax lower bounds"
        ],
        "abstract": "We study offline reinforcement learning (RL) with general function approximation. General function approximation is a powerful tool for algorithm design and analysis, but its adaptation to offline RL encounters several challenges due to varying approximation targets and assumptions that blur the real meanings of function assumptions. In this paper, we try to formulate and clarify the treatment of general function approximation in offline RL in two aspects: (1) analyzing different types of assumptions and their practical usage, and (2) understanding its role as a restriction on underlying MDPs from information-theoretic perspectives. Additionally, we introduce a new insight for lower bound establishing: one can exploit model-realizability to establish general-purpose lower bounds that can be generalized into other functions. Building upon this insight, we propose two generic lower bounds that contribute to a better understanding of offline RL with general function approximation.",
        "_bibtex": "@inproceedings{\nmao2024on,\ntitle={On the Role of General Function Approximation in Offline Reinforcement Learning},\nauthor={Chenjie Mao and Qiaosheng Zhang and Zhen Wang and Xuelong Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=JSS9rKHySk}\n}"
    },
    {
        "title": "Analyzing Feed-Forward Blocks in Transformers through the Lens of Attention Maps",
        "authorids": [
            "~Goro_Kobayashi1",
            "~Tatsuki_Kuribayashi1",
            "~Sho_Yokoi1",
            "~Kentaro_Inui1"
        ],
        "keywords": [
            "Transformer",
            "Attention map",
            "Feed-forward",
            "Contextualization",
            "Interpretation",
            "Analysis",
            "Pre-trained models",
            "Masked language models",
            "Causal language models"
        ],
        "abstract": "Transformers are ubiquitous in wide tasks.\nInterpreting their internals is a pivotal goal. \nNevertheless, their particular components, feed-forward (FF) blocks, have typically been less analyzed despite their substantial parameter amounts.\nWe analyze the input contextualization effects of FF blocks by rendering them in the attention maps as a human-friendly visualization scheme.\nOur experiments with both masked- and causal-language models reveal that FF networks modify the input contextualization to emphasize specific types of linguistic compositions. \nIn addition, FF and its surrounding components tend to cancel out each other's effects, suggesting potential redundancy in the processing of the Transformer layer.",
        "_bibtex": "@inproceedings{\nkobayashi2024analyzing,\ntitle={Analyzing Feed-Forward Blocks in Transformers through the Lens of Attention Maps},\nauthor={Goro Kobayashi and Tatsuki Kuribayashi and Sho Yokoi and Kentaro Inui},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=mYWsyTuiRp}\n}"
    },
    {
        "title": "Asymptotically Free Sketched Ridge Ensembles: Risks, Cross-Validation, and Tuning",
        "authorids": [
            "~Pratik_Patil1",
            "~Daniel_LeJeune1"
        ],
        "keywords": [
            "asymptotic freeness",
            "sketching",
            "ensembles",
            "ridge regression",
            "generalized cross-validation",
            "tuning"
        ],
        "abstract": "We employ random matrix theory to establish consistency of generalized cross validation (GCV) for estimating prediction risks of sketched ridge regression ensembles, enabling efficient and consistent tuning of regularization and sketching parameters. Our results hold for a broad class of asymptotically free sketches under very mild data assumptions. For squared prediction risk, we provide a decomposition into an unsketched equivalent implicit ridge bias and a sketching-based variance, and prove that the risk can be globally optimized by only tuning sketch size in infinite ensembles. For general subquadratic prediction risk functionals, we extend GCV to construct consistent risk estimators, and thereby obtain distributional convergence of the GCV-corrected predictions in Wasserstein-2 metric. This in particular allows construction of prediction intervals with asymptotically correct coverage conditional on the training data. We also propose an \"ensemble trick\" whereby the risk for unsketched ridge regression can be efficiently estimated via GCV using small sketched ridge ensembles. We empirically validate our theoretical results using both synthetic and real large-scale datasets with practical sketches including CountSketch and subsampled randomized discrete cosine transforms.",
        "_bibtex": "@inproceedings{\npatil2024asymptotically,\ntitle={Asymptotically Free Sketched Ridge Ensembles: Risks, Cross-Validation, and Tuning},\nauthor={Pratik Patil and Daniel LeJeune},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=i9Vs5NGDpk}\n}"
    },
    {
        "title": "Nemesis: Normalizing the Soft-prompt Vectors of Vision-Language Models",
        "authorids": [
            "~Shuai_Fu1",
            "~Xiequn_Wang1",
            "~Qiushi_Huang1",
            "~Yu_Zhang3"
        ],
        "keywords": [
            "Vision-language models; Soft-prompt tuning; Low-norm effect; Normalizing soft prompts"
        ],
        "abstract": "With the prevalence of large-scale pretrained vision-language models (VLMs), such as CLIP, soft-prompt tuning has become a popular method for adapting these models to various downstream tasks. However, few works delve into the inherent properties of learnable soft-prompt vectors, specifically the impact of their norms to the performance of VLMs. This motivates us to pose an unexplored research question: ``Do we need to normalize the soft prompts in VLMs?'' To fill this research gap, we first uncover a phenomenon, called the $\\textbf{Low-Norm Effect}$ by performing extensive corruption experiments, suggesting that reducing the norms of certain learned prompts occasionally enhances the performance of VLMs, while increasing them often degrades it. To harness this effect, we propose a novel method named $\\textbf{N}$ormalizing th$\\textbf{e}$ soft-pro$\\textbf{m}$pt v$\\textbf{e}$ctors of vi$\\textbf{si}$on-language model$\\textbf{s}$ ($\\textbf{Nemesis}$) to normalize soft-prompt vectors in VLMs. To the best of our knowledge, our work is the first to systematically investigate the role of norms of soft-prompt vector in VLMs, offering valuable insights for future research in soft-prompt tuning.",
        "_bibtex": "@inproceedings{\nfu2024nemesis,\ntitle={Nemesis: Normalizing the Soft-prompt Vectors of Vision-Language Models},\nauthor={Shuai Fu and Xiequn Wang and Qiushi Huang and Yu Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=zmJDzPh1Dm}\n}"
    },
    {
        "title": "Towards Understanding Factual Knowledge of Large Language Models",
        "authorids": [
            "~Xuming_Hu1",
            "~Junzhe_Chen1",
            "~Xiaochuan_Li3",
            "~Yufei_Guo3",
            "~Lijie_Wen1",
            "~Philip_S._Yu1",
            "~Zhijiang_Guo2"
        ],
        "keywords": [
            "Large Language Models",
            "Resource and Evaluation",
            "Interpretability",
            "NLP Application"
        ],
        "abstract": "Large language models (LLMs) have recently driven striking performance improvements across a range of natural language processing tasks. The factual knowledge acquired during pretraining and instruction tuning can be useful in various downstream tasks, such as question answering, and language generation. Unlike conventional Knowledge Bases (KBs) that explicitly store factual knowledge, LLMs implicitly store facts in their parameters. Content generated by the LLMs can often exhibit inaccuracies or deviations from the truth, due to facts that can be incorrectly induced or become obsolete over time. To this end, we aim to explore the extent and scope of factual knowledge within LLMs by designing the benchmark Pinocchio. Pinocchio contains 20K diverse factual questions that span different sources, timelines, domains, regions, and languages. Furthermore, we investigate whether LLMs can compose multiple facts, update factual knowledge temporally, reason over multiple pieces of facts, identify subtle factual differences, and resist adversarial examples. Extensive experiments on different sizes and types of LLMs show that existing LLMs still lack factual knowledge and suffer from various spurious correlations. We believe this is a critical bottleneck for realizing trustworthy artificial intelligence. The dataset Pinocchio and our codes are publicly available at: https://github.com/THU-BPM/Pinocchio.",
        "_bibtex": "@inproceedings{\nhu2024towards,\ntitle={Towards Understanding Factual Knowledge of Large Language Models},\nauthor={Xuming Hu and Junzhe Chen and Xiaochuan Li and Yufei Guo and Lijie Wen and Philip S. Yu and Zhijiang Guo},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=9OevMUdods}\n}"
    },
    {
        "title": "CAS: A Probability-Based Approach for Universal Condition Alignment Score",
        "authorids": [
            "~Chunsan_Hong1",
            "~ByungHee_Cha1",
            "~Tae-Hyun_Oh3"
        ],
        "keywords": [
            "Generative model",
            "diffusion model",
            "score-based prior",
            "conditional diffusion model",
            "text-to-image alignment score",
            "inversion process",
            "image quality assessment",
            "T2I alignment score"
        ],
        "abstract": "Recent conditional diffusion models have shown remarkable advancements and have been widely applied in fascinating real-world applications. However, samples generated by these models often do not strictly comply with user-provided conditions. Due to this, there have been few attempts to evaluate this alignment via pre-trained scoring models to select well-generated samples. Nonetheless, current studies are confined to the text-to-image domain and require large training datasets. This suggests that crafting alignment scores for various conditions will demand considerable resources in the future. In this context, we introduce a universal condition alignment score that leverages the conditional probability measurable through the diffusion process. Our technique operates across all conditions and requires no additional models beyond the diffusion model used for generation, effectively enabling self-rejection. Our experiments validate that our met- ric effectively applies in diverse conditional generations, such as text-to-image, {instruction, image}-to-image, edge-/scribble-to-image, and text-to-audio.",
        "_bibtex": "@inproceedings{\nhong2024cas,\ntitle={{CAS}: A Probability-Based Approach for Universal Condition Alignment Score},\nauthor={Chunsan Hong and ByungHee Cha and Tae-Hyun Oh},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=E78OaH2s3f}\n}"
    },
    {
        "title": "Demystifying CLIP Data",
        "authorids": [
            "~Hu_Xu1",
            "~Saining_Xie2",
            "~Xiaoqing_Tan1",
            "~Po-Yao_Huang2",
            "~Russell_Howes1",
            "~Vasu_Sharma1",
            "~Shang-Wen_Li1",
            "~Gargi_Ghosh3",
            "~Luke_Zettlemoyer1",
            "~Christoph_Feichtenhofer4"
        ],
        "keywords": [
            "multi-modal pretraining",
            "CLIP",
            "image",
            "text"
        ],
        "abstract": "Contrastive Language-Image Pre-training (CLIP) is an approach that has advanced research and applications in computer vision, fueling modern recognition systems and generative models. We believe that the main ingredient to the success of CLIP is its \\textit{data} and \\textit{not} the \\textit{model} architecture or pre-training {objective}. However, CLIP only provides very limited information about its data and how it has been collected, leading to works that aim to reproduce CLIP's data by filtering with its model parameters. In this work, we intend to reveal CLIP's data curation approach and in our pursuit of making it open to the community introduce Metadata-Curated Language-Image Pre-training (MetaCLIP). MetaCLIP takes a raw data pool and metadata (derived from CLIP's concepts) and yields a balanced subset over the metadata distribution. Our experimental study rigorously isolates the model and training settings, concentrating solely on data. MetaCLIP applied to CommonCrawl with 400M image-text data pairs outperforms CLIP's data on multiple standard benchmarks. In zero-shot ImageNet classification, MetaCLIP achieves 70.8\\% accuracy, surpassing CLIP's 68.3\\% on \\mbox{ViT-B} models. Scaling to 1B data, while maintaining the same training budget, attains \\textbf{72.4\\%}. Our observations hold across various model sizes, exemplified by ViT-H achieving \\textbf{80.5\\%}, without any bells-and-whistles. Curation code and training data distribution over metadata will be made available.",
        "_bibtex": "@inproceedings{\nxu2024demystifying,\ntitle={Demystifying {CLIP} Data},\nauthor={Hu Xu and Saining Xie and Xiaoqing Tan and Po-Yao Huang and Russell Howes and Vasu Sharma and Shang-Wen Li and Gargi Ghosh and Luke Zettlemoyer and Christoph Feichtenhofer},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5BCFlnfE1g}\n}"
    },
    {
        "title": "Adversarial AutoMixup",
        "authorids": [
            "~Huafeng_Qin1",
            "~Xin_Jin20",
            "~Yun_Jiang2",
            "~Moun\u00eem_El-Yacoubi1",
            "~Xinbo_Gao5"
        ],
        "keywords": [
            "Data Augmentation",
            "Mixup",
            "Image Classification"
        ],
        "abstract": "Data mixing augmentation has been widely applied to improve the generalization ability of deep neural networks. Recently, offline data mixing augmentation, e.g. handcrafted and saliency information-based mixup, has been gradually replaced by automatic mixing approaches. Through minimizing two sub-tasks, namely, mixed sample generation and mixup classification in an end-to-end way, AutoMix significantly improves accuracy on image classification tasks. However, as the optimization objective is consistent for the two sub-tasks, this approach is prone to generating consistent instead of diverse mixed samples, which results in overfitting for target task training. In this paper, we propose AdAutomixup, an adversarial automatic mixup augmentation approach that generates challenging samples to train a robust classifier for image classification, by alternatively optimizing the classifier and the mixup sample generator. AdAutomixup comprises two modules, a mixed example generator, and a target classifier. The mixed sample generator aims to produce hard mixed examples to challenge the target classifier, while the target classifier's aim is to learn robust features from hard mixed examples to improve generalization. To prevent the collapse of the inherent meanings of images, we further introduce an exponential moving average (EMA) teacher and cosine similarity to train AdAutomixup in an end-to-end way. Extensive experiments on seven image benchmarks consistently prove that our approach outperforms the state of the art in various classification scenarios. The source code is available at \nhttps://github.com/JinXins/Adversarial-AutoMixup.",
        "_bibtex": "@inproceedings{\nqin2024adversarial,\ntitle={Adversarial AutoMixup},\nauthor={Huafeng Qin and Xin Jin and Yun Jiang and Moun{\\^\\i}m El-Yacoubi and Xinbo Gao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=o8tjamaJ80}\n}"
    },
    {
        "title": "Spatially-Aware Transformers for Embodied Agents",
        "authorids": [
            "~Junmo_Cho1",
            "~Jaesik_Yoon1",
            "~Sungjin_Ahn1"
        ],
        "keywords": [
            "Episodic Memory",
            "Spatial Inference",
            "Prediction",
            "Generation",
            "Reinforcement Learning"
        ],
        "abstract": "Episodic memory plays a crucial role in various cognitive processes, such as the ability to mentally recall past events. While cognitive science emphasizes the significance of spatial context in the formation and retrieval of episodic memory, the current primary approach to implementing episodic memory in AI systems is through transformers that store temporally ordered experiences, which overlooks the spatial dimension. As a result, it is unclear how the underlying structure could be extended to incorporate the spatial axis beyond temporal order alone and thereby what benefits can be obtained. To address this, this paper explores the use of Spatially-Aware Transformer models that incorporate spatial information. These models enable the creation of place-centric episodic memory that considers both temporal and spatial dimensions. Adopting this approach, we demonstrate that memory utilization efficiency can be improved, leading to enhanced accuracy in various place-centric downstream tasks. Additionally, we propose the Adaptive Memory Allocator, a memory management method based on reinforcement learning that aims to optimize efficiency of memory utilization. Our experiments demonstrate the advantages of our proposed model in various environments and across multiple downstream tasks, including prediction, generation, reasoning, and reinforcement learning. The source code for our models and experiments will be available at \\href{https://github.com/spatially_aware_transformer}{https://github.com/spatially_aware_transformer}.",
        "_bibtex": "@inproceedings{\ncho2024spatiallyaware,\ntitle={Spatially-Aware Transformers for Embodied Agents},\nauthor={Junmo Cho and Jaesik Yoon and Sungjin Ahn},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Ts95eXsPBc}\n}"
    },
    {
        "title": "Grounding Language Plans in Demonstrations Through Counterfactual Perturbations",
        "authorids": [
            "~Yanwei_Wang1",
            "~Tsun-Hsuan_Wang2",
            "~Jiayuan_Mao1",
            "hagenow@mit.edu",
            "~Julie_Shah2"
        ],
        "keywords": [
            "Grounding LLM",
            "Learning Mode Abstractions for Manipulation",
            "Learning from Demonstration",
            "Robotics",
            "Task and Motion Planning"
        ],
        "abstract": "Grounding the common-sense reasoning of Large Language Models in physical domains remains a pivotal yet unsolved problem for embodied AI. Whereas prior works have focused on leveraging LLMs directly for planning in symbolic spaces, this work uses LLMs to guide the search of task structures and constraints implicit in multi-step demonstrations. Specifically, we borrow from manipulation planning literature the concept of mode families, which group robot configurations by specific motion constraints, to serve as an abstraction layer between the high-level language representations of an LLM and the low-level physical trajectories of a robot. By replaying a few human demonstrations with synthetic perturbations, we generate coverage over the demonstrations' state space with additional successful executions as well as counterfactuals that fail the task. Our explanation-based learning framework trains an end-to-end differentiable neural network to predict successful trajectories from failures and as a by-product learns classifiers that ground low-level states and images in mode families without dense labeling. The learned grounding classifiers can further be used to translate language plans into reactive policies in the physical domain in an interpretable manner. We show our approach improves the interpretability and reactivity of imitation learning through 2D navigation and simulated and real robot manipulation tasks. Website: https://yanweiw.github.io/glide/",
        "_bibtex": "@inproceedings{\nwang2024grounding,\ntitle={Grounding Language Plans in Demonstrations Through Counterfactual Perturbations},\nauthor={Yanwei Wang and Tsun-Hsuan Wang and Jiayuan Mao and Michael Hagenow and Julie Shah},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=qoHeuRAcSl}\n}"
    },
    {
        "title": "Beyond Worst-case Attacks: Robust RL with Adaptive Defense via Non-dominated Policies",
        "authorids": [
            "~Xiangyu_Liu4",
            "~Chenghao_Deng1",
            "~Yanchao_Sun1",
            "~Yongyuan_Liang1",
            "~Furong_Huang1"
        ],
        "keywords": [
            "robust reinforcement learning; beyond worse-case"
        ],
        "abstract": "In light of the burgeoning success of reinforcement learning (RL) in diverse real-world applications, considerable focus has been directed towards ensuring RL policies are robust to adversarial attacks during test time. Current approaches largely revolve around solving a minimax problem to prepare for potential worst-case scenarios. While effective against strong attacks, these methods often compromise performance in the absence of attacks or the presence of only weak attacks. To address this, we study policy robustness under the well-accepted state-adversarial attack model, extending our focus beyond merely worst-case attacks. We first formalize this task at test time as a regret minimization problem and establish its intrinsic difficulty in achieving sublinear regret when the baseline policy is from a general continuous policy class, $\\Pi$. This finding prompts us to \\textit{refine} the baseline policy class $\\Pi$ prior to test time, aiming for efficient adaptation within a compact, finite policy class $\\tilde{\\Pi}$, which can resort to an adversarial bandit subroutine. In light of the importance of a finite and compact $\\tilde{\\Pi}$, we propose a novel training-time algorithm to iteratively discover \\textit{non-dominated policies}, forming a near-optimal and minimal $\\tilde{\\Pi}$, thereby ensuring both robustness and test-time efficiency. Empirical validation on the Mujoco corroborates the superiority of our approach in terms of natural and robust performance, as well as adaptability to various attack scenarios.",
        "_bibtex": "@inproceedings{\nliu2024beyond,\ntitle={Beyond Worst-case Attacks: Robust {RL} with Adaptive Defense via Non-dominated Policies},\nauthor={Xiangyu Liu and Chenghao Deng and Yanchao Sun and Yongyuan Liang and Furong Huang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=DFTHW0MyiW}\n}"
    },
    {
        "title": "Merge, Then Compress: Demystify Efficient SMoE with Hints from Its Routing Policy",
        "authorids": [
            "~Pingzhi_Li1",
            "~Zhenyu_Zhang4",
            "~Prateek_Yadav1",
            "~Yi-Lin_Sung1",
            "~Yu_Cheng1",
            "~Mohit_Bansal2",
            "~Tianlong_Chen1"
        ],
        "keywords": [
            "Sparse Mixture-of-Experts",
            "Efficiency",
            "Merging",
            "Compression"
        ],
        "abstract": "Sparsely activated Mixture-of-Experts (SMoE) has shown promise to scale up the learning capacity of neural networks, however, they have issues like: ($a$) $\\textit{High Memory Usage,}$ due to duplication of the network layers into multiple copies as experts; and ($b$) $\\textit{Redundancy in Experts,}$ as common learning-based routing policies suffer from representational collapse. Therefore, vanilla SMoE models are memory inefficient and non-scalable, especially for resource-constrained downstream scenarios. In this paper, we ask: Can we craft a compact SMoE model by consolidating expert information? What is the best recipe to merge multiple experts into fewer but more knowledgeable experts? Our pilot investigation reveals that conventional model merging methods fail to be effective in such expert merging for SMoE. The potential reasons are: ($1$) redundant information overshadows critical experts; ($2$) appropriate neuron permutation for each expert is missing to bring all of them in alignment. To address these challenges, we propose a novel merging algorithm for SMoE, $\\textit{i.e.}$, $\\texttt{M-SMoE}$, which leverages routing statistics to guide expert merging. Specifically, it starts with neuron permutation alignment for experts; then, dominant experts and their \"group members\" are formed based on routing policies; lastly, every expert group is merged into a single expert by utilizing each expert's activation frequency as their weight for merging, thus diminishing the impact of insignificant experts. Moreover, we draw an interesting observation that our proposed merging promotes a low dimensionality in the merged expert's weight space, naturally paving the way for additional compression. Hence, our final method, $\\texttt{MC-SMoE}$ ($\\textit{i.e.}$, Merge, then Compress SMoE), further decomposes the merged experts into low-rank and structural sparse alternatives. Extensive experiments across $8$ benchmarks validate the effectiveness of our proposals. For instance, our $\\texttt{MC-SMoE}$ achieves up to $80\\%$ memory and a $20\\%$ FLOPs reduction, with virtually no loss in performance. Our code is provided as supplementary material.",
        "_bibtex": "@inproceedings{\nli2024merge,\ntitle={Merge, Then Compress: Demystify Efficient {SM}oE with Hints from Its Routing Policy},\nauthor={Pingzhi Li and Zhenyu Zhang and Prateek Yadav and Yi-Lin Sung and Yu Cheng and Mohit Bansal and Tianlong Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=eFWG9Cy3WK}\n}"
    },
    {
        "title": "On Bias-Variance Alignment in Deep Models",
        "authorids": [
            "~Lin_Chen14",
            "~Michal_Lukasik1",
            "~Wittawat_Jitkrittum1",
            "~Chong_You2",
            "~Sanjiv_Kumar1"
        ],
        "keywords": [
            "bias-variance decomposition",
            "ensemble",
            "deep learning"
        ],
        "abstract": "Classical wisdom in machine learning holds that the generalization error can be decomposed into bias and variance, and these two terms exhibit a \\emph{trade-off}. However, in this paper, we show that for an ensemble of deep learning based classification models, bias and variance are \\emph{aligned} at a sample level, where squared bias is approximately \\emph{equal} to variance for correctly classified sample points. We present empirical evidence confirming this phenomenon in a variety of deep learning models and datasets. Moreover, we study this phenomenon from two theoretical perspectives: calibration and neural collapse. We first show theoretically that under the assumption that the models are well calibrated, we can observe the bias-variance alignment. Second, starting from the picture provided by the neural collapse theory, we show an approximate correlation between bias and variance.",
        "_bibtex": "@inproceedings{\nchen2024on,\ntitle={On Bias-Variance Alignment in Deep Models},\nauthor={Lin Chen and Michal Lukasik and Wittawat Jitkrittum and Chong You and Sanjiv Kumar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=i2Phucne30}\n}"
    },
    {
        "title": "SEGNO: Generalizing Equivariant Graph Neural Networks with Physical Inductive Biases",
        "authorids": [
            "~Yang_Liu21",
            "~Jiashun_Cheng1",
            "~Haihong_Zhao2",
            "~Tingyang_Xu1",
            "~Peilin_Zhao2",
            "~Fugee_Tsung1",
            "~Jia_Li4",
            "~Yu_Rong1"
        ],
        "keywords": [
            "Equivariant Graph Neural Network",
            "Graph Neural Network"
        ],
        "abstract": "Graph Neural Networks (GNNs) with equivariant properties have emerged as powerful tools for modeling complex dynamics of multi-object physical systems. However, their generalization ability is limited by the inadequate consideration of physical inductive biases: (1) Existing studies overlook the continuity of transitions among system states, opting to employ several discrete transformation layers to learn the direct mapping between two adjacent states; (2) Most models only account for first-order velocity information, despite the fact that many physical systems are governed by second-order motion laws. To incorporate these inductive biases, we propose the Second-order Equivariant Graph Neural Ordinary Differential Equation (SEGNO). Specifically, we show how the second-order continuity can be incorporated into GNNs while maintaining the equivariant property. Furthermore, we offer theoretical insights into SEGNO, highlighting that it can learn a unique trajectory between adjacent states, which is crucial for model generalization. Additionally, we prove that the discrepancy between this learned trajectory of SEGNO and the true trajectory is bounded. Extensive experiments on complex dynamical systems including molecular dynamics and motion capture demonstrate that our model yields a significant improvement over the state-of-the-art baselines.",
        "_bibtex": "@inproceedings{\nliu2024segno,\ntitle={{SEGNO}: Generalizing Equivariant Graph Neural Networks with Physical Inductive Biases},\nauthor={Yang Liu and Jiashun Cheng and Haihong Zhao and Tingyang Xu and Peilin Zhao and Fugee Tsung and Jia Li and Yu Rong},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3oTPsORaDH}\n}"
    },
    {
        "title": "Spectrally Transformed Kernel Regression",
        "authorids": [
            "~Runtian_Zhai1",
            "~Rattana_Pukdee1",
            "rrjin@andrew.cmu.edu",
            "~Maria_Florina_Balcan1",
            "~Pradeep_Kumar_Ravikumar1"
        ],
        "keywords": [
            "Learning Theory",
            "Unlabeled Data",
            "Kernel Methods",
            "Semi-supervised Learning",
            "Representation Learning",
            "Label Propagation"
        ],
        "abstract": "Unlabeled data is a key component of modern machine learning. In general, the role\nof unlabeled data is to impose a form of smoothness, usually from the similarity\ninformation encoded in a base kernel, such as the \u03f5-neighbor kernel or the adjacency\nmatrix of a graph. This work revisits the classical idea of spectrally transformed\nkernel regression (STKR), and provides a new class of general and scalable STKR\nestimators able to leverage unlabeled data. Intuitively, via spectral transformation,\nSTKR exploits the data distribution for which unlabeled data can provide additional\ninformation. First, we show that STKR is a principled and general approach,\nby characterizing a universal type of \u201ctarget smoothness\u201d, and proving that any\nsufficiently smooth function can be learned by STKR. Second, we provide scalable\nSTKR implementations for the inductive setting and a general transformation\nfunction, while prior work is mostly limited to the transductive setting. Third, we\nderive statistical guarantees for two scenarios: STKR with a known polynomial\ntransformation, and STKR with kernel PCA when the transformation is unknown.\nOverall, we believe that this work helps deepen our understanding of how to work\nwith unlabeled data, and its generality makes it easier to inspire new methods.",
        "_bibtex": "@inproceedings{\nzhai2024spectrally,\ntitle={Spectrally Transformed Kernel Regression},\nauthor={Runtian Zhai and Rattana Pukdee and Roger Jin and Maria Florina Balcan and Pradeep Kumar Ravikumar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=OeQE9zsztS}\n}"
    },
    {
        "title": "Online GNN Evaluation Under Test-time Graph Distribution Shifts",
        "authorids": [
            "~Xin_Zheng4",
            "~Dongjin_Song2",
            "~Qingsong_Wen2",
            "~Bo_Du3",
            "~Shirui_Pan1"
        ],
        "keywords": [
            "Graph neural networks",
            "Model evaluation",
            "Distribution shift"
        ],
        "abstract": "Evaluating the performance of a well-trained GNN model on real-world graphs is a pivotal step for reliable GNN online deployment and serving. \nDue to a lack of test node labels and unknown potential training-test graph data distribution shifts, conventional model evaluation encounters limitations in calculating performance metrics (e.g., test error) and measuring graph data-level discrepancies, particularly when the training graph used for developing GNNs remains unobserved during test time.\nIn this paper, we study a new research problem, online GNN evaluation, which aims to provide valuable insights into the well-trained GNNs's ability to effectively generalize to real-world unlabeled graphs under the test-time graph distribution shifts.\nConcretely, we develop an effective learning behavior discrepancy score, dubbed LeBeD, to estimate the test-time generalization errors of well-trained GNN models. \nThrough a novel GNN re-training strategy with a parameter-free optimality criterion, the proposed LeBeD comprehensively integrates learning behavior discrepancies from both node prediction and structure reconstruction perspectives.\nThis enables the effective evaluation of the well-trained GNNs' ability to capture test node semantics and structural representations, making it an expressive metric for estimating the generalization error in online GNN evaluation.\nExtensive experiments on real-world test graphs under diverse graph distribution shifts could verify the effectiveness of the proposed method, revealing its strong correlation with ground-truth test errors on various well-trained GNN models.",
        "_bibtex": "@inproceedings{\nzheng2024online,\ntitle={Online {GNN} Evaluation Under Test-time Graph Distribution Shifts},\nauthor={Xin Zheng and Dongjin Song and Qingsong Wen and Bo Du and Shirui Pan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=KbetDM33YG}\n}"
    },
    {
        "title": "Understanding and Mitigating the Label Noise in Pre-training on Downstream Tasks",
        "authorids": [
            "~Hao_Chen15",
            "~Jindong_Wang1",
            "~Ankit_Shah1",
            "~Ran_Tao2",
            "~Hongxin_Wei1",
            "~Xing_Xie3",
            "~Masashi_Sugiyama1",
            "~Bhiksha_Raj1"
        ],
        "keywords": [
            "Pre training",
            "Noisy model learning",
            "Label noise",
            "Noise mitigation"
        ],
        "abstract": "Pre-training on large-scale datasets and then fine-tuning on downstream tasks have become a standard practice in deep learning. However, pre-training data often contain label noise that may adversely affect the generalization of the model. This paper aims to understand the nature of noise in pre-training datasets and to mitigate its impact on downstream tasks. More specifically, through extensive experiments of supervised pre-training models on synthetic noisy ImageNet-1K and YFCC15M datasets, we demonstrate that while slight noise in pre-training can benefit in-domain (ID) transfer performance, where the training and testing data share the same distribution, it always deteriorates out-of-domain (OOD) performance, where training and testing data distribution are different. We empirically verify that the reason behind is noise in pre-training shapes the feature space differently. We then propose a light-weight black-box tuning method (NMTune) to affine the feature space to mitigate the malignant effect of noise and improve generalization on both ID and OOD tasks, considering one may not be able to fully fine-tune or even access the pre-trained models. We conduct practical experiments on popular vision and language models that are pre-trained on noisy data for evaluation of our approach. Our analysis and results show the importance of this interesting and novel research direction, which we term Noisy Model Learning.",
        "_bibtex": "@inproceedings{\nchen2024understanding,\ntitle={Understanding and Mitigating the Label Noise in Pre-training on Downstream Tasks},\nauthor={Hao Chen and Jindong Wang and Ankit Shah and Ran Tao and Hongxin Wei and Xing Xie and Masashi Sugiyama and Bhiksha Raj},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TjhUtloBZU}\n}"
    },
    {
        "title": "WildChat: 1M ChatGPT Interaction Logs in the Wild",
        "authorids": [
            "~Wenting_Zhao1",
            "~Xiang_Ren1",
            "~Jack_Hessel1",
            "~Claire_Cardie1",
            "~Yejin_Choi1",
            "~Yuntian_Deng2"
        ],
        "keywords": [
            "dataset",
            "dialogues",
            "chatbot",
            "ChatGPT",
            "instruction tuning",
            "toxicity",
            "AI safety"
        ],
        "abstract": "Chatbots such as GPT-4 and ChatGPT are now serving millions of users. Despite their widespread use, there remains a lack of public datasets showcasing how these tools are used by a population of users in practice. To bridge this gap, we offered free access to ChatGPT for online users in exchange for their affirmative, consensual opt-in to anonymously collect their chat transcripts and request headers. From this, we compiled WildChat, a corpus of 1 million user-ChatGPT conversations, which consists of over 2.5 million interaction turns. We compare WildChat with other popular user-chatbot interaction datasets, and find that our dataset offers the most diverse user prompts, contains the largest number of languages, and presents the richest variety of potentially toxic use-cases for researchers to study. In addition to timestamped chat transcripts, we enrich the dataset with demographic data, including state, country, and hashed IP addresses, alongside request headers. This augmentation allows for more detailed analysis of user behaviors across different geographical regions and temporal dimensions. Finally, because it captures a broad range of use cases, we demonstrate the dataset\u2019s potential utility in fine-tuning instruction-following models. WildChat is released at https://wildchat.allen.ai under AI2 ImpACT Licenses.",
        "_bibtex": "@inproceedings{\nzhao2024wildchat,\ntitle={WildChat: 1M Chat{GPT} Interaction Logs in the Wild},\nauthor={Wenting Zhao and Xiang Ren and Jack Hessel and Claire Cardie and Yejin Choi and Yuntian Deng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Bl8u7ZRlbM}\n}"
    },
    {
        "title": "Learning Hierarchical Image Segmentation For Recognition and By Recognition",
        "authorids": [
            "~Tsung-Wei_Ke2",
            "~Sangwoo_Mo1",
            "~Stella_X._Yu2"
        ],
        "keywords": [
            "segmentation in the loop for recognition",
            "hierarchical segmentation",
            "part-to-whole recognition",
            "vision transformer"
        ],
        "abstract": "Large vision and language models learned directly through image-text associations often lack detailed visual substantiation, whereas image segmentation tasks are treated separately from recognition, supervisedly learned without interconnections.\n\nOur key observation is that,  while an image can be recognized in multiple ways, each has a consistent part-and-whole visual organization.  Segmentation thus should be treated not as an end task to be mastered through supervised learning, but as an internal process that evolves with and supports the ultimate goal of recognition. \n\nWe propose to integrate a hierarchical segmenter into the recognition process, \n{\\it train} and {\\it adapt} the entire model solely on image-level recognition objectives.  We learn hierarchical segmentation {\\it for free} alongside recognition,  automatically uncovering part-to-whole relationships that not only underpin but also enhance recognition. \n\nEnhancing the Vision Transformer (ViT) with adaptive segment tokens and graph pooling, our model surpasses ViT in unsupervised part-whole discovery, semantic segmentation, image classification, and efficiency.  Notably, our model (trained on {\\it unlabeled} 1M ImageNet images) outperforms SAM (trained on 11M images and 1 billion masks) by absolute 8\\% in mIoU on PartImageNet object segmentation.",
        "_bibtex": "@inproceedings{\nke2024learning,\ntitle={Learning Hierarchical Image Segmentation For Recognition and By Recognition},\nauthor={Tsung-Wei Ke and Sangwoo Mo and Stella X. Yu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=IRcv4yFX6z}\n}"
    },
    {
        "title": "Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models",
        "authorids": [
            "~Erfan_Shayegani1",
            "~Yue_Dong2",
            "~Nael_Abu-Ghazaleh2"
        ],
        "keywords": [
            "Adversarial attacks",
            "Vision encoders",
            "Jailbreak",
            "Prompt Injection",
            "Security",
            "Embedding space attacks",
            "Black box",
            "LLM",
            "Vision-Language Models",
            "Multi-Modal Models",
            "VLM",
            "Alignment",
            "Cross-Modality alignment"
        ],
        "abstract": "We introduce new jailbreak attacks on vision language models (VLMs), which use aligned LLMs and are resilient to text-only jailbreak attacks. Specifically, we develop cross-modality attacks on alignment where we pair adversarial images going through the vision encoder with textual prompts to break the alignment of the language model. Our attacks employ a novel compositional strategy that combines an image, adversarially targeted towards toxic embeddings, with generic prompts to accomplish the jailbreak. Thus, the LLM draws the context to answer the generic prompt from the adversarial image. The generation of benign-appearing adversarial images leverages a novel embedding-space-based methodology, operating with no access to the LLM model. Instead, the attacks require access only to the vision encoder and utilize one of our four embedding space targeting strategies. By not requiring access to the LLM, the attacks lower the entry barrier for attackers, particularly when vision encoders such as CLIP are embedded in closed-source LLMs. The attacks achieve a high success rate across different VLMs, highlighting the risk of cross-modality alignment vulnerabilities, and the need for new alignment approaches for multi-modal models.",
        "_bibtex": "@inproceedings{\nshayegani2024jailbreak,\ntitle={Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models},\nauthor={Erfan Shayegani and Yue Dong and Nael Abu-Ghazaleh},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=plmBsXHxgR}\n}"
    },
    {
        "title": "DreamFlow: High-quality text-to-3D generation by Approximating Probability Flow",
        "authorids": [
            "~Kyungmin_Lee1",
            "~Kihyuk_Sohn1",
            "~Jinwoo_Shin1"
        ],
        "keywords": [
            "Text-to-3D generation",
            "Diffusion model",
            "Score Distillation Sampling"
        ],
        "abstract": "Recent progress in text-to-3D generation has been achieved through the utilization of score distillation methods: they make use of the pre-trained text-to-image (T2I) diffusion models by distilling via the diffusion model training objective. However, such an approach inevitably results in the use of random timesteps at each update, which increases the variance of the gradient and ultimately prolongs the optimization process. In this paper, we propose to enhance the text-to-3D optimization by leveraging the T2I diffusion prior in the generative sampling process with a predetermined timestep schedule. To this end, we interpret text-to-3D optimization as a multi-view image-to-image translation problem, and propose a solution by approximating the probability flow. By leveraging the proposed novel optimization algorithm, we design DreamFlow, a practical three-stage coarse-to-fine text-to-3D optimization framework that enables fast generation of high-quality and high-resolution (i.e., 1024\u00d71024) 3D contents. For example, we demonstrate that DreamFlow is 5 times faster than the existing state-of-the-art text-to-3D method, while producing more photorealistic 3D contents.",
        "_bibtex": "@inproceedings{\nlee2024dreamflow,\ntitle={DreamFlow: High-quality text-to-3D generation by Approximating Probability Flow},\nauthor={Kyungmin Lee and Kihyuk Sohn and Jinwoo Shin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=GURqUuTebY}\n}"
    },
    {
        "title": "Stack Attention: Improving the Ability of Transformers to Model Hierarchical Patterns",
        "authorids": [
            "~Brian_DuSell1",
            "~David_Chiang1"
        ],
        "keywords": [
            "transformer",
            "attention",
            "context-free languages",
            "pushdown automata",
            "formal languages",
            "language modeling",
            "machine translation"
        ],
        "abstract": "Attention, specifically scaled dot-product attention, has proven effective for natural language, but it does not have a mechanism for handling hierarchical patterns of arbitrary nesting depth, which limits its ability to recognize certain syntactic structures. To address this shortcoming, we propose stack attention: an attention operator that incorporates stacks, inspired by their theoretical connections to context-free languages (CFLs). We show that stack attention is analogous to standard attention, but with a latent model of syntax that requires no syntactic supervision. We propose two variants: one related to deterministic pushdown automata (PDAs) and one based on nondeterministic PDAs, which allows transformers to recognize arbitrary CFLs. We show that transformers with stack attention are very effective at learning CFLs that standard transformers struggle on, achieving strong results on a CFL with theoretically maximal parsing difficulty. We also show that stack attention is more effective at natural language modeling under a constrained parameter budget, and we include results on machine translation.",
        "_bibtex": "@inproceedings{\ndusell2024stack,\ntitle={Stack Attention: Improving the Ability of Transformers to Model Hierarchical Patterns},\nauthor={Brian DuSell and David Chiang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=XVhm3X8Fum}\n}"
    },
    {
        "title": "SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents",
        "authorids": [
            "~Xuhui_Zhou1",
            "~Hao_Zhu1",
            "~Leena_Mathur1",
            "~Ruohong_Zhang1",
            "~Haofei_Yu1",
            "~Zhengyang_Qi1",
            "~Louis-Philippe_Morency1",
            "~Yonatan_Bisk1",
            "~Daniel_Fried1",
            "~Graham_Neubig1",
            "~Maarten_Sap1"
        ],
        "keywords": [
            "Social",
            "Interaction",
            "Agent",
            "Social intelligence",
            "Large Language Models",
            "Evaluation",
            "Theory of Mind"
        ],
        "abstract": "*Humans are social beings*; we pursue social goals in our daily interactions, which is a crucial aspect of social intelligence. Yet, AI systems' abilities in this realm remain elusive. We present SOTOPIA, an open-ended environment to simulate complex social interactions between artificial agents and evaluate their social intelligence. In our environment, agents role-play and *interact* under a wide variety of scenarios; they coordinate, collaborate, exchange, and compete with each other to achieve complex social goals. We simulate the role-play interaction between LLM-based agents and humans within this task space and evaluate their performance with a holistic evaluation framework called SOTOPIA-Eval. With SOTOPIA, we find significant differences between these models in terms of their social intelligence, and we identify a subset of SOTOPIA scenarios, SOTOPIA-hard, that is generally challenging for all models. We find that on this subset, GPT-4 achieves a significantly lower goal completion rate than humans and struggles to exhibit social commonsense reasoning and strategic communication skills. These findings demonstrate SOTOPIA's promise as a general platform for research on evaluating and improving social intelligence in artificial agents.",
        "_bibtex": "@inproceedings{\nzhou2024sotopia,\ntitle={{SOTOPIA}: Interactive Evaluation for Social Intelligence in Language Agents},\nauthor={Xuhui Zhou and Hao Zhu and Leena Mathur and Ruohong Zhang and Haofei Yu and Zhengyang Qi and Louis-Philippe Morency and Yonatan Bisk and Daniel Fried and Graham Neubig and Maarten Sap},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=mM7VurbA4r}\n}"
    },
    {
        "title": "Privileged Sensing Scaffolds Reinforcement Learning",
        "authorids": [
            "~Edward_S._Hu1",
            "~James_Springer1",
            "~Oleh_Rybkin1",
            "~Dinesh_Jayaraman2"
        ],
        "keywords": [
            "reinforcement learning",
            "model-based reinforcement learning",
            "world models",
            "robotics",
            "privileged information",
            "asymmetric learning",
            "multimodality",
            "perception",
            "sensing"
        ],
        "abstract": "We need to look at our shoelaces as we first learn to tie them but having mastered this skill, can do it from touch alone. We call this phenomenon \u201csensory scaffolding\u201d: observation streams that are not needed by a master might yet aid a novice learner. We consider such sensory scaffolding setups for training artificial agents. For example, a robot arm may need to be deployed with just a low-cost, robust, general-purpose camera; yet its performance may improve by having privileged training-time-only access to informative albeit expensive and unwieldy motion capture rigs or fragile tactile sensors. For these settings, we propose \u201cScaffolder\u201d, a reinforcement learning approach which effectively exploits privileged sensing in critics, world models, reward estimators, and other such auxiliary components that are only used at training time, to improve the target policy. For evaluating sensory scaffolding agents, we design a new \u201cS3\u201d suite of ten diverse simulated robotic tasks that explore a wide range of practical sensor setups. Agents must use privileged camera sensing to train blind hurdlers, privileged active visual perception to help robot arms overcome visual occlusions, privileged touch sensors to train robot hands, and more. Scaffolder easily outperforms relevant prior baselines and frequently performs comparably even to policies that have test-time access to the privileged sensors. Website: https://penn-pal-lab.github.io/scaffolder/",
        "_bibtex": "@inproceedings{\nhu2024privileged,\ntitle={Privileged Sensing Scaffolds Reinforcement Learning},\nauthor={Edward S. Hu and James Springer and Oleh Rybkin and Dinesh Jayaraman},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=EpVe8jAjdx}\n}"
    },
    {
        "title": "Learning to Act without Actions",
        "authorids": [
            "~Dominik_Schmidt2",
            "~Minqi_Jiang1"
        ],
        "keywords": [
            "reinforcement learning",
            "world models",
            "inverse dynamics models",
            "imitation learning",
            "representation learning"
        ],
        "abstract": "Pre-training large models on vast amounts of web data has proven to be an effective approach for obtaining powerful, general models in domains such as language and vision. However, this paradigm has not yet taken hold in reinforcement learning. This is because videos, the most abundant form of embodied behavioral data on the web, lack the action labels required by existing methods for imitating behavior from demonstrations. We introduce **Latent Action Policies** (LAPO), a method for recovering latent action information\u2014and thereby latent-action policies, world models, and inverse dynamics models\u2014purely from videos. LAPO is the first method able to recover the structure of the true action space just from observed dynamics, even in challenging procedurally-generated environments. LAPO enables training latent-action policies that can be rapidly fine-tuned into expert-level policies, either offline using a small action-labeled dataset, or online with rewards. LAPO takes a first step towards pre-training powerful, generalist policies and world models on the vast amounts of videos readily available on the web. Our code is available here: \n[https://github.com/schmidtdominik/LAPO](https://github.com/schmidtdominik/LAPO).",
        "_bibtex": "@inproceedings{\nschmidt2024learning,\ntitle={Learning to Act without Actions},\nauthor={Dominik Schmidt and Minqi Jiang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rvUq3cxpDF}\n}"
    },
    {
        "title": "Error Norm Truncation: Robust Training in the Presence of Data Noise for Text Generation Models",
        "authorids": [
            "~Tianjian_Li1",
            "~Haoran_Xu3",
            "~Philipp_Koehn2",
            "~Daniel_Khashabi2",
            "~Kenton_Murray1"
        ],
        "keywords": [
            "language generation",
            "language modeling",
            "machine translation",
            "robustness",
            "estimating data quality"
        ],
        "abstract": "Text generation models are notoriously vulnerable to errors in the training data. With the wide-spread availability of massive amounts of web-crawled data becoming more commonplace, how can we enhance the robustness of models trained on a massive amount of noisy web-crawled text? In our work, we propose Error Norm Truncation (ENT), a robust enhancement method to the standard training objective that truncates noisy data. Compared to methods that only uses the negative log-likelihood loss to estimate data quality, our method provides a more accurate estimation by considering the distribution of non-target tokens, which is often overlooked by previous work. Through comprehensive experiments across language modeling, machine translation, and text summarization, we show that equipping text generation models with ENT improves generation quality over standard training and previous soft and hard truncation methods. Furthermore, we show that our method improves the robustness of models against two of the most detrimental types of noise in machine translation, resulting in an increase of more than 2 BLEU points over the MLE baseline when up to 50\\% of noise is added to the data.",
        "_bibtex": "@inproceedings{\nli2024error,\ntitle={Error Norm Truncation: Robust Training in the Presence of Data Noise for Text Generation Models},\nauthor={Tianjian Li and Haoran Xu and Philipp Koehn and Daniel Khashabi and Kenton Murray},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=zMvMwNvs4R}\n}"
    },
    {
        "title": "Massively Scalable Inverse Reinforcement Learning in Google Maps",
        "authorids": [
            "~Matt_Barnes1",
            "~Matthew_Abueg1",
            "~Oliver_F._Lange1",
            "~Matt_Deeds1",
            "~Jason_Trader1",
            "~Denali_Molitor1",
            "~Markus_Wulfmeier1",
            "~Shawn_O'Banion1"
        ],
        "keywords": [
            "Inverse reinforcement learning",
            "route optimization"
        ],
        "abstract": "Inverse reinforcement learning (IRL) offers a powerful and general framework for learning humans' latent preferences in route recommendation, yet no approach has successfully addressed planetary-scale problems with hundreds of millions of states and demonstration trajectories. In this paper, we introduce scaling techniques based on graph compression, spatial parallelization, and improved initialization conditions inspired by a connection to eigenvector algorithms. We revisit classic IRL methods in the routing context, and make the key observation that there exists a trade-off between the use of cheap, deterministic planners and expensive yet robust stochastic policies. This insight is leveraged in Receding Horizon Inverse Planning (RHIP), a new generalization of classic IRL algorithms that provides fine-grained control over performance trade-offs via its planning horizon. Our contributions culminate in a policy that achieves a 16-24% improvement in route quality at a global scale, and to the best of our knowledge, represents the largest published study of IRL algorithms in a real-world setting to date. We conclude by conducting an ablation study of key components, presenting negative results from alternative eigenvalue solvers, and identifying opportunities to further improve scalability via IRL-specific batching strategies.",
        "_bibtex": "@inproceedings{\nbarnes2024massively,\ntitle={Massively Scalable Inverse Reinforcement Learning in Google Maps},\nauthor={Matt Barnes and Matthew Abueg and Oliver F. Lange and Matt Deeds and Jason Trader and Denali Molitor and Markus Wulfmeier and Shawn O'Banion},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=z3L59iGALM}\n}"
    },
    {
        "title": "Thin-Shell Object Manipulations With Differentiable Physics Simulations",
        "authorids": [
            "~Yian_Wang1",
            "~Juntian_Zheng1",
            "~Zhehuan_Chen1",
            "~Zhou_Xian1",
            "~Gu_Zhang1",
            "~Chao_Liu9",
            "~Chuang_Gan1"
        ],
        "keywords": [
            "differentiable physics simulation",
            "thin-shell object manipulation"
        ],
        "abstract": "In this work, we aim to teach robots to manipulate various thin-shell materials. \nPrior works studying thin-shell object manipulation mostly rely on heuristic policies or learn policies from real-world video demonstrations, and only focus on limited material types and tasks (e.g., cloth unfolding). However, these approaches face significant challenges when extended to a wider variety of thin-shell materials and a diverse range of tasks.\nOn the other hand, while virtual simulations are shown to be effective in diverse robot skill learning and evaluation, prior thin-shell simulation environments only support a subset of thin-shell materials, which also limits their supported range of tasks. \nTo fill in this gap, we introduce ThinShellLab - a fully differentiable simulation platform tailored for robotic interactions with diverse thin-shell materials possessing varying material properties, enabling flexible thin-shell manipulation skill learning and evaluation. Building on top of our developed simulation engine, we design a diverse set of manipulation tasks centered around different thin-shell objects. Our experiments suggest that manipulating thin-shell objects presents several unique challenges: 1) thin-shell manipulation relies heavily on frictional forces due to the objects' co-dimensional nature, 2) the materials being manipulated are highly sensitive to minimal variations in interaction actions, and 3) the constant and frequent alteration in contact pairs makes trajectory optimization methods susceptible to local optima, and neither standard reinforcement learning algorithms nor trajectory optimization methods (either gradient-based or gradient-free) are able to solve the tasks alone. To overcome these challenges, we present an optimization scheme that couples sampling-based trajectory optimization and gradient-based optimization, boosting both learning efficiency and converged performance across various proposed tasks. In addition, the differentiable nature of our platform facilitates a smooth sim-to-real transition. By tuning simulation parameters with a minimal set of real-world data, we demonstrate successful deployment of the learned skills to real-robot settings.  ThinShellLab will be publicly available. Video demonstration and more information can be found on the project website https://vis-www.cs.umass.edu/ThinShellLab/.",
        "_bibtex": "@inproceedings{\nwang2024thinshell,\ntitle={Thin-Shell Object Manipulations With Differentiable Physics Simulations},\nauthor={Yian Wang and Juntian Zheng and Zhehuan Chen and Zhou Xian and Gu Zhang and Chao Liu and Chuang Gan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=KsUh8MMFKQ}\n}"
    },
    {
        "title": "Can Sensitive Information Be Deleted From LLMs? Objectives for Defending Against Extraction Attacks",
        "authorids": [
            "~Vaidehi_Patil1",
            "~Peter_Hase1",
            "~Mohit_Bansal2"
        ],
        "keywords": [
            "Sensitive Information Deletion",
            "Privacy Attacks",
            "Model editing",
            "Language Models"
        ],
        "abstract": "Pretrained language models sometimes possess knowledge that we do not wish them to, including memorized personal information and knowledge that could be used to harm people. They can also output toxic or harmful text. To mitigate these safety and informational issues, we propose an attack-and-defense framework for studying the task of deleting sensitive information directly from model weights. We study direct edits to model weights because (1) this approach should guarantee that particular deleted information is never extracted by future prompt attacks, and (2) it should protect against whitebox attacks, which is necessary for making claims about safety/privacy in a setting where publicly available model weights could be used to elicit sensitive information. Our threat model assumes that an attack succeeds if the answer to a sensitive question is located among a set of B generated candidates, based on scenarios where the information would be insecure if the answer is among B candidates. Experimentally, we show that even state-of-the-art model editing methods such as ROME struggle to truly delete factual information from models like GPT-J, as our whitebox and blackbox attacks can recover \u201cdeleted\u201d information from an edited model 38% of the time. These attacks leverage two key observations: (1) that traces of deleted information can be found in intermediate model hidden states, and (2) that applying an editing method for one question may not delete information across rephrased versions of the question. Finally, we provide new defense methods that protect against some extraction attacks, but we do not find a single universally effective defense method. Our results suggest that truly deleting sensitive information is a tractable but difficult problem, since even relatively low attack success rates have potentially severe implications for the deployment of language models in a world where individuals enjoy ownership of their personal data, a right to privacy, and safety from harmful model outputs.",
        "_bibtex": "@inproceedings{\npatil2024can,\ntitle={Can Sensitive Information Be Deleted From {LLM}s? Objectives for Defending Against Extraction Attacks},\nauthor={Vaidehi Patil and Peter Hase and Mohit Bansal},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=7erlRDoaV8}\n}"
    },
    {
        "title": "Learning to Reject Meets Long-tail Learning",
        "authorids": [
            "~Harikrishna_Narasimhan1",
            "~Aditya_Krishna_Menon1",
            "~Wittawat_Jitkrittum1",
            "~Neha_Gupta1",
            "~Sanjiv_Kumar1"
        ],
        "keywords": [
            "Learning to reject",
            "balanced error",
            "evaluation metrics",
            "selective classification",
            "plug-in approach",
            "long-tail learning",
            "class imbalance",
            "non-decomposable metrics"
        ],
        "abstract": "Learning to reject (L2R) is a classical problem where one seeks a classifier capable of abstaining on low-confidence samples. Most prior work on L2R has focused on minimizing the standard misclassification error. However, in many real-world applications, the label distribution is highly imbalanced,  necessitating alternate evaluation metrics such as the balanced error or the worst-group error that enforce equitable performance across both the head and tail classes. In this paper, we establish that traditional L2R methods can be grossly sub-optimal for such metrics, and show that this is due to an intricate  dependence in the objective between the label costs and the rejector. We then derive the form of the Bayes-optimal classifier and rejector for the balanced error, propose a novel plug-in approach to mimic this solution, and extend our results to general evaluation metrics. Through experiments on benchmark  image classification tasks, we show that our approach yields better trade-offs in both the balanced and worst-group error compared to L2R baselines.",
        "_bibtex": "@inproceedings{\nnarasimhan2024learning,\ntitle={Learning to Reject Meets Long-tail Learning},\nauthor={Harikrishna Narasimhan and Aditya Krishna Menon and Wittawat Jitkrittum and Neha Gupta and Sanjiv Kumar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ta26LtNq2r}\n}"
    },
    {
        "title": "On the Foundations of Shortcut Learning",
        "authorids": [
            "~Katherine_Hermann1",
            "~Hossein_Mobahi2",
            "~Thomas_FEL1",
            "~Michael_Curtis_Mozer1"
        ],
        "keywords": [
            "shortcut learning",
            "spurious correlations",
            "architectural inductive bias"
        ],
        "abstract": "Deep-learning models can extract a rich assortment of features from data. Which features a model uses depends not only on *predictivity*---how reliably a feature indicates training-set labels---but also on *availability*---how easily the feature can be extracted from inputs. The literature on shortcut learning has noted examples in which models privilege one feature over another, for example texture over shape and image backgrounds over foreground objects. Here, we test hypotheses about which input properties are more available to a model, and systematically study how predictivity and availability interact to shape models' feature use. We construct a minimal, explicit generative framework for synthesizing classification datasets with two latent features that vary in predictivity and in factors we hypothesize to relate to availability, and we quantify a model's shortcut bias---its over-reliance on the shortcut (more available, less predictive) feature at the expense of the core (less available, more predictive) feature. We find that linear models are relatively unbiased, but introducing a single hidden layer with ReLU or Tanh units yields a bias. Our empirical findings are consistent with a theoretical account based on Neural Tangent Kernels. Finally, we study how models used in practice trade off predictivity and availability in naturalistic datasets, discovering availability manipulations which increase models' degree of shortcut bias. Taken together, these findings suggest that the propensity to learn shortcut features is a fundamental characteristic of deep nonlinear architectures warranting systematic study given its role in shaping how models solve tasks.",
        "_bibtex": "@inproceedings{\nhermann2024on,\ntitle={On the Foundations of Shortcut Learning},\nauthor={Katherine Hermann and Hossein Mobahi and Thomas FEL and Michael Curtis Mozer},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Tj3xLVuE9f}\n}"
    },
    {
        "title": "Synaptic Weight Distributions Depend on the Geometry of Plasticity",
        "authorids": [
            "~Roman_Pogodin1",
            "~Jonathan_Cornford1",
            "~Arna_Ghosh1",
            "~Gauthier_Gidel1",
            "~Guillaume_Lajoie1",
            "~Blake_Aaron_Richards1"
        ],
        "keywords": [
            "synaptic weight distributions",
            "synaptic plasticity",
            "biologically plausible learning",
            "mirror descent"
        ],
        "abstract": "A growing literature in computational neuroscience leverages gradient descent and learning algorithms that approximate it to study synaptic plasticity in the brain. However, the vast majority of this work ignores a critical underlying assumption: the choice of distance for synaptic changes - i.e. the geometry of synaptic plasticity. Gradient descent assumes that the distance is Euclidean, but many other distances are possible, and there is no reason that biology necessarily uses Euclidean geometry. Here, using the theoretical tools provided by mirror descent, we show that the distribution of synaptic weights will depend on the geometry of synaptic plasticity. We use these results to show that experimentally-observed log-normal weight distributions found in several brain areas are not consistent with standard gradient descent (i.e. a Euclidean geometry), but rather with non-Euclidean distances. Finally, we show that it should be possible to experimentally test for different synaptic geometries by comparing synaptic weight distributions before and after learning. Overall, our work shows that the current paradigm in theoretical work on synaptic plasticity that assumes Euclidean synaptic geometry may be misguided and that it should be possible to experimentally determine the true geometry of synaptic plasticity in the brain.",
        "_bibtex": "@inproceedings{\npogodin2024synaptic,\ntitle={Synaptic Weight Distributions Depend on the Geometry of Plasticity},\nauthor={Roman Pogodin and Jonathan Cornford and Arna Ghosh and Gauthier Gidel and Guillaume Lajoie and Blake Aaron Richards},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=x5txICnnjC}\n}"
    },
    {
        "title": "Graph Metanetworks for Processing Diverse Neural Architectures",
        "authorids": [
            "~Derek_Lim1",
            "~Haggai_Maron1",
            "~Marc_T._Law1",
            "~Jonathan_Lorraine1",
            "~James_Lucas1"
        ],
        "keywords": [
            "Metanetwork",
            "graph",
            "equivariance",
            "expressivity"
        ],
        "abstract": "Neural networks efficiently encode learned information within their parameters. Consequently, many tasks can be unified by treating neural networks themselves as input data. When doing so, recent studies demonstrated the importance of accounting for the symmetries and geometry of parameter spaces. However, those works developed architectures tailored to specific networks such as MLPs and CNNs without normalization layers, and generalizing such architectures to other types of networks can be challenging. In this work, we overcome these challenges by building new metanetworks --- neural networks that take weights from other neural networks as input. Put simply, we carefully build graphs representing the input neural networks and process the graphs using graph neural networks. Our approach, Graph Metanetworks (GMNs), generalizes to neural architectures where competing methods struggle, such as multi-head attention layers, normalization layers, convolutional layers, ResNet blocks, and group-equivariant linear layers. We prove that GMNs are expressive and equivariant to parameter permutation symmetries that leave the input neural network functions unchanged. We validate the effectiveness of our method on several metanetwork tasks over diverse neural network architectures.",
        "_bibtex": "@inproceedings{\nlim2024graph,\ntitle={Graph Metanetworks for Processing Diverse Neural Architectures},\nauthor={Derek Lim and Haggai Maron and Marc T. Law and Jonathan Lorraine and James Lucas},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ijK5hyxs0n}\n}"
    },
    {
        "title": "Dropout Enhanced Bilevel Training",
        "authorids": [
            "~Peiran_Yu1",
            "~Junyi_Li1",
            "~Heng_Huang1"
        ],
        "keywords": [
            "Bilevel Optimization",
            "Overfitting"
        ],
        "abstract": "Bilevel optimization problems appear in many widely used machine learning tasks. Bilevel optimization models are sensitive to small changes, and bilevel training tasks typically involve limited datasets. Therefore, overfitting is a common challenge in bilevel training tasks. This paper considers the use of dropout to address this problem. We propose a bilevel optimization model that depends on the distribution of dropout masks. We investigate how the dropout rate affects the hypergradient of this model. We propose a dropout bilevel method to solve the dropout bilevel optimization model. Subsequently, we analyze the resulting dropout bilevel method from an optimization perspective. Analyzing the optimization properties of methods with dropout is essential because it provides convergence guarantees for methods using dropout. However, there has been limited investigation in this research direction. We provide the complexity of the resulting dropout bilevel method in terms of reaching an $\\epsilon$ stationary point of the proposed stochastic bilevel model. Empirically, we demonstrate that overfitting occurs in data cleaning problems, and the method proposed in this work mitigates this issue.",
        "_bibtex": "@inproceedings{\nyu2024dropout,\ntitle={Dropout Enhanced Bilevel Training},\nauthor={Peiran Yu and Junyi Li and Heng Huang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=06lrITXVAx}\n}"
    },
    {
        "title": "Privacy Amplification for Matrix Mechanisms",
        "authorids": [
            "~Christopher_A._Choquette-Choo1",
            "~Arun_Ganesh1",
            "~Thomas_Steinke2",
            "~Abhradeep_Guha_Thakurta1"
        ],
        "keywords": [
            "differential privacy",
            "privacy amplification",
            "matrix mechanism"
        ],
        "abstract": "Privacy amplification exploits randomness in data selection to provide tighter differential privacy (DP) guarantees. This analysis is key to DP-SGD's success in machine learning (ML), but, is not readily applicable to the newer state-of-the-art (SOTA) algorithms. This is because these algorithms, known as DP-FTRL, use the matrix mechanism to add correlated noise instead of independent noise as in DP-SGD.\n\nIn this paper, we propose \"MMCC'' (matrix mechanism conditional composition), the first algorithm to analyze privacy amplification via sampling for any generic matrix mechanism. MMCC is nearly tight in that it approaches a lower bound as $\\epsilon\\to0$. \nTo analyze correlated outputs in MMCC, we prove that they can be analyzed as if they were independent, by conditioning them on prior outputs. Our \"conditional composition theorem'' has broad utility: we use it to show that the noise added to binary-tree-DP-FTRL can asymptotically match the noise added to DP-SGD with amplification. Our algorithm also has practical empirical utility. We show that amplification leads to significant improvement in the privacy/utility trade-offs for DP-FTRL style algorithms for standard benchmark tasks.",
        "_bibtex": "@inproceedings{\nchoquette-choo2024privacy,\ntitle={Privacy Amplification for Matrix Mechanisms},\nauthor={Christopher A. Choquette-Choo and Arun Ganesh and Thomas Steinke and Abhradeep Guha Thakurta},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xUzWmFdglP}\n}"
    },
    {
        "title": "Bandits Meet Mechanism Design to Combat Clickbait in Online Recommendation",
        "authorids": [
            "~Thomas_Kleine_Buening1",
            "~Aadirupa_Saha1",
            "~Christos_Dimitrakakis1",
            "~Haifeng_Xu1"
        ],
        "keywords": [
            "bandits",
            "mechanism design",
            "incentive-aware learning",
            "nash equilibrium"
        ],
        "abstract": "We study a strategic variant of the multi-armed bandit problem, which we coin the strategic click-bandit. This model is motivated by applications in online recommendation where the choice of recommended items depends on both the click-through rates and the post-click rewards. Like in classical bandits, rewards follow a fixed unknown distribution. However, we assume that the click-rate of each arm is chosen  strategically by the arm (e.g., a host on Airbnb)  in order to maximize  the number of times it gets clicked. The algorithm designer does not know the post-click rewards nor the arms' actions (i.e., strategically chosen click-rates) in advance, and must learn both values over time. To solve this problem, we design an incentive-aware learning algorithm, UCB-S, which achieves two goals simultaneously: (a) incentivizing desirable arm behavior under uncertainty; (b) minimizing regret by learning unknown parameters.  We approximately characterize all Nash equilibria of the arms under UCB-S and show a $\\tilde{\\mathcal{O}} (\\sqrt{KT})$ regret bound uniformly in every equilibrium. We also show that incentive-unaware algorithms generally fail to achieve low regret in the strategic click-bandit. Finally, we support our theoretical results by simulations of strategic arm behavior which confirm the effectiveness and robustness of our proposed incentive design.",
        "_bibtex": "@inproceedings{\nbuening2024bandits,\ntitle={Bandits Meet Mechanism Design to Combat Clickbait in Online Recommendation},\nauthor={Thomas Kleine Buening and Aadirupa Saha and Christos Dimitrakakis and Haifeng Xu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=lsxeNvYqCj}\n}"
    },
    {
        "title": "Towards Principled Representation Learning from Videos for Reinforcement Learning",
        "authorids": [
            "~Dipendra_Misra1",
            "~Akanksha_Saran1",
            "~Tengyang_Xie1",
            "~Alex_Lamb1",
            "~John_Langford1"
        ],
        "keywords": [
            "Reinforcement Learning",
            "Representation Learning"
        ],
        "abstract": "We study pre-training representations for decision-making using video data, which is abundantly available for tasks such as game agents and software testing. Even though significant empirical advances have been made on this problem, a theoretical understanding remains absent. We initiate the theoretical investigation into principled approaches for representation learning and focus on learning the latent state representations of the underlying MDP using video data. We study two types of settings: one where there is iid noise in the observation, and a more challenging setting where there is also the presence of exogenous noise, which is non-iid noise that is temporally correlated, such as the motion of people or cars in the background. We study three commonly used approaches: autoencoding, temporal contrastive learning, and forward modeling. We prove upper bounds for temporal contrastive learning and forward modeling in the presence of only iid noise. We show that these approaches can learn the latent state and use it to do efficient downstream RL with polynomial sample complexity. When exogenous noise is also present, we establish a lower bound result showing that the sample complexity of learning from video data can be exponentially worse than learning from action-labeled trajectory data. This partially explains why reinforcement learning with video pre-training is hard. We evaluate these representational learning methods in two visual domains, yielding results that are consistent with our theoretical findings.",
        "_bibtex": "@inproceedings{\nmisra2024towards,\ntitle={Towards Principled Representation Learning from Videos for Reinforcement Learning},\nauthor={Dipendra Misra and Akanksha Saran and Tengyang Xie and Alex Lamb and John Langford},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3mnWvUZIXt}\n}"
    },
    {
        "title": "Optimal Sample Complexity of Contrastive Learning",
        "authorids": [
            "~Noga_Alon1",
            "~Dmitrii_Avdiukhin1",
            "~Dor_Elboim1",
            "~Orr_Fischer1",
            "~Grigory_Yaroslavtsev1"
        ],
        "keywords": [
            "learning theory",
            "sample complexity",
            "vc dimension",
            "contrastive learning",
            "metric learning"
        ],
        "abstract": "Contrastive learning is a highly successful technique for learning representations of data from labeled tuples, specifying the distance relations within the tuple. We study the sample complexity of contrastive learning, i.e. the minimum number of labeled tuples sufficient for getting high generalization accuracy. We give tight bounds on the sample complexity in a variety of settings, focusing on arbitrary distance functions,  $\\ell_p$-distances, and tree metrics. Our main result is an (almost) optimal bound on the sample complexity of learning $\\ell_p$-distances for integer $p$. For any $p \\ge 1$, we show that $\\tilde \\Theta(nd)$ labeled tuples are necessary and sufficient for learning $d$-dimensional representations of $n$-point datasets. Our results hold for an arbitrary distribution of the input samples and are based on giving the corresponding bounds on the Vapnik-Chervonenkis/Natarajan dimension of the associated problems. We further show that the theoretical bounds on sample complexity obtained via VC/Natarajan dimension can have strong predictive power for experimental results, in contrast with the folklore belief about a substantial gap between the statistical learning theory and the practice of deep learning.",
        "_bibtex": "@inproceedings{\nalon2024optimal,\ntitle={Optimal Sample Complexity of Contrastive Learning},\nauthor={Noga Alon and Dmitrii Avdiukhin and Dor Elboim and Orr Fischer and Grigory Yaroslavtsev},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=NU9AYHJvYe}\n}"
    },
    {
        "title": "Post-hoc bias scoring is optimal for fair classification",
        "authorids": [
            "~Wenlong_Chen1",
            "~Yegor_Klochkov2",
            "~Yang_Liu3"
        ],
        "keywords": [
            "group fairness",
            "post-hoc fair classification",
            "Bayes optimal classifier",
            "accuracy-fairness trade-off"
        ],
        "abstract": "We consider a binary classification problem under group fairness constraints, which can be one of Demographic Parity (DP), Equalized Opportunity (EOp), or Equalized Odds (EO). We propose an explicit characterization of Bayes optimal classifier under the fairness constraints, which turns out to be a simple modification rule of the unconstrained classifier. Namely, we introduce a novel instance-level measure of bias, which we call bias score, and the modification rule is a simple linear rule on top of the finite amount of bias scores. Based on this characterization, we develop a post-hoc approach that allows us to adapt to fairness constraints while maintaining high accuracy. In the case of DP and EOp constraints, the modification rule is thresholding a single bias score, while in the case of EO constraints we are required to fit a linear modification rule with 2 parameters. The method can also be applied for composite group-fairness criteria, such as ones involving several sensitive attributes. We achieve competitive or better performance compared to both in-processing and post-processing methods across three datasets: Adult, COMPAS, and CelebA. Unlike most post-processing methods, we do not require access to sensitive attributes during the inference time.",
        "_bibtex": "@inproceedings{\nchen2024posthoc,\ntitle={Post-hoc bias scoring is optimal for fair classification},\nauthor={Wenlong Chen and Yegor Klochkov and Yang Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=FM5xfcaR2Y}\n}"
    },
    {
        "title": "Sharpness-Aware Data Poisoning Attack",
        "authorids": [
            "~Pengfei_He2",
            "~Han_Xu1",
            "~Jie_Ren6",
            "~Yingqian_Cui1",
            "~Shenglai_Zeng2",
            "~Hui_Liu8",
            "~Charu_C._Aggarwal2",
            "~Jiliang_Tang1"
        ],
        "keywords": [
            "Data poisoning attack; generalization; deep learning"
        ],
        "abstract": "Recent research has highlighted the vulnerability of Deep Neural Networks (DNNs) against data poisoning attacks. These attacks aim to inject poisoning samples into the models' training dataset such that the trained models have inference failures. While previous studies have executed different types of attacks, one major challenge that greatly limits their effectiveness is the \nuncertainty of the re-training process after the injection of poisoning samples. It includes the uncertainty of training initialization, algorithm and model architecture. To address this challenge, we propose a new strategy called **Sharpness-Aware Data Poisoning Attack (SAPA)**. In particular, it leverages the concept of DNNs' loss landscape sharpness to optimize the poisoning effect on the (approximately) worst re-trained model. Extensive experiments demonstrate that SAPA offers a general and principled strategy that significantly enhances various types of poisoning attacks against various types of re-training uncertainty.",
        "_bibtex": "@inproceedings{\nhe2024sharpnessaware,\ntitle={Sharpness-Aware Data Poisoning Attack},\nauthor={Pengfei He and Han Xu and Jie Ren and Yingqian Cui and Shenglai Zeng and Hui Liu and Charu C. Aggarwal and Jiliang Tang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=bxITGFPVWh}\n}"
    },
    {
        "title": "Pre-training with Random Orthogonal Projection Image Modeling",
        "authorids": [
            "~Maryam_Haghighat1",
            "~Peyman_Moghadam1",
            "~Shaheer_Mohamed1",
            "~Piotr_Koniusz1"
        ],
        "keywords": [
            "Random Projection",
            "Self-supervised Learning",
            "Image Modelling",
            "Representation Learning",
            "Vision Transformer"
        ],
        "abstract": "Masked Image Modeling (MIM) is a powerful self-supervised strategy for visual pre-training without the use of labels. MIM applies random crops to input images, processes them with an encoder, and then recovers the masked inputs with a decoder, which encourages the network to capture and learn structural information about objects and scenes. The intermediate feature representations obtained from MIM are suitable for fine-tuning on downstream tasks. In this paper, we propose an Image Modeling framework based on random orthogonal projection instead of binary masking as in MIM. Our proposed Random Orthogonal Projection Image Modeling (ROPIM) reduces spatially-wise token information under guaranteed bound on the noise variance and can be considered as masking entire spatial image area under locally varying masking degrees. Since ROPIM uses a random subspace for the projection that realizes the masking step, the readily available complement of the subspace can be used during unmasking to promote recovery of removed information. In this paper, we show that using random orthogonal projection leads to superior performance compared to crop-based masking. We demonstrate state-of-the-art results on several popular benchmarks.",
        "_bibtex": "@inproceedings{\nhaghighat2024pretraining,\ntitle={Pre-training with Random Orthogonal Projection Image Modeling},\nauthor={Maryam Haghighat and Peyman Moghadam and Shaheer Mohamed and Piotr Koniusz},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=z4Hcegjzph}\n}"
    },
    {
        "title": "Lagrangian Flow Networks for Conservation Laws",
        "authorids": [
            "~Fabricio_Arend_Torres1",
            "~Marcello_Massimo_Negri1",
            "~Marco_Inversi1",
            "~Jonathan_Aellen1",
            "~Volker_Roth1"
        ],
        "keywords": [
            "Physics-informed Neural Network",
            "Fluid Dynamics",
            "Conservation Law",
            "Partial Differential Equation",
            "Conditional Normalizing Flows",
            "Bird-Migration"
        ],
        "abstract": "We introduce Lagrangian Flow Networks (LFlows) for modeling fluid densities and velocities continuously in space and time.\nBy construction, the proposed LFlows satisfy the continuity equation,\na PDE describing mass conservation in its differential form. \nOur model is based on the insight that solutions to the continuity equation can be expressed as\ntime-dependent density transformations via differentiable and invertible maps.\nThis follows from classical theory of the existence and uniqueness of Lagrangian flows for smooth vector fields.\nHence, we model fluid densities by transforming a base density with parameterized diffeomorphisms conditioned on time.\nThe key benefit compared to methods relying on numerical ODE solvers or PINNs is that the analytic expression of the velocity is always consistent with changes in density.\nFurthermore, we require neither expensive numerical solvers, nor additional penalties to enforce the PDE.\nLFlows show higher predictive accuracy in density modeling tasks compared to competing models in 2D and 3D,\nwhile being computationally efficient.\nAs a real-world application, we model bird migration based on sparse weather radar measurements.",
        "_bibtex": "@inproceedings{\ntorres2024lagrangian,\ntitle={Lagrangian Flow Networks for Conservation Laws},\nauthor={Fabricio Arend Torres and Marcello Massimo Negri and Marco Inversi and Jonathan Aellen and Volker Roth},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Nshk5YpdWE}\n}"
    },
    {
        "title": "Linearity of Relation Decoding in Transformer Language Models",
        "authorids": [
            "~Evan_Hernandez1",
            "~Arnab_Sen_Sharma1",
            "~Tal_Haklay1",
            "~Kevin_Meng1",
            "~Martin_Wattenberg1",
            "~Jacob_Andreas1",
            "~Yonatan_Belinkov1",
            "~David_Bau1"
        ],
        "keywords": [
            "Natural language processing",
            "interpretability",
            "language models"
        ],
        "abstract": "Much of the knowledge encoded in transformer language models (LMs) may be expressed in terms of relations: relations between words and their synonyms, entities and their attributes, etc. We show that, for a subset of relations, this computation is well-approximated by a single linear transformation on the subject representation. Linear relation representations may be obtained by constructing a first-order approximation to the LM from a single prompt, and they exist for a variety of factual, commonsense, and linguistic relations. However, we also identify many cases in which LM predictions capture relational knowledge accurately, but this knowledge is not linearly encoded in their representations. Our results thus reveal a simple, interpretable, but heterogeneously deployed knowledge representation strategy in transformer LMs.",
        "_bibtex": "@inproceedings{\nhernandez2024linearity,\ntitle={Linearity of Relation Decoding in Transformer Language Models},\nauthor={Evan Hernandez and Arnab Sen Sharma and Tal Haklay and Kevin Meng and Martin Wattenberg and Jacob Andreas and Yonatan Belinkov and David Bau},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=w7LU2s14kE}\n}"
    },
    {
        "title": "Subtractive Mixture Models via Squaring: Representation and Learning",
        "authorids": [
            "~Lorenzo_Loconte1",
            "~Aleksanteri_Mikulus_Sladek1",
            "~Stefan_Mengel1",
            "~Martin_Trapp2",
            "~Arno_Solin1",
            "~Nicolas_Gillis1",
            "~Antonio_Vergari3"
        ],
        "keywords": [
            "tractable inference",
            "distribution estimation",
            "probabilistic circuits",
            "tensor networks"
        ],
        "abstract": "Mixture models are traditionally represented and learned by adding several distributions as components. Allowing mixtures to subtract probability mass or density can drastically reduce the number of components needed to model complex distributions. However, learning such subtractive mixtures while ensuring they still encode a non-negative function is challenging. We investigate how to learn and perform inference on deep subtractive mixtures by squaring them. We do this in the framework of probabilistic circuits, which enable us to represent tensorized mixtures and generalize several other subtractive models. We theoretically prove that the class of squared circuits allowing subtractions can be exponentially more expressive than traditional additive mixtures; and, we empirically show this increased expressiveness on a series of real-world distribution estimation tasks.",
        "_bibtex": "@inproceedings{\nloconte2024subtractive,\ntitle={Subtractive Mixture Models via Squaring: Representation and Learning},\nauthor={Lorenzo Loconte and Aleksanteri Mikulus Sladek and Stefan Mengel and Martin Trapp and Arno Solin and Nicolas Gillis and Antonio Vergari},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xIHi5nxu9P}\n}"
    },
    {
        "title": "On the Provable Advantage of Unsupervised Pretraining",
        "authorids": [
            "~Jiawei_Ge3",
            "~Shange_Tang1",
            "~Jianqing_Fan1",
            "~Chi_Jin1"
        ],
        "keywords": [
            "unsupervised pretraining; representation learning; sample complexity"
        ],
        "abstract": "Unsupervised pretraining, which learns a useful representation using a large amount of unlabeled data to facilitate the learning of downstream tasks, is a critical component of modern large-scale machine learning systems. Despite its tremendous empirical success, the rigorous theoretical understanding of why unsupervised pretraining generally helps remains rather limited---most existing results are restricted to particular methods or approaches for unsupervised pretraining with specialized structural assumptions. This paper studies a generic framework,\nwhere the unsupervised representation learning task is specified by an abstract class of latent variable models $\\Phi$ and the downstream task is specified by a class of prediction functions $\\Psi$. We consider a natural approach of using Maximum Likelihood Estimation (MLE) for unsupervised pretraining and Empirical Risk Minimization (ERM) for learning downstream tasks. We prove that, under a mild ``informative'' condition, our algorithm achieves an excess risk of $\\\\tilde{\\\\mathcal{O}}(\\sqrt{\\mathcal{C}\\_\\Phi/m} + \\sqrt{\\mathcal{C}\\_\\Psi/n})$ for downstream tasks, where $\\mathcal{C}\\_\\Phi, \\mathcal{C}\\_\\Psi$ are complexity measures of function classes $\\Phi, \\Psi$, and $m, n$ are the number of unlabeled and labeled data respectively. Comparing to the baseline of $\\tilde{\\mathcal{O}}(\\sqrt{\\mathcal{C}\\_{\\Phi \\circ \\Psi}/n})$ achieved by performing supervised learning using only the labeled data, our result rigorously shows the benefit of unsupervised pretraining when $m \\gg n$ and $\\mathcal{C}\\_{\\Phi\\circ \\Psi} > \\mathcal{C}\\_\\Psi$. This paper further shows that our generic framework covers a wide range of approaches for unsupervised pretraining, including factor models, Gaussian mixture models, and contrastive learning.",
        "_bibtex": "@inproceedings{\nge2024on,\ntitle={On the Provable Advantage of Unsupervised Pretraining},\nauthor={Jiawei Ge and Shange Tang and Jianqing Fan and Chi Jin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rmXXKxQpOR}\n}"
    },
    {
        "title": "TorchRL: A data-driven decision-making library for PyTorch",
        "authorids": [
            "~Albert_Bou1",
            "~Matteo_Bettini1",
            "~Sebastian_Dittert1",
            "~Vikash_Kumar2",
            "~Shagun_Sodhani1",
            "~Xiaomeng_Yang1",
            "~Gianni_De_Fabritiis1",
            "~Vincent_Moens3"
        ],
        "keywords": [
            "Reinforcement Learning",
            "pytorch",
            "control",
            "robotics"
        ],
        "abstract": "PyTorch has ascended as a premier machine learning framework, yet it lacks a native and comprehensive library for decision and control tasks suitable for large development teams dealing with complex real-world data and environments. To address this issue, we propose TorchRL, a generalistic control library for PyTorch that provides well-integrated, yet standalone components. We introduce a new and flexible PyTorch primitive, the TensorDict, which facilitates streamlined algorithm development across the many branches of Reinforcement Learning (RL) and control. We provide a detailed description of the building blocks and an extensive overview of the library across domains and tasks. Finally, we experimentally demonstrate its reliability and flexibility, and show comparative benchmarks to demonstrate its computational efficiency. TorchRL fosters long-term support and is publicly available on GitHub for greater reproducibility and collaboration within the research community. The code is open-sourced on GitHub.",
        "_bibtex": "@inproceedings{\nbou2024torchrl,\ntitle={Torch{RL}: A data-driven decision-making library for PyTorch},\nauthor={Albert Bou and Matteo Bettini and Sebastian Dittert and Vikash Kumar and Shagun Sodhani and Xiaomeng Yang and Gianni De Fabritiis and Vincent Moens},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=QxItoEAVMb}\n}"
    },
    {
        "title": "Towards Robust Offline Reinforcement Learning under Diverse Data Corruption",
        "authorids": [
            "~Rui_Yang8",
            "~Han_Zhong1",
            "~Jiawei_Xu1",
            "~Amy_Zhang1",
            "~Chongjie_Zhang1",
            "~Lei_Han1",
            "~Tong_Zhang2"
        ],
        "keywords": [
            "Offline RL",
            "robust RL",
            "data corruption",
            "training-time attack"
        ],
        "abstract": "Offline reinforcement learning (RL) presents a promising approach for learning reinforced policies from offline datasets without the need for costly or unsafe interactions with the environment. However, datasets collected by humans in real-world environments are often noisy and may even be maliciously corrupted, which can significantly degrade the performance of offline RL. In this work, we first investigate the performance of current offline RL algorithms under comprehensive data corruption, including states, actions, rewards, and dynamics. Our extensive experiments reveal that implicit Q-learning (IQL) demonstrates remarkable resilience to data corruption among various offline RL algorithms. Furthermore, we conduct both empirical and theoretical analyses to understand IQL's robust performance, identifying its supervised policy learning scheme as the key factor. Despite its relative robustness, IQL still suffers from heavy-tail targets of Q functions under dynamics corruption. To tackle this challenge, we draw inspiration from robust statistics to employ the Huber loss to handle the heavy-tailedness and utilize quantile estimators to balance penalization for corrupted data and learning stability. By incorporating these simple yet effective modifications into IQL, we propose a more robust offline RL approach named Robust IQL (RIQL). Extensive experiments demonstrate that RIQL exhibits highly robust performance when subjected to diverse data corruption scenarios.",
        "_bibtex": "@inproceedings{\nyang2024towards,\ntitle={Towards Robust Offline Reinforcement Learning under Diverse Data Corruption},\nauthor={Rui Yang and Han Zhong and Jiawei Xu and Amy Zhang and Chongjie Zhang and Lei Han and Tong Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5hAMmCU0bK}\n}"
    },
    {
        "title": "Variational Bayesian Last Layers",
        "authorids": [
            "~James_Harrison1",
            "~John_Willes2",
            "~Jasper_Snoek1"
        ],
        "keywords": [
            "bayesian deep learning",
            "variational methods",
            "bayesian last layers",
            "neural linear models"
        ],
        "abstract": "We introduce a deterministic variational formulation for training Bayesian last layer neural networks. This yields a sampling-free, single-pass model and loss that effectively improves uncertainty estimation. Our variational Bayesian last layer (VBLL) can be trained and evaluated with only quadratic complexity in last layer width, and is thus (nearly) computationally free to add to standard architectures. We experimentally investigate VBLLs, and show that they improve predictive accuracy, calibration, and out of distribution detection over baselines across both regression and classification. Finally, we investigate combining VBLL layers with variational Bayesian feature learning, yielding a lower variance collapsed variational inference method for Bayesian neural networks.",
        "_bibtex": "@inproceedings{\nharrison2024variational,\ntitle={Variational Bayesian Last Layers},\nauthor={James Harrison and John Willes and Jasper Snoek},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Sx7BIiPzys}\n}"
    },
    {
        "title": "EQA-MX: Embodied Question Answering using Multimodal Expression",
        "authorids": [
            "~Md_Mofijul_Islam1",
            "~Alexi_Gladstone1",
            "~Riashat_Islam1",
            "~Tariq_Iqbal1"
        ],
        "keywords": [
            "multimodal representation learning",
            "visual-language models",
            "embodied question answering"
        ],
        "abstract": "Humans predominantly use verbal utterances and nonverbal gestures (e.g., eye gaze and pointing gestures) in their natural interactions. For instance, pointing gestures and verbal information is often required to comprehend questions such as \"what object is that?\" Thus, this question-answering (QA) task involves complex reasoning of multimodal expressions (verbal utterances and nonverbal gestures). However, prior works have explored QA tasks in non-embodied settings, where questions solely contain verbal utterances from a single verbal and visual perspective. In this paper, we have introduced 8 novel embodied question answering (EQA) tasks to develop learning models to comprehend embodied questions with multimodal expressions. We have developed a novel large-scale dataset, EQA-MX, with over 8 million diverse embodied QA data samples involving multimodal expressions from multiple visual and verbal perspectives. To learn salient multimodal representations from discrete verbal embeddings and continuous wrapping of multiview visual representations, we propose a vector-quantization (VQ) based multimodal representation learning model, VQ-Fusion, for the EQA tasks. Our extensive experimental results suggest that VQ-Fusion can improve the performance of existing state-of-the-art visual-language models up to 13% across EQA tasks.",
        "_bibtex": "@inproceedings{\nislam2024eqamx,\ntitle={{EQA}-{MX}: Embodied Question Answering using Multimodal Expression},\nauthor={Md Mofijul Islam and Alexi Gladstone and Riashat Islam and Tariq Iqbal},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=7gUrYE50Rb}\n}"
    },
    {
        "title": "Retrieval-based Disentangled Representation Learning with Natural Language Supervision",
        "authorids": [
            "~Jiawei_Zhou2",
            "~Xiaoguang_Li1",
            "~Lifeng_Shang1",
            "~Xin_Jiang1",
            "~Qun_Liu1",
            "~Lei_Chen7"
        ],
        "keywords": [
            "Disentangled representation learning",
            "information retriever",
            "sparse retriever"
        ],
        "abstract": "Disentangled representation learning remains challenging as the underlying factors of variation in the data do not naturally exist. The inherent complexity of real-world data makes it unfeasible to exhaustively enumerate and encapsulate all its variations within a finite set of factors. However, it is worth noting that most real-world data have linguistic equivalents, typically in the form of textual descriptions. These linguistic counterparts can represent the data and effortlessly decomposed into distinct tokens. In light of this, we present Vocabulary Disentangled Retrieval (VDR), a retrieval-based framework that harnesses natural language as proxies of the underlying data variation to drive disentangled representation learning. Our approach employ a bi-encoder model to represent both data and natural language in a vocabulary space, enabling the model to distinguish dimensions that capture intrinsic characteristics within data through its natural language counterpart, thus facilitating disentanglement. We extensively assess the performance of VDR across 15 retrieval benchmark datasets, covering text-to-text and cross-modal retrieval scenarios, as well as human evaluation. Our experimental results compellingly demonstrate the superiority of VDR over previous bi-encoder retrievers with comparable model size and training costs, achieving an impressive 8.7% improvement in NDCG@10 on the BEIR benchmark, a 5.3\\% increase on MS COCO, and a 6.0% increase on Flickr30k in terms of mean recall in the zero-shot setting. Moreover, The results from human evaluation indicate that interpretability of our method is on par with SOTA captioning models.",
        "_bibtex": "@inproceedings{\nzhou2024retrievalbased,\ntitle={Retrieval-based Disentangled Representation Learning with Natural Language Supervision},\nauthor={Jiawei Zhou and Xiaoguang Li and Lifeng Shang and Xin Jiang and Qun Liu and Lei Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ZlQRiFmq7Y}\n}"
    },
    {
        "title": "On the Markov Property of Neural Algorithmic Reasoning: Analyses and Methods",
        "authorids": [
            "~Montgomery_Bohde1",
            "~Meng_Liu3",
            "~Alexandra_Saxton1",
            "~Shuiwang_Ji1"
        ],
        "keywords": [
            "Neural Algorithmic Reasoning"
        ],
        "abstract": "Neural algorithmic reasoning is an emerging research direction that endows neural networks with the ability to mimic algorithmic executions step-by-step. A common paradigm in existing designs involves the use of historical embeddings in predicting the results of future execution steps. Our observation in this work is that such historical dependence intrinsically contradicts the Markov nature of algorithmic reasoning tasks. Based on this motivation, we present our ForgetNet, which does not use historical embeddings and thus is consistent with the Markov nature of the tasks. To address challenges in training ForgetNet at early stages, we further introduce G-ForgetNet, which uses a gating mechanism to allow for the selective integration of historical embeddings. Such an enhanced capability provides valuable computational pathways during the model's early training phase. Our extensive experiments, based on the CLRS-30 algorithmic reasoning benchmark, demonstrate that both ForgetNet and G-ForgetNet achieve better generalization capability than existing methods. Furthermore, we investigate the behavior of the gating mechanism, highlighting its degree of alignment with our intuitions and its effectiveness for robust performance. Our code is publicly available at https://github.com/divelab/ForgetNet.",
        "_bibtex": "@inproceedings{\nbohde2024on,\ntitle={On the Markov Property of Neural Algorithmic Reasoning: Analyses and Methods},\nauthor={Montgomery Bohde and Meng Liu and Alexandra Saxton and Shuiwang Ji},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Kn7tWhuetn}\n}"
    },
    {
        "title": "TRAM: Bridging Trust Regions and Sharpness Aware Minimization",
        "authorids": [
            "~Tom_Sherborne2",
            "~Naomi_Saphra1",
            "~Pradeep_Dasigi1",
            "~Hao_Peng4"
        ],
        "keywords": [
            "sharpness-aware minimization",
            "sam",
            "trust region",
            "optimization",
            "cross-lingual transfer",
            "language modeling"
        ],
        "abstract": "Sharpness-aware minimization (SAM) reports improving domain generalization by\nreducing the loss surface curvature in the parameter space. However,\ngeneralization during _fine-tuning_ is often more dependent on the\ntransferability of _representations_ in the function space. Trust-region\nmethods (TR) target this goal by regularizing representation curvature to reduce\ncatastrophic forgetting of pre-trained task-agnostic information while adopting\ntask-specific skills. We consider unifying these strategies for low curvature in\nboth parameter space and function space to improve out-of-domain (OOD)\ngeneralization. We propose **Trust Region Aware Minimization** (TRAM), a\nSAM algorithm fine-tuning for low parameter sharpness and smooth, informative\nrepresentations preserving pre-trained structure. TRAM uses a trust region bound\nto inform the SAM adversarial neighborhood, introducing an awareness of function\ncurvature within optimization for flatter minima. We empirically validate TRAM\nin vision (cross-dataset adaptation) and text (OOD language modeling, zero-shot\ncross-lingual transfer) tasks where robust domain transfer and representation\ngenerality are critical. TRAM outperforms SAM- and TR-based optimization across\nall tasks, notably surpassing competing methods for hard transfer between\n_anticorrelated_ domains. TRAM establishes a novel standard in\nfine-tuning for domain-generalizable models with minimal additional computation\nover previous sharpness-aware methods.",
        "_bibtex": "@inproceedings{\nsherborne2024tram,\ntitle={{TRAM}: Bridging Trust Regions and Sharpness Aware Minimization},\nauthor={Tom Sherborne and Naomi Saphra and Pradeep Dasigi and Hao Peng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=kxebDHZ7b7}\n}"
    },
    {
        "title": "CAMIL: Context-Aware Multiple Instance Learning for Cancer Detection and Subtyping in Whole Slide Images",
        "authorids": [
            "~Olga_Fourkioti2",
            "~Matt_De_Vries1",
            "~Chris_Bakal1"
        ],
        "keywords": [
            "Multiple Instance Learning",
            "Histopathology",
            "Nearest Neighbors",
            "Graph Representation"
        ],
        "abstract": "The visual examination of tissue biopsy sections is fundamental for cancer diagnosis, with pathologists analyzing sections at multiple magnifications to discern tumor cells and their subtypes. However, existing attention-based multiple instance learning (MIL) models used for analyzing Whole Slide Images (WSIs) in cancer diagnostics often overlook the contextual information of tumor and neighboring tiles, leading to misclassifications. To address this, we propose the Context-Aware Multiple Instance Learning (CAMIL) architecture. CAMIL incorporates neighbor-constrained attention to consider dependencies among tiles within a WSI and integrates contextual constraints as prior knowledge into the MIL model. We evaluated CAMIL on subtyping non-small cell lung cancer (TCGA-NSCLC) and detecting lymph node (CAMELYON16 and CAMELYON17) metastasis, achieving test AUCs of 97.5\\%, 95.9\\%, and 88.1\\%, respectively, outperforming other state-of-the-art methods. Additionally, CAMIL enhances model interpretability by identifying regions of high diagnostic value. Our code is available at https://github.com/olgarithmics/ICLR_CAMIL.",
        "_bibtex": "@inproceedings{\nfourkioti2024camil,\ntitle={{CAMIL}: Context-Aware Multiple Instance Learning for Cancer Detection and Subtyping in Whole Slide Images},\nauthor={Olga Fourkioti and Matt De Vries and Chris Bakal},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rzBskAEmoc}\n}"
    },
    {
        "title": "DyST: Towards Dynamic Neural Scene Representations on Real-World Videos",
        "authorids": [
            "~Maximilian_Seitzer1",
            "~Sjoerd_van_Steenkiste1",
            "~Thomas_Kipf2",
            "~Klaus_Greff1",
            "~Mehdi_S._M._Sajjadi1"
        ],
        "keywords": [
            "neural scene representations",
            "scene representations",
            "representation learning",
            "novel view synthesis"
        ],
        "abstract": "Visual understanding of the world goes beyond the semantics and flat structure of individual images. In this work, we aim to capture both the 3D structure and dynamics of real-world scenes from monocular real-world videos. Our Dynamic Scene Transformer (DyST) model leverages recent work in neural scene representation to learn a latent decomposition of monocular real-world videos into scene content, per-view scene dynamics, and camera pose. This separation is achieved through a novel co-training scheme on monocular videos and our new synthetic dataset DySO. DyST learns tangible latent representations for dynamic scenes that enable view generation with separate control over the camera and the content of the scene.",
        "_bibtex": "@inproceedings{\nseitzer2024dyst,\ntitle={Dy{ST}: Towards Dynamic Neural Scene Representations on Real-World Videos},\nauthor={Maximilian Seitzer and Sjoerd van Steenkiste and Thomas Kipf and Klaus Greff and Mehdi S. M. Sajjadi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MnMWa94t12}\n}"
    },
    {
        "title": "Bilevel Optimization under Unbounded Smoothness: A New Algorithm and Convergence Analysis",
        "authorids": [
            "~Jie_Hao3",
            "~Xiaochuan_Gong1",
            "~Mingrui_Liu2"
        ],
        "keywords": [
            "Bilevel Optimization",
            "Unbounded Smoothness",
            "Deep Learning"
        ],
        "abstract": "Bilevel optimization is an important formulation for many machine learning problems, such as meta-learning and hyperparameter optimization. Current bilevel optimization algorithms assume that the gradient of the upper-level function is Lipschitz (i.e., the upper-level function has a bounded smoothness parameter). However, recent studies reveal that certain neural networks such as recurrent neural networks (RNNs) and long-short-term memory networks (LSTMs) exhibit potential unbounded smoothness, rendering conventional bilevel optimization algorithms unsuitable for these neural networks. In this paper, we design a new bilevel optimization algorithm, namely BO-REP, to address this challenge. This algorithm updates the upper-level variable using normalized momentum and incorporates two novel techniques for updating the lower-level variable: \\textit{initialization refinement} and \\textit{periodic updates}. Specifically, once the upper-level variable is initialized, a subroutine is invoked to obtain a refined estimate of the corresponding optimal lower-level variable, and the lower-level variable is updated only after every specific period instead of each iteration. When the upper-level problem is nonconvex and unbounded smooth, and the lower-level problem is strongly convex, we prove that our algorithm requires $\\widetilde{O}(1/\\epsilon^4)$ \\footnote{Here $\\widetilde{O}(\\cdot)$ compresses logarithmic factors of $1/\\epsilon$ and $1/\\delta$, where $\\delta\\in(0,1)$ denotes the failure probability.} iterations to find an $\\epsilon$-stationary point in the stochastic setting, where each iteration involves calling a stochastic gradient or Hessian-vector product oracle. Notably, this result matches the state-of-the-art complexity results under the bounded smoothness setting and without mean-squared smoothness of the stochastic gradient, up to logarithmic factors. Our proof relies on novel technical lemmas for the periodically updated lower-level variable, which are of independent interest. Our experiments on hyper-representation learning, hyperparameter optimization, and data hyper-cleaning for text classification tasks demonstrate the effectiveness of our proposed algorithm. The code is available at [https://github.com/MingruiLiu-ML-Lab/Bilevel-Optimization-under-Unbounded-Smoothness](https://github.com/MingruiLiu-ML-Lab/Bilevel-Optimization-under-Unbounded-Smoothness).",
        "_bibtex": "@inproceedings{\nhao2024bilevel,\ntitle={Bilevel Optimization under Unbounded Smoothness: A New Algorithm and Convergence Analysis},\nauthor={Jie Hao and Xiaochuan Gong and Mingrui Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=LqRGsGWOTX}\n}"
    },
    {
        "title": "Bounds on Representation-Induced Confounding Bias for Treatment Effect Estimation",
        "authorids": [
            "~Valentyn_Melnychuk1",
            "~Dennis_Frauen1",
            "~Stefan_Feuerriegel1"
        ],
        "keywords": [
            "causal inference",
            "representation learning",
            "individualized treatment effect estimation"
        ],
        "abstract": "State-of-the-art methods for conditional average treatment effect (CATE) estimation make widespread use of representation learning. Here, the idea is to reduce the variance of the low-sample CATE estimation by a (potentially constrained) low-dimensional representation. However, low-dimensional representations can lose information about the observed confounders and thus lead to bias, because of which the validity of representation learning for CATE estimation is typically violated. In this paper, we propose a new, representation-agnostic refutation framework for estimating bounds on the representation-induced confounding bias that comes from dimensionality reduction (or other constraints on the representations) in CATE estimation. First, we establish theoretically under which conditions CATE is non-identifiable given low-dimensional (constrained) representations. Second, as our remedy, we propose a neural refutation framework which performs partial identification of CATE or, equivalently, aims at estimating lower and upper bounds of the representation-induced confounding bias. We demonstrate the effectiveness of our bounds in a series of experiments. In sum, our refutation framework is of direct relevance in practice where the validity of CATE estimation is of importance.",
        "_bibtex": "@inproceedings{\nmelnychuk2024bounds,\ntitle={Bounds on Representation-Induced Confounding Bias for Treatment Effect Estimation},\nauthor={Valentyn Melnychuk and Dennis Frauen and Stefan Feuerriegel},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=d3xKPQVjSc}\n}"
    },
    {
        "title": "DSPy: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines",
        "authorids": [
            "~Omar_Khattab1",
            "~Arnav_Singhvi1",
            "~Paridhi_Maheshwari1",
            "~Zhiyuan_Zhang4",
            "~Keshav_Santhanam1",
            "~Sri_Vardhamanan_A1",
            "~Saiful_Haq1",
            "~Ashutosh_Sharma1",
            "~Thomas_T._Joshi1",
            "~Hanna_Moazam1",
            "~Heather_Miller1",
            "~Matei_Zaharia1",
            "~Christopher_Potts1"
        ],
        "keywords": [
            "programming models",
            "prompting techniques",
            "in-context learning",
            "few-shot learning",
            "chain of thought",
            "multi-hop reasoning",
            "language agents"
        ],
        "abstract": "The ML community is rapidly exploring techniques for prompting language models (LMs) and for stacking them into pipelines that solve complex tasks. Unfortunately, existing LM pipelines are typically implemented using hard-coded \u201cprompt templates\u201d, i.e. lengthy strings discovered via trial and error. Toward a more systematic approach for developing and optimizing LM pipelines, we introduce DSPy, a programming model that abstracts LM pipelines as text transformation graphs, or imperative computational graphs where LMs are invoked through declarative modules. DSPy modules are parameterized, meaning they can learn how to apply compositions of prompting, finetuning, augmentation, and reasoning techniques. We design a compiler that will optimize any DSPy pipeline to maximize a given metric, by creating and collecting demonstrations. We conduct two case studies, showing that succinct DSPy programs can express and optimize pipelines that reason about math word problems, tackle multi-hop retrieval, answer complex questions, and control agent loops. Within minutes of compiling, DSPy can automatically produce pipelines that outperform out-of-the-box few-shot prompting as well as expert-created demonstrations for GPT-3.5 and Llama2-13b-chat. On top of that, DSPy programs compiled for relatively small LMs like 770M parameter T5 and Llama2-13b-chat are competitive with many approaches that rely on large and proprietary LMs like GPT-3.5 and on expert-written prompt chains. DSPy is available at https://github.com/stanfordnlp/dspy",
        "_bibtex": "@inproceedings{\nkhattab2024dspy,\ntitle={{DSP}y: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines},\nauthor={Omar Khattab and Arnav Singhvi and Paridhi Maheshwari and Zhiyuan Zhang and Keshav Santhanam and Sri Vardhamanan A and Saiful Haq and Ashutosh Sharma and Thomas T. Joshi and Hanna Moazam and Heather Miller and Matei Zaharia and Christopher Potts},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=sY5N0zY5Od}\n}"
    },
    {
        "title": "Impact of Computation in Integral Reinforcement Learning for Continuous-Time Control",
        "authorids": [
            "~Wenhan_Cao1",
            "~Wei_Pan2"
        ],
        "keywords": [
            "Integral Reinforcement Learning",
            "Bayesian Quadrature",
            "Newton's Method"
        ],
        "abstract": "Integral reinforcement learning (IntRL) demands the precise computation of the utility function's integral at its policy evaluation (PEV) stage. This is achieved through quadrature rules, which are weighted sums of utility functions evaluated from state samples obtained in discrete time. Our research reveals a critical yet underexplored phenomenon: the choice of the computational method -- in this case, the quadrature rule -- can significantly impact control performance. This impact is traced back to the fact that computational errors introduced in the PEV stage can affect the policy iteration's convergence behavior, which in turn affects the learned controller. To elucidate how computation impacts control, we draw a parallel between IntRL's policy iteration and Newton's method applied to the Hamilton-Jacobi-Bellman equation. In this light, computational error in PEV manifests as an extra error term in each iteration of Newton's method, with its upper bound proportional to the computational error. Further, we demonstrate that when the utility function resides in a reproducing kernel Hilbert space (RKHS), the optimal quadrature is achievable by employing Bayesian quadrature with the RKHS-inducing kernel function. We prove that the local convergence rates for IntRL using the trapezoidal rule and Bayesian quadrature with a Mat\u00e9rn kernel to be $O(N^{-2})$ and $O(N^{-b})$, where $N$ is the number of evenly-spaced samples and $b$ is the Mat\u00e9rn kernel's smoothness parameter. These theoretical findings are finally validated by two canonical control tasks.",
        "_bibtex": "@inproceedings{\ncao2024impact,\ntitle={Impact of Computation in Integral Reinforcement Learning for Continuous-Time Control},\nauthor={Wenhan Cao and Wei Pan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xJEd8PkdNz}\n}"
    },
    {
        "title": "Masks, Signs, And Learning Rate Rewinding",
        "authorids": [
            "~Advait_Harshal_Gadhikar2",
            "~Rebekka_Burkholz1"
        ],
        "keywords": [
            "sparsity",
            "pruning",
            "lottery tickets",
            "learning rate rewinding",
            "iterative magnitude pruning"
        ],
        "abstract": "Learning Rate Rewinding (LRR) has been established as a strong variant of Iterative Magnitude Pruning (IMP) to find lottery tickets in deep overparameterized neural networks. While both iterative pruning schemes couple structure and parameter learning, understanding how LRR excels in both aspects can bring us closer to the design of more flexible deep learning algorithms that can optimize diverse sets of sparse architectures. To this end, we conduct experiments that disentangle the effect of mask learning and parameter optimization and how both benefit from overparameterization. The ability of LRR to flip parameter signs early and stay robust to sign perturbations seems to make it not only more effective in mask identification but also in optimizing  diverse sets of masks, including random ones. In support of this hypothesis, we prove in a simplified single hidden neuron setting that LRR succeeds in more cases than IMP, as it can escape initially problematic sign configurations.",
        "_bibtex": "@inproceedings{\ngadhikar2024masks,\ntitle={Masks, Signs, And Learning Rate Rewinding},\nauthor={Advait Harshal Gadhikar and Rebekka Burkholz},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=qODvxQ8TXW}\n}"
    },
    {
        "title": "Gradual Domain Adaptation via Gradient Flow",
        "authorids": [
            "~Zhan_Zhuang1",
            "~Yu_Zhang3",
            "~Ying_Wei1"
        ],
        "keywords": [
            "Domain adaptation",
            "gradual domain adaptation",
            "gradient flow"
        ],
        "abstract": "Domain shift degrades classification models on new data distributions. Conventional unsupervised domain adaptation (UDA) aims to learn features that bridge labeled source and unlabeled target domains. In contrast to feature learning, gradual domain adaptation (GDA) leverages extra continuous intermediate domains with pseudo-labels to boost the source classifier. However, real intermediate domains are sometimes unavailable or ineffective. In this paper, we propose $\\textbf{G}$radual Domain Adaptation via $\\textbf{G}$radient $\\textbf{F}$low (GGF) to generate intermediate domains with preserving labels, thereby enabling us a fine-tuning method for GDA. We employ the Wasserstein gradient flow in Kullback\u2013Leibler divergence to transport samples from the source to the target domain. To simulate the dynamics, we utilize the Langevin algorithm. Since the Langevin algorithm disregards label information and introduces diffusion noise, we introduce classifier-based and sample-based potentials to avoid label switching and dramatic deviations in the sampling process. For the proposed GGF model, we analyze its generalization bound. Experiments on several benchmark datasets demonstrate the superiority of the proposed GGF method compared to state-of-the-art baselines.",
        "_bibtex": "@inproceedings{\nzhuang2024gradual,\ntitle={Gradual Domain Adaptation via Gradient Flow},\nauthor={Zhan Zhuang and Yu Zhang and Ying Wei},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=iTTZFKrlGV}\n}"
    },
    {
        "title": "Maximum Entropy Heterogeneous-Agent Reinforcement Learning",
        "authorids": [
            "~Jiarong_Liu1",
            "~Yifan_Zhong2",
            "~Siyi_Hu1",
            "~Haobo_Fu2",
            "~QIANG_FU8",
            "~Xiaojun_Chang4",
            "~Yaodong_Yang1"
        ],
        "keywords": [
            "cooperative multi-agent reinforcement learning",
            "heterogeneous-agent soft actor-critic",
            "maximum entropy heterogeneous-agent mirror learning"
        ],
        "abstract": "*Multi-agent reinforcement learning* (MARL) has been shown effective for cooperative games in recent years. However, existing state-of-the-art methods face challenges related to sample complexity, training instability, and the risk of converging to a suboptimal Nash Equilibrium. In this paper, we propose a unified framework for learning \\emph{stochastic} policies to resolve these issues. We embed cooperative MARL problems into probabilistic graphical models, from which we derive the maximum entropy (MaxEnt) objective for MARL. Based on the MaxEnt framework, we propose *Heterogeneous-Agent Soft Actor-Critic* (HASAC) algorithm. Theoretically, we prove the monotonic improvement and convergence to *quantal response equilibrium* (QRE) properties of HASAC. Furthermore, we generalize a unified template for MaxEnt algorithmic design named *Maximum Entropy Heterogeneous-Agent Mirror Learning* (MEHAML), which provides any induced method with the same guarantees as HASAC. We evaluate HASAC on six benchmarks: Bi-DexHands, Multi-Agent MuJoCo, StarCraft Multi-Agent Challenge, Google Research Football, Multi-Agent Particle Environment, and Light Aircraft Game. Results show that HASAC consistently outperforms strong baselines, exhibiting better sample efficiency, robustness, and sufficient exploration.",
        "_bibtex": "@inproceedings{\nliu2024maximum,\ntitle={Maximum Entropy Heterogeneous-Agent Reinforcement Learning},\nauthor={Jiarong Liu and Yifan Zhong and Siyi Hu and Haobo Fu and QIANG FU and Xiaojun Chang and Yaodong Yang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tmqOhBC4a5}\n}"
    },
    {
        "title": "Hybrid Directional Graph Neural Network for Molecules",
        "authorids": [
            "~Junyi_An1",
            "~Chao_Qu3",
            "~Zhipeng_Zhou3",
            "~Fenglei_Cao1",
            "~Xu_Yinghui3",
            "~Yuan_Qi2",
            "~Furao_Shen1"
        ],
        "keywords": [
            "Graph Neural Networks; Equivariance; Molecular model"
        ],
        "abstract": "Equivariant message passing neural networks have emerged as the prevailing approach for predicting chemical properties of molecules due to their ability to leverage translation and rotation symmetries, resulting in a strong inductive bias. However, the equivariant operations in each layer can impose excessive constraints on the function form and network flexibility. To address these challenges, we introduce a novel network called the Hybrid Directional Graph Neural Network (HDGNN), which effectively combines strictly equivariant operations with learnable modules. We evaluate the performance of HDGNN on the QM9 dataset and the IS2RE dataset of OC20, demonstrating its state-of-the-art performance on several tasks and competitive performance on others. Our code is anonymously released on https://github.com/ajy112/HDGNN.",
        "_bibtex": "@inproceedings{\nan2024hybrid,\ntitle={Hybrid Directional Graph Neural Network for Molecules},\nauthor={Junyi An and Chao Qu and Zhipeng Zhou and Fenglei Cao and Xu Yinghui and Yuan Qi and Furao Shen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=BBD6KXIGJL}\n}"
    },
    {
        "title": "Unbiased Watermark for Large Language Models",
        "authorids": [
            "~Zhengmian_Hu1",
            "~Lichang_Chen2",
            "~Xidong_Wu1",
            "~Yihan_Wu1",
            "~Hongyang_Zhang1",
            "~Heng_Huang1"
        ],
        "keywords": [
            "watermark",
            "bias"
        ],
        "abstract": "The recent advancements in large language models (LLMs) have sparked a growing apprehension regarding the potential misuse. One approach to mitigating this risk is to incorporate watermarking techniques into LLMs, allowing for the tracking and attribution of model outputs. This study examines a crucial aspect of watermarking: how significantly watermarks impact the quality of model-generated outputs. Previous studies have suggested a trade-off between watermark strength and output quality. However, our research demonstrates that it is possible to integrate watermarks without affecting the output probability distribution with appropriate implementation. We refer to this type of watermark as an unbiased watermark. This has significant implications for the use of LLMs, as it becomes impossible for users to discern whether a service provider has incorporated watermarks or not. Furthermore, the presence of watermarks does not compromise the performance of the model in downstream tasks, ensuring that the overall utility of the language model is preserved. Our findings contribute to the ongoing discussion around responsible AI development, suggesting that unbiased watermarks can serve as an effective means of tracking and attributing model outputs without sacrificing output quality.",
        "_bibtex": "@inproceedings{\nhu2024unbiased,\ntitle={Unbiased Watermark for Large Language Models},\nauthor={Zhengmian Hu and Lichang Chen and Xidong Wu and Yihan Wu and Hongyang Zhang and Heng Huang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=uWVC5FVidc}\n}"
    },
    {
        "title": "Leveraging Low-Rank and Sparse Recurrent Connectivity for Robust Closed-Loop Control",
        "authorids": [
            "~Neehal_Tumma1",
            "~Mathias_Lechner1",
            "~Noel_Loo1",
            "~Ramin_Hasani1",
            "~Daniela_Rus1"
        ],
        "keywords": [
            "Low-rank",
            "sparsity",
            "closed-loop",
            "recurrent neural networks"
        ],
        "abstract": "Developing autonomous agents that can interact with changing environments is an open challenge in machine learning. Robustness is particularly important in these settings as agents are often fit offline on expert demonstrations but deployed online where they must generalize to the closed feedback loop within the environment. In this work, we explore the application of recurrent neural networks to tasks of this nature and understand how a parameterization of their recurrent connectivity influences robustness in closed-loop settings. Specifically, we represent the recurrent connectivity as a function of rank and sparsity and show both theoretically and empirically that modulating these two variables has desirable effects on network dynamics. The proposed low-rank, sparse connectivity induces an interpretable prior on the network that proves to be most amenable for a class of models known as closed-form continuous-time neural networks (CfCs). We find that CfCs with fewer parameters can outperform their full-rank, fully-connected counterparts in the online setting under distribution shift. This yields memory-efficient and robust agents while opening a new perspective on how we can modulate network dynamics through connectivity.",
        "_bibtex": "@inproceedings{\ntumma2024leveraging,\ntitle={Leveraging Low-Rank and Sparse Recurrent Connectivity for Robust Closed-Loop Control},\nauthor={Neehal Tumma and Mathias Lechner and Noel Loo and Ramin Hasani and Daniela Rus},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=EriR6Ec69a}\n}"
    },
    {
        "title": "CLIPSelf: Vision Transformer Distills Itself for Open-Vocabulary Dense Prediction",
        "authorids": [
            "~Size_Wu1",
            "~Wenwei_Zhang1",
            "~Lumin_Xu1",
            "~Sheng_Jin1",
            "~Xiangtai_Li1",
            "~Wentao_Liu1",
            "~Chen_Change_Loy2"
        ],
        "keywords": [
            "open-vocabulary object detection",
            "open-vocabulary image segmentation"
        ],
        "abstract": "Open-vocabulary dense prediction tasks including object detection and image segmentation have been advanced by the success of Contrastive Language-Image Pre-training (CLIP). CLIP models, particularly those incorporating vision transformers (ViTs), have exhibited remarkable generalization ability in zero-shot image classification. However, when transferring the vision-language alignment of CLIP from global image representation to local region representation for the open-vocabulary dense prediction tasks, CLIP ViTs suffer from the domain shift from full images to local image regions. In this paper, we embark on an in-depth analysis of the region-language alignment in CLIP models, which is essential for downstream open-vocabulary dense prediction tasks. Subsequently, we propose an approach named CLIPSelf, which adapts the image-level recognition ability of CLIP ViT to local image regions without needing any region-text pairs. CLIPSelf empowers ViTs to distill itself by aligning a region representation extracted from its dense feature map with the image-level representation of the corresponding image crop. With the enhanced CLIP ViTs, we achieve new state-of-the-art performance on open-vocabulary object detection, semantic segmentation, and panoptic segmentation across various benchmarks. Models and code are released at https://github.com/wusize/CLIPSelf.",
        "_bibtex": "@inproceedings{\nwu2024clipself,\ntitle={{CLIPS}elf: Vision Transformer Distills Itself for Open-Vocabulary Dense Prediction},\nauthor={Size Wu and Wenwei Zhang and Lumin Xu and Sheng Jin and Xiangtai Li and Wentao Liu and Chen Change Loy},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=DjzvJCRsVf}\n}"
    },
    {
        "title": "Large Brain Model for Learning Generic Representations with Tremendous EEG Data in BCI",
        "authorids": [
            "~Weibang_Jiang2",
            "~Liming_Zhao3",
            "~Bao-liang_Lu1"
        ],
        "keywords": [
            "EEG",
            "brain-computer interface",
            "representation learning"
        ],
        "abstract": "The current electroencephalogram (EEG) based deep learning models are typically designed for specific datasets and applications in brain-computer interaction (BCI), limiting the scale of the models and thus diminishing their perceptual capabilities and generalizability. Recently, Large Language Models (LLMs) have achieved unprecedented success in text processing, prompting us to explore the capabilities of Large EEG Models (LEMs). We hope that LEMs can break through the limitations of different task types of EEG datasets, and obtain universal perceptual capabilities of EEG signals through unsupervised pre-training. Then the models can be fine-tuned for different downstream tasks. However, compared to text data, the volume of EEG datasets is generally small and the format varies widely. For example, there can be mismatched numbers of electrodes, unequal length data samples, varied task designs, and low signal-to-noise ratio. To overcome these challenges, we propose a unified foundation model for EEG called Large Brain Model (LaBraM). LaBraM enables cross-dataset learning by segmenting the EEG signals into EEG channel patches. Vector-quantized neural spectrum prediction is used to train a semantically rich neural tokenizer that encodes continuous raw EEG channel patches into compact neural codes. We then pre-train neural Transformers by predicting the original neural codes for the masked EEG channel patches. The LaBraMs were pre-trained on about 2,500 hours of various types of EEG signals from around 20 datasets and validated on multiple different types of downstream tasks. Experiments on abnormal detection, event type classification, emotion recognition, and gait prediction show that our LaBraM outperforms all compared SOTA methods in their respective fields. Our code is available at https://github.com/935963004/LaBraM.",
        "_bibtex": "@inproceedings{\njiang2024large,\ntitle={Large Brain Model for Learning Generic Representations with Tremendous {EEG} Data in {BCI}},\nauthor={Weibang Jiang and Liming Zhao and Bao-liang Lu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=QzTpTRVtrP}\n}"
    },
    {
        "title": "Towards LLM4QPE: Unsupervised Pretraining of Quantum Property Estimation and A Benchmark",
        "authorids": [
            "~Yehui_Tang3",
            "~Hao_Xiong5",
            "~Nianzu_Yang1",
            "~Tailong_Xiao1",
            "~Junchi_Yan2"
        ],
        "keywords": [
            "quantum property estimation",
            "pretraining",
            "finetuning"
        ],
        "abstract": "Estimating the properties of quantum systems such as quantum phase has been critical in addressing the essential quantum many-body problems in physics and chemistry. Deep learning models have been recently introduced to property estimation, surpassing  conventional statistical approaches. However, these methods are tailored to the specific task and quantum data at hand. It remains an open and attractive question for devising a more universal task-agnostic pretraining model for quantum property estimation. In this paper, we propose LLM4QPE, a large language model style quantum task-agnostic pretraining and finetuning paradigm that 1) performs unsupervised pretraining on diverse quantum systems with different physical conditions; 2) uses the pretrained model for supervised finetuning and delivers high performance with limited training data, on downstream tasks. It mitigates the cost for quantum data collection and speeds up convergence. Extensive experiments show the promising efficacy of LLM4QPE in various tasks including classifying quantum phases of matter on Rydberg atom model and predicting two-body correlation function on anisotropic Heisenberg model.",
        "_bibtex": "@inproceedings{\ntang2024towards,\ntitle={Towards {LLM}4{QPE}: Unsupervised Pretraining of Quantum Property Estimation and A Benchmark},\nauthor={Yehui Tang and Hao Xiong and Nianzu Yang and Tailong Xiao and Junchi Yan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=vrBVFXwAmi}\n}"
    },
    {
        "title": "GTMGC: Using Graph Transformer to Predict Molecule\u2019s Ground-State Conformation",
        "authorids": [
            "~Guikun_Xu1",
            "~Yongquan_Jiang1",
            "~PengChuan_Lei1",
            "~Yan_Yang8",
            "~Jim_Chen2"
        ],
        "keywords": [
            "molecular conformation prediction",
            "molecule modeling",
            "graph neural network",
            "graph transformer"
        ],
        "abstract": "The ground-state conformation of a molecule is often decisive for its properties. However, experimental or computational methods, such as density functional theory (DFT), are time-consuming and labor-intensive for obtaining this conformation. Deep learning (DL) based molecular representation learning (MRL) has made significant advancements in molecular modeling and has achieved remarkable results in various tasks. Consequently, it has emerged as a promising approach for directly predicting the ground-state conformation of molecules. In this regard, we introduce GTMGC, a novel network based on Graph-Transformer (GT) that seamlessly predicts the spatial configuration of molecules in a 3D space from their 2D topological architecture in an end-to-end manner. Moreover, we propose a novel self-attention mechanism called Molecule Structural Residual Self-Attention (MSRSA) for molecular structure modeling. This mechanism not only guarantees high model performance and easy implementation but also lends itself well to other molecular modeling tasks. Our method has been evaluated on the Molecule3D benchmark dataset and the QM9 dataset. Experimental results demonstrate that our approach achieves remarkable performance and outperforms current state-of-the-art methods as well as the widely used open-source software RDkit.",
        "_bibtex": "@inproceedings{\nxu2024gtmgc,\ntitle={{GTMGC}: Using Graph Transformer to Predict Molecule{\\textquoteright}s Ground-State Conformation},\nauthor={Guikun Xu and Yongquan Jiang and PengChuan Lei and Yan Yang and Jim Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=F7QnIKlC1N}\n}"
    },
    {
        "title": "Generalization of Scaled Deep ResNets in the Mean-Field Regime",
        "authorids": [
            "~Yihang_Chen1",
            "~Fanghui_Liu1",
            "~Yiping_Lu1",
            "~Grigorios_Chrysos1",
            "~Volkan_Cevher1"
        ],
        "keywords": [
            "ResNet",
            "mean field",
            "generalization",
            "Rademacher complexity"
        ],
        "abstract": "Despite the widespread empirical success of ResNet, the generalization properties of deep ResNet are rarely explored beyond the lazy training regime. In this work, we investigate scaled ResNet in the limit of infinitely deep and wide neural networks, of which the gradient flow is described by a partial differential equation in the large-neural network limit, i.e., the mean-field regime. To derive the generalization bounds under this setting, our analysis necessitates a shift from the conventional time-invariant Gram matrix employed in the lazy training regime to a time-variant, distribution-dependent version. To this end, we provide a global lower bound on the minimum eigenvalue of the Gram matrix under the mean-field regime. Besides, for the traceability of the dynamic of Kullback-Leibler (KL) divergence, we establish the linear convergence of the empirical error and estimate the upper bound of the KL divergence over parameters distribution. Finally, we build the uniform convergence for generalization bound via Rademacher complexity. Our results offer new insights into the generalization ability of deep ResNet beyond the lazy training regime and contribute to advancing the understanding of the fundamental properties of deep neural networks.",
        "_bibtex": "@inproceedings{\nchen2024generalization,\ntitle={Generalization of Scaled Deep ResNets in the Mean-Field Regime},\nauthor={Yihang Chen and Fanghui Liu and Yiping Lu and Grigorios Chrysos and Volkan Cevher},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tMzPZTvz2H}\n}"
    },
    {
        "title": "ODE Discovery for Longitudinal Heterogeneous Treatment Effects Inference",
        "authorids": [
            "~Krzysztof_Kacprzyk1",
            "~Samuel_Holt1",
            "~Jeroen_Berrevoets1",
            "~Zhaozhi_Qian1",
            "~Mihaela_van_der_Schaar2"
        ],
        "keywords": [
            "Treatment Effects over Time"
        ],
        "abstract": "Inferring unbiased treatment effects has received widespread attention in the machine learning community. In recent years, our community has proposed numerous solutions in standard settings, high-dimensional treatment settings, and even longitudinal settings. While very diverse, the solution has mostly relied on neural networks for inference and simultaneous correction of assignment bias. New approaches typically build on top of previous approaches by proposing new (or refined) architectures and learning algorithms. However, the end result\u2014a neural-network-based inference machine\u2014remains unchallenged. In this paper, we introduce a different type of solution in the longitudinal setting: a closed-form ordinary differential equation (ODE). While we still rely on continuous optimization to learn an ODE, the resulting inference machine is no longer a neural network. Doing so yields several advantages such as interpretability, irregular sampling, and a different set of identification assumptions. Above all, we consider the introduction of a completely new type of solution to be our most important contribution as it may spark entirely new innovations in treatment effects in general. We facilitate this by formulating our contribution as a framework that can transform any ODE discovery method into a treatment effects method.",
        "_bibtex": "@inproceedings{\nkacprzyk2024ode,\ntitle={{ODE} Discovery for Longitudinal Heterogeneous Treatment Effects Inference},\nauthor={Krzysztof Kacprzyk and Samuel Holt and Jeroen Berrevoets and Zhaozhi Qian and Mihaela van der Schaar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=pxI5IPeWgW}\n}"
    },
    {
        "title": "Learning Hierarchical World Models with Adaptive Temporal Abstractions from Discrete Latent Dynamics",
        "authorids": [
            "~Christian_Gumbsch1",
            "~Noor_Sajid1",
            "~Georg_Martius1",
            "~Martin_V._Butz2"
        ],
        "keywords": [
            "world models",
            "temporal abstraction",
            "hierarchical learning",
            "model-based reinforcement learning",
            "hierarchical planning"
        ],
        "abstract": "Hierarchical world models can significantly improve model-based reinforcement learning (MBRL) and planning by enabling reasoning across multiple time scales. Nonetheless, the majority of state-of-the-art MBRL methods employ flat, non-hierarchical models. We propose Temporal Hierarchies from Invariant Context Kernels (THICK), an algorithm that learns a world model hierarchy via discrete latent dynamics. The lower level of THICK updates parts of its latent state sparsely in time, forming invariant contexts. The higher level exclusively predicts situations involving context changes. Our experiments demonstrate that THICK learns categorical, interpretable, temporal abstractions on the high level, while maintaining precise low-level predictions. Furthermore, we show that the emergent hierarchical predictive model seamlessly enhances the abilities of MBRL or planning methods. We believe that THICK contributes to the further development of hierarchical agents capable of more sophisticated planning and reasoning abilities.",
        "_bibtex": "@inproceedings{\ngumbsch2024learning,\ntitle={Learning Hierarchical World Models with Adaptive Temporal Abstractions from Discrete Latent Dynamics},\nauthor={Christian Gumbsch and Noor Sajid and Georg Martius and Martin V. Butz},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TjCDNssXKU}\n}"
    },
    {
        "title": "Prediction without Preclusion: Recourse Verification with Reachable Sets",
        "authorids": [
            "~Avni_Kothari1",
            "~Bogdan_Kulynych1",
            "~Tsui-Wei_Weng1",
            "~Berk_Ustun1"
        ],
        "keywords": [
            "algorithmic recourse",
            "fairness",
            "robustness",
            "consumer finance",
            "integer programming",
            "trustworthy AI"
        ],
        "abstract": "Machine learning models are often used to decide who receives a loan, a job interview, or a public benefit. Models in such settings use features without considering their *actionability*. As a result, they can assign predictions that are \\emph{fixed} -- meaning that individuals who are denied loans and interviews are, in fact, *precluded from access* to credit and employment. In this work, we introduce a procedure called *recourse verification* to test if a model assigns fixed predictions to its decision subjects. We propose a model-agnostic approach for verification with *reachable sets* -- i.e., the set of all points that a person can reach through their actions in feature space. We develop methods to construct reachable sets for discrete feature spaces, which can certify the responsiveness of *any model* by simply querying its predictions. We conduct a comprehensive empirical study on the infeasibility of recourse on datasets from consumer finance. Our results highlight how models can inadvertently preclude access by assigning fixed predictions and underscore the need to account for actionability in model development.",
        "_bibtex": "@inproceedings{\nkothari2024prediction,\ntitle={Prediction without Preclusion: Recourse Verification with Reachable Sets},\nauthor={Avni Kothari and Bogdan Kulynych and Tsui-Wei Weng and Berk Ustun},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=SCQfYpdoGE}\n}"
    },
    {
        "title": "ODICE: Revealing the Mystery of Distribution Correction Estimation via Orthogonal-gradient Update",
        "authorids": [
            "~Liyuan_Mao2",
            "~Haoran_Xu4",
            "~Weinan_Zhang1",
            "~Xianyuan_Zhan1"
        ],
        "keywords": [
            "offline reinforcement learning",
            "imitation learning",
            "distribution correction estimation"
        ],
        "abstract": "In this study, we investigate the DIstribution Correction Estimation (DICE) methods, an important line of work in offline reinforcement learning (RL) and imitation learning (IL). DICE-based methods impose state-action-level behavior constraint, which is an ideal choice for offline learning. However, they typically perform much worse than current state-of-the-art (SOTA) methods that solely use action-level behavior constraint. After revisiting DICE-based methods, we find there exist two gradient terms when learning the value function using true-gradient update: forward gradient (taken on the current state) and backward gradient (taken on the next state). Using forward gradient bears a large similarity to many offline RL methods, and thus can be regarded as applying action-level constraint. However, directly adding the backward gradient may degenerate or cancel out its effect if these two gradients have conflicting directions. To resolve this issue, we propose a simple yet effective modification that projects the backward gradient onto the normal plane of the forward gradient, resulting in an orthogonal-gradient update, a new learning rule for DICE-based methods. We conduct thorough theoretical analyses and find that the projected backward gradient brings state-level behavior regularization, which reveals the mystery of DICE-based methods: the value learning objective does try to impose state-action-level constraint, but needs to be used in a corrected way. Through toy examples and extensive experiments on complex offline RL and IL tasks, we demonstrate that DICE-based methods using orthogonal-gradient updates achieve SOTA performance and great robustness.",
        "_bibtex": "@inproceedings{\nmao2024odice,\ntitle={{ODICE}: Revealing the Mystery of Distribution Correction Estimation via Orthogonal-gradient Update},\nauthor={Liyuan Mao and Haoran Xu and Weinan Zhang and Xianyuan Zhan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=L8UNn7Llt4}\n}"
    },
    {
        "title": "Improving Non-Transferable Representation Learning by Harnessing Content and Style",
        "authorids": [
            "~Ziming_Hong1",
            "~Zhenyi_Wang1",
            "~Li_Shen1",
            "~Yu_Yao3",
            "~Zhuo_Huang2",
            "~Shiming_Chen1",
            "~Chuanwu_Yang1",
            "~Mingming_Gong1",
            "~Tongliang_Liu1"
        ],
        "keywords": [
            "non-transferable representation learning",
            "domain adaptation",
            "transfer learning"
        ],
        "abstract": "Non-transferable learning (NTL) aims to restrict the generalization of models toward the target domain(s). To this end, existing works learn non-transferable representations by reducing statistical dependence between the source and target domain. However, such statistical methods essentially neglect to distinguish between *styles* and *contents*, leading them to inadvertently fit (i) spurious correlation between *styles* and *labels*, and (ii) fake independence between *contents* and *labels*. Consequently, their performance will be limited when natural distribution shifts occur or malicious intervention is imposed. In this paper, we propose a novel method (dubbed as H-NTL) to understand and advance the NTL problem by introducing a causal model to separately model *content* and *style* as two latent factors, based on which we disentangle and harness them as guidances for learning non-transferable representations with intrinsically causal relationships. Speci\ufb01cally, to avoid fitting spurious correlation and fake independence, we propose a variational inference framework to disentangle the naturally mixed *content factors* and *style factors* under our causal model. Subsequently, based on dual-path knowledge distillation, we harness the disentangled two *factors* as guidances for non-transferable representation learning: (i) we constraint the source domain representations to fit *content factors* (which are the intrinsic cause of *labels*), and (ii) we enforce that the target domain representations fit *style factors* which barely can predict labels. As a result, the learned feature representations follow optimal untransferability toward the target domain and minimal negative influence on the source domain, thus enabling better NTL performance. Empirically, the proposed H-NTL signi\ufb01cantly outperforms competing methods by a large margin.",
        "_bibtex": "@inproceedings{\nhong2024improving,\ntitle={Improving Non-Transferable Representation Learning by Harnessing Content and Style},\nauthor={Ziming Hong and Zhenyi Wang and Li Shen and Yu Yao and Zhuo Huang and Shiming Chen and Chuanwu Yang and Mingming Gong and Tongliang Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=FYKVPOHCpE}\n}"
    },
    {
        "title": "ModernTCN: A Modern Pure Convolution Structure for General Time Series Analysis",
        "authorids": [
            "~Luo_donghao2",
            "~wang_xue3"
        ],
        "keywords": [
            "Time Series Analysis",
            "Deep Learning"
        ],
        "abstract": "Recently, Transformer-based and MLP-based models have emerged rapidly and\nwon dominance in time series analysis. In contrast, convolution is losing steam\nin time series tasks nowadays for inferior performance. This paper studies the\nopen question of how to better use convolution in time series analysis and makes\nefforts to bring convolution back to the arena of time series analysis. To this end,\nwe modernize the traditional TCN and conduct time series related modifications\nto make it more suitable for time series tasks. As the outcome, we propose\nModernTCN and successfully solve this open question through a seldom-explored\nway in time series community. As a pure convolution structure, ModernTCN still\nachieves the consistent state-of-the-art performance on five mainstream time series\nanalysis tasks while maintaining the efficiency advantage of convolution-based\nmodels, therefore providing a better balance of efficiency and performance than\nstate-of-the-art Transformer-based and MLP-based models. Our study further\nreveals that, compared with previous convolution-based models, our ModernTCN\nhas much larger effective receptive fields (ERFs), therefore can better unleash the\npotential of convolution in time series analysis. Code is available at this repository:\nhttps://github.com/luodhhh/ModernTCN.",
        "_bibtex": "@inproceedings{\ndonghao2024moderntcn,\ntitle={Modern{TCN}: A Modern Pure Convolution Structure for General Time Series Analysis},\nauthor={Luo donghao and wang xue},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=vpJMJerXHU}\n}"
    },
    {
        "title": "Towards Robust Out-of-Distribution Generalization Bounds via Sharpness",
        "authorids": [
            "~Yingtian_Zou1",
            "~Kenji_Kawaguchi1",
            "~Yingnan_Liu1",
            "~Jiashuo_Liu1",
            "~Mong-Li_Lee1",
            "~Wynne_Hsu1"
        ],
        "keywords": [
            "Out-of-Distribution generalization",
            "Sharpness",
            "Robustness"
        ],
        "abstract": "Generalizing to out-of-distribution (OOD) data or unseen domain, termed OOD generalization, still lacks appropriate theoretical guarantees. Canonical OOD bounds focus on different distance measurements between source and target domains but fail to consider the optimization property of the learned model. As empirically shown in recent work, sharpness of learned minimum influences OOD generalization. To bridge this gap between optimization and OOD generalization, we study the effect of sharpness on how a model tolerates data change in domain shift which is usually captured by \"robustness\" in generalization. In this paper, we give a rigorous connection between sharpness and robustness, which gives better OOD guarantees for robust algorithms. It also provides a theoretical backing for \"flat minima leads to better OOD generalization\". Overall, we propose a sharpness-based OOD generalization bound by taking robustness into consideration, resulting in a tighter bound than non-robust guarantees. Our findings are supported by the experiments on a ridge regression model, as well as the experiments on deep learning classification tasks.",
        "_bibtex": "@inproceedings{\nzou2024towards,\ntitle={Towards Robust Out-of-Distribution Generalization Bounds via Sharpness},\nauthor={Yingtian Zou and Kenji Kawaguchi and Yingnan Liu and Jiashuo Liu and Mong-Li Lee and Wynne Hsu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tPEwSYPtAC}\n}"
    },
    {
        "title": "MAPE-PPI: Towards Effective and Efficient Protein-Protein Interaction Prediction via Microenvironment-Aware Protein Embedding",
        "authorids": [
            "~Lirong_Wu1",
            "~Yijun_Tian1",
            "~Yufei_Huang4",
            "~Siyuan_Li6",
            "~Haitao_Lin2",
            "~Nitesh_V_Chawla1",
            "~Stan_Z._Li2"
        ],
        "keywords": [
            "Bioinformatics",
            "Protein-Protein Interaction",
            "Protein Sequence-Structure Co-Modeling"
        ],
        "abstract": "Protein-Protein Interactions (PPIs) are fundamental in various biological processes and play a key role in life activities. The growing demand and cost of experimental PPI assays require computational methods for efficient PPI prediction. While existing methods rely heavily on protein sequence for PPI prediction, it is the protein structure that is the key to determine the interactions. To take both protein modalities into account, we define the microenvironment of an amino acid residue by its sequence and structural contexts, which describe the surrounding chemical properties and geometric features. In addition, microenvironments defined in previous work are largely based on experimentally assayed physicochemical properties, for which the \"vocabulary\" is usually extremely small. This makes it difficult to cover the diversity and complexity of microenvironments. In this paper, we propose Microenvironment-Aware Protein Embedding for PPI prediction (MPAE-PPI), which encodes microenvironments into chemically meaningful discrete codes via a sufficiently large microenvironment \"vocabulary\" (i.e., codebook). Moreover, we propose a novel pre-training strategy, namely Masked Codebook Modeling (MCM), to capture the dependencies between different microenvironments by randomly masking the codebook and reconstructing the input. With the learned microenvironment codebook, we can reuse it as an off-the-shelf tool to efficiently and effectively encode proteins of different sizes and functions for large-scale PPI prediction. Extensive experiments show that MAPE-PPI can scale to PPI prediction with millions of PPIs with superior trade-offs between effectiveness and computational efficiency than the state-of-the-art competitors.",
        "_bibtex": "@inproceedings{\nwu2024mapeppi,\ntitle={{MAPE}-{PPI}: Towards Effective and Efficient Protein-Protein Interaction Prediction via Microenvironment-Aware Protein Embedding},\nauthor={Lirong Wu and Yijun Tian and Yufei Huang and Siyuan Li and Haitao Lin and Nitesh V Chawla and Stan Z. Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=itGkF993gz}\n}"
    },
    {
        "title": "Negative Label Guided OOD Detection with Pretrained Vision-Language Models",
        "authorids": [
            "~Xue_Jiang3",
            "~Feng_Liu2",
            "~Zhen_Fang2",
            "~Hong_Chen1",
            "~Tongliang_Liu1",
            "~Feng_Zheng1",
            "~Bo_Han1"
        ],
        "keywords": [
            "OOD detection"
        ],
        "abstract": "Out-of-distribution (OOD) detection aims at identifying samples from unknown classes, playing a crucial role in trustworthy models against errors on unexpected inputs.  \nExtensive research has been dedicated to exploring OOD detection in the vision modality. \n{Vision-language models (VLMs) can leverage both textual and visual information for various multi-modal applications, whereas few OOD detection methods take into account information from the text modality. \nIn this paper, we propose a novel post hoc OOD detection method, called NegLabel, which takes a vast number of negative labels from extensive corpus databases. We design a novel scheme for the OOD score collaborated with negative labels.\nTheoretical analysis helps to understand the mechanism of negative labels. Extensive experiments demonstrate that our method NegLabel achieves state-of-the-art performance on various OOD detection benchmarks and generalizes well on multiple VLM architectures. Furthermore, our method NegLabel exhibits remarkable robustness against diverse domain shifts. The codes are available at https://github.com/tmlr-group/NegLabel.",
        "_bibtex": "@inproceedings{\njiang2024negative,\ntitle={Negative Label Guided {OOD} Detection with Pretrained Vision-Language Models},\nauthor={Xue Jiang and Feng Liu and Zhen Fang and Hong Chen and Tongliang Liu and Feng Zheng and Bo Han},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xUO1HXz4an}\n}"
    },
    {
        "title": "OPTIMAL ROBUST MEMORIZATION WITH RELU NEURAL NETWORKS",
        "authorids": [
            "~Lijia_Yu2",
            "~Xiao-Shan_Gao2",
            "~Lijun_Zhang2"
        ],
        "keywords": [
            "Memorization",
            "expressive power of network",
            "optimal robust memorization",
            "computation complexity",
            "Lipschitz constant"
        ],
        "abstract": "Memorization with neural networks is to study the expressive power of neural networks to interpolate a finite classification data set, which is closely related to the generalizability of deep learning. However, the important problem of robust memorization has not been thoroughly studied. In this paper, several basic problems about robust memorization are solved. First, we prove that it is NP-hard to compute neural networks with certain simple structures, which are robust memorization. A network hypothesis space is called optimal robust memorization for a data set if it can achieve robust memorization for any budget less than half the separation bound of the data set. Second, we explicitly construct neural networks with O(N n) parameters for optimal robust memorization of any data set with dimension n and size N . We also give a lower bound for the width of networks to achieve optimal robust memorization. Finally, we explicitly construct neural networks with\nO(N n log n) parameters for optimal robust memorization of any binary classification data set by controlling the Lipschitz constant of the network.",
        "_bibtex": "@inproceedings{\nyu2024optimal,\ntitle={{OPTIMAL} {ROBUST} {MEMORIZATION} {WITH} {RELU} {NEURAL} {NETWORKS}},\nauthor={Lijia Yu and Xiao-Shan Gao and Lijun Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=47hDbAMLbc}\n}"
    },
    {
        "title": "Neural Contractive Dynamical Systems",
        "authorids": [
            "~Hadi_Beik_Mohammadi1",
            "~S\u00f8ren_Hauberg1",
            "~Georgios_Arvanitidis1",
            "~Nadia_Figueroa1",
            "~Gerhard_Neumann2",
            "~Leonel_Rozo1"
        ],
        "keywords": [
            "learning from demonstration",
            "dynamical systems",
            "contraction theory"
        ],
        "abstract": "Stability guarantees are crucial when ensuring that a fully autonomous robot does not take undesirable or potentially harmful actions. Unfortunately, global stability guarantees are hard to provide in dynamical systems learned from data, especially when the learned dynamics are governed by neural networks. We propose a novel methodology to learn \\emph{neural contractive dynamical systems}, where our neural architecture ensures contraction, and hence, global stability. To efficiently scale the method to high-dimensional dynamical systems, we develop a variant of the variational autoencoder that learns dynamics in a low-dimensional latent representation space while retaining contractive stability after decoding. We further extend our approach to learning contractive systems on the Lie group of rotations to account for full-pose end-effector dynamic motions. The result is the first highly flexible learning architecture that provides contractive stability guarantees with capability to perform obstacle avoidance. Empirically, we demonstrate that our approach encodes the desired dynamics more accurately than the current state-of-the-art, which provides less strong stability guarantees.",
        "_bibtex": "@inproceedings{\nmohammadi2024neural,\ntitle={Neural Contractive Dynamical Systems},\nauthor={Hadi Beik Mohammadi and S{\\o}ren Hauberg and Georgios Arvanitidis and Nadia Figueroa and Gerhard Neumann and Leonel Rozo},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=iAYIRHOYy8}\n}"
    },
    {
        "title": "Scaling Laws for Associative Memories",
        "authorids": [
            "~Vivien_Cabannes1",
            "~Elvis_Dohmatob1",
            "~Alberto_Bietti1"
        ],
        "keywords": [
            "scaling law",
            "associative memory",
            "mechanistic interpretability",
            "Hopfield network"
        ],
        "abstract": "Learning arguably involves the discovery and memorization of abstract rules. The aim of this paper is to study associative memory mechanisms. Our model is based on high-dimensional matrices consisting of outer products of embeddings, which relates to the inner layers of transformer language models. We derive precise scaling laws with respect to sample size and parameter size, and discuss the statistical efficiency of different estimators, including optimization-based algorithms. We provide extensive numerical experiments to validate and interpret theoretical results, including fine-grained visualizations of the stored memory associations.",
        "_bibtex": "@inproceedings{\ncabannes2024scaling,\ntitle={Scaling Laws for Associative Memories},\nauthor={Vivien Cabannes and Elvis Dohmatob and Alberto Bietti},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Tzh6xAJSll}\n}"
    },
    {
        "title": "Text2Reward: Reward Shaping with Language Models for Reinforcement Learning",
        "authorids": [
            "~Tianbao_Xie1",
            "~Siheng_Zhao1",
            "~Chen_Henry_Wu1",
            "~Yitao_Liu2",
            "~Qian_Luo1",
            "~Victor_Zhong1",
            "~Yanchao_Yang1",
            "~Tao_Yu5"
        ],
        "keywords": [
            "reinforcement learning; large language models; robotics"
        ],
        "abstract": "Designing reward functions is a longstanding challenge in reinforcement learning (RL); it requires specialized knowledge or domain data, leading to high costs for development. To address this, we introduce Text2Reward, a data-free framework that automates the generation and shaping of dense reward functions based on large language models (LLMs). Given a goal described in natural language, Text2Reward generates shaped dense reward functions as an executable program grounded in a compact representation of the environment. Unlike inverse RL and recent work that uses LLMs to write sparse reward codes or unshaped dense rewards with a constant function across timesteps, Text2Reward produces interpretable, free-form dense reward codes that cover a wide range of tasks, utilize existing packages, and allow iterative refinement with human feedback. We evaluate Text2Reward on two robotic manipulation benchmarks (ManiSkill2, MetaWorld) and two locomotion environments of MuJoCo. On 13 of the 17 manipulation tasks, policies trained with generated reward codes achieve similar or better task success rates and convergence speed than expert-written reward codes. For locomotion tasks, our method learns six novel locomotion behaviors with a success rate exceeding 94%. Furthermore, we show that the policies trained in the simulator with our method can be deployed in the real world. Finally, Text2Reward further improves the policies by refining their reward functions with human feedback. Video results are available at https://text-to-reward.github.io/",
        "_bibtex": "@inproceedings{\nxie2024textreward,\ntitle={Text2Reward: Reward Shaping with Language Models for Reinforcement Learning},\nauthor={Tianbao Xie and Siheng Zhao and Chen Henry Wu and Yitao Liu and Qian Luo and Victor Zhong and Yanchao Yang and Tao Yu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tUM39YTRxH}\n}"
    },
    {
        "title": "Towards Meta-Pruning via Optimal Transport",
        "authorids": [
            "~Alexander_Theus1",
            "~Olin_Geimer1",
            "~Friedrich_Wicke1",
            "~Thomas_Hofmann1",
            "~Sotiris_Anagnostidis1",
            "~Sidak_Pal_Singh1"
        ],
        "keywords": [
            "Pruning",
            "Fusion"
        ],
        "abstract": "Structural pruning of neural networks conventionally relies on identifying and discarding less important neurons, a practice often resulting in significant accuracy loss that necessitates subsequent fine-tuning efforts. This paper introduces a novel approach named Intra-Fusion, challenging this prevailing pruning paradigm.\nUnlike existing methods that focus on designing meaningful neuron importance metrics, Intra-Fusion redefines the overlying pruning procedure.\nThrough utilizing the concepts of model fusion and Optimal Transport, we leverage an agnostically given importance metric to arrive at a more effective sparse model representation.\nNotably, our approach achieves substantial accuracy recovery without the need for resource-intensive fine-tuning, making it an efficient and promising tool for neural network compression.\nAdditionally, we explore how fusion can be added to the pruning process to significantly decrease the training time while maintaining competitive performance. We benchmark our results for various networks on commonly used datasets such as CIFAR-10, CIFAR-100, and ImageNet. More broadly, we hope that the proposed Intra-Fusion approach invigorates exploration into a fresh alternative to the predominant compression approaches.\nOur code is available [here](https://github.com/alexandertheus/Intra-Fusion).",
        "_bibtex": "@inproceedings{\ntheus2024towards,\ntitle={Towards Meta-Pruning via Optimal Transport},\nauthor={Alexander Theus and Olin Geimer and Friedrich Wicke and Thomas Hofmann and Sotiris Anagnostidis and Sidak Pal Singh},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=sMoifbuxjB}\n}"
    },
    {
        "title": "InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation",
        "authorids": [
            "~Yi_Wang19",
            "~Yinan_He1",
            "~Yizhuo_Li1",
            "~Kunchang_Li1",
            "~Jiashuo_Yu1",
            "~Xin_Ma3",
            "~Xinhao_Li1",
            "~Guo_Chen2",
            "~Xinyuan_Chen1",
            "~Yaohui_Wang1",
            "~Ping_Luo2",
            "~Ziwei_Liu1",
            "~Yali_Wang1",
            "~Limin_Wang1",
            "~Yu_Qiao1"
        ],
        "keywords": [
            "video-language dataset",
            "video understanding",
            "video generation",
            "multimodal understanding",
            "action recognition",
            "video retrieval"
        ],
        "abstract": "This paper introduces InternVid, a large-scale video-centric multimodal dataset that enables learning powerful and transferable video-text representations for multimodal understanding and generation. InternVid contains over 7 million videos lasting nearly 760K hours, yielding 234M video clips accompanied by detailed descriptions of total 4.1B words. Our core contribution is to develop a scalable approach to autonomously build a high-quality video-text dataset with large language models (LLM), thereby showcasing its efficacy in learning video-language representation at scale. Specifically, we utilize a multi-scale approach to generate video-related descriptions. Furthermore, we introduce ViCLIP, a video-text representation learning model based on ViT-L. Learned on InternVid via contrastive learning, this model demonstrates leading zero-shot action recognition and competitive video retrieval performance. Beyond basic video understanding tasks like recognition and retrieval, our dataset and model have broad applications. They are particularly beneficial for generating interleaved video-text data for learning a video-centric dialogue system, advancing video-to-text and text-to-video generation research. These proposed resources provide a tool for researchers and practitioners interested in multimodal video understanding and generation.",
        "_bibtex": "@inproceedings{\nwang2024internvid,\ntitle={InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation},\nauthor={Yi Wang and Yinan He and Yizhuo Li and Kunchang Li and Jiashuo Yu and Xin Ma and Xinhao Li and Guo Chen and Xinyuan Chen and Yaohui Wang and Ping Luo and Ziwei Liu and Yali Wang and Limin Wang and Yu Qiao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MLBdiWu4Fw}\n}"
    },
    {
        "title": "Dictionary Contrastive Learning for Efficient Local Supervision without Auxiliary Networks",
        "authorids": [
            "~Suhwan_Choi1",
            "~Myeongho_Jeon1",
            "~Yeonjung_Hwang1",
            "~Jeonglyul_Oh1",
            "~Sungjun_Lim3",
            "~Joonseok_Lee1",
            "~Myungjoo_Kang1"
        ],
        "keywords": [
            "Contrastive learning",
            "Forward learning",
            "Local learning",
            "Image classification",
            "Efficient learning"
        ],
        "abstract": "While backpropagation (BP) has achieved widespread success in deep learning, it\nfaces two prominent challenges: computational inefficiency and biological implausibility.\nIn response to these challenges, local supervision, encompassing Local\nLearning (LL) and Forward Learning (FL), has emerged as a promising research\ndirection. LL employs module-wise BP to achieve competitive results yet relies on\nmodule-wise auxiliary networks, which increase memory and parameter demands.\nConversely, FL updates layer weights without BP and auxiliary networks but falls\nshort of BP\u2019s performance. This paper proposes a simple yet effective objective\nwithin a contrastive learning framework for local supervision without auxiliary\nnetworks. Given the insight that the existing contrastive learning framework for\nlocal supervision is susceptible to task-irrelevant information without auxiliary\nnetworks, we present DICTIONARY CONTRASTIVE LEARNING (DCL) that optimizes\nthe similarity between local features and label embeddings. Our method\nusing static label embeddings yields substantial performance improvements in the\nFL scenario, outperforming state-of-the-art FL approaches. Moreover, our method\nusing adaptive label embeddings closely approaches the performance achieved by\nLL while achieving superior memory and parameter efficiency.",
        "_bibtex": "@inproceedings{\nchoi2024dictionary,\ntitle={Dictionary Contrastive Learning for Efficient Local Supervision without Auxiliary Networks},\nauthor={Suhwan Choi and Myeongho Jeon and Yeonjung Hwang and Jeonglyul Oh and Sungjun Lim and Joonseok Lee and Myungjoo Kang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Gg7cXo3S8l}\n}"
    },
    {
        "title": "Bounding Box Stability against Feature Dropout Reflects Detector Generalization across Environments",
        "authorids": [
            "~Yang_Yang32",
            "~Wenhai_Wang2",
            "~Zhe_Chen10",
            "~Jifeng_Dai1",
            "~Liang_Zheng4"
        ],
        "keywords": [
            "Object Detection",
            "Model Generalization"
        ],
        "abstract": "Bounding boxes uniquely characterize object detection, where a good detector gives accurate bounding boxes of categories of interest. However, in the real-world where test ground truths are not provided, it is non-trivial to find out whether bounding boxes are accurate, thus preventing us from assessing the detector generalization ability. In this work, we find under feature map dropout, good detectors tend to output bounding boxes whose locations do not change much, while bounding boxes of poor detectors will undergo noticeable position changes. We compute the box stability score (BS score) to reflect this stability. Specifically, given an image, we compute a normal set of bounding boxes and a second set after feature map dropout. To obtain BS score, we use bipartite matching to find the corresponding boxes between the two sets and compute the average Intersection over Union (IoU) across the entire test set. We contribute to finding that BS score has a strong, positive correlation with detection accuracy measured by mean average precision (mAP) under various test environments. This relationship allows us to predict the accuracy of detectors on various real-world test sets without accessing test ground truths, verified on canonical detection tasks such as vehicle detection and pedestrian detection.",
        "_bibtex": "@inproceedings{\nyang2024bounding,\ntitle={Bounding Box Stability against Feature Dropout Reflects Detector Generalization across Environments},\nauthor={Yang Yang and Wenhai Wang and Zhe Chen and Jifeng Dai and Liang Zheng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=lmM4Ecm4HJ}\n}"
    },
    {
        "title": "Deep Geodesic Canonical Correlation Analysis for Covariance-Based Neuroimaging Data",
        "authorids": [
            "~Ce_Ju1",
            "~Reinmar_J_Kobler1",
            "~Liyao_Tang1",
            "~Cuntai_Guan1",
            "~Motoaki_Kawanabe1"
        ],
        "keywords": [
            "Geometric Deep Learning",
            "Self-Supervised Learning",
            "Brain-Computer Interfaces",
            "Neuroimaging",
            "Neuroscience"
        ],
        "abstract": "In human neuroimaging, multi-modal imaging techniques are frequently combined to enhance our comprehension of whole-brain dynamics and improve diagnosis in clinical practice. Modalities like electroencephalography and functional magnetic resonance imaging provide distinct views to the brain dynamics due to diametral spatiotemporal sensitivities and underlying neurophysiological coupling mechanisms. These distinct views pose a considerable challenge to learning a shared representation space, especially when dealing with covariance-based data characterized by their geometric structure. To capitalize on the geometric structure, we introduce a measure called geodesic correlation which expands traditional correlation consistency to covariance-based data on the symmetric positive definite (SPD) manifold. This measure is derived from classical canonical correlation analysis and serves to evaluate the consistency of latent representations obtained from paired views. For multi-view, self-supervised learning where one or both latent views are SPD we propose an innovative geometric deep learning framework termed DeepGeoCCA. Its primary objective is to enhance the geodesic correlation of unlabeled, paired data, thereby generating novel representations while retaining the geometric structures. In simulations and experiments with multi-view and multi-modal human neuroimaging data, we find that DeepGeoCCA learns latent representations with high geodesic correlation for unseen data while retaining relevant information for downstream tasks.",
        "_bibtex": "@inproceedings{\nju2024deep,\ntitle={Deep Geodesic Canonical Correlation Analysis for Covariance-Based Neuroimaging Data},\nauthor={Ce Ju and Reinmar J Kobler and Liyao Tang and Cuntai Guan and Motoaki Kawanabe},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=PnR1MNen7u}\n}"
    },
    {
        "title": "SWAP-NAS: Sample-Wise Activation Patterns for Ultra-fast NAS",
        "authorids": [
            "~Yameng_Peng1",
            "~Andy_Song1",
            "~Haytham_M._Fayek1",
            "~Vic_Ciesielski1",
            "~Xiaojun_Chang4"
        ],
        "keywords": [
            "Neural Architecture Search",
            "Network evaluation",
            "Training-free metric",
            "Deep neural networks"
        ],
        "abstract": "Training-free metrics (a.k.a. zero-cost proxies) are widely used to avoid resource-intensive neural network training, especially in Neural Architecture Search (NAS). Recent studies show that existing training-free metrics have several limitations, such as limited correlation and poor generalisation across different search spaces and tasks. Hence, we propose Sample-Wise Activation Patterns and its derivative, SWAP-Score, a novel high-performance training-free metric. It measures the expressivity of networks over a batch of input samples. The SWAP-Score is strongly correlated with ground-truth performance across various search spaces and tasks, outperforming 15 existing training-free metrics on NAS-Bench-101/201/301 and TransNAS-Bench-101. The SWAP-Score can be further enhanced by regularisation, which leads to even higher correlations in cell-based search space and enables model size control during the search. For example, Spearman\u2019s rank correlation coefficient between regularised SWAP-Score and CIFAR-100 validation accuracies on NAS-Bench-201 networks is 0.90, significantly higher than 0.80 from the second-best metric, NWOT. When integrated with an evolutionary algorithm for NAS, our SWAP-NAS achieves competitive performance on CIFAR-10 and ImageNet in approximately 6 minutes and 9 minutes of GPU time respectively.",
        "_bibtex": "@inproceedings{\npeng2024swapnas,\ntitle={{SWAP}-{NAS}: Sample-Wise Activation Patterns for Ultra-fast {NAS}},\nauthor={Yameng Peng and Andy Song and Haytham M. Fayek and Vic Ciesielski and Xiaojun Chang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tveiUXU2aa}\n}"
    },
    {
        "title": "RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches",
        "authorids": [
            "~Jiayuan_Gu1",
            "~Sean_Kirmani1",
            "~Paul_Wohlhart1",
            "~Yao_Lu13",
            "~Montserrat_Gonzalez_Arenas1",
            "~Kanishka_Rao1",
            "~Wenhao_Yu1",
            "~Chuyuan_Fu1",
            "~Keerthana_Gopalakrishnan1",
            "~Zhuo_Xu1",
            "~Priya_Sundaresan1",
            "~Peng_Xu9",
            "~Hao_Su1",
            "~Karol_Hausman2",
            "~Chelsea_Finn1",
            "~Quan_Vuong2",
            "~Ted_Xiao1"
        ],
        "keywords": [
            "robotics",
            "robot learning",
            "robot manipulation",
            "task representation",
            "behavior cloning",
            "multitask imitation learning",
            "goal conditioning"
        ],
        "abstract": "Generalization remains one of the most important desiderata for robust robot learning systems. While recently proposed approaches show promise in generalization to novel objects, semantic concepts, or visual distribution shifts, generalization to new tasks remains challenging. For example, a language-conditioned policy trained on pick-and-place tasks will not be able to generalize to a folding task, even if the arm trajectory of folding is similar to pick-and-place. Our key insight is that this kind of generalization becomes feasible if we represent the task through rough trajectory sketches. We propose a policy conditioning method using such rough trajectory sketches, which we call RT-Trajectory, that is practical, easy to specify, and allows the policy to effectively perform new tasks that would otherwise be challenging to perform. We find that trajectory sketches strike a balance between being detailed enough to express low-level motion-centric guidance while being coarse enough to allow the learned policy to interpret the trajectory sketch in the context of situational visual observations. In addition, we show how trajectory sketches can provide a useful interface to communicate with robotic policies -- they can be specified through simple human inputs like drawings or videos, or through automated methods such as modern image-generating or waypoint-generating methods. We evaluate RT-Trajectory at scale on a variety of real-world robotic tasks, and find that RT-Trajectory is able to perform a wider range of tasks compared to language-conditioned and goal-conditioned policies, when provided the same training data.",
        "_bibtex": "@inproceedings{\ngu2024rttrajectory,\ntitle={{RT}-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches},\nauthor={Jiayuan Gu and Sean Kirmani and Paul Wohlhart and Yao Lu and Montserrat Gonzalez Arenas and Kanishka Rao and Wenhao Yu and Chuyuan Fu and Keerthana Gopalakrishnan and Zhuo Xu and Priya Sundaresan and Peng Xu and Hao Su and Karol Hausman and Chelsea Finn and Quan Vuong and Ted Xiao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=F1TKzG8LJO}\n}"
    },
    {
        "title": "NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers",
        "authorids": [
            "~Kai_Shen2",
            "~Zeqian_Ju1",
            "~Xu_Tan1",
            "~Eric_Liu1",
            "~Yichong_Leng1",
            "~Lei_He6",
            "~Tao_Qin1",
            "~sheng_zhao1",
            "~Jiang_Bian1"
        ],
        "keywords": [
            "text-to-speech",
            "large-scale corpus",
            "non-autoregressive",
            "diffusion"
        ],
        "abstract": "Scaling text-to-speech (TTS) to large-scale, multi-speaker, and in-the-wild datasets is important to capture the diversity in human speech such as speaker identities, prosodies, and styles (e.g., singing). Current large TTS systems usually quantize speech into discrete tokens and use language models to generate these tokens one by one, which suffer from unstable prosody, word skipping/repeating issue, and poor voice quality. In this paper, we develop NaturalSpeech 2, a TTS system that leverages a neural audio codec with residual vector quantizers to get the quantized latent vectors and uses a diffusion model to generate these latent vectors conditioned on text input. To enhance the zero-shot capability that is important to achieve diverse speech synthesis, we design a speech prompting mechanism to facilitate in-context learning in the diffusion model and the duration/pitch predictor. We scale NaturalSpeech 2 to large-scale datasets with 44K hours of speech and singing data and evaluate its voice quality on unseen speakers. NaturalSpeech 2 outperforms previous TTS systems by a large margin in terms of prosody/timbre similarity, robustness, and voice quality in a zero-shot setting, and performs novel zero-shot singing synthesis with only a speech prompt. Audio samples are available at https://naturalspeech2.github.io/.",
        "_bibtex": "@inproceedings{\nshen2024naturalspeech,\ntitle={NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers},\nauthor={Kai Shen and Zeqian Ju and Xu Tan and Eric Liu and Yichong Leng and Lei He and Tao Qin and sheng zhao and Jiang Bian},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Rc7dAwVL3v}\n}"
    },
    {
        "title": "Submodular Reinforcement Learning",
        "authorids": [
            "~Manish_Prajapat1",
            "~Mojmir_Mutny1",
            "~Melanie_Zeilinger1",
            "~Andreas_Krause1"
        ],
        "keywords": [
            "Reinforcement learning",
            "Non-Markovian rewards",
            "Submodular optimization",
            "Policy gradient",
            "Complex objectives in RL"
        ],
        "abstract": "In reinforcement learning (RL), rewards of states are typically considered additive, and following the Markov assumption, they are independent of states visited previously. In many important applications, such as coverage control, experiment design and informative path planning, rewards naturally have diminishing returns, i.e., their value decreases in light of similar states visited previously. To tackle this, we propose Submodular RL (subRL), a paradigm which seeks to optimize more general, non-additive (and history-dependent) rewards modelled via submodular set functions, which capture diminishing returns. Unfortunately, in general, even in tabular settings, we show that the resulting optimization problem is hard to approximate. On the other hand, motivated by the success of greedy algorithms in classical submodular optimization, we propose subPO, a simple policy gradient-based algorithm for subRL that handles non-additive rewards by greedily maximizing marginal gains. Indeed, under some assumptions on the underlying Markov Decision Process (MDP), subPO recovers optimal constant factor approximations of submodular bandits. Moreover, we derive a natural policy gradient approach for locally optimizing subRL instances even in large state- and action- spaces. We showcase the versatility of our approach by applying subPO to several applications, such as biodiversity monitoring, Bayesian experiment design, informative path planning, and coverage maximization. Our results demonstrate sample efficiency, as well as scalability to high-dimensional state-action spaces.",
        "_bibtex": "@inproceedings{\nprajapat2024submodular,\ntitle={Submodular Reinforcement Learning},\nauthor={Manish Prajapat and Mojmir Mutny and Melanie Zeilinger and Andreas Krause},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=loYSzjSaAK}\n}"
    },
    {
        "title": "Making Pre-trained Language Models Great on Tabular Prediction",
        "authorids": [
            "~Jiahuan_Yan1",
            "~Bo_Zheng7",
            "~Hongxia_Xu1",
            "~Yiheng_Zhu3",
            "~Danny_Chen1",
            "~Jimeng_Sun3",
            "~Jian_Wu6",
            "~Jintai_Chen1"
        ],
        "keywords": [
            "language models",
            "classification and regression",
            "model pre-training",
            "tabular data"
        ],
        "abstract": "The transferability of deep neural networks (DNNs) has made significant progress in image and language processing. However, due to the heterogeneity among tables, such DNN bonus is still far from being well exploited on tabular data prediction (e.g., regression or classification tasks). Condensing knowledge from diverse domains, language models (LMs) possess the capability to comprehend feature names from various tables, potentially serving as versatile learners in transferring knowledge across distinct tables and diverse prediction tasks, but their discrete text representation space is inherently incompatible with numerical feature values in tables. In this paper, we present TP-BERTa, a specifically pre-trained LM for tabular data prediction. Concretely, a novel relative magnitude tokenization converts scalar numerical feature values to finely discrete, high-dimensional tokens, and an intra-feature attention approach integrates feature values with the corresponding feature names. Comprehensive experiments demonstrate that our pre-trained TP-BERTa leads the performance among tabular DNNs and is competitive with Gradient Boosted Decision Tree models in typical tabular data regime.",
        "_bibtex": "@inproceedings{\nyan2024making,\ntitle={Making Pre-trained Language Models Great on Tabular Prediction},\nauthor={Jiahuan Yan and Bo Zheng and Hongxia Xu and Yiheng Zhu and Danny Chen and Jimeng Sun and Jian Wu and Jintai Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=anzIzGZuLi}\n}"
    },
    {
        "title": "Solving Inverse Problems with Latent Diffusion Models via Hard Data Consistency",
        "authorids": [
            "~Bowen_Song3",
            "~Soo_Min_Kwon1",
            "~Zecheng_Zhang1",
            "~Xinyu_Hu2",
            "~Qing_Qu2",
            "~Liyue_Shen1"
        ],
        "keywords": [
            "Diffusion models",
            "inverse problems"
        ],
        "abstract": "Latent diffusion models have been demonstrated to generate high-quality images, while offering efficiency in model training compared to diffusion models operating in the pixel space. However, incorporating latent diffusion models to solve inverse problems remains a challenging problem due to the nonlinearity of the encoder and decoder. To address these issues, we propose ReSample, an algorithm that can solve general inverse problems with pre-trained latent diffusion models. Our algorithm incorporates data consistency by solving an optimization problem during the reverse sampling process, a concept that we term as hard data consistency. Upon solving this optimization problem, we propose a novel resampling scheme to map the measurement-consistent sample back onto the noisy data manifold and theoretically demonstrate its benefits. Lastly, we apply our algorithm to solve a wide range of linear and nonlinear inverse problems in both natural and medical images, demonstrating that our approach outperforms existing state-of-the-art approaches, including those based on pixel-space diffusion models.",
        "_bibtex": "@inproceedings{\nsong2024solving,\ntitle={Solving Inverse Problems with Latent Diffusion Models via Hard Data Consistency},\nauthor={Bowen Song and Soo Min Kwon and Zecheng Zhang and Xinyu Hu and Qing Qu and Liyue Shen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=j8hdRqOUhN}\n}"
    },
    {
        "title": "The False Promise of Imitating Proprietary Language Models",
        "authorids": [
            "~Arnav_Gudibande1",
            "~Eric_Wallace1",
            "~Charlie_Victor_Snell1",
            "~Xinyang_Geng1",
            "~Hao_Liu1",
            "~Pieter_Abbeel2",
            "~Sergey_Levine1",
            "~Dawn_Song2"
        ],
        "keywords": [
            "Language Models",
            "Model Imitation",
            "Distillation",
            "Instruction-Tuning"
        ],
        "abstract": "An emerging method to cheaply improve a weaker language model is to finetune it on outputs from a stronger model, such as a proprietary system like ChatGPT (e.g., Alpaca, Self-Instruct, and others). In this work, we critically analyze this approach of imitating language models. We first finetune a series of LMs that imitate ChatGPT using varying base model sizes (1.5B--13B), data sources, and imitation data amounts (0.3M--150M tokens). We then evaluate the models using crowd raters and canonical NLP benchmarks. Initially, we were surprised by the output quality of our imitation models---they appear far better at following instructions, and crowd workers rate their outputs as competitive with ChatGPT. However, when conducting more targeted automatic evaluations, we find that imitation models close little to none of the gap from the base LM to ChatGPT on tasks that are not heavily supported in the imitation data. We show that these performance discrepancies may slip past human raters because imitation models are adept at mimicking ChatGPT\u2019s style but not its factuality. Overall, we conclude that while model imitation can be useful for training models to follow instructions and avoid toxic outputs, it falls short its full promise in many ways. In particular, there exists a substantial capabilities gap between open and closed LMs that we find cannot be bridged merely by adding more imitation data. Instead, we find that fine-tuning more capable base LMs has a significantly more substantial effect on closing this gap. In turn, we argue that the higher leverage action for improving open-source models is to tackle the difficult challenge of developing better base LMs, rather than taking the shortcut of imitating proprietary systems.",
        "_bibtex": "@inproceedings{\ngudibande2024the,\ntitle={The False Promise of Imitating Proprietary Language Models},\nauthor={Arnav Gudibande and Eric Wallace and Charlie Victor Snell and Xinyang Geng and Hao Liu and Pieter Abbeel and Sergey Levine and Dawn Song},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Kz3yckpCN5}\n}"
    },
    {
        "title": "Sample-Efficient Linear Representation Learning from Non-IID Non-Isotropic Data",
        "authorids": [
            "~Thomas_TCK_Zhang1",
            "~Leonardo_Felipe_Toso1",
            "~James_Anderson6",
            "~Nikolai_Matni2"
        ],
        "keywords": [
            "Representation learning",
            "meta learning",
            "multi-task learning"
        ],
        "abstract": "A powerful concept behind much of the recent progress in machine learning is the extraction of common features across data from heterogeneous sources or tasks. Intuitively, using all of one's data to learn a common representation function benefits both computational effort and statistical generalization by leaving a smaller number of parameters to fine-tune on a given task. Toward theoretically grounding these merits, we propose a general setting of recovering linear operators $M$\nfrom noisy vector measurements $y = Mx + w$, where the covariates $x$ may be both non-i.i.d. and non-isotropic. We demonstrate that existing isotropy-agnostic meta-learning approaches incur biases on the representation update, which causes the scaling of the noise terms to lose favorable dependence on the number of source tasks. This in turn can cause the sample complexity of representation learning to be bottlenecked by the single-task data size. We introduce an adaptation, $\\texttt{De-bias}$ & $\\texttt{Feature-Whiten}$ ($\\texttt{DFW}$), of the popular alternating minimization-descent (AMD) scheme proposed in Collins et al., (2021), and establish linear convergence to the optimal representation with noise level scaling down with the $\\textit{total}$ source data size. This leads to generalization bounds on the same order as an oracle empirical risk minimizer. We verify the vital importance of $\\texttt{DFW}$ on various numerical simulations. In particular, we show that vanilla alternating-minimization descent fails catastrophically even for iid, but mildly non-isotropic data.\nOur analysis unifies and generalizes prior work, and provides a flexible framework for a wider range of applications, such as in controls and dynamical systems.",
        "_bibtex": "@inproceedings{\nzhang2024sampleefficient,\ntitle={Sample-Efficient Linear Representation Learning from Non-{IID} Non-Isotropic Data},\nauthor={Thomas TCK Zhang and Leonardo Felipe Toso and James Anderson and Nikolai Matni},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Tr3fZocrI6}\n}"
    },
    {
        "title": "Information Retention via Learning Supplemental Features",
        "authorids": [
            "~Zhipeng_Xie1",
            "~Yahe_Li1"
        ],
        "keywords": [
            "Information Retention",
            "Few-shot Learning",
            "Deep Neural Network"
        ],
        "abstract": "The information bottleneck principle provides an information-theoretic method for learning a good representation as a trade-off between conciseness and predictive ability, which can reduce information redundancy, eliminate irrelevant and superfluous features, and thus enhance the in-domain generalizability. However, in low-resource or out-of-domain scenarios where the assumption of i.i.d does not necessarily hold true, superfluous (or redundant) relevant features may be supplemental to the mainline features of the model, and be beneficial in making prediction for test dataset with distribution shift. Therefore, instead of squeezing the input information by information bottleneck, we propose to keep as much relevant information as possible in use for making predictions. A three-stage supervised learning framework is designed and implemented to jointly learn the mainline and supplemental features, relieving supplemental features from the suppression of mainline features. Extensive experiments have shown that the learned representations of our method have good in-domain and out-of-domain generalization abilities, especially in low-resource cases.",
        "_bibtex": "@inproceedings{\nxie2024information,\ntitle={Information Retention via Learning Supplemental Features},\nauthor={Zhipeng Xie and Yahe Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=o83eu4H9Mb}\n}"
    },
    {
        "title": "Mayfly: a Neural Data Structure for Graph Stream Summarization",
        "authorids": [
            "~Yuan_Feng10",
            "~Yukun_Cao1",
            "~Wang_Hairu2",
            "~Xike_Xie1",
            "~S_Kevin_Zhou1"
        ],
        "keywords": [
            "Meta-Learning;Memory Augmented Neural Network; Deep Neural Network Application;Graph Summarization"
        ],
        "abstract": "A graph is a structure made up of vertices and edges used to represent complex relationships between entities, while a graph stream is a continuous flow of graph updates that convey evolving relationships between entities. The massive volume and high dynamism of graph streams promote research on data structures of graph summarization, which provides a concise and approximate view of graph streams with sub-linear space and linear construction time, enabling real-time graph analytics in various domains, such as social networking, financing, and cybersecurity.\nIn this work, we propose the Mayfly, the first neural data structure for summarizing graph streams. The Mayfly replaces handcrafted data structures with better accuracy and adaptivity.\nTo cater to practical applications, Mayfly incorporates two offline training phases.\nDuring the larval phase, the Mayfly learns basic summarization abilities from automatically and synthetically constituted meta-tasks, and in the metamorphosis phase, it rapidly adapts to real graph streams via meta-tasks.\nWith specific configurations of information pathways, the Mayfly enables flexible support for miscellaneous graph queries, including edge, node, and connectivity queries.\nExtensive empirical studies show that the Mayfly significantly outperforms its handcrafted competitors.",
        "_bibtex": "@inproceedings{\nfeng2024mayfly,\ntitle={Mayfly: a Neural Data Structure for Graph Stream Summarization},\nauthor={Yuan Feng and Yukun Cao and Wang Hairu and Xike Xie and S Kevin Zhou},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=n7Sr8SW4bn}\n}"
    },
    {
        "title": "Exploring the Common Appearance-Boundary Adaptation for Nighttime Optical Flow",
        "authorids": [
            "~Hanyu_Zhou1",
            "~Yi_Chang2",
            "~Haoyue_Liu1",
            "~YAN_WENDING1",
            "~Yuxing_Duan1",
            "~Zhiwei_Shi2",
            "~Luxin_Yan2"
        ],
        "keywords": [
            "nighttime optical flow",
            "event camera",
            "domain adaptation",
            "common space"
        ],
        "abstract": "We investigate a challenging task of nighttime optical flow, which suffers from weakened texture and amplified noise. These degradations weaken discriminative visual features, thus causing invalid motion feature matching. Typically, existing methods employ domain adaptation to transfer knowledge from auxiliary domain to nighttime domain in either input visual space or output motion space. However, this direct adaptation is ineffective, since there exists a large domain gap due to the intrinsic heterogeneous nature of the feature representations between auxiliary and nighttime domains. To overcome this issue, we explore a common-latent space as the intermediate bridge to reinforce the feature alignment between auxiliary and nighttime domains. In this work, we exploit two auxiliary daytime and event domains, and propose a novel common appearance-boundary adaptation framework for nighttime optical flow. In appearance adaptation, we employ the intrinsic image decomposition to embed the auxiliary daytime image and the nighttime image into a reflectance-aligned common space. We discover that motion distributions of the two reflectance maps are very similar, benefiting us to consistently transfer motion appearance knowledge from daytime to nighttime domain. In boundary adaptation, we theoretically derive the motion correlation formula between nighttime image and accumulated events within a spatiotemporal gradient-aligned common space. We figure out that the correlation of the two spatiotemporal gradient maps shares significant discrepancy, benefitting us to contrastively transfer boundary knowledge from event to nighttime domain. Moreover, appearance adaptation and boundary adaptation are complementary to each other, since they could jointly transfer global motion and local boundary knowledge to the nighttime domain. Extensive experiments have been performed to verify the superiority of the proposed method.",
        "_bibtex": "@inproceedings{\nzhou2024exploring,\ntitle={Exploring the Common Appearance-Boundary Adaptation for Nighttime Optical Flow},\nauthor={Hanyu Zhou and Yi Chang and Haoyue Liu and YAN WENDING and Yuxing Duan and Zhiwei Shi and Luxin Yan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=776lhoaulC}\n}"
    },
    {
        "title": "Graphical Multioutput Gaussian Process with Attention",
        "authorids": [
            "~Yijue_Dai1",
            "~Wenzhong_Yan1",
            "~Feng_Yin1"
        ],
        "keywords": [
            "Gaussian process regression",
            "Multioutput Gaussian process",
            "Attention mechanism"
        ],
        "abstract": "Integrating information while recognizing dependence from multiple data sources and enhancing the predictive performance of the multi-output regression are challenging tasks. Multioutput Gaussian Process (MOGP) methods offer outstanding solutions with tractable predictions and uncertainty quantification. However, their practical applications are hindered by high computational complexity and storage demand. Additionally, there exist model mismatches in existing MOGP models when dealing with non-Gaussian data. To improve the model representation ability in terms of flexibility, optimality, and scalability, this paper introduces a novel multi-output regression framework, termed Graphical MOGP (GMOGP), which is empowered by: (i) Generating flexible Gaussian process priors consolidated from dentified parents, (ii) providing dependent processes with attention-based graphical representations, and (iii) achieving Pareto optimal solutions of kernel hyperparameters via a distributed learning framework. Numerical results confirm that the proposed GMOGP significantly outperforms state-of-the-art MOGP alternatives in predictive performance, as well as in time and memory efficiency, across various synthetic and real datasets.",
        "_bibtex": "@inproceedings{\ndai2024graphical,\ntitle={Graphical Multioutput Gaussian Process with Attention},\nauthor={Yijue Dai and Wenzhong Yan and Feng Yin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=6N8TW504aa}\n}"
    },
    {
        "title": "Soft Contrastive Learning for Time Series",
        "authorids": [
            "~Seunghan_Lee1",
            "~Taeyoung_Park1",
            "~Kibok_Lee1"
        ],
        "keywords": [
            "Soft Contrastive Learning",
            "Time Series Analysis",
            "Self-supervised Learning"
        ],
        "abstract": "Contrastive learning has shown to be effective to learn representations from time series in a self-supervised way.\nHowever, contrasting similar time series instances or values from adjacent timestamps within a time series leads to ignore their inherent correlations, which results in deteriorating the quality of learned representations.\nTo address this issue, we propose \\textit{SoftCLT}, a simple yet effective soft contrastive learning strategy for time series.\nThis is achieved by introducing instance-wise and temporal contrastive loss with soft assignments ranging from zero to one.\nSpecifically, we define soft assignments for 1) instance-wise contrastive loss by distance between time series on the data space, warping and 2) temporal contrastive loss by the difference of timestamps.\nSoftCLT is a plug-and-play method for time series contrastive learning that improves the quality of learned representations without bells and whistles.\nIn experiments, we demonstrate that SoftCLT consistently improves the performance in various downstream tasks including classification, semi-supervised learning, transfer learning, and anomaly detection, showing state-of-the-art performance.\nCode is available at this repository: https://github.com/seunghan96/softclt.",
        "_bibtex": "@inproceedings{\nlee2024soft,\ntitle={Soft Contrastive Learning for Time Series},\nauthor={Seunghan Lee and Taeyoung Park and Kibok Lee},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=pAsQSWlDUf}\n}"
    },
    {
        "title": "Enhancing Group Fairness in Online Settings Using Oblique Decision Forests",
        "authorids": [
            "~Somnath_Basu_Roy_Chowdhury3",
            "~Nicholas_Monath1",
            "~Ahmad_Beirami1",
            "~Rahul_Kidambi1",
            "~Kumar_Avinava_Dubey1",
            "~Amr_Ahmed1",
            "~Snigdha_Chaturvedi2"
        ],
        "keywords": [
            "Fairness",
            "Online Learning",
            "Oblique Decision Trees"
        ],
        "abstract": "Fairness, especially group fairness, is an important consideration in the context of machine learning systems. The most commonly adopted group fairness-enhancing techniques are in-processing methods that rely on a mixture of a fairness objective (e.g., demographic parity) and a task-specific objective (e.g., cross-entropy) during the training process. However, when data arrives in an online fashion \u2013 one instance at a time \u2013 optimizing such fairness objectives poses several challenges. In particular, group fairness objectives are defined using expectations of predictions across different demographic groups. In the online setting, where the algorithm has access to a single instance at a time, estimating the group fairness objective requires additional storage and significantly more computation (e.g., forward/backward passes) than the task-specific objective at every time step. In this paper, we propose Aranyani, an ensemble of oblique decision trees, to make fair decisions in online settings. The hierarchical tree structure of Aranyani enables parameter isolation and allows us to efficiently compute the fairness gradients using aggregate statistics of previous decisions, eliminating the need for additional storage and forward/backward passes. We also present an efficient framework to train Aranyani and theoretically analyze several of its properties. We conduct empirical evaluations on 5 publicly available benchmarks (including vision and language datasets) to show that Aranyani achieves a better accuracy-fairness trade-off compared to baseline approaches.",
        "_bibtex": "@inproceedings{\nchowdhury2024enhancing,\ntitle={Enhancing Group Fairness in Online Settings Using Oblique Decision Forests},\nauthor={Somnath Basu Roy Chowdhury and Nicholas Monath and Ahmad Beirami and Rahul Kidambi and Kumar Avinava Dubey and Amr Ahmed and Snigdha Chaturvedi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=E1NxN5QMOE}\n}"
    },
    {
        "title": "Generative Learning for Financial Time Series with Irregular and Scale-Invariant Patterns",
        "authorids": [
            "~Hongbin_Huang1",
            "~Minghua_Chen1",
            "~Xiao_Qiao1"
        ],
        "keywords": [
            "generative model",
            "time series pattern recognition",
            "diffusion model",
            "financial time series"
        ],
        "abstract": "Limited data availability poses a major obstacle in training deep learning models for financial applications. Synthesizing financial time series to augment real-world data is challenging due to the irregular and scale-invariant patterns uniquely associated with financial time series - temporal dynamics that repeat with varying duration and magnitude. Such dynamics cannot be captured by existing approaches, which often assume regularity and uniformity in the underlying data. We develop a novel generative framework called FTS-Diffusion to model irregular and scale-invariant patterns that consists of three modules. First, we develop a scale-invariant pattern recognition algorithm to extract recurring patterns that vary in duration and magnitude. Second, we construct a diffusion-based generative network to synthesize segments of patterns. Third, we model the temporal transition of patterns in order to aggregate the generated segments. Extensive experiments show that FTS-Diffusion generates synthetic financial time series highly resembling observed data, outperforming state-of-the-art alternatives. Two downstream experiments demonstrate that augmenting real-world data with synthetic data generated by FTS-Diffusion reduces the error of stock market prediction by up to 17.9%. To the best of our knowledge, this is the first work on generating intricate time series with irregular and scale-invariant patterns, addressing data limitation issues in finance.",
        "_bibtex": "@inproceedings{\nhuang2024generative,\ntitle={Generative Learning for Financial Time Series with Irregular and Scale-Invariant Patterns},\nauthor={Hongbin Huang and Minghua Chen and Xiao Qiao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=CdjnzWsQax}\n}"
    },
    {
        "title": "Multiscale Positive-Unlabeled Detection of AI-Generated Texts",
        "authorids": [
            "~Yuchuan_Tian1",
            "~Hanting_Chen1",
            "~Xutao_Wang1",
            "~Zheyuan_Bai2",
            "~QINGHUA_ZHANG1",
            "~Ruifeng_Li3",
            "~Chao_Xu1",
            "~Yunhe_Wang1"
        ],
        "keywords": [
            "Large Language Models",
            "AI-Generated Texts",
            "Positive-Unlabeled Learning"
        ],
        "abstract": "Recent releases of Large Language Models (LLMs), e.g. ChatGPT, are astonishing at generating human-like texts, but they may impact the authenticity of texts. Previous works proposed methods to detect these AI-generated texts, including simple ML classifiers, pretrained-model-based zero-shot methods, and finetuned language classification models. However, mainstream detectors always fail on short texts, like SMSes, Tweets, and reviews. In this paper, a Multiscale Positive-Unlabeled (MPU) training framework is proposed to address the difficulty of short-text detection without sacrificing long-texts. Firstly, we acknowledge the human-resemblance property of short machine texts, and rephrase AI text detection as a partial Positive-Unlabeled (PU) problem by regarding these short machine texts as partially \"unlabeled\". Then in this PU context, we propose the length-sensitive Multiscale PU Loss, where a recurrent model in abstraction is used to estimate positive priors of scale-variant corpora. Additionally, we introduce a Text Multiscaling module to enrich training corpora. Experiments show that our MPU method augments detection performance on long AI-generated texts, and significantly improves short-text detection of language model detectors. Language Models trained with MPU could outcompete existing detectors on various short-text and long-text detection benchmarks. The codes are available at https://github.com/mindspore-lab/mindone/tree/master/examples/detect_chatgpt and https://github.com/YuchuanTian/AIGC_text_detector.",
        "_bibtex": "@inproceedings{\ntian2024multiscale,\ntitle={Multiscale Positive-Unlabeled Detection of {AI}-Generated Texts},\nauthor={Yuchuan Tian and Hanting Chen and Xutao Wang and Zheyuan Bai and QINGHUA ZHANG and Ruifeng Li and Chao Xu and Yunhe Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5Lp6qU9hzV}\n}"
    },
    {
        "title": "A Lightweight Method for Tackling Unknown Participation Statistics in Federated Averaging",
        "authorids": [
            "~Shiqiang_Wang1",
            "~Mingyue_Ji1"
        ],
        "keywords": [
            "federated learning",
            "partial client participation",
            "adaptation",
            "aggregation weights"
        ],
        "abstract": "In federated learning (FL), clients usually have diverse participation statistics that are unknown a priori, which can significantly harm the performance of FL if not handled properly. Existing works aiming at addressing this problem are usually based on global variance reduction, which requires a substantial amount of additional memory in a multiplicative factor equal to the total number of clients. An important open problem is to find a lightweight method for FL in the presence of clients with unknown participation rates. In this paper, we address this problem by adapting the aggregation weights in federated averaging (FedAvg) based on the participation history of each client. We first show that, with heterogeneous participation statistics, FedAvg with non-optimal aggregation weights can diverge from the optimal solution of the original FL objective, indicating the need of finding optimal aggregation weights. However, it is difficult to compute the optimal weights when the participation statistics are unknown. To address this problem, we present a new algorithm called FedAU, which improves FedAvg by adaptively weighting the client updates based on online estimates of the optimal weights without knowing the statistics of client participation. We provide a theoretical convergence analysis of FedAU using a novel methodology to connect the estimation error and convergence. Our theoretical results reveal important and interesting insights, while showing that FedAU converges to an optimal solution of the original objective and has desirable properties such as linear speedup. Our experimental results also verify the advantage of FedAU over baseline methods with various participation patterns.",
        "_bibtex": "@inproceedings{\nwang2024a,\ntitle={A Lightweight Method for Tackling Unknown Participation Statistics in Federated Averaging},\nauthor={Shiqiang Wang and Mingyue Ji},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ZKEuFKfCKA}\n}"
    },
    {
        "title": "Identifying the Risks of LM Agents with an LM-Emulated Sandbox",
        "authorids": [
            "~Yangjun_Ruan1",
            "~Honghua_Dong1",
            "~Andrew_Wang4",
            "~Silviu_Pitis1",
            "~Yongchao_Zhou1",
            "~Jimmy_Ba1",
            "~Yann_Dubois1",
            "~Chris_J._Maddison1",
            "~Tatsunori_Hashimoto1"
        ],
        "keywords": [
            "Language Model Agent",
            "Tool Use",
            "Evaluation",
            "Safety",
            "Language Model"
        ],
        "abstract": "Recent advances in Language Model (LM) agents and tool use, exemplified by applications like ChatGPT Plugins, enable a rich set of capabilities but also amplify potential risks\u2014such as leaking private data or causing financial losses. Identifying these risks is labor-intensive, necessitating implementing the tools, setting up the environment for each test scenario manually, and finding risky cases. As tools and agents become more complex, the high cost of testing these agents will make it increasingly difficult to find high-stakes, long-tail risks. To address these challenges, we introduce ToolEmu: a framework that uses an LM to emulate tool execution and enables scalable testing of LM agents against a diverse range of tools and scenarios. Alongside the emulator, we develop an LM-based automatic safety evaluator that examines agent failures and quantifies associated risks. We test both the tool emulator and evaluator through human evaluation and find that 68.8% of failures identified with ToolEmu would be valid real-world agent failures. Using our curated initial benchmark consisting of 36 high-stakes toolkits and 144 test cases, we provide a quantitative risk analysis of current LM agents and identify numerous failures with potentially severe outcomes. Notably, even the safest LM agent exhibits such failures 23.9% of the time according to our evaluator, underscoring the need to develop safer LM agents for real-world deployment.",
        "_bibtex": "@inproceedings{\nruan2024identifying,\ntitle={Identifying the Risks of {LM} Agents with an {LM}-Emulated Sandbox},\nauthor={Yangjun Ruan and Honghua Dong and Andrew Wang and Silviu Pitis and Yongchao Zhou and Jimmy Ba and Yann Dubois and Chris J. Maddison and Tatsunori Hashimoto},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=GEcwtMk1uA}\n}"
    },
    {
        "title": "Coeditor: Leveraging Repo-level Diffs for Code Auto-editing",
        "authorids": [
            "~Jiayi_Wei2",
            "~Greg_Durrett1",
            "~Isil_Dillig1"
        ],
        "keywords": [
            "language model for code",
            "editing",
            "refactoring"
        ],
        "abstract": "Developers often dedicate significant time to maintaining and refactoring existing code. However, most prior work on generative models for code focuses solely on creating new code, overlooking the distinctive needs of editing existing code. In this work, we explore a multi-round code auto-editing setting, aiming to predict edits to a code region based on recent changes within the same codebase. Our model, Coeditor, is a fine-tuned language model specifically designed for code editing tasks. We represent code changes using a line diff format and employ static analysis to form large customized model contexts, ensuring the availability of appropriate information for prediction. We collect a code editing dataset from the commit histories of 1650 open-source Python projects for training and evaluation. In a simplified single-round, single-edit task, Coeditor significantly outperforms GPT-3.5 and SOTA open-source code completion models (bringing exact-match accuracy from 34.7 up to 60.4), demonstrating the benefits of incorporating editing history for code completion. In a multi-round, multi-edit setting, we observe substantial gains by iteratively conditioning on additional user edits. We have open-sourced our code, data, and model weights to encourage future research and have released a VSCode extension powered by our model for interactive IDE usage.",
        "_bibtex": "@inproceedings{\nwei2024coeditor,\ntitle={Coeditor: Leveraging Repo-level Diffs for Code Auto-editing},\nauthor={Jiayi Wei and Greg Durrett and Isil Dillig},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ALVwQjZRS8}\n}"
    },
    {
        "title": "FITS: Modeling Time Series with $10k$ Parameters",
        "authorids": [
            "~Zhijian_Xu1",
            "~Ailing_Zeng1",
            "~Qiang_Xu1"
        ],
        "keywords": [
            "Time series analysis",
            "Time series forecasting",
            "Complex-valued neural network"
        ],
        "abstract": "In this paper, we introduce FITS, a lightweight yet powerful model for time series analysis. Unlike existing models that directly process raw time-domain data, FITS operates on the principle that time series can be manipulated through interpolation in the complex frequency domain, achieving performance comparable to state-of-the-art models for time series forecasting and anomaly detection tasks. Notably, FITS accomplishes this with a svelte profile of just about $10k$ parameters, making it ideally suited for edge devices and paving the way for a wide range of applications. The code is available for review at: \\url{https://anonymous.4open.science/r/FITS}.",
        "_bibtex": "@inproceedings{\nxu2024fits,\ntitle={{FITS}: Modeling Time Series with \\$10k\\$ Parameters},\nauthor={Zhijian Xu and Ailing Zeng and Qiang Xu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=bWcnvZ3qMb}\n}"
    },
    {
        "title": "MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models",
        "authorids": [
            "~Longhui_Yu1",
            "~Weisen_Jiang1",
            "~Han_Shi1",
            "~Jincheng_YU1",
            "~Zhengying_Liu2",
            "~Yu_Zhang3",
            "~James_Kwok1",
            "~Zhenguo_Li1",
            "~Adrian_Weller1",
            "~Weiyang_Liu1"
        ],
        "keywords": [
            "Large Language Model; Mathematical Reasoning"
        ],
        "abstract": "Large language models (LLMs) have pushed the limits of natural language understanding and exhibited excellent problem-solving ability. Despite the great success, most existing open-source LLMs (\\eg, LLaMA-2) are still far away from satisfactory for solving mathematical problems due to the complex reasoning procedures. To bridge this gap, we propose \\emph{MetaMath}, a finetuned language model that specializes in mathematical reasoning. Specifically, we start by bootstrapping mathematical questions by rewriting the question from multiple perspectives, which results in a new dataset called MetaMathQA. Then we finetune the LLaMA-2 models on MetaMathQA. Experimental results on two popular benchmarks (\\ie, GSM8K and MATH) for mathematical reasoning demonstrate that MetaMath outperforms a suite of open-source LLMs by a significant margin.  Our MetaMath-7B model achieves $66.5\\%$ on GSM8K and $19.8\\%$ on MATH, exceeding the state-of-the-art models of the same size by $11.5\\%$ and $8.7\\%$. Particularly, MetaMath-70B achieves an accuracy of $82.3\\%$ on GSM8K, slightly better than GPT-3.5-Turbo. We release the MetaMathQA dataset, the MetaMath models with different model sizes and the training code for public use.",
        "_bibtex": "@inproceedings{\nyu2024metamath,\ntitle={MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models},\nauthor={Longhui Yu and Weisen Jiang and Han Shi and Jincheng YU and Zhengying Liu and Yu Zhang and James Kwok and Zhenguo Li and Adrian Weller and Weiyang Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=N8N0hgNDRt}\n}"
    },
    {
        "title": "Query-Policy Misalignment in Preference-Based Reinforcement Learning",
        "authorids": [
            "~Xiao_Hu7",
            "~Jianxiong_Li1",
            "~Xianyuan_Zhan1",
            "~Qing-Shan_Jia1",
            "~Ya-Qin_Zhang1"
        ],
        "keywords": [
            "preference-based reinforcement learning",
            "human feedback efficiency",
            "query-policy misalignment"
        ],
        "abstract": "Preference-based reinforcement learning (PbRL) provides a natural way to align RL agents\u2019 behavior with human desired outcomes, but is often restrained by costly human feedback. To improve feedback efficiency, most existing PbRL methods focus on selecting queries to maximally improve the overall quality of the reward model, but counter-intuitively, we find that this may not necessarily lead to improved performance. To unravel this mystery, we identify a long-neglected issue in the query selection schemes of existing PbRL studies: Query-Policy Misalignment. We show that the seemingly informative queries selected to improve the overall quality of reward model actually may not align with RL agents\u2019 interests, thus offering little help on policy learning and eventually resulting in poor feedback efficiency. We show that this issue can be effectively addressed via policy-aligned query and a specially designed hybrid experience replay, which together enforce the bidirectional query-policy alignment. Simple yet elegant, our method can be easily incorporated into existing approaches by changing only a few lines of code. We showcase in comprehensive experiments that our method achieves substantial gains in both human feedback and RL sample efficiency, demonstrating the importance of addressing query-policy misalignment in PbRL tasks.",
        "_bibtex": "@inproceedings{\nhu2024querypolicy,\ntitle={Query-Policy Misalignment in Preference-Based Reinforcement Learning},\nauthor={Xiao Hu and Jianxiong Li and Xianyuan Zhan and Qing-Shan Jia and Ya-Qin Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=UoBymIwPJR}\n}"
    },
    {
        "title": "Feature-aligned N-BEATS with Sinkhorn divergence",
        "authorids": [
            "~Joonhun_Lee1",
            "~Myeongho_Jeon1",
            "~Myungjoo_Kang1",
            "~Kyunghyun_Park1"
        ],
        "keywords": [
            "Time series forecasting",
            "Deep learning",
            "Domain generalization",
            "Representation learning",
            "Sinkhorn divergence"
        ],
        "abstract": "We propose Feature-aligned N-BEATS as a domain-generalized time series forecasting model. It is a nontrivial extension of N-BEATS with doubly residual stacking principle (Oreshkin et al. [45]) into a representation learning framework. In particular, it revolves around marginal feature probability measures induced by the intricate composition of residual and feature extracting operators of N-BEATS in each stack and aligns them stack-wise via an approximate of an optimal transport distance referred to as the Sinkhorn divergence. The training loss consists of an empirical risk minimization from multiple source domains, i.e., forecasting loss, and an alignment loss calculated with the Sinkhorn divergence, which allows the model to learn invariant features stack-wise across multiple source data sequences while retaining N-BEATS\u2019s interpretable design and forecasting power. Comprehensive experimental evaluations with ablation studies are provided and the corresponding results demonstrate the proposed model\u2019s forecasting and generalization capabilities.",
        "_bibtex": "@inproceedings{\nlee2024featurealigned,\ntitle={Feature-aligned N-{BEATS} with Sinkhorn divergence},\nauthor={Joonhun Lee and Myeongho Jeon and Myungjoo Kang and Kyunghyun Park},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TS8HoIWAPQ}\n}"
    },
    {
        "title": "Instructive Decoding: Instruction-Tuned Large Language Models are Self-Refiner from Noisy Instructions",
        "authorids": [
            "~Taehyeon_Kim1",
            "~Joonkee_Kim1",
            "~Gihun_Lee1",
            "~Se-Young_Yun1"
        ],
        "keywords": [
            "Instruction Following",
            "Language Model",
            "Decoding"
        ],
        "abstract": "While instruction-tuned language models have demonstrated impressive zero-shot generalization, these models often struggle to generate accurate responses when faced with instructions that fall outside their training set. This paper presents Instructive Decoding (ID), a simple yet effective approach that augments the efficacy of instruction-tuned models. Specifically, ID adjusts the logits for next-token prediction in a contrastive manner, utilizing predictions generated from a manipulated version of the original instruction, referred to as a noisy instruction. This noisy instruction aims to elicit responses that could diverge from the intended instruction yet remain plausible. We conduct experiments across a spectrum of such noisy instructions, ranging from those that insert semantic noise via random words to others like 'opposite' that elicit the deviated responses. Our approach achieves considerable performance gains across various instruction-tuned models and tasks without necessitating any additional parameter updates. Notably, utilizing 'opposite' as the noisy instruction in ID, which shows the maximum divergence from the original instruction, consistently produces the most significant performance gains across multiple models and tasks.",
        "_bibtex": "@inproceedings{\nkim2024instructive,\ntitle={Instructive Decoding: Instruction-Tuned Large Language Models are Self-Refiner from Noisy Instructions},\nauthor={Taehyeon Kim and Joonkee Kim and Gihun Lee and Se-Young Yun},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=LebzzClHYw}\n}"
    },
    {
        "title": "Consistent Multi-Class Classification from Multiple Unlabeled Datasets",
        "authorids": [
            "~Zixi_Wei1",
            "~Senlin_Shu2",
            "~Yuzhou_Cao1",
            "~Hongxin_Wei1",
            "~Bo_An2",
            "~Lei_Feng1"
        ],
        "keywords": [
            "mutli-class classification",
            "multiple unlabeled datasets",
            "learning consistency"
        ],
        "abstract": "Weakly supervised learning aims to construct effective predictive models from imperfectly labeled data. The recent trend of weakly supervised learning has focused on how to learn an accurate classifier from completely unlabeled data, given little supervised information such as class priors. In this paper, we consider a newly proposed weakly supervised learning problem called multi-class classification from multiple unlabeled datasets, where only multiple sets of unlabeled data and their class priors (i.e., the proportions of each class) are provided for training the classifier. To solve this problem, we first propose a classifier-consistent method (CCM) based on a probability transition matrix. However, CCM cannot guarantee risk consistency and lacks of purified supervision information during training. Therefore, we further propose a risk-consistent method (RCM) that progressively purifies supervision information during training by importance weighting. We provide comprehensive theoretical analyses for our methods to demonstrate the statistical consistency. Experimental results on multiple benchmark datasets and various prior matrices demonstrate the superiority of our proposed methods.",
        "_bibtex": "@inproceedings{\nwei2024consistent,\ntitle={Consistent Multi-Class Classification from Multiple Unlabeled Datasets},\nauthor={Zixi Wei and Senlin Shu and Yuzhou Cao and Hongxin Wei and Bo An and Lei Feng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=fW7DOHDQvF}\n}"
    },
    {
        "title": "SpikePoint: An Efficient Point-based Spiking Neural Network for Event Cameras Action Recognition",
        "authorids": [
            "~Hongwei_Ren2",
            "~Yue_Zhou8",
            "~Xiaopeng_LIN1",
            "~Yulong_Huang2",
            "~Haotian_FU4",
            "~Jie_Song1",
            "~Bojun_Cheng1"
        ],
        "keywords": [
            "Spiking Neural Betwork",
            "Point Cloud",
            "Event Camera",
            "Action Recognition"
        ],
        "abstract": "Event cameras are bio-inspired sensors that respond to local changes in light intensity and feature low latency, high energy efficiency, and high dynamic range. Meanwhile, Spiking Neural Networks (SNNs) have gained significant attention due to their remarkable efficiency and fault tolerance. By synergistically harnessing the energy efficiency inherent in event cameras and the spike-based processing capabilities of SNNs, their integration could enable ultra-low-power application scenarios, such as action recognition tasks. However, existing approaches often entail converting asynchronous events into conventional frames, leading to additional data mapping efforts and a loss of sparsity, contradicting the design concept of SNNs and event cameras. To address this challenge, we propose SpikePoint, a novel end-to-end point-based SNN architecture. SpikePoint excels at processing sparse event cloud data, effectively extracting both global and local features through a singular-stage structure. Leveraging the surrogate training method, SpikePoint achieves high accuracy with few parameters and maintains low power consumption, specifically employing the identity mapping feature extractor on diverse datasets. SpikePoint achieves state-of-the-art (SOTA) performance on four event-based action recognition datasets using only 16 timesteps, surpassing other SNN methods. Moreover, it also achieves SOTA performance across all methods on three datasets, utilizing approximately 0.3 % of the parameters and 0.5 % of power consumption employed by artificial neural networks (ANNs). These results emphasize the significance of Point Cloud and pave the way for many ultra-low-power event-based data processing applications.",
        "_bibtex": "@inproceedings{\nren2024spikepoint,\ntitle={SpikePoint: An Efficient Point-based Spiking Neural Network for Event Cameras Action Recognition},\nauthor={Hongwei Ren and Yue Zhou and Xiaopeng LIN and Yulong Huang and Haotian FU and Jie Song and Bojun Cheng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=7etoNfU9uF}\n}"
    },
    {
        "title": "Inverse Approximation Theory for Nonlinear Recurrent Neural Networks",
        "authorids": [
            "~Shida_Wang1",
            "~Zhong_Li2",
            "~Qianxiao_Li1"
        ],
        "keywords": [
            "Recurrent neural networks",
            "sequence modelling",
            "approximation theory"
        ],
        "abstract": "We prove an inverse approximation theorem for the approximation of nonlinear sequence-to-sequence relationships using recurrent neural networks (RNNs). This is a so-called Bernstein-type result in approximation theory, which deduces properties of a target function under the assumption that it can be effectively approximated by a hypothesis space. In particular, we show that nonlinear sequence relationships that can be stably approximated by nonlinear RNNs must have an exponential decaying memory structure - a notion that can be made precise. This extends the previously identified curse of memory in linear RNNs into the general nonlinear setting, and quantifies the essential limitations of the RNN architecture for learning sequential relationships with long-term memory. Based on the analysis, we propose a principled reparameterization method to overcome the limitations. Our theoretical results are confirmed by numerical experiments.",
        "_bibtex": "@inproceedings{\nwang2024inverse,\ntitle={Inverse Approximation Theory for Nonlinear Recurrent Neural Networks},\nauthor={Shida Wang and Zhong Li and Qianxiao Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=yC2waD70Vj}\n}"
    },
    {
        "title": "Kernel Metric Learning for In-Sample Off-Policy Evaluation of Deterministic RL Policies",
        "authorids": [
            "~Haanvid_Lee1",
            "~Tri_Wahyu_Guntara1",
            "~Jongmin_Lee1",
            "~Yung-Kyun_Noh1",
            "~Kee-Eung_Kim2"
        ],
        "keywords": [
            "off-policy evaluation",
            "reinforcement learning",
            "deterministic policy",
            "continuous actions",
            "metric learning"
        ],
        "abstract": "We consider off-policy evaluation (OPE) of deterministic target policies for reinforcement learning (RL) in environments with continuous action spaces. While it is common to use importance sampling for OPE, it suffers from high variance when the behavior policy deviates significantly from the target policy. In order to address this issue, some recent works on OPE proposed in-sample learning with importance resampling. Yet, these approaches are not applicable to deterministic target policies for continuous action spaces. To address this limitation, we propose to relax the deterministic target policy using a kernel and learn the kernel metrics that minimize the overall mean squared error of the estimated temporal difference update vector of an action value function, where the action value function is used for policy evaluation. We derive the bias and variance of the estimation error due to this relaxation and provide analytic solutions for the optimal kernel metric. In empirical studies using various test domains, we show that the OPE with in-sample learning using the kernel with optimized metric achieves significantly improved accuracy than other baselines.",
        "_bibtex": "@inproceedings{\nlee2024kernel,\ntitle={Kernel Metric Learning for In-Sample Off-Policy Evaluation of Deterministic {RL} Policies},\nauthor={Haanvid Lee and Tri Wahyu Guntara and Jongmin Lee and Yung-Kyun Noh and Kee-Eung Kim},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=plebgsdiiV}\n}"
    },
    {
        "title": "Large Language Models are Efficient Learners of Noise-Robust Speech Recognition",
        "authorids": [
            "~Yuchen_Hu1",
            "~CHEN_CHEN37",
            "~Chao-Han_Huck_Yang1",
            "~Ruizhe_Li2",
            "~Chao_Zhang20",
            "~Pin-Yu_Chen1",
            "~EngSiong_Chng1"
        ],
        "keywords": [
            "Large language models",
            "automatic speech recognition",
            "generative error correction",
            "noise-robustness"
        ],
        "abstract": "Recent advances in large language models (LLMs) have promoted generative error correction (GER) for automatic speech recognition (ASR), which leverages the rich linguistic knowledge and powerful reasoning ability of LLMs to improve recognition results. The latest work proposes a GER benchmark with \"HyPoradise\" dataset to learn the mapping from ASR N-best hypotheses to ground-truth transcription by efficient LLM finetuning, which shows great effectiveness but lacks specificity on noise-robust ASR. In this work, we extend the benchmark to noisy conditions and investigate if we can teach LLMs to perform denoising for GER just like what robust ASR do, where one solution is introducing noise information as a conditioner into LLM. However, directly incorporating noise embeddings from audio encoder could harm the LLM tuning due to cross-modality gap. To this end, we propose to extract a language-space noise embedding from the N-best list to represent the noise conditions of source speech, which can promote the denoising process in GER. Furthermore, in order to enhance its representation ability of audio noise, we design a knowledge distillation (KD) approach via mutual information estimation to distill the real noise information in audio embeddings to our language embedding. Experiments on various latest LLMs demonstrate our approach achieves a new breakthrough with up to 53.9% correction improvement in terms of word error rate while with limited training data. Analysis shows that our language-space noise embedding can well represent the noise conditions of source speech, under which off-the-shelf LLMs show strong ability of language-space denoising.",
        "_bibtex": "@inproceedings{\nhu2024large,\ntitle={Large Language Models are Efficient Learners of Noise-Robust Speech Recognition},\nauthor={Yuchen Hu and CHEN CHEN and Chao-Han Huck Yang and Ruizhe Li and Chao Zhang and Pin-Yu Chen and EngSiong Chng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ceATjGPTUD}\n}"
    },
    {
        "title": "H2O-SDF: Two-phase Learning for 3D Indoor Reconstruction using Object Surface Fields",
        "authorids": [
            "~Minyoung_Park3",
            "~Mirae_Do1",
            "~Yeon_Jae_Shin2",
            "~Jaeseok_Yoo2",
            "~Jongkwang_Hong1",
            "~Joongrock_Kim1",
            "~Chul_Lee1"
        ],
        "keywords": [
            "3D reconstruction",
            "Neural implicit surface learning"
        ],
        "abstract": "Advanced techniques using Neural Radiance Fields (NeRF), Signed Distance Fields (SDF), and Occupancy Fields have recently emerged as solutions for 3D indoor scene reconstruction. We introduce a novel two-phase learning approach, H2O-SDF,  that discriminates between object and non-object regions within indoor environments. This method achieves a nuanced balance, carefully preserving the geometric integrity of room layouts while also capturing intricate surface details of specific objects. A cornerstone of our two-phase learning framework is the introduction of the Object Surface Field (OSF), a novel concept designed to mitigate the persistent vanishing gradient problem that has previously hindered the capture of high-frequency details in other methods. Our proposed approach is validated through several experiments that include ablation studies.",
        "_bibtex": "@inproceedings{\npark2024hosdf,\ntitle={H2O-{SDF}: Two-phase Learning for 3D Indoor Reconstruction using Object Surface Fields},\nauthor={Minyoung Park and Mirae Do and Yeon Jae Shin and Jaeseok Yoo and Jongkwang Hong and Joongrock Kim and Chul Lee},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=P1ANzoGg3W}\n}"
    },
    {
        "title": "Sample-Efficient Quality-Diversity by Cooperative Coevolution",
        "authorids": [
            "~Ke_Xue1",
            "~Ren-Jian_Wang1",
            "~Pengyi_Li1",
            "~Dong_Li10",
            "~Jianye_HAO1",
            "~Chao_Qian1"
        ],
        "keywords": [
            "Quality-Diversity",
            "Reinforcement Learning",
            "Evolutionary Algorithms"
        ],
        "abstract": "Quality-Diversity (QD) algorithms, as a subset of evolutionary algorithms, have emerged as a powerful optimization paradigm with the aim of generating a set of high-quality and diverse solutions. Although QD has demonstrated competitive performance in reinforcement learning, its low sample efficiency remains a significant impediment for real-world applications. Recent research has primarily focused on augmenting sample efficiency by refining selection and variation operators of QD. However, one of the less considered yet crucial factors is the inherently large-scale issue of the QD optimization problem. In this paper, we propose a novel Cooperative Coevolution QD (CCQD) framework, which decomposes a policy network naturally into two types of layers, corresponding to representation and decision respectively, and thus simplifies the problem significantly. The resulting two (representation and decision) subpopulations are coevolved cooperatively. CCQD can be implemented with different selection and variation operators. Experiments on several popular tasks within the QDAX suite demonstrate that an instantiation of CCQD achieves approximately a 200% improvement in sample efficiency.",
        "_bibtex": "@inproceedings{\nxue2024sampleefficient,\ntitle={Sample-Efficient Quality-Diversity by Cooperative Coevolution},\nauthor={Ke Xue and Ren-Jian Wang and Pengyi Li and Dong Li and Jianye HAO and Chao Qian},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=JDud6zbpFv}\n}"
    },
    {
        "title": "SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore",
        "authorids": [
            "~Sewon_Min1",
            "~Suchin_Gururangan1",
            "~Eric_Wallace1",
            "~Weijia_Shi1",
            "~Hannaneh_Hajishirzi1",
            "~Noah_A._Smith2",
            "~Luke_Zettlemoyer1"
        ],
        "keywords": [
            "language modeling; retrieval; legality of language modeling"
        ],
        "abstract": "The legality of training language models (LMs) on copyrighted or otherwise restricted data is under intense debate. However, as we show, model performance significantly degrades if trained only on low-risk text (e.g., out-of-copyright books or government documents), due to its limited size and domain coverage. We present SILO, a new language model that manages this risk-performance tradeoff during inference. SILO is built by (1) training a parametric LM on the Open License Corpus (OLC), a new corpus we curate with 228B tokens of public domain and permissively licensed text and (2) augmenting it with a more general and easily modifiable nonparametric datastore (e.g., containing copyrighted books or news) that is only queried during inference. The datastore allows use of high-risk data without training on it, supports sentence-level data attribution, and enables data producers to opt out from the model by removing content from the store. These capabilities can foster compliance with data-use regulations such as the fair use doctrine in the United States and the GDPR in the European Union. Our experiments show that the parametric LM struggles on its own with domains not covered by OLC. However, access to the datastore greatly improves out of domain performance, closing 90% of the performance gap with an LM trained on the Pile, a more diverse corpus with mostly high-risk text. We also analyze which nonparametric approach works best, where the remaining errors lie, and how performance scales with datastore size. Our results suggest that it is possible to build high quality language models while mitigating legal risk.",
        "_bibtex": "@inproceedings{\nmin2024silo,\ntitle={{SILO} Language Models: Isolating Legal Risk In a Nonparametric Datastore},\nauthor={Sewon Min and Suchin Gururangan and Eric Wallace and Weijia Shi and Hannaneh Hajishirzi and Noah A. Smith and Luke Zettlemoyer},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ruk0nyQPec}\n}"
    },
    {
        "title": "Dynamic Discounted Counterfactual Regret Minimization",
        "authorids": [
            "~Hang_Xu5",
            "~Kai_Li2",
            "~Haobo_Fu2",
            "~QIANG_FU8",
            "~Junliang_Xing1",
            "~Jian_Cheng7"
        ],
        "keywords": [
            "imperfect-information games",
            "regret minimization",
            "Nash equilibrium"
        ],
        "abstract": "Counterfactual regret minimization (CFR) is a family of iterative algorithms showing promising results in solving imperfect-information games. Recent novel CFR variants (e.g., CFR+, DCFR) have significantly improved the convergence rate of the vanilla CFR. The key to these CFR variants\u2019 performance is weighting each iteration non-uniformly, i.e., discounting earlier iterations. However, these algorithms use a fixed, manually-specified scheme to weight each iteration, which enormously limits their potential. In this work, we propose Dynamic Discounted CFR (DDCFR), the first equilibrium-finding framework that discounts prior iterations using a dynamic, automatically-learned scheme. We formalize CFR\u2019s iteration process as a carefully designed Markov decision process and transform the discounting scheme learning problem into a policy optimization problem within it. The learned discounting scheme dynamically weights each iteration on the fly using information available at runtime. Experimental results across multiple games demonstrate that DDCFR\u2019s dynamic discounting scheme has a strong generalization ability and leads to faster convergence with improved performance. The code is  available at https://github.com/rpSebastian/DDCFR.",
        "_bibtex": "@inproceedings{\nxu2024dynamic,\ntitle={Dynamic Discounted Counterfactual Regret Minimization},\nauthor={Hang Xu and Kai Li and Haobo Fu and QIANG FU and Junliang Xing and Jian Cheng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=6PbvbLyqT6}\n}"
    },
    {
        "title": "GIO: Gradient Information Optimization for Training Dataset Selection",
        "authorids": [
            "~Dante_Everaert1",
            "~Christopher_Potts1"
        ],
        "keywords": [
            "data selection",
            "data-centric AI",
            "information theory",
            "kl divergence",
            "gradient",
            "natural language processing",
            "computer vision"
        ],
        "abstract": "It is often advantageous to train models on a subset of the available train examples, because the examples are of variable quality or because one would like to train with fewer examples, without sacrificing performance. We present Gradient Information Optimization (GIO), a scalable, task-agnostic approach to this data selection problem that requires only a small set of (unlabeled) examples representing a target distribution. GIO begins from a natural, information-theoretic objective that is intractable in practice. Our contribution is in showing that it can be made highly scalable through a simple relaxation of the objective and a highly efficient implementation. In experiments with machine translation, spelling correction, and image recognition, we show that GIO delivers outstanding results with very small train sets. These findings are robust to different representation models and hyperparameters for GIO itself. GIO is task- and domain-agnostic and can be applied out-of-the-box to new datasets and domains. We open source a pip-installable implementation of the algorithm as \"pip install grad-info-opt\".",
        "_bibtex": "@inproceedings{\neveraert2024gio,\ntitle={{GIO}: Gradient Information Optimization for Training Dataset Selection},\nauthor={Dante Everaert and Christopher Potts},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3NnfJnbJT2}\n}"
    },
    {
        "title": "SNIP: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training",
        "authorids": [
            "~Kazem_Meidani1",
            "~Parshin_Shojaee1",
            "~Chandan_K._Reddy1",
            "~Amir_Barati_Farimani2"
        ],
        "keywords": [
            "Symbolic Mathematics",
            "Pre-training",
            "Transformers",
            "Symbolic Regression",
            "Deep Learning"
        ],
        "abstract": "In an era where symbolic mathematical equations are indispensable for modeling complex natural phenomena, scientific inquiry often involves collecting observations and translating them into mathematical expressions. Recently, deep learning has emerged as a powerful tool for extracting insights from data. However, existing models typically specialize in either numeric or symbolic domains, and are usually trained in a supervised manner tailored to specific tasks. This approach neglects the substantial benefits that could arise from a task-agnostic multi-modal understanding between symbolic equations and their numeric counterparts. To bridge the gap, we introduce SNIP, a Symbolic-Numeric Integrated Pre-training model, which employs contrastive learning between symbolic and numeric domains, enhancing their mutual similarities in the embeddings. By performing latent space analysis, we observe that SNIP provides cross-domain insights into the representations, revealing that symbolic supervision enhances the embeddings of numeric data and vice versa. We evaluate SNIP across diverse tasks, including symbolic-to-numeric mathematical property prediction and numeric-to-symbolic equation discovery, commonly known as symbolic regression. Results show that SNIP effectively transfers to various tasks, consistently outperforming fully supervised baselines and competing strongly with established task-specific methods, especially in the low data regime scenarios where available data is limited.",
        "_bibtex": "@inproceedings{\nmeidani2024snip,\ntitle={{SNIP}: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training},\nauthor={Kazem Meidani and Parshin Shojaee and Chandan K. Reddy and Amir Barati Farimani},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=KZSEgJGPxu}\n}"
    },
    {
        "title": "Fantastic Gains and Where to Find Them: On the Existence and Prospect of General Knowledge Transfer between Any Pretrained Model",
        "authorids": [
            "~Karsten_Roth1",
            "~Lukas_Thede1",
            "~A._Sophia_Koepke1",
            "~Oriol_Vinyals1",
            "~Olivier_J_Henaff1",
            "~Zeynep_Akata1"
        ],
        "keywords": [
            "transfer learning",
            "pretraining",
            "weak-to-strong transfer",
            "continual learning"
        ],
        "abstract": "Training deep networks requires various design decisions regarding for instance their architecture, data augmentation, or optimization. In this work, we find these training variations to result in networks learning unique feature sets from the data. Using public model libraries comprising thousands of models trained on canonical datasets like ImageNet, we observe that for arbitrary pairings of pretrained models, one model extracts significant data context unavailable in the other \u2013 independent of overall performance. Given any arbitrary pairing of pretrained models and no external rankings (such as separate test sets, e.g. due to data privacy), we investigate if it is possible to transfer such \"complementary\" knowledge from one model to another without performance degradation \u2013 a task made particularly difficult as additional knowledge can be contained in stronger, equiperformant or weaker models. Yet facilitating robust transfer in scenarios agnostic to pretrained model pairings would unlock auxiliary gains and knowledge fusion from any model repository without restrictions on model and problem specifics - including from weaker, lower-performance models. This work therefore provides an initial, in-depth exploration on the viability of such general-purpose knowledge transfer. Across large-scale experiments, we first reveal the shortcomings of standard knowledge distillation techniques, and then propose a much more general extension through data partitioning for successful transfer between nearly all pretrained models, which we show can also be done unsupervised. Finally, we assess both the scalability and impact of fundamental model properties on successful model-agnostic knowledge transfer.",
        "_bibtex": "@inproceedings{\nroth2024fantastic,\ntitle={Fantastic Gains and Where to Find Them: On the Existence and Prospect of General Knowledge Transfer between Any Pretrained Model},\nauthor={Karsten Roth and Lukas Thede and A. Sophia Koepke and Oriol Vinyals and Olivier J Henaff and Zeynep Akata},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=m50eKHCttz}\n}"
    },
    {
        "title": "Robustifying State-space Models for Long Sequences via Approximate Diagonalization",
        "authorids": [
            "~Annan_Yu1",
            "~Arnur_Nigmetov1",
            "~Dmitriy_Morozov1",
            "~Michael_W._Mahoney1",
            "~N._Benjamin_Erichson1"
        ],
        "keywords": [
            "state-space models",
            "sequence models",
            "Long-Range Arena",
            "recurrent neural networks"
        ],
        "abstract": "State-space models (SSMs) have recently emerged as a framework for learning long-range sequence tasks. An example is the structured state-space sequence (S4) layer, which uses the diagonal-plus-low-rank structure of the HiPPO initialization framework. However, the complicated structure of the S4 layer poses challenges; and, in an effort to address these challenges, models such as S4D and S5 have considered a purely diagonal structure. This choice simplifies the implementation, improves computational efficiency, and allows channel communication. However, diagonalizing the HiPPO framework is itself an ill-posed problem. In this paper, we propose a general solution for this and related ill-posed diagonalization problems in machine learning. We introduce a generic, backward-stable ``perturb-then-diagonalize'' (PTD) methodology, which is based on the pseudospectral theory of non-normal operators, and which may be interpreted as the approximate diagonalization of the non-normal matrices defining SSMs. Based on this, we introduce the S4-PTD and S5-PTD models. Through theoretical analysis of the transfer functions of different initialization schemes, we demonstrate that the S4-PTD/S5-PTD initialization strongly converges to the HiPPO framework, while the S4D/S5 initialization only achieves weak convergences. As a result, our new models show resilience to Fourier-mode noise-perturbed inputs, a crucial property not achieved by the S4D/S5 models. In addition to improved robustness, our S5-PTD model averages 87.6% accuracy on the Long-Range Arena benchmark, demonstrating that the PTD methodology helps to improve the accuracy of deep learning models.",
        "_bibtex": "@inproceedings{\nyu2024robustifying,\ntitle={Robustifying State-space Models for Long Sequences via Approximate Diagonalization},\nauthor={Annan Yu and Arnur Nigmetov and Dmitriy Morozov and Michael W. Mahoney and N. Benjamin Erichson},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=DjeQ39QoLQ}\n}"
    },
    {
        "title": "Provable Offline Preference-Based Reinforcement Learning",
        "authorids": [
            "~Wenhao_Zhan1",
            "~Masatoshi_Uehara1",
            "~Nathan_Kallus1",
            "~Jason_D._Lee1",
            "~Wen_Sun1"
        ],
        "keywords": [
            "reinforcement learning theory",
            "offline reinforcement learning"
        ],
        "abstract": "In this paper, we investigate the problem of offline Preference-based Reinforcement Learning (PbRL) with human feedback where feedback is available in the form of preference between trajectory pairs rather than explicit rewards. Our proposed algorithm consists of two main steps: (1) estimate the implicit reward using Maximum Likelihood Estimation (MLE) with general function approximation from offline data and (2) solve a distributionally robust planning problem over a confidence set around the MLE. We consider the general reward setting where the reward can be defined over the whole trajectory and provide a novel guarantee that allows us to learn any target policy with a polynomial number of samples, as long as the target policy is covered by the offline data. This guarantee is the first of its kind with general function approximation. To measure the coverage of the target policy, we introduce a new single-policy concentrability coefficient, which can be upper bounded by the per-trajectory concentrability coefficient. We also establish lower bounds that highlight the necessity of such concentrability and the difference from standard RL, where state-action-wise rewards are directly observed. We further extend and analyze our algorithm when the feedback is given over action pairs.",
        "_bibtex": "@inproceedings{\nzhan2024provable,\ntitle={Provable Offline Preference-Based Reinforcement Learning},\nauthor={Wenhao Zhan and Masatoshi Uehara and Nathan Kallus and Jason D. Lee and Wen Sun},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tVMPfEGT2w}\n}"
    },
    {
        "title": "Can LLMs Keep a Secret? Testing  Privacy  Implications of Language Models  via Contextual Integrity Theory",
        "authorids": [
            "~Niloofar_Mireshghallah1",
            "~Hyunwoo_Kim3",
            "~Xuhui_Zhou1",
            "~Yulia_Tsvetkov1",
            "~Maarten_Sap1",
            "~Reza_Shokri1",
            "~Yejin_Choi1"
        ],
        "keywords": [
            "Contextual Integrity",
            "Privacy",
            "Theory of Mind"
        ],
        "abstract": "Existing efforts on quantifying privacy implications for large language models (LLMs) solely focus on measuring leakage of training data. In this work, we shed light on the often-overlooked interactive settings where an LLM receives information from multiple sources and generates an output to be shared with other entities, creating the potential of exposing sensitive input data in inappropriate contexts. In these scenarios, humans nat- urally uphold privacy by choosing whether or not to disclose information depending on the context. We ask the question \u201cCan LLMs demonstrate an equivalent discernment and reasoning capability when considering privacy in context?\u201d We propose CONFAIDE, a benchmark grounded in the theory of contextual integrity and designed to identify critical weaknesses in the privacy reasoning capabilities of instruction-tuned LLMs. CONFAIDE consists of four tiers, gradually increasing in complexity, with the final tier evaluating contextual privacy reasoning and theory of mind capabilities. Our experiments show that even commercial models such as GPT-4 and ChatGPT reveal private information in contexts that humans would not, 39% and 57% of the time, respectively, highlighting the urgent need for a new direction of privacy-preserving approaches as we demonstrate a larger underlying problem stemmed in the models\u2019 lack of reasoning capabilities.",
        "_bibtex": "@inproceedings{\nmireshghallah2024can,\ntitle={Can {LLM}s Keep a Secret? Testing  Privacy  Implications of Language Models  via Contextual Integrity Theory},\nauthor={Niloofar Mireshghallah and Hyunwoo Kim and Xuhui Zhou and Yulia Tsvetkov and Maarten Sap and Reza Shokri and Yejin Choi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=gmg7t8b4s0}\n}"
    },
    {
        "title": "Provable Reward-Agnostic Preference-Based Reinforcement Learning",
        "authorids": [
            "~Wenhao_Zhan1",
            "~Masatoshi_Uehara1",
            "~Wen_Sun1",
            "~Jason_D._Lee1"
        ],
        "keywords": [
            "reinforcement learning theory",
            "reward-agnostic learning"
        ],
        "abstract": "Preference-based Reinforcement Learning (PbRL) is a paradigm in which an RL agent learns to optimize a task using pair-wise preference-based feedback over trajectories, rather than explicit reward signals. While PbRL has demonstrated practical success in fine-tuning language models, existing theoretical work focuses on regret minimization and fails to capture most of the practical frameworks. In this study, we fill in such a gap between theoretical PbRL and practical algorithms by proposing a theoretical reward-agnostic PbRL framework where exploratory trajectories that enable accurate learning of hidden reward functions are acquired before collecting any human feedback. Theoretical analysis demonstrates that our algorithm requires less human feedback for learning the optimal policy under preference-based models with linear parameterization and unknown transitions, compared to the existing theoretical literature. Specifically, our framework can incorporate linear and low-rank MDPs with efficient sample complexity. Additionally, we investigate reward-agnostic RL with action-based comparison feedback and introduce an efficient querying algorithm tailored to this scenario.",
        "_bibtex": "@inproceedings{\nzhan2024provable,\ntitle={Provable Reward-Agnostic Preference-Based Reinforcement Learning},\nauthor={Wenhao Zhan and Masatoshi Uehara and Wen Sun and Jason D. Lee},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=yTBXeXdbMf}\n}"
    },
    {
        "title": "Unleashing the Potential of Fractional Calculus in Graph Neural Networks with FROND",
        "authorids": [
            "~Qiyu_Kang2",
            "~Kai_Zhao7",
            "~Qinxu_Ding1",
            "~Feng_Ji2",
            "~Xuhao_Li2",
            "~Wenfei_Liang1",
            "~Yang_Song7",
            "~Wee_Peng_Tay1"
        ],
        "keywords": [
            "graph neural network"
        ],
        "abstract": "We introduce the FRactional-Order graph Neural Dynamical network (FROND), a new continuous graph neural network (GNN) framework. Unlike traditional continuous GNNs that rely on integer-order differential equations, FROND employs the Caputo fractional derivative to leverage the non-local properties of fractional calculus. This approach enables the capture of long-term dependencies in feature updates, moving beyond the Markovian update mechanisms in conventional integer-order models and offering enhanced capabilities in graph representation learning. \nWe offer an interpretation of the node feature updating process in FROND from a non-Markovian random walk perspective when the feature updating is particularly governed by a diffusion process.\nWe demonstrate analytically that oversmoothing can be mitigated in this setting.\nExperimentally, we validate the FROND framework by comparing the fractional adaptations of various established integer-order continuous GNNs, demonstrating their consistently improved performance and underscoring the framework's potential as an effective extension to enhance traditional continuous GNNs.\nThe code is available at \\url{https://github.com/zknus/ICLR2024-FROND}.",
        "_bibtex": "@inproceedings{\nkang2024unleashing,\ntitle={Unleashing the Potential of Fractional Calculus in Graph Neural Networks with {FROND}},\nauthor={Qiyu Kang and Kai Zhao and Qinxu Ding and Feng Ji and Xuhao Li and Wenfei Liang and Yang Song and Wee Peng Tay},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=wcka3bd7P4}\n}"
    },
    {
        "title": "MetaPhysiCa: Improving OOD Robustness in Physics-informed Machine Learning",
        "authorids": [
            "~S_Chandra_Mouli1",
            "~Muhammad_Alam1",
            "~Bruno_Ribeiro1"
        ],
        "keywords": [
            "physics-informed machine learning",
            "OOD robustness",
            "meta learning",
            "causal structure discovery"
        ],
        "abstract": "A fundamental challenge in physics-informed machine learning (PIML) is the design of robust PIML methods for out-of-distribution (OOD) forecasting tasks. These OOD tasks require learning-to-learn from observations of the same (ODE) dynamical system with different unknown ODE parameters, and demand accurate forecasts even under out-of-support initial conditions and out-of-support ODE parameters. In this work we propose to improve the OOD robustness of PIML via a meta-learning procedure for causal structure discovery. Using three different OOD tasks, we empirically observe that the proposed approach significantly outperforms existing state-of-the-art PIML and deep learning methods (with $2\\times$ to $28\\times$ lower OOD errors).",
        "_bibtex": "@inproceedings{\nmouli2024metaphysica,\ntitle={MetaPhysiCa: Improving {OOD} Robustness in Physics-informed Machine Learning},\nauthor={S Chandra Mouli and Muhammad Alam and Bruno Ribeiro},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=KrWuDiW4Qm}\n}"
    },
    {
        "title": "Views Can Be Deceiving: Improved SSL Through Feature Space Augmentation",
        "authorids": [
            "~Kimia_Hamidieh1",
            "~Haoran_Zhang4",
            "~Swami_Sankaranarayanan1",
            "~Marzyeh_Ghassemi2"
        ],
        "keywords": [
            "Representation Learning",
            "Spurious Correlations",
            "Self-supervised Learning"
        ],
        "abstract": "Supervised learning methods have been found to exhibit inductive biases favoring simpler features. When such features are spuriously correlated with the label, this can result in suboptimal performance on minority subgroups. Despite the growing popularity of methods which learn from unlabeled data, the extent to which these representations rely on spurious features for prediction is unclear. In this work, we explore the impact of spurious features on Self-Supervised Learning (SSL) for visual representation learning. We first empirically show that commonly used augmentations in SSL can cause undesired invariances in the image space, and illustrate this with a simple example. We further show that classical approaches in combating spurious correlations, such as dataset re-sampling during SSL, do not consistently lead to invariant representations. Motivated by these findings, we propose LateTVG to remove spurious information from these representations during pre-training, by regularizing later layers of the encoder via pruning. We find that our method produces representations which outperform the baselines on several benchmarks, without the need for group or label information during SSL.",
        "_bibtex": "@inproceedings{\nhamidieh2024views,\ntitle={Views Can Be Deceiving: Improved {SSL} Through Feature Space Augmentation},\nauthor={Kimia Hamidieh and Haoran Zhang and Swami Sankaranarayanan and Marzyeh Ghassemi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=mutJBk3ILg}\n}"
    },
    {
        "title": "Project and Probe: Sample-Efficient Adaptation by Interpolating Orthogonal Features",
        "authorids": [
            "~Annie_S_Chen1",
            "~Yoonho_Lee1",
            "~Amrith_Setlur1",
            "~Sergey_Levine1",
            "~Chelsea_Finn1"
        ],
        "keywords": [
            "distribution-shift robustness",
            "fine-tuning",
            "adaptation",
            "transfer learning"
        ],
        "abstract": "Transfer learning with a small amount of target data is an effective and common approach to adapting a pre-trained model to distribution shifts. In some situations, target data labels may be expensive to obtain, so we may only have access to a limited number of target data points. To make the most of a very small target dataset, we propose a lightweight, sample-efficient approach that learns a diverse set of features and adapts to a target distribution by interpolating these features. Our approach, Project and Probe (Pro$^2$), first learns a linear projection that maps a pre-trained embedding onto orthogonal directions while being predictive of labels in the source dataset. The goal of this step is to learn a variety of predictive features, so that at least some of them remain useful after distribution shift. Pro$^2$ then learns a linear classifier on top of these projected features using a small target dataset. Theoretically, we find that Pro$^2$ results in more sample-efficient generalization by inducing a favorable bias-variance tradeoff. Our experiments on four datasets, with multiple distribution shift settings for each, show that Pro$^2$ improves performance by 5-15% when given limited target data compared to prior methods such as standard linear probing.",
        "_bibtex": "@inproceedings{\nchen2024project,\ntitle={Project and Probe: Sample-Efficient Adaptation by Interpolating Orthogonal Features},\nauthor={Annie S Chen and Yoonho Lee and Amrith Setlur and Sergey Levine and Chelsea Finn},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=f6CBQYxXvr}\n}"
    },
    {
        "title": "Implicit bias of SGD in $L_2$-regularized linear DNNs: One-way jumps from high to low rank",
        "authorids": [
            "~Zihan_Wang20",
            "~Arthur_Jacot1"
        ],
        "keywords": [
            "implicit bias",
            "SGD",
            "low-rank",
            "linear networks"
        ],
        "abstract": "The $L_{2}$-regularized loss of Deep Linear Networks (DLNs) with\nmore than one hidden layers has multiple local minima, corresponding\nto matrices with different ranks. In tasks such as matrix completion,\nthe goal is to converge to the local minimum with the smallest rank\nthat still fits the training data. While rank-underestimating minima\ncan be avoided since they do not fit the data, GD might get\nstuck at rank-overestimating minima. We show that with SGD, there is always a probability to jump\nfrom a higher rank minimum to a lower rank one, but the probability\nof jumping back is zero. More precisely, we define a sequence of sets\n$B_{1}\\subset B_{2}\\subset\\cdots\\subset B_{R}$ so that $B_{r}$\ncontains all minima of rank $r$ or less (and not more) that are absorbing\nfor small enough ridge parameters $\\lambda$ and learning rates $\\eta$:\nSGD has prob. 0 of leaving $B_{r}$, and from any starting point there\nis a non-zero prob. for SGD to go in $B_{r}$.",
        "_bibtex": "@inproceedings{\nwang2024implicit,\ntitle={Implicit bias of {SGD} in \\$L\\_2\\$-regularized linear {DNN}s: One-way jumps from high to low rank},\nauthor={Zihan Wang and Arthur Jacot},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=P1aobHnjjj}\n}"
    },
    {
        "title": "Whole-Song Hierarchical Generation of Symbolic Music Using Cascaded Diffusion Models",
        "authorids": [
            "~Ziyu_Wang10",
            "~Lejun_Min1",
            "~Gus_Xia1"
        ],
        "keywords": [
            "Cascaded generative models",
            "Diffusion models",
            "Symbolic Music Generation"
        ],
        "abstract": "Recent deep music generation studies have put much emphasis on long-term generation with structures. However, we are yet to see high-quality, well-structured **whole-song** generation. In this paper, we make the first attempt to model a full music piece under the realization of *compositional hierarchy*. With a focus on symbolic representations of pop songs, we define a hierarchical language, in which each level of hierarchy focuses on the semantics and context dependency at a certain music scope. The high-level languages reveal whole-song form, phrase, and cadence, whereas the low-level languages focus on notes, chords, and their local patterns. A cascaded diffusion model is trained to model the hierarchical language, where each level is conditioned on its upper levels. Experiments and analysis show that our model is capable of generating full-piece music with recognizable global verse-chorus structure and cadences, and the music quality is higher than the baselines. Additionally, we show that the proposed model is *controllable* in a flexible way. By sampling from the interpretable hierarchical languages or adjusting pre-trained external representations, users can control the music flow via various features such as phrase harmonic structures, rhythmic patterns, and accompaniment texture.",
        "_bibtex": "@inproceedings{\nwang2024wholesong,\ntitle={Whole-Song Hierarchical Generation of Symbolic Music Using Cascaded Diffusion Models},\nauthor={Ziyu Wang and Lejun Min and Gus Xia},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=sn7CYWyavh}\n}"
    },
    {
        "title": "Evaluating the Zero-shot Robustness of Instruction-tuned Language Models",
        "authorids": [
            "~Jiuding_Sun1",
            "~Chantal_Shaib1",
            "~Byron_C_Wallace1"
        ],
        "keywords": [
            "Instruction Tuning",
            "Robustness",
            "Large Language Models"
        ],
        "abstract": "Instruction fine-tuning has recently emerged as a promising approach for improving the zero-shot capabilities of Large Language Models (LLMs) on new tasks. This technique has shown particular strength in improving the performance of modestly sized LLMs, sometimes inducing performance competitive with much larger model variants. In this paper, we ask two questions: (1) How sensitive are instruction-tuned models to the particular phrasings of instructions, and, (2) How can we make them more robust to such natural language variation? To answer the former, we collect a set of 319 instructions manually written by NLP practitioners for over 80 unique tasks included in widely used benchmarks, and we evaluate the variance and average performance of these instructions as compared to instruction phrasings observed during instruction fine-tuning. We find that using novel (unobserved) but appropriate instruction phrasings consistently degrades model performance, sometimes substantially so. Further, such natural instructions yield a wide variance in downstream performance, despite their semantic equivalence. Put another way, instruction-tuned models are not especially robust to instruction re-phrasings. \nWe propose a simple method to mitigate this issue by introducing ``soft prompt'' embedding parameters and optimizing these to maximize the similarity between representations of semantically equivalent instructions. We show that this method consistently improves the robustness of instruction-tuned models.",
        "_bibtex": "@inproceedings{\nsun2024evaluating,\ntitle={Evaluating the Zero-shot Robustness of Instruction-tuned Language Models},\nauthor={Jiuding Sun and Chantal Shaib and Byron C Wallace},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=g9diuvxN6D}\n}"
    },
    {
        "title": "Critical Learning Periods Emerge Even in Deep Linear Networks",
        "authorids": [
            "~Michael_Kleinman2",
            "~Alessandro_Achille1",
            "~Stefano_Soatto1"
        ],
        "keywords": [
            "critical learning periods",
            "deep neural networks",
            "gradient descent",
            "linear networks"
        ],
        "abstract": "Critical learning periods are periods early in development where temporary sensory deficits can have a permanent effect on behavior and learned representations. \nDespite the radical differences between biological and artificial networks, critical learning periods have been empirically observed in both systems. This suggests that critical periods may be fundamental to learning and not an accident of biology.\nYet, why exactly critical periods emerge in deep networks is still an open question, and in particular it is unclear whether the critical periods observed in both systems depend on particular architectural or optimization details. To isolate the key underlying factors, we focus on deep linear network models, and show that, surprisingly, such networks also display much of the behavior seen in biology and artificial networks, while being amenable to analytical treatment. We show that critical periods depend on the depth of the model and structure of the data distribution. We also show analytically and in simulations that the learning of features is tied to competition between sources. Finally, we extend our analysis to multi-task learning to show that pre-training on certain tasks can damage the transfer performance on new tasks, and show how this depends on the relationship between tasks and the duration of the pre-training stage. To the best of our knowledge, our work provides the first analytically tractable model that sheds light into why critical learning periods emerge in biological and artificial networks.",
        "_bibtex": "@inproceedings{\nkleinman2024critical,\ntitle={Critical Learning Periods Emerge Even in Deep Linear Networks},\nauthor={Michael Kleinman and Alessandro Achille and Stefano Soatto},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Aq35gl2c1k}\n}"
    },
    {
        "title": "MOTOR: A Time-to-Event Foundation Model For Structured Medical Records",
        "authorids": [
            "~Ethan_Steinberg1",
            "~Jason_Alan_Fries1",
            "~Yizhe_Xu1",
            "~Nigam_Shah1"
        ],
        "keywords": [
            "foundation models",
            "time-to-event",
            "electronic health records",
            "deep learning",
            "self-supervised learning",
            "transfer learning"
        ],
        "abstract": "We present a self-supervised, time-to-event (TTE) foundation model called MOTOR (Many Outcome Time Oriented Representations) which is pretrained on timestamped sequences of events in electronic health records (EHR) and health insurance claims. TTE models are used for estimating the probability distribution of the time until a specific event occurs, which is an important task in medical settings. TTE models provide many advantages over classification using fixed time horizons, including naturally handling censored observations, but are challenging to train with limited labeled data. MOTOR addresses this challenge by pretraining on up to 55M patient records (9B clinical events). We evaluate MOTOR's transfer learning performance on 19 tasks, across 3 patient databases (a private EHR system, MIMIC-IV, and Merative claims data). Task-specific models adapted from MOTOR improve time-dependent C statistics by 4.6\\% over state-of-the-art, improve label efficiency by up to 95\\%, and are more robust to temporal distributional shifts. We further evaluate cross-site portability by adapting our MOTOR foundation model for six prediction tasks on the MIMIC-IV dataset, where it outperforms all baselines. MOTOR is the first foundation model for medical TTE predictions and we release a 143M parameter pretrained model for research use at https://huggingface.co/StanfordShahLab/motor-t-base.",
        "_bibtex": "@inproceedings{\nsteinberg2024motor,\ntitle={{MOTOR}: A Time-to-Event Foundation Model For Structured Medical Records},\nauthor={Ethan Steinberg and Jason Alan Fries and Yizhe Xu and Nigam Shah},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=NialiwI2V6}\n}"
    },
    {
        "title": "GenSim: Generating Robotic Simulation Tasks via Large Language Models",
        "authorids": [
            "~Lirui_Wang1",
            "~Yiyang_Ling1",
            "~Zhecheng_Yuan1",
            "~Mohit_Shridhar1",
            "~Chen_Bao2",
            "~Yuzhe_Qin1",
            "~Bailin_Wang3",
            "~Huazhe_Xu1",
            "~Xiaolong_Wang3"
        ],
        "keywords": [
            "LLM Code Generation",
            "Robotic Simulation",
            "Multi-task Policy Learning"
        ],
        "abstract": "Collecting large amounts of real-world interaction data to train general robotic policies is often prohibitively expensive, thus motivating the use of simulation data. However, existing methods for data generation have generally focused on scene-level diversity (e.g., object instances and poses) rather than task-level diversity, due to the human effort required to come up with and verify novel tasks. This has made it challenging for policies trained on simulation data to demonstrate significant task-level generalization. In this paper, we propose to automatically generate rich simulation environments and expert demonstrations by exploiting a large language models' (LLM) grounding and coding ability. Our approach, dubbed GenSim, has two modes: goal-directed generation, wherein a target task is given to the LLM and the LLM proposes a task curriculum to solve the target task, and exploratory generation, wherein the LLM  bootstraps from previous tasks and iteratively proposes novel tasks that would be helpful in solving more complex tasks. We use GPT4 to expand the existing benchmark by ten times to over 100 tasks, on which we conduct supervised finetuning and evaluate several LLMs including finetuned GPTs and Code Llama on code generation for robotic simulation tasks. Furthermore, we observe that LLMs-generated simulation programs can enhance task-level generalization significantly when used for multitask policy training. We further find that with minimal sim-to-real adaptation, the multitask policies pretrained on GPT4-generated simulation tasks exhibit stronger transfer to unseen long-horizon tasks in the real world and outperform baselines by 25%. See our project website (https://gen-sim.github.io) and demo (https://huggingface.co/spaces/Gen-Sim/Gen-Sim) for visualizations and open-source models and datasets.",
        "_bibtex": "@inproceedings{\nwang2024gensim,\ntitle={GenSim: Generating Robotic Simulation Tasks via Large Language Models},\nauthor={Lirui Wang and Yiyang Ling and Zhecheng Yuan and Mohit Shridhar and Chen Bao and Yuzhe Qin and Bailin Wang and Huazhe Xu and Xiaolong Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=OI3RoHoWAN}\n}"
    },
    {
        "title": "Understanding Augmentation-based Self-Supervised Representation Learning via RKHS Approximation and Regression",
        "authorids": [
            "~Runtian_Zhai1",
            "~Bingbin_Liu1",
            "~Andrej_Risteski2",
            "~J_Zico_Kolter1",
            "~Pradeep_Kumar_Ravikumar1"
        ],
        "keywords": [
            "Learning Theory",
            "Representation Learning",
            "Self-supervised Learning",
            "Data Augmentation",
            "RKHS Approximation",
            "RKHS Regression"
        ],
        "abstract": "Data augmentation is critical to the empirical success of modern self-supervised representation learning, such as contrastive learning and masked language modeling.\nHowever, a theoretical understanding of the exact role of the augmentation remains limited.\nRecent work has built the connection between self-supervised learning and the approximation of the top eigenspace of a graph Laplacian operator, suggesting that learning a linear probe atop such representation can be connected to RKHS regression.\nBuilding on this insight, this work delves into a statistical analysis of augmentation-based pretraining.\nStarting from the isometry property, a geometric characterization of the target function given by the augmentation, we disentangle the effects of the model and the augmentation,\nand prove two generalization bounds that are free of model complexity.\nOur first bound works for an arbitrary encoder, and it is the sum of an estimation error bound incurred by fitting a linear probe, and an approximation error bound by RKHS approximation.\nOur second bound specifically addresses the case\nwhere the encoder extracts the top-d eigenspace of a finite-sample-based approximation of the underlying RKHS.\nA key ingredient in our analysis is the *augmentation complexity*,\nwhich we use to quantitatively compare different augmentations and analyze their impact on downstream performance.",
        "_bibtex": "@inproceedings{\nzhai2024understanding,\ntitle={Understanding Augmentation-based Self-Supervised Representation Learning via {RKHS} Approximation and Regression},\nauthor={Runtian Zhai and Bingbin Liu and Andrej Risteski and J Zico Kolter and Pradeep Kumar Ravikumar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Ax2yRhCQr1}\n}"
    },
    {
        "title": "Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs",
        "authorids": [
            "~Angelica_Chen1",
            "~Ravid_Shwartz-Ziv2",
            "~Kyunghyun_Cho1",
            "~Matthew_L_Leavitt1",
            "~Naomi_Saphra1"
        ],
        "keywords": [
            "interpretability",
            "BERT",
            "syntax",
            "phase changes",
            "simplicity bias",
            "training dynamics"
        ],
        "abstract": "Most interpretability research in NLP focuses on understanding the behavior and features of a fully trained model. However, certain insights into model behavior may only be accessible by observing the trajectory of the training process. We present a case study of syntax acquisition in masked language models (MLMs) that demonstrates how analyzing the evolution of interpretable artifacts throughout training deepens our understanding of emergent behavior. In particular, we study Syntactic Attention Structure (SAS), a naturally emerging property of MLMs wherein specific Transformer heads tend to focus on specific syntactic relations. We identify a brief window in pretraining when models abruptly acquire SAS, concurrent with a steep drop in loss. This breakthrough precipitates the subsequent acquisition of linguistic capabilities. We then examine the causal role of SAS by manipulating SAS during training, and demonstrate that SAS is necessary for the development of grammatical capabilities. We further find that SAS competes with other beneficial traits during training, and that briefly suppressing SAS improves model quality. These findings offer an interpretation of a real-world example of both simplicity bias and breakthrough training dynamics.",
        "_bibtex": "@inproceedings{\nchen2024sudden,\ntitle={Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in {MLM}s},\nauthor={Angelica Chen and Ravid Shwartz-Ziv and Kyunghyun Cho and Matthew L Leavitt and Naomi Saphra},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MO5PiKHELW}\n}"
    },
    {
        "title": "SE(3)-Stochastic Flow Matching for Protein Backbone Generation",
        "authorids": [
            "~Joey_Bose1",
            "~Tara_Akhound-Sadegh1",
            "~Guillaume_Huguet1",
            "~Kilian_FATRAS1",
            "~Jarrid_Rector-Brooks2",
            "~Cheng-Hao_Liu1",
            "~Andrei_Cristian_Nica1",
            "~Maksym_Korablyov1",
            "~Michael_M._Bronstein1",
            "~Alexander_Tong1"
        ],
        "keywords": [
            "Proteins; Equivariance; Riemannian; Flow Matching; Generative models"
        ],
        "abstract": "The computational design of novel protein structures has the potential to impact numerous scientific disciplines greatly. Toward this goal, we introduce \\foldflow, a series of novel generative models of increasing modeling power based on the flow-matching paradigm over $3\\mathrm{D}$ rigid motions---i.e. the group $\\mathrm{SE(3)}$---enabling accurate modeling of protein backbones. We first introduce $\\text{FoldFlow-Base}$, a simulation-free approach to learning deterministic continuous-time dynamics and matching invariant target distributions on $\\mathrm{SE(3)}$. We next accelerate training by incorporating Riemannian optimal transport to create $\\text{FoldFlow-OT}$, leading to the construction of both more simple and stable flows. Finally, we design \\foldflowsfm, coupling both Riemannian OT and simulation-free training to learn stochastic continuous-time dynamics over $\\mathrm{SE(3)}$. Our family of $\\text{FoldFlow}$, generative models offers several key advantages over previous approaches to the generative modeling of proteins: they are more stable and faster to train than diffusion-based approaches, and our models enjoy the ability to map any invariant source distribution to any invariant target distribution over $\\mathrm{SE(3)}$. Empirically, we validate $\\text{FoldFlow}$, on protein backbone generation of up to $300$ amino acids leading to high-quality designable, diverse, and novel samples.",
        "_bibtex": "@inproceedings{\nbose2024sestochastic,\ntitle={{SE}(3)-Stochastic Flow Matching for Protein Backbone Generation},\nauthor={Joey Bose and Tara Akhound-Sadegh and Guillaume Huguet and Kilian FATRAS and Jarrid Rector-Brooks and Cheng-Hao Liu and Andrei Cristian Nica and Maksym Korablyov and Michael M. Bronstein and Alexander Tong},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=kJFIH23hXb}\n}"
    },
    {
        "title": "DP-OPT: Make Large Language Model Your Privacy-Preserving Prompt Engineer",
        "authorids": [
            "~Junyuan_Hong1",
            "~Jiachen_T._Wang1",
            "~Chenhui_Zhang2",
            "~Zhangheng_LI2",
            "~Bo_Li19",
            "~Zhangyang_Wang1"
        ],
        "keywords": [
            "large language model",
            "privacy",
            "prompt tuing"
        ],
        "abstract": "Large Language Models (LLMs) have emerged as dominant tools for various tasks, particularly when tailored for a specific target by prompt tuning. Nevertheless, concerns surrounding data privacy present obstacles due to the tuned prompts' dependency on sensitive private information. A practical solution is to host a local LLM and optimize a soft prompt privately using data. Yet, hosting a local model becomes problematic when model ownership is protected. Alternative methods, like sending data to the model's provider for training, intensify these privacy issues facing an untrusted provider. In this paper, we present a novel solution called Differentially-Private Offsite Prompt Tuning (DP-OPT) to address this challenge. Our approach involves tuning a discrete prompt on the client side and then applying it to the desired cloud models. We demonstrate that prompts suggested by LLMs themselves can be transferred without compromising performance significantly. To ensure that the prompts do not leak private information, we introduce the first private prompt generation mechanism, by a differentially-private (DP) ensemble of in-context learning with private demonstrations.  With DP-OPT, generating privacy-preserving prompts by Vicuna-7b can yield competitive performance compared to non-private in-context learning on GPT3.5 or local private prompt tuning.\nCodes are available at https://github.com/VITA-Group/DP-OPT.",
        "_bibtex": "@inproceedings{\nhong2024dpopt,\ntitle={{DP}-{OPT}: Make Large Language Model Your Privacy-Preserving Prompt Engineer},\nauthor={Junyuan Hong and Jiachen T. Wang and Chenhui Zhang and Zhangheng LI and Bo Li and Zhangyang Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Ifz3IgsEPX}\n}"
    },
    {
        "title": "Geographic Location Encoding with Spherical Harmonics and Sinusoidal Representation Networks",
        "authorids": [
            "~Marc_Ru\u00dfwurm1",
            "~Konstantin_Klemmer1",
            "~Esther_Rolf1",
            "~Robin_Zbinden1",
            "~Devis_Tuia1"
        ],
        "keywords": [
            "Location Encoding",
            "Positional Encoding",
            "Implicit Neural Representations",
            "Species Distribution Modeling"
        ],
        "abstract": "Learning representations of geographical space is vital for any machine learning model that integrates geolocated data, spanning application domains such as remote sensing, ecology, or epidemiology. Recent work embeds coordinates using sine and cosine projections based on Double Fourier Sphere (DFS) features. These embeddings assume a rectangular data domain even on global data, which can lead to artifacts, especially at the poles. At the same time, little attention has been paid to the exact design of the neural network architectures with which these functional embeddings are combined. This work proposes a novel location encoder for globally distributed geographic data that combines spherical harmonic basis functions, natively defined on spherical surfaces, with sinusoidal representation networks (SirenNets) that can be interpreted as learned Double Fourier Sphere embedding. We systematically evaluate positional embeddings and neural network architectures across various benchmarks and synthetic evaluation datasets. In contrast to previous approaches that require the combination of both positional encoding and neural networks to learn meaningful representations, we show that both spherical harmonics and sinusoidal representation networks are competitive on their own but set state-of-the-art performances across tasks when combined. The model code and experiments are available at https://github.com/marccoru/locationencoder.",
        "_bibtex": "@inproceedings{\nru{\\ss}wurm2024geographic,\ntitle={Geographic Location Encoding with Spherical Harmonics and Sinusoidal Representation Networks},\nauthor={Marc Ru{\\ss}wurm and Konstantin Klemmer and Esther Rolf and Robin Zbinden and Devis Tuia},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=PudduufFLa}\n}"
    },
    {
        "title": "A General Framework for User-Guided Bayesian Optimization",
        "authorids": [
            "~Carl_Hvarfner1",
            "~Frank_Hutter1",
            "~Luigi_Nardi1"
        ],
        "keywords": [
            "Bayesian Optimization",
            "Hyperparameter Optimization",
            "Gaussian Processes"
        ],
        "abstract": "The optimization of expensive-to-evaluate black-box functions is prevalent in various scientific disciplines. Bayesian optimization is an automatic, general and sample-efficient method to solve these problems with minimal knowledge of the the underlying function dynamics. However, the ability of Bayesian optimization to incorporate prior knowledge or beliefs about the function at hand in order to accelerate the optimization is limited, which reduces its appeal for knowledgeable practitioners with tight  budgets. To allow domain experts to customize the optimization routine, we propose ColaBO, the first Bayesian-principled framework for incorporating prior beliefs beyond the typical kernel structure, such as the likely location of the optimizer or the optimal value. The generality of ColaBO makes it applicable across different Monte Carlo acquisition functions and types of user beliefs. We empirically demonstrate ColaBO's ability to substantially accelerate optimization when the prior information is accurate, and to retain approximately default performance when it is misleading.",
        "_bibtex": "@inproceedings{\nhvarfner2024a,\ntitle={A General Framework for User-Guided Bayesian Optimization},\nauthor={Carl Hvarfner and Frank Hutter and Luigi Nardi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=NjU0jtXcYn}\n}"
    },
    {
        "title": "Lemur: Harmonizing Natural Language and Code for Language Agents",
        "authorids": [
            "~Yiheng_Xu1",
            "~Hongjin_SU1",
            "~Chen_Xing2",
            "~Boyu_Mi1",
            "~Qian_Liu2",
            "~Weijia_Shi1",
            "~Binyuan_Hui1",
            "~Fan_Zhou6",
            "~Yitao_Liu2",
            "~Tianbao_Xie1",
            "~Zhoujun_Cheng1",
            "~Siheng_Zhao1",
            "~Lingpeng_Kong1",
            "~Bailin_Wang3",
            "~Caiming_Xiong1",
            "~Tao_Yu5"
        ],
        "keywords": [
            "large language model",
            "agent",
            "code generation",
            "reasoning",
            "decision making"
        ],
        "abstract": "We introduce Lemur and Lemur-Chat, openly accessible language models optimized\nfor both natural language and coding capabilities to serve as the backbone\nof versatile language agents. The evolution from language chat models to\nfunctional language agents demands that models not only master human interaction,\nreasoning, and planning but also ensure grounding in the relevant environments.\nThis calls for a harmonious blend of language and coding capabilities\nin the models. Lemur and Lemur-Chat are proposed to address this necessity,\ndemonstrating balanced proficiencies in both domains, unlike existing\nopen-source models that tend to specialize in either. Through meticulous pretraining\nusing a code-intensive corpus and instruction fine-tuning on text and code\ndata, our models achieve state-of-the-art averaged performance across diverse\ntext and coding benchmarks. Comprehensive experiments demonstrate Lemur\u2019s\nsuperiority over existing open-source models and its proficiency across various\nagent tasks involving human communication, tool usage, and interaction under\nfully- and partially- observable environments. The harmonization between natural\nand programming languages enables Lemur-Chat to significantly narrow the\ngap with proprietary models on agent abilities, providing key insights into developing\nadvanced open-source agents adept at reasoning, planning, and operating\nseamlessly across environments. Our model and code have been open-sourced at\nhttps://github.com/OpenLemur/Lemur.",
        "_bibtex": "@inproceedings{\nxu2024lemur,\ntitle={Lemur: Harmonizing Natural Language and Code for Language Agents},\nauthor={Yiheng Xu and Hongjin SU and Chen Xing and Boyu Mi and Qian Liu and Weijia Shi and Binyuan Hui and Fan Zhou and Yitao Liu and Tianbao Xie and Zhoujun Cheng and Siheng Zhao and Lingpeng Kong and Bailin Wang and Caiming Xiong and Tao Yu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=hNhwSmtXRh}\n}"
    },
    {
        "title": "A path-norm toolkit for modern networks: consequences, promises and challenges",
        "authorids": [
            "~Antoine_Gonon1",
            "~Nicolas_Brisebarre1",
            "~Elisa_Riccietti1",
            "~R\u00e9mi_Gribonval1"
        ],
        "keywords": [
            "ReLU neural networks",
            "path-norm",
            "generalization",
            "contraction lemma",
            "peeling"
        ],
        "abstract": "This work introduces the first toolkit around path-norms that fully encompasses general DAG ReLU networks with biases, skip connections and any operation based on the extraction of order statistics: max pooling, GroupSort etc.\nThis toolkit notably allows us to establish generalization bounds for modern neural networks that are not only the most widely applicable path-norm based ones, but also recover or beat the sharpest known bounds of this type. \nThese extended path-norms further enjoy the usual benefits of path-norms: ease of computation,  invariance under the symmetries of the network, and improved sharpness on layered fully-connected networks compared to the product of operator norms, another complexity measure most commonly used.\n\nThe versatility of the toolkit and its ease of implementation allow us to challenge the concrete promises of path-norm-based generalization bounds, by numerically evaluating the sharpest known bounds for ResNets on ImageNet.",
        "_bibtex": "@inproceedings{\ngonon2024a,\ntitle={A path-norm toolkit for modern networks: consequences, promises and challenges},\nauthor={Antoine Gonon and Nicolas Brisebarre and Elisa Riccietti and R{\\'e}mi Gribonval},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=hiHZVUIYik}\n}"
    },
    {
        "title": "Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages",
        "authorids": [
            "~Jinyi_Hu1",
            "~Yuan_Yao12",
            "~Chongyi_Wang1",
            "~SHAN_WANG4",
            "~Yinxu_Pan1",
            "~Qianyu_Chen2",
            "~Tianyu_Yu1",
            "~Hanghao_Wu1",
            "~Yue_Zhao22",
            "~Haoye_Zhang1",
            "~Xu_Han2",
            "~Yankai_Lin1",
            "~Jiao_Xue1",
            "~dahai_li1",
            "~Zhiyuan_Liu1",
            "~Maosong_Sun1"
        ],
        "keywords": [
            "Large Multimodal Models",
            "Multilingual Transfer"
        ],
        "abstract": "Recently there has been a significant surge in multimodal learning in terms of both image-to-text and text-to-image generation. However, the success is typically limited to English, leaving other languages largely behind. Building a competitive counterpart in other languages is highly challenging due to the low-resource nature of non-English multimodal data (i.e., lack of large-scale, high-quality image-text data). In this work, we propose MPM, an effective training paradigm for training large multimodal models in low-resource languages. MPM demonstrates that Multilingual language models can Pivot zero-shot Multimodal learning across languages. Specifically, based on a strong multilingual large language model, multimodal models pretrained on English-only image-text data can well generalize to other languages in a (quasi)-zero-shot manner, even surpassing models trained on image-text data in native languages. Taking Chinese as a practice of MPM, we build large multimodal models VisCPM in image-to-text and text-to-image generation, which achieve state-of-the-art (open-source) performance in Chinese. To facilitate future research, we open-source codes and model weights at https://github.com/OpenBMB/VisCPM.",
        "_bibtex": "@inproceedings{\nhu2024large,\ntitle={Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages},\nauthor={Jinyi Hu and Yuan Yao and Chongyi Wang and SHAN WANG and Yinxu Pan and Qianyu Chen and Tianyu Yu and Hanghao Wu and Yue Zhao and Haoye Zhang and Xu Han and Yankai Lin and Jiao Xue and dahai li and Zhiyuan Liu and Maosong Sun},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Kuh5qgCGCp}\n}"
    },
    {
        "title": "From Sparse to Soft Mixtures of Experts",
        "authorids": [
            "~Joan_Puigcerver1",
            "~Carlos_Riquelme_Ruiz1",
            "~Basil_Mustafa1",
            "~Neil_Houlsby1"
        ],
        "keywords": [
            "transformers",
            "mixtures of experts",
            "computer vision"
        ],
        "abstract": "Sparse mixture of expert architectures (MoEs) scale model capacity without significant increases in training or inference costs.\nDespite their success, MoEs suffer from a number of issues: training instability, token dropping, inability to scale the number of experts, or ineffective finetuning.\nIn this work, we propose Soft MoE, a fully-differentiable sparse Transformer that addresses these challenges, while maintaining the benefits of MoEs.\nSoft MoE performs an implicit soft assignment by passing different weighted combinations of all input tokens to each expert.\nAs in other MoEs, experts in Soft MoE only process a subset of the (combined) tokens, enabling larger model capacity (and performance) at lower inference cost.\nIn the context of visual recognition, Soft MoE greatly outperforms dense Transformers (ViTs) and popular MoEs (Tokens Choice and Experts Choice).\nSoft MoE scales well: Soft MoE Huge/14 with 128 experts in 16 MoE layers has over 40x more parameters than ViT Huge/14, with only 2% increased inference time, and substantially better quality.",
        "_bibtex": "@inproceedings{\npuigcerver2024from,\ntitle={From Sparse to Soft Mixtures of Experts},\nauthor={Joan Puigcerver and Carlos Riquelme Ruiz and Basil Mustafa and Neil Houlsby},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=jxpsAj7ltE}\n}"
    },
    {
        "title": "Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Objectives",
        "authorids": [
            "~Shrinivas_Ramasubramanian1",
            "~Harsh_Rangwani1",
            "~Sho_Takemori1",
            "~Kunal_Samanta1",
            "~Yuhei_Umeda1",
            "~Venkatesh_Babu_Radhakrishnan2"
        ],
        "keywords": [
            "Non-Decomposable Objectives",
            "Long-Tail Learning",
            "Semi-Supervised Learning"
        ],
        "abstract": "The rise in internet usage has led to the generation of massive amounts of data, resulting in the adoption of various supervised and semi-supervised machine learning algorithms, which can effectively utilize the colossal amount of data to train models. However, before deploying these models in the real world, these must be strictly evaluated on performance measures like worst-case recall and satisfy constraints such as fairness. We find that current state-of-the-art empirical techniques offer sub-optimal performance on these practical, non-decomposable performance objectives. On the other hand, the theoretical techniques necessitate training a new model from scratch for each performance objective. To bridge the gap, we propose SelMix, a selective mixup-based inexpensive fine-tuning technique for pre-trained models, to optimize for the desired objective. The core idea of our framework is to determine a sampling distribution to perform a mixup of features between samples from particular classes such that it optimizes the given objective.  We comprehensively evaluate our technique against the existing empirical and theoretically principled methods on standard benchmark datasets for imbalanced classification. We find that proposed SelMix fine-tuning significantly improves the performance for various practical non-decomposable objectives across benchmarks.",
        "_bibtex": "@inproceedings{\nramasubramanian2024selective,\ntitle={Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Objectives},\nauthor={Shrinivas Ramasubramanian and Harsh Rangwani and Sho Takemori and Kunal Samanta and Yuhei Umeda and Venkatesh Babu Radhakrishnan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rxVBKhyfSo}\n}"
    },
    {
        "title": "NoiseDiffusion: Correcting Noise for Image  Interpolation  with Diffusion Models beyond Spherical Linear Interpolation",
        "authorids": [
            "~PengFei_Zheng2",
            "~Yonggang_Zhang1",
            "~Zhen_Fang2",
            "~Tongliang_Liu1",
            "~Defu_Lian1",
            "~Bo_Han1"
        ],
        "keywords": [
            "Image Interpolation; Diffusion Models"
        ],
        "abstract": "Image interpolation based on diffusion models is promising in creating fresh and interesting images. \nAdvanced interpolation methods mainly focus on spherical linear interpolation, where images are encoded into the noise space and then interpolated for denoising to images. \nHowever, existing methods face challenges in effectively interpolating natural images (not generated by diffusion models), thereby restricting their practical applicability. \nOur experimental investigations reveal that these challenges stem from the invalidity of the encoding noise, which may no longer obey the expected noise distribution, e.g., a normal distribution. \nTo address these challenges, we propose a novel approach to correct noise for image interpolation, NoiseDiffusion. Specifically, NoiseDiffusion approaches the invalid noise to the expected distribution by introducing subtle Gaussian noise and introduces a constraint to suppress noise with extreme values. In this context, promoting noise validity contributes to mitigating image artifacts, but the constraint and introduced exogenous noise typically lead to a reduction in signal-to-noise ratio, i.e., loss of original image information. Hence, NoiseDiffusion performs interpolation within the noisy image space and injects raw images into these noisy counterparts to address the challenge of information loss. Consequently, NoiseDiffusion enables us to interpolate natural images without causing artifacts or information loss, thus achieving the best interpolation results.",
        "_bibtex": "@inproceedings{\nzheng2024noisediffusion,\ntitle={NoiseDiffusion: Correcting Noise for Image  Interpolation  with Diffusion Models beyond Spherical Linear Interpolation},\nauthor={PengFei Zheng and Yonggang Zhang and Zhen Fang and Tongliang Liu and Defu Lian and Bo Han},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=6O3Q6AFUTu}\n}"
    },
    {
        "title": "SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis",
        "authorids": [
            "~Dustin_Podell1",
            "~Zion_English1",
            "~Kyle_Lacey1",
            "~Andreas_Blattmann1",
            "~Tim_Dockhorn1",
            "~Jonas_M\u00fcller1",
            "~Joe_Penna1",
            "~Robin_Rombach1"
        ],
        "keywords": [
            "Image Synthesis",
            "Diffusion",
            "Generative AI"
        ],
        "abstract": "We present Stable Diffusion XL (SDXL), a latent diffusion model for text-to-image synthesis. Compared to previous versions of Stable Diffusion, SDXL leverages a three times larger UNet backbone, achieved by significantly increasing the number of attention blocks and including a second text encoder. Further, we design multiple novel conditioning schemes and train SDXL on multiple aspect ratios. To ensure highest quality results, we also introduce a refinement model which is used to improve the visual fidelity of samples generated by SDXL using a post-hoc image-to-image technique. We demonstrate that SDXL improves dramatically over previous versions of Stable Diffusion and achieves results competitive with those of black-box state-of-the-art image generators such as Midjourney.",
        "_bibtex": "@inproceedings{\npodell2024sdxl,\ntitle={{SDXL}: Improving Latent Diffusion Models for High-Resolution Image Synthesis},\nauthor={Dustin Podell and Zion English and Kyle Lacey and Andreas Blattmann and Tim Dockhorn and Jonas M{\\\"u}ller and Joe Penna and Robin Rombach},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=di52zR8xgf}\n}"
    },
    {
        "title": "Entity-Centric Reinforcement Learning for Object Manipulation from Pixels",
        "authorids": [
            "~Dan_Haramati1",
            "~Tal_Daniel2",
            "~Aviv_Tamar2"
        ],
        "keywords": [
            "deep reinforcement learning",
            "visual reinforcement learning",
            "object-centric",
            "robotic object manipulation",
            "compositional generalization"
        ],
        "abstract": "Manipulating objects is a hallmark of human intelligence, and an important task in domains such as robotics. In principle, Reinforcement Learning (RL) offers a general approach to learn object manipulation. In practice, however, domains with more than a few objects are difficult for RL agents due to the curse of dimensionality, especially when learning from raw image observations. In this work we propose a structured approach for visual RL that is suitable for representing multiple objects and their interaction, and use it to learn goal-conditioned manipulation of several objects. Key to our method is the ability to handle goals with dependencies between the objects (e.g., moving objects in a certain order). We further relate our architecture to the generalization capability of the trained agent, based on a theoretical result for compositional generalization, and demonstrate agents that learn with 3 objects but generalize to similar tasks with over 10 objects. Videos and code are available on the project website: https://sites.google.com/view/entity-centric-rl",
        "_bibtex": "@inproceedings{\nharamati2024entitycentric,\ntitle={Entity-Centric Reinforcement Learning for Object Manipulation from Pixels},\nauthor={Dan Haramati and Tal Daniel and Aviv Tamar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=uDxeSZ1wdI}\n}"
    },
    {
        "title": "Constrained Bi-Level Optimization: Proximal Lagrangian Value Function Approach and Hessian-free Algorithm",
        "authorids": [
            "~Wei_Yao3",
            "~Chengming_Yu1",
            "~Shangzhi_Zeng1",
            "~Jin_Zhang8"
        ],
        "keywords": [
            "Bi-level Optimization",
            "Constrained Optimization",
            "Hessian-free",
            "Single-loop",
            "Value Function",
            "Convergence Analysis"
        ],
        "abstract": "This paper presents a new approach and algorithm for solving a class of constrained Bi-Level Optimization (BLO) problems in which the lower-level problem involves constraints coupling both upper-level and lower-level variables. Such problems have recently gained significant attention due to their broad applicability in machine learning. However, conventional gradient-based methods unavoidably rely on computationally intensive calculations related to the Hessian matrix. To address this challenge, we devise a smooth proximal Lagrangian value function to handle the constrained lower-level problem. Utilizing this construct, we introduce a single-level reformulation for constrained BLOs that transforms the original BLO problem into an equivalent optimization problem with smooth constraints. Enabled by this reformulation, we develop a Hessian-free gradient-based algorithm\u2014termed proximal Lagrangian Value function-based Hessian-free Bi-level Algorithm (LV-HBA)\u2014that is straightforward to implement in a single loop manner. Consequently, LV-HBA is especially well-suited for machine learning applications. Furthermore, we offer non-asymptotic convergence analysis for LV-HBA, eliminating the need for traditional strong convexity assumptions for the lower-level problem while also being capable of accommodating non-singleton scenarios. Empirical results substantiate the algorithm's superior practical performance.",
        "_bibtex": "@inproceedings{\nyao2024constrained,\ntitle={Constrained Bi-Level Optimization: Proximal Lagrangian Value Function Approach and Hessian-free Algorithm},\nauthor={Wei Yao and Chengming Yu and Shangzhi Zeng and Jin Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xJ5N8qrEPl}\n}"
    },
    {
        "title": "Inherently Interpretable Time Series Classification via Multiple Instance Learning",
        "authorids": [
            "~Joseph_Early1",
            "~Gavin_Cheung1",
            "~Kurt_Cutajar1",
            "~Hanting_Xie1",
            "~Jas_Kandola1",
            "~Niall_Twomey1"
        ],
        "keywords": [
            "Multiple Instance Learning",
            "Time Series Classification",
            "Interpretability"
        ],
        "abstract": "Conventional Time Series Classification (TSC) methods are often black boxes that obscure inherent interpretation of their decision-making processes. In this work, we leverage Multiple Instance Learning (MIL) to overcome this issue, and propose a new framework called MILLET: Multiple Instance Learning for Locally Explainable Time series classification. We apply MILLET to existing deep learning TSC models and show how they become inherently interpretable without compromising (and in some cases, even improving) predictive performance. We evaluate MILLET on 85 UCR TSC datasets and also present a novel synthetic dataset that is specially designed to facilitate interpretability evaluation. On these datasets, we show MILLET produces sparse explanations quickly that are of higher quality than other well-known interpretability methods. To the best of our knowledge, our work with MILLET is the first to develop general MIL methods for TSC and apply them to an extensive variety of domains.",
        "_bibtex": "@inproceedings{\nearly2024inherently,\ntitle={Inherently Interpretable Time Series Classification via Multiple Instance Learning},\nauthor={Joseph Early and Gavin Cheung and Kurt Cutajar and Hanting Xie and Jas Kandola and Niall Twomey},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xriGRsoAza}\n}"
    },
    {
        "title": "A Mutual Information Perspective on Federated Contrastive Learning",
        "authorids": [
            "~Christos_Louizos1",
            "~Matthias_Reisser1",
            "~Denis_Korzhenkov1"
        ],
        "keywords": [
            "federated learning",
            "contrastive learning",
            "self-supervised",
            "semi-supervised",
            "mutual information"
        ],
        "abstract": "We investigate contrastive learning in the federated setting through the lens of Sim- CLR and multi-view mutual information maximization. In doing so, we uncover a connection between contrastive representation learning and user verification; by adding a user verification loss to each client\u2019s local SimCLR loss we recover a lower bound to the global multi-view mutual information. To accommodate for the case of when some labelled data are available at the clients, we extend our SimCLR variant to the federated semi-supervised setting. We see that a supervised SimCLR objective can be obtained with two changes: a) the contrastive loss is computed between datapoints that share the same label and b) we require an additional auxiliary head that predicts the correct labels from either of the two views. Along with the proposed SimCLR extensions, we also study how different sources of non-i.i.d.-ness can impact the performance of federated unsupervised learning through global mutual information maximization; we find that a global objective is beneficial for some sources of non-i.i.d.-ness but can be detrimental for others. We empirically evaluate our proposed extensions in various tasks to validate our claims and furthermore demonstrate that our proposed modifications generalize to other pretraining methods.",
        "_bibtex": "@inproceedings{\nlouizos2024a,\ntitle={A Mutual Information Perspective on Federated Contrastive Learning},\nauthor={Christos Louizos and Matthias Reisser and Denis Korzhenkov},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=JrmPG9ufKg}\n}"
    },
    {
        "title": "MMD Graph Kernel: Effective Metric Learning for Graphs via Maximum Mean Discrepancy",
        "authorids": [
            "~Yan_Sun7",
            "~Jicong_Fan2"
        ],
        "keywords": [
            "graph kernel",
            "graph metric learning",
            "maximum mean discrepancy"
        ],
        "abstract": "This paper focuses on graph metric learning. First, we present a class of maximum mean discrepancy (MMD) based graph kernels, called MMD-GK. These kernels are computed by applying MMD to the node representations of two graphs with message-passing propagation. \nSecondly, we provide a class of deep MMD-GKs that are able to learn graph kernels and implicit graph features adaptively in an unsupervised manner. Thirdly, we propose a class of supervised deep MMD-GKs that are able to utilize label information of graphs and hence yield more discriminative metrics. Besides the algorithms, we provide theoretical analysis for the proposed methods. The proposed methods are evaluated in comparison to many baselines such as graph kernels and graph neural networks in the tasks of graph clustering and graph classification. The numerical results demonstrate the effectiveness and superiority of our methods.",
        "_bibtex": "@inproceedings{\nsun2024mmd,\ntitle={{MMD} Graph Kernel: Effective Metric Learning for Graphs via Maximum Mean Discrepancy},\nauthor={Yan Sun and Jicong Fan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=GZ6AcZwA8r}\n}"
    },
    {
        "title": "SGD Finds then Tunes Features in Two-Layer Neural Networks with near-Optimal Sample Complexity: A Case Study in the XOR problem",
        "authorids": [
            "~Margalit_Glasgow1"
        ],
        "keywords": [
            "optimization",
            "stochastic gradient descent",
            "two-layer neural network",
            "sample complexity"
        ],
        "abstract": "In this work, we consider the optimization process of minibatch stochastic gradient descent (SGD) on a 2-layer neural network with data separated by a quadratic ground truth function. We prove that with data drawn from the Boolean hypercube labeled by the quadratic ``XOR'' function $y = -x_ix_j$ , it is possible to train to a population error $o(1)$\n with $\\Theta(d\\text{polylog}(d))$ samples. Our result considers simultaneously training both layers of the two-layer-neural network with ReLU activations via standard minibatch SGD on the logistic loss. To our knowledge, this work is the first to give a sample complexity of \n for efficiently learning the XOR function on isotropic data on a standard neural network with standard training. Our main technique is showing that the network evolves in two phases: a \\em signal-finding \\em phase where the network is small and many of the neurons evolve independently to find features, and a \\em signal-heavy \\em phase, where SGD maintains and balances the features. We leverage the simultaneous training of the layers to show that it is sufficient for only a small fraction of the neurons to learn features, since those neurons will be amplified by the simultaneous growth of their second layer weights.",
        "_bibtex": "@inproceedings{\nglasgow2024sgd,\ntitle={{SGD} Finds then Tunes Features in Two-Layer Neural Networks with near-Optimal Sample Complexity: A Case Study in the {XOR} problem},\nauthor={Margalit Glasgow},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=HgOJlxzB16}\n}"
    },
    {
        "title": "DyVal: Dynamic Evaluation of Large Language Models for Reasoning Tasks",
        "authorids": [
            "~Kaijie_Zhu1",
            "~Jiaao_Chen2",
            "~Jindong_Wang1",
            "~Neil_Zhenqiang_Gong1",
            "~Diyi_Yang2",
            "~Xing_Xie3"
        ],
        "keywords": [
            "Large Language Models",
            "Evaluation",
            "Data Contamination"
        ],
        "abstract": "Large language models (LLMs) have achieved remarkable performance in various evaluation benchmarks. However, concerns are raised about potential data contamination in their considerable volume of training corpus. Moreover, the static nature and fixed complexity of current benchmarks may inadequately gauge the advancing capabilities of LLMs. \nIn this paper, we introduce DyVal, a general and flexible protocol for dynamic evaluation of LLMs. Based on our framework, we build graph-informed DyVal by leveraging the structural advantage of directed acyclic graphs to dynamically generate evaluation samples with controllable complexities. DyVal generates challenging evaluation sets on reasoning tasks including mathematics, logical reasoning, and algorithm problems. We evaluate various LLMs ranging from Flan-T5-large to GPT-3.5-Turbo and GPT-4. Experiments show that LLMs perform worse in DyVal-generated evaluation samples with different complexities, highlighting the significance of dynamic evaluation.\nWe also analyze the failure cases and results of different prompting methods.\nMoreover, DyVal-generated samples are not only evaluation sets, but also helpful data for fine-tuning to improve the performance of LLMs on existing benchmarks.\nWe hope that DyVal can shed light on future evaluation research of LLMs. Code is available at: https://github.com/microsoft/promptbench.",
        "_bibtex": "@inproceedings{\nzhu2024dyval,\ntitle={DyVal: Dynamic Evaluation of Large Language Models for Reasoning Tasks},\nauthor={Kaijie Zhu and Jiaao Chen and Jindong Wang and Neil Zhenqiang Gong and Diyi Yang and Xing Xie},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=gjfOL9z5Xr}\n}"
    },
    {
        "title": "Illusory Attacks: Information-theoretic detectability matters in adversarial attacks",
        "authorids": [
            "~Tim_Franzmeyer1",
            "~Stephen_Marcus_McAleer1",
            "~Joao_F._Henriques1",
            "~Jakob_Nicolaus_Foerster1",
            "~Philip_Torr1",
            "~Adel_Bibi1",
            "~Christian_Schroeder_de_Witt1"
        ],
        "keywords": [
            "sequential decision making",
            "adversarial attacks",
            "robust human-AI systems",
            "robust mixed-autonomy systems"
        ],
        "abstract": "Autonomous agents deployed in the real world need to be robust against adversarial attacks on sensory inputs. \nRobustifying agent policies requires anticipating the strongest attacks possible.\nWe demonstrate that existing observation-space attacks on reinforcement learning agents have a common weakness: while effective, their lack of information-theoretic detectability constraints makes them \\textit{detectable} using automated means or human inspection. \nDetectability is undesirable to adversaries as it may trigger security escalations.\nWe introduce \\textit{\\eattacks{}}, a novel form of adversarial attack on sequential decision-makers that is both effective and of $\\epsilon-$bounded statistical detectability. \nWe propose a novel dual ascent algorithm to learn such attacks end-to-end.\nCompared to existing attacks, we empirically find \\eattacks{} to be significantly harder to detect with automated methods, and a small study with human participants\\footnote{IRB approval under reference R84123/RE001} suggests they are similarly harder to detect for humans. \nOur findings suggest the need for better anomaly detectors, as well as effective hardware- and system-level defenses. The project website can be found at https://tinyurl.com/illusory-attacks.",
        "_bibtex": "@inproceedings{\nfranzmeyer2024illusory,\ntitle={Illusory Attacks: Information-theoretic detectability matters in adversarial attacks},\nauthor={Tim Franzmeyer and Stephen Marcus McAleer and Joao F. Henriques and Jakob Nicolaus Foerster and Philip Torr and Adel Bibi and Christian Schroeder de Witt},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=F5dhGCdyYh}\n}"
    },
    {
        "title": "Addressing Signal Delay in Deep Reinforcement Learning",
        "authorids": [
            "~Wei_Wang59",
            "~Dongqi_Han1",
            "~Xufang_Luo1",
            "~Dongsheng_Li2"
        ],
        "keywords": [
            "Deep Reinforcement Learning",
            "Signal Delay",
            "Robotic Control",
            "Continuous Control"
        ],
        "abstract": "Despite the notable advancements in deep reinforcement learning (DRL) in recent years, a prevalent issue that is often overlooked is the impact of signal delay. Signal delay occurs when there is a lag between an agent's perception of the environment and its corresponding actions. In this paper, we first formalize delayed-observation Markov decision processes (DOMDP) by extending the standard MDP framework to incorporate signal delays. Next, we elucidate the challenges posed by the presence of signal delay in DRL, showing that trivial DRL algorithms and generic methods for partially observable tasks suffer greatly from delays. Lastly, we propose effective strategies to overcome these challenges. Our methods achieve remarkable performance in continuous robotic control tasks with large delays, yielding results comparable to those in non-delayed cases. Overall, our work contributes to a deeper understanding of DRL in the presence of signal delays and introduces novel approaches to address the associated challenges.",
        "_bibtex": "@inproceedings{\nwang2024addressing,\ntitle={Addressing Signal Delay in Deep Reinforcement Learning},\nauthor={Wei Wang and Dongqi Han and Xufang Luo and Dongsheng Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Z8UfDs4J46}\n}"
    },
    {
        "title": "Relay Diffusion: Unifying diffusion process across resolutions for image synthesis",
        "authorids": [
            "~Jiayan_Teng1",
            "~Wendi_Zheng1",
            "~Ming_Ding1",
            "~Wenyi_Hong1",
            "~Jianqiao_Wangni1",
            "~Zhuoyi_Yang1",
            "~Jie_Tang1"
        ],
        "keywords": [
            "generative models",
            "diffusion model",
            "image synthesis"
        ],
        "abstract": "Diffusion models achieved great success in image synthesis, but still face challenges in high-resolution generation. Through the lens of discrete cosine transformation, we find the main reason is that *the same noise level on a higher resolution results in a higher Signal-to-Noise Ratio in the frequency domain*. In this work, we present Relay Diffusion Model (RDM), which transfers a low-resolution image or noise into an equivalent high-resolution one for diffusion model via blurring diffusion and block noise. Therefore, the diffusion process can continue seamlessly in any new resolution or model without restarting from pure noise or low-resolution conditioning. RDM achieves state-of-the-art FID on CelebA-HQ and sFID on ImageNet 256$\\times$256, surpassing previous works such as ADM, LDM and DiT by a large margin. All the codes and checkpoints are open-sourced at \\url{https://github.com/THUDM/RelayDiffusion}.",
        "_bibtex": "@inproceedings{\nteng2024relay,\ntitle={Relay Diffusion: Unifying diffusion process across resolutions for image synthesis},\nauthor={Jiayan Teng and Wendi Zheng and Ming Ding and Wenyi Hong and Jianqiao Wangni and Zhuoyi Yang and Jie Tang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=qTlcbLSm4p}\n}"
    },
    {
        "title": "ScaleCrafter: Tuning-free Higher-Resolution Visual Generation with Diffusion Models",
        "authorids": [
            "~Yingqing_He1",
            "~Shaoshu_Yang1",
            "~Haoxin_Chen2",
            "~Xiaodong_Cun1",
            "~Menghan_Xia1",
            "~Yong_Zhang6",
            "~Xintao_Wang1",
            "~Ran_He1",
            "~Qifeng_Chen1",
            "~Ying_Shan2"
        ],
        "keywords": [
            "text-to-image generation",
            "diffusion models",
            "high resolution generation"
        ],
        "abstract": "In this work, we investigate the capability of generating images from pre-trained diffusion models at much higher resolutions than the training image sizes. In addition, the generated images should have arbitrary image aspect ratios. When generating images directly at a higher resolution, 1024 x 1024, with the pre-trained Stable Diffusion using training images of resolution 512 x 512, we observe persistent problems of object repetition and unreasonable object structures. Existing works for higher-resolution generation, such as attention-based and joint-diffusion approaches, cannot well address these issues. As a new perspective, we examine the structural components of the U-Net in diffusion models and identify the crucial cause as the limited perception field of convolutional kernels. Based on this key observation, we propose a simple yet effective re-dilation that can dynamically adjust the convolutional perception field during inference. We further propose the dispersed convolution and noise-damped classifier-free guidance, which can enable ultra-high-resolution image generation  (e.g., 4096 x 4096). Notably, our approach does not require any training or optimization. Extensive experiments demonstrate that our approach can address the repetition issue well and achieve state-of-the-art performance on higher-resolution image synthesis, especially in texture details. Our work also suggests that a pre-trained diffusion model trained on low-resolution images can be directly used for high-resolution visual generation without further tuning, which may provide insights for future research on ultra-high-resolution image and video synthesis. More results are available at the anonymous website: https://scalecrafter.github.io/ScaleCrafter/",
        "_bibtex": "@inproceedings{\nhe2024scalecrafter,\ntitle={ScaleCrafter: Tuning-free Higher-Resolution Visual Generation with Diffusion Models},\nauthor={Yingqing He and Shaoshu Yang and Haoxin Chen and Xiaodong Cun and Menghan Xia and Yong Zhang and Xintao Wang and Ran He and Qifeng Chen and Ying Shan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=u48tHG5f66}\n}"
    },
    {
        "title": "DrM: Mastering Visual Reinforcement Learning through Dormant Ratio Minimization",
        "authorids": [
            "~Guowei_Xu2",
            "~Ruijie_Zheng1",
            "~Yongyuan_Liang1",
            "~Xiyao_Wang1",
            "~Zhecheng_Yuan1",
            "~Tianying_Ji2",
            "~Yu_Luo5",
            "~Xiaoyu_Liu3",
            "~Jiaxin_Yuan1",
            "~Pu_Hua1",
            "~Shuzhen_Li1",
            "~Yanjie_Ze1",
            "~Hal_Daum\u00e9_III1",
            "~Furong_Huang1",
            "~Huazhe_Xu1"
        ],
        "keywords": [
            "Visual RL; Dormant Ratio"
        ],
        "abstract": "Visual reinforcement learning (RL) has shown promise in continuous control tasks.\nDespite its progress, current algorithms are still unsatisfactory in virtually every aspect of the performance such as sample efficiency, asymptotic performance, and their robustness to the choice of random seeds.\nIn this paper, we identify a major shortcoming in existing visual RL methods that is the agents often exhibit sustained inactivity during early training, thereby limiting their ability to explore effectively. \nExpanding upon this crucial observation, we additionally unveil a significant correlation between the agents' inclination towards motorically inactive exploration and the absence of neuronal activity within their policy networks.\nTo quantify this inactivity, we adopt dormant ratio as a metric to measure inactivity in the RL agent's network.\nEmpirically, we also recognize that the dormant ratio can act as a standalone indicator of an agent's activity level, regardless of the received reward signals.\nLeveraging the aforementioned insights, we introduce DrM, a method that uses three core mechanisms to guide agents' exploration-exploitation trade-offs by actively minimizing the dormant ratio. \nExperiments demonstrate that  DrM achieves significant improvements in sample efficiency and asymptotic performance with no broken seeds (76 seeds in total) across three continuous control benchmark environments, including DeepMind Control Suite, MetaWorld, and Adroit.\nMost importantly, DrM is the first model-free algorithm that consistently solves tasks in both the Dog and Manipulator domains from the DeepMind Control Suite as well as three dexterous hand manipulation tasks without demonstrations in Adroit, all based on pixel observations.",
        "_bibtex": "@inproceedings{\nxu2024drm,\ntitle={DrM: Mastering Visual Reinforcement Learning through Dormant Ratio Minimization},\nauthor={Guowei Xu and Ruijie Zheng and Yongyuan Liang and Xiyao Wang and Zhecheng Yuan and Tianying Ji and Yu Luo and Xiaoyu Liu and Jiaxin Yuan and Pu Hua and Shuzhen Li and Yanjie Ze and Hal Daum{\\'e} III and Furong Huang and Huazhe Xu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MSe8YFbhUE}\n}"
    },
    {
        "title": "How Over-Parameterization Slows Down Gradient Descent in Matrix Sensing: The Curses of Symmetry and Initialization",
        "authorids": [
            "~Nuoya_Xiong1",
            "~Lijun_Ding1",
            "~Simon_Shaolei_Du1"
        ],
        "keywords": [
            "non-convex optimization",
            "random initialization",
            "global convergence",
            "matrix recovery",
            "matrix sensing"
        ],
        "abstract": "This paper rigorously shows how over-parameterization dramatically changes the convergence behaviors of gradient descent (GD) for the matrix sensing problem, where the goal is to recover an unknown low-rank ground-truth matrix from near-isotropic linear measurements.\nFirst, we consider the symmetric setting with the symmetric parameterization where $M^* \\in \\mathbb{R}^{n \\times n}$ is a positive semi-definite unknown matrix of rank $r \\ll n$, and one uses a symmetric parameterization $XX^\\top$ to learn $M^*$. Here $X \\in \\mathbb{R}^{n \\times k}$ with $k > r$ is the factor matrix. We give a novel $\\Omega\\left(1/T^2\\right)$ lower bound of randomly initialized GD for the over-parameterized case ($k >r$) where $T$ is the number of iterations. This is in stark contrast to the exact-parameterization scenario ($k=r$) where the convergence rate is $\\exp\\left(-\\Omega\\left(T\\right)\\right)$. Next, we study asymmetric setting where $M^* \\in \\mathbb{R}^{n_1 \\times n_2}$ is the unknown matrix of rank $r \\ll \\min\\{n_1,n_2\\}$, and one uses an asymmetric parameterization $FG^\\top$ to learn $M^*$ where $F \\in \\mathbb{R}^{n_1 \\times k}$ and $G \\in \\mathbb{R}^{n_2 \\times k}$. We give the first global exact convergence result of randomly initialized GD for the exact-parameterization case ($k=r$) with an $\\exp\\left(-\\Omega\\left(T\\right)\\right)$ rate. Furthermore, we give the first global exact convergence result for the over-parameterization case ($k>r$) with an $\\exp\\left(-\\Omega\\left(\\alpha^2 T\\right)\\right)$ rate where $\\alpha$ is the initialization scale. This linear convergence result in the over-parameterization case is especially significant because one can apply the asymmetric parameterization to the symmetric setting to speed up from $\\Omega\\left(1/T^2\\right)$ to linear convergence. Therefore, we identify a surprising phenomenon: asymmetric parameterization can exponentially speed up convergence. Equally surprising is our analysis that highlights the importance of imbalance between $F$ and $G$. This is in sharp contrast to prior works which emphasize balance.  We further give an example showing the dependency on $\\alpha$ in the convergence rate is unavoidable in the worst case. On the other hand, we propose a novel method that only modifies one step of GD and obtains a convergence rate independent of $\\alpha$, recovering the rate in the exact-parameterization case. We provide empirical studies to verify our theoretical findings.",
        "_bibtex": "@inproceedings{\nxiong2024how,\ntitle={How Over-Parameterization Slows Down Gradient Descent in Matrix Sensing: The Curses of Symmetry and Initialization},\nauthor={Nuoya Xiong and Lijun Ding and Simon Shaolei Du},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xGvPKAiOhq}\n}"
    },
    {
        "title": "AnyText: Multilingual Visual Text Generation and Editing",
        "authorids": [
            "~Yuxiang_Tuo2",
            "~Wangmeng_Xiang1",
            "~Jun-Yan_He2",
            "~Yifeng_Geng2",
            "~Xuansong_Xie1"
        ],
        "keywords": [
            "diffusion model",
            "text-to-image",
            "text generation"
        ],
        "abstract": "Diffusion model based Text-to-Image has achieved impressive achievements recently. Although current technology for synthesizing images is highly advanced and capable of generating images with high fidelity, it is still possible to give the show away when focusing on the text area in the generated image, as synthesized text often contains blurred, unreadable, or incorrect characters, making visual text generation one of the most challenging issues in this field. To address this issue, we introduce AnyText, a diffusion-based multilingual visual text generation and editing model, that focuses on rendering accurate and coherent text in the image. AnyText comprises a diffusion pipeline with two primary elements: an auxiliary latent module and a text embedding module. The former uses inputs like text glyph, position, and masked image to generate latent features for text generation or editing. The latter employs an OCR model for encoding stroke data as embeddings, which blend with image caption embeddings from the tokenizer to generate texts that seamlessly integrate with the background. We employed text-control diffusion loss and text perceptual loss for training to further enhance writing accuracy. AnyText can write characters in multiple languages, to the best of our knowledge, this is the first work to address multilingual visual text generation. It is worth mentioning that AnyText can be plugged into existing diffusion models from the community for rendering or editing text accurately. After conducting extensive evaluation experiments, our method has outperformed all other approaches by a significant margin. Additionally, we contribute the first large-scale multilingual text images dataset, AnyWord-3M, containing 3 million image-text pairs with OCR annotations in multiple languages. Based on AnyWord-3M dataset, we propose AnyText-benchmark for the evaluation of visual text generation accuracy and quality. Our project will be open-sourced soon to improve and promote the development of text generation technology.",
        "_bibtex": "@inproceedings{\ntuo2024anytext,\ntitle={AnyText: Multilingual Visual Text Generation and Editing},\nauthor={Yuxiang Tuo and Wangmeng Xiang and Jun-Yan He and Yifeng Geng and Xuansong Xie},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ezBH9WE9s2}\n}"
    },
    {
        "title": "At Which Training Stage Does Code Data Help LLMs Reasoning?",
        "authorids": [
            "~YINGWEI_MA2",
            "~Yue_Liu10",
            "~Yue_Yu8",
            "~Yuanliang_Zhang1",
            "~Yu_Jiang4",
            "~Changjian_Wang1",
            "~Shanshan_Li1"
        ],
        "keywords": [
            "code data",
            "large language models",
            "reasoning capabilities"
        ],
        "abstract": "Large Language models (LLMs) have exhibited remarkable reasoning capabilities and become the foundation of language technologies. Inspired by the great success of code data in training LLMs, we naturally wonder at which training stage introducing code data can really help LLMs reasoning. To this end, this paper systematically explores the impact of code data on LLMs at different stages. Concretely, we introduce the code data at the pre-training stage, instruction-tuning stage, and both of them, respectively. Then, the reasoning capability of LLMs is comprehensively and fairly evaluated via six reasoning tasks. We critically analyze the experimental results and provide conclusions with insights. First, pre-training LLMs with the mixture of code and text can significantly enhance LLMs' general reasoning capability almost without negative transfer on other tasks. Besides, at the instruction-tuning stage, code data endows LLMs the task-specific reasoning capability. Moreover, the dynamic mixing strategy of code and text data assists LLMs to learn reasoning capability step-by-step during training. These insights deepen the understanding of LLMs regarding reasoning ability for their application, such as scientific question answering, legal support, etc.",
        "_bibtex": "@inproceedings{\nma2024at,\ntitle={At Which Training Stage Does Code Data Help {LLM}s Reasoning?},\nauthor={YINGWEI MA and Yue Liu and Yue Yu and Yuanliang Zhang and Yu Jiang and Changjian Wang and Shanshan Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=KIPJKST4gw}\n}"
    },
    {
        "title": "Coordinate-Aware Modulation for Neural Fields",
        "authorids": [
            "~Joo_Chan_Lee1",
            "~Daniel_Rho1",
            "~Seungtae_Nam1",
            "~Jong_Hwan_Ko2",
            "~Eunbyung_Park1"
        ],
        "keywords": [
            "Neural Fields",
            "Neural Representation"
        ],
        "abstract": "Neural fields, mapping low-dimensional input coordinates to corresponding signals, have shown promising results in representing various signals. Numerous methodologies have been proposed, and techniques employing MLPs and grid representations have achieved substantial success. MLPs allow compact and high expressibility, yet often suffer from spectral bias and slow convergence speed. On the other hand, methods using grids are free from spectral bias and achieve fast training speed, however, at the expense of high spatial complexity. In this work, we propose a novel way for exploiting both MLPs and grid representations in neural fields. Unlike the prevalent methods that combine them sequentially (extract features from the grids first and feed them to the MLP), we inject spectral bias-free grid representations into the intermediate features in the MLP. More specifically, we suggest a Coordinate-Aware Modulation (CAM), which modulates the intermediate features using scale and shift parameters extracted from the grid representations. This can maintain the strengths of MLPs while mitigating any remaining potential biases, facilitating the rapid learning of high-frequency components. In addition, we empirically found that the feature normalizations, which have not been successful in neural filed literature, proved to be effective when applied in conjunction with the proposed CAM. Experimental results demonstrate that CAM enhances the performance of neural representation and improves learning stability across a range of signals. Especially in the novel view synthesis task, we achieved state-of-the-art performance with the least number of parameters and fast training speed for dynamic scenes and the best performance under 1MB memory for static scenes. CAM also outperforms the best-performing video compression methods using neural fields by a large margin. Our project page is available at https://maincold2.github.io/cam/.",
        "_bibtex": "@inproceedings{\nlee2024coordinateaware,\ntitle={Coordinate-Aware Modulation for Neural Fields},\nauthor={Joo Chan Lee and Daniel Rho and Seungtae Nam and Jong Hwan Ko and Eunbyung Park},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=4UiLqimGm5}\n}"
    },
    {
        "title": "Efficient ConvBN Blocks for Transfer Learning and Beyond",
        "authorids": [
            "~Kaichao_You1",
            "~Guo_Qin1",
            "~Anchang_Bao1",
            "~Meng_Cao2",
            "~Ping_Huang1",
            "~Jiulong_Shan2",
            "~Mingsheng_Long5"
        ],
        "keywords": [
            "transfer learning",
            "batch normalization",
            "efficient training"
        ],
        "abstract": "Convolution-BatchNorm (ConvBN) blocks are integral components in various computer vision tasks and other domains. A ConvBN block can operate in three modes: Train, Eval, and Deploy. While the Train mode is indispensable for training models from scratch, the Eval mode is suitable for transfer learning and beyond, and the Deploy mode is designed for the deployment of models. This paper focuses on the trade-off between stability and efficiency in ConvBN blocks: Deploy mode is efficient but suffers from training instability; Eval mode is widely used in transfer learning but lacks efficiency. To solve the dilemma, we theoretically reveal the reason behind the diminished training stability observed in the Deploy mode. Subsequently, we propose a novel Tune mode to bridge the gap between Eval mode and Deploy mode. The proposed Tune mode is as stable as Eval mode for transfer learning, and its computational efficiency closely matches that of the Deploy mode. Through extensive experiments in object detection, classification, and adversarial example generation across $5$ datasets and $12$ model architectures, we demonstrate that the proposed Tune mode retains the performance while significantly reducing GPU memory footprint and training time, thereby contributing efficient ConvBN blocks for transfer learning and beyond. Our method has been integrated into both PyTorch (general machine learning framework) and MMCV/MMEngine (computer vision framework). Practitioners just need one line of code to enjoy our efficient ConvBN blocks thanks to PyTorch's builtin machine learning compilers.",
        "_bibtex": "@inproceedings{\nyou2024efficient,\ntitle={Efficient Conv{BN} Blocks for Transfer Learning and Beyond},\nauthor={Kaichao You and Guo Qin and Anchang Bao and Meng Cao and Ping Huang and Jiulong Shan and Mingsheng Long},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=lHZm9vNm5H}\n}"
    },
    {
        "title": "Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior",
        "authorids": [
            "~Ashmit_Khandelwal1",
            "~Aditya_Agrawal3",
            "~Aanisha_Bhattacharyya2",
            "~Yaman_Kumar1",
            "~Somesh_Singh1",
            "~Uttaran_Bhattacharya1",
            "~Ishita_Dasgupta3",
            "~Stefano_Petrangeli1",
            "~Rajiv_Ratn_Shah1",
            "~Changyou_Chen1",
            "~Balaji_Krishnamurthy1"
        ],
        "keywords": [
            "large language models",
            "behavior simulation",
            "large content and behavior models",
            "behavior understanding",
            "behavior in the wild",
            "computational marketing",
            "computational behavior science"
        ],
        "abstract": "Shannon and Weaver's seminal information theory divides communication into three levels: technical, semantic, and effectiveness. While the technical level deals with the accurate reconstruction of transmitted symbols, the semantic and effectiveness levels deal with the inferred meaning and its effect on the receiver. Large Language Models (LLMs), with their wide generalizability, make some progress towards the second level. However, LLMs and other communication models are not conventionally designed for predicting and optimizing communication for desired receiver behaviors and intents. As a result, the effectiveness level remains largely untouched by modern communication systems. In this paper, we introduce the receivers' \"behavior tokens,\" such as shares, likes, clicks, purchases, and retweets, in the LLM's training corpora to optimize content for the receivers and predict their behaviors. Other than showing similar performance to LLMs on content understanding tasks, our trained models show generalization capabilities on the behavior dimension for behavior simulation, content simulation, behavior understanding, and behavior domain adaptation. We show results on all these capabilities using a wide range of tasks on three corpora. We call these models Large Content and Behavior Models (LCBMs). Further, to spur more research on LCBMs, we release our new Content Behavior Corpus (CBC), a repository containing communicator, message, and corresponding receiver behavior (https://behavior-in-the-wild.github.io/LCBM).",
        "_bibtex": "@inproceedings{\nkhandelwal2024large,\ntitle={Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior},\nauthor={Ashmit Khandelwal and Aditya Agrawal and Aanisha Bhattacharyya and Yaman Kumar and Somesh Singh and Uttaran Bhattacharya and Ishita Dasgupta and Stefano Petrangeli and Rajiv Ratn Shah and Changyou Chen and Balaji Krishnamurthy},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TrKq4Wlwcz}\n}"
    },
    {
        "title": "Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints",
        "authorids": [
            "~Chaoqi_Wang1",
            "~Yibo_Jiang2",
            "~Chenghao_Yang1",
            "~Han_Liu12",
            "~Yuxin_Chen1"
        ],
        "keywords": [
            "Large language models",
            "Preference optimization",
            "AI Alignment"
        ],
        "abstract": "The increasing capabilities of large language models (LLMs) raise opportunities for artificial general intelligence but concurrently amplify safety concerns, such as potential misuse of AI systems, necessitating effective AI alignment. Reinforcement Learning from Human Feedback (RLHF) has emerged as a promising pathway towards AI alignment but brings forth challenges due to its complexity and dependence on a separate reward model. Direct Preference Optimization (DPO) has been proposed as an alternative; and it remains equivalent to RLHF under the reverse KL regularization constraint. This paper presents $f$-DPO, a generalized approach to DPO by incorporating diverse divergence constraints. We show that under certain $f$-divergences, including Jensen-Shannon divergence, forward KL divergences and $\\alpha$-divergences, the complex relationship between the reward and optimal policy can also be simplified by addressing the Karush\u2013Kuhn\u2013Tucker conditions. This eliminates the need for estimating the normalizing constant in the Bradley-Terry model and enables a tractable mapping between the reward function and the optimal policy. Our approach optimizes LLMs to align with human preferences in a more efficient and supervised manner under a broad set of divergence constraints. Empirically, adopting these divergences ensures a balance between alignment performance and generation diversity. Importantly, our $f$-DPO outperforms PPO-based methods in divergence efficiency, and divergence constraints directly influence expected calibration error (ECE).",
        "_bibtex": "@inproceedings{\nwang2024beyond,\ntitle={Beyond Reverse {KL}: Generalizing Direct Preference Optimization with Diverse Divergence Constraints},\nauthor={Chaoqi Wang and Yibo Jiang and Chenghao Yang and Han Liu and Yuxin Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=2cRzmWXK9N}\n}"
    },
    {
        "title": "FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets",
        "authorids": [
            "~Seonghyeon_Ye1",
            "~Doyoung_Kim3",
            "~Sungdong_Kim1",
            "~Hyeonbin_Hwang1",
            "~Seungone_Kim1",
            "~Yongrae_Jo1",
            "~James_Thorne1",
            "~Juho_Kim2",
            "~Minjoon_Seo1"
        ],
        "keywords": [
            "large language models",
            "language model evaluation",
            "natural language processing"
        ],
        "abstract": "Evaluation of Large Language Models (LLMs) is challenging because instruction-following necessitates alignment with human values and the required set of skills varies depending on the instruction. However, previous studies have mainly focused on coarse-grained evaluation (i.e. overall preference-based evaluation), which limits interpretability since it does not consider the nature of user instructions that require instance-wise skill composition. In this paper, we introduce FLASK (Fine-grained Language Model Evaluation based on Alignment Skill Sets), a fine-grained evaluation protocol for both human-based and model-based evaluation which decomposes coarse-level scoring to a skill set-level scoring for each instruction. We experimentally observe that the fine-graininess of evaluation is crucial for attaining a holistic view of model performance and increasing the reliability of the evaluation. Using FLASK, we compare multiple open-source and proprietary LLMs and observe a high correlation between model-based and human-based evaluations.",
        "_bibtex": "@inproceedings{\nye2024flask,\ntitle={{FLASK}: Fine-grained Language Model Evaluation based on Alignment Skill Sets},\nauthor={Seonghyeon Ye and Doyoung Kim and Sungdong Kim and Hyeonbin Hwang and Seungone Kim and Yongrae Jo and James Thorne and Juho Kim and Minjoon Seo},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=CYmF38ysDa}\n}"
    },
    {
        "title": "LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset",
        "authorids": [
            "~Lianmin_Zheng2",
            "~Wei-Lin_Chiang1",
            "~Ying_Sheng1",
            "~Tianle_Li2",
            "~Siyuan_Zhuang1",
            "~Zhanghao_Wu1",
            "~Yonghao_Zhuang1",
            "~Zhuohan_Li1",
            "~Zi_Lin1",
            "~Eric_Xing1",
            "~Joseph_E._Gonzalez1",
            "~Ion_Stoica1",
            "~Hao_Zhang2"
        ],
        "keywords": [
            "large language models",
            "dataset",
            "conversation",
            "safety",
            "benchmark"
        ],
        "abstract": "Studying how people interact with large language models (LLMs) in real-world scenarios is increasingly important due to their widespread use in various applications. In this paper, we introduce LMSYS-Chat-1M, a large-scale dataset containing one million real-world conversations with 25 state-of-the-art LLMs. This dataset is collected from 210K unique IP addresses in the wild on our Vicuna demo and Chatbot Arena website. We offer an overview of the dataset's content, including its curation process, basic statistics, and topic distribution, highlighting its diversity, originality, and scale. We demonstrate its versatility through four use cases: developing content moderation models that perform similarly to GPT-4, building a safety benchmark, training instruction-following models that perform similarly to Vicuna, and creating challenging benchmark questions. We believe that this dataset will serve as a valuable resource for understanding and advancing LLM capabilities. The dataset is publicly available at https://huggingface.co/datasets/lmsys/lmsys-chat-1m.",
        "_bibtex": "@inproceedings{\nzheng2024lmsyschatm,\ntitle={{LMSYS}-Chat-1M: A Large-Scale Real-World {LLM} Conversation Dataset},\nauthor={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Tianle Li and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zhuohan Li and Zi Lin and Eric Xing and Joseph E. Gonzalez and Ion Stoica and Hao Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=BOfDKxfwt0}\n}"
    },
    {
        "title": "EfficientDM: Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models",
        "authorids": [
            "~Yefei_He1",
            "~Jing_Liu8",
            "~Weijia_Wu2",
            "~Hong_Zhou3",
            "~Bohan_Zhuang1"
        ],
        "keywords": [
            "Diffusion Models",
            "Model Quantization",
            "Model Compression",
            "Efficient Models"
        ],
        "abstract": "Diffusion models have demonstrated remarkable capabilities in image synthesis and related generative tasks. Nevertheless, their practicality for low-latency real-world applications is constrained by substantial computational costs and latency issues. Quantization is a dominant way to compress and accelerate diffusion models, where post-training quantization (PTQ) and quantization-aware training (QAT) are two main approaches, each bearing its own properties. While PTQ exhibits efficiency in terms of both time and data usage, it may lead to diminished performance in low bit-width settings. On the other hand, QAT can help alleviate performance degradation but comes with substantial demands on computational and data resources. To capitalize on the advantages while avoiding their respective drawbacks, we introduce a data-free, quantization-aware and parameter-efficient fine-tuning framework for low-bit diffusion models, dubbed EfficientDM, to achieve QAT-level performance with PTQ-like efficiency. Specifically, we propose a quantization-aware variant of the low-rank adapter (QALoRA) that can be merged with model weights and jointly quantized to low bit-width. The fine-tuning process distills the denoising capabilities of the full-precision model into its quantized counterpart, eliminating the requirement for training data. To further enhance performance, we introduce scale-aware optimization to address ineffective learning of QALoRA due to variations in weight quantization scales across different layers. We also employ temporal learned step-size quantization to handle notable variations in activation distributions across denoising steps. Extensive experimental results demonstrate that our method significantly outperforms previous PTQ-based diffusion models while maintaining similar time and data efficiency. Specifically, there is only a marginal $0.05$ sFID increase when quantizing both weights and activations of LDM-4 to 4-bit on ImageNet $256\\times256$. Compared to QAT-based methods, our EfficientDM also boasts a $16.2\\times$ faster quantization speed with comparable generation quality, rendering it a compelling choice for practical applications.",
        "_bibtex": "@inproceedings{\nhe2024efficientdm,\ntitle={Efficient{DM}: Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models},\nauthor={Yefei He and Jing Liu and Weijia Wu and Hong Zhou and Bohan Zhuang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=UmMa3UNDAz}\n}"
    },
    {
        "title": "BTR: Binary Token Representations for Efficient Retrieval Augmented Language Models",
        "authorids": [
            "~Qingqing_Cao1",
            "~Sewon_Min1",
            "~Yizhong_Wang2",
            "~Hannaneh_Hajishirzi1"
        ],
        "keywords": [
            "language models",
            "question answering",
            "binary representations",
            "retrieval-augmented language models"
        ],
        "abstract": "Retrieval augmentation addresses many critical problems in large language models such as hallucination, staleness, and privacy leaks.\nHowever, running retrieval-augmented language models (LMs) is slow and difficult to scale due to processing large amounts of retrieved text. \nWe introduce binary token representations (BTR), which use 1-bit vectors to precompute every token in passages, significantly reducing computation during inference. \nDespite the potential loss of accuracy, our new calibration techniques and training objectives restore performance. Combined with offline and runtime compression, this only requires 127GB of disk space for encoding 3 billion tokens in Wikipedia.\nOur experiments show that on five knowledge-intensive NLP tasks, BTR accelerates state-of-the-art inference by up to 4x and reduces storage by over 100x while maintaining over 95% task performance. Our code is publicly available at https://github.com/csarron/BTR.",
        "_bibtex": "@inproceedings{\ncao2024btr,\ntitle={{BTR}: Binary Token Representations for Efficient Retrieval Augmented Language Models},\nauthor={Qingqing Cao and Sewon Min and Yizhong Wang and Hannaneh Hajishirzi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3TO3TtnOFl}\n}"
    },
    {
        "title": "Frozen Transformers in Language Models Are Effective Visual Encoder Layers",
        "authorids": [
            "~Ziqi_Pang1",
            "~Ziyang_Xie1",
            "~Yunze_Man2",
            "~Yu-Xiong_Wang1"
        ],
        "keywords": [
            "representation learning",
            "vision-language models",
            "transformer"
        ],
        "abstract": "This paper reveals that large language models (LLMs), despite being trained solely on text data, are surprisingly}strong encoders for purely visual tasks in the absence of language. Even more intriguingly, this can be achieved by a simple yet previously overlooked strategy -- employing a frozen transformer block from pre-trained LLMs as a constituent encoder layer to directly process visual tokens. Our work pushes the boundaries of leveraging LLMs for computer vision tasks, significantly departing from conventional practices that typically necessitate a multi-modal vision-language setup with associated language prompts, inputs, or outputs. We demonstrate that our approach consistently enhances performance across a diverse range of tasks} encompassing pure 2D or 3D visual recognition tasks (e.g., image and point cloud classification), temporal modeling tasks (e.g., action recognition), non-semantic tasks (e.g., motion forecasting), and multi-modal tasks (e.g., 2D/3D visual question answering and image-text retrieval). Such improvements are a general phenomenon, applicable to various types of LLMs (e.g., LLaMA and OPT) and different LLM transformer blocks. We additionally propose the information filtering hypothesis to explain the effectiveness of pre-trained LLMs in visual encoding -- the pre-trained LLM transformer blocks discern informative visual tokens and further amplify their effect. This hypothesis is empirically supported by the observation that the feature activation, after training with LLM transformer blocks, exhibits a stronger focus on relevant regions. We hope that our work inspires new perspectives on utilizing LLMs and deepening our understanding of their underlying mechanisms.",
        "_bibtex": "@inproceedings{\npang2024frozen,\ntitle={Frozen Transformers in Language Models Are Effective Visual Encoder Layers},\nauthor={Ziqi Pang and Ziyang Xie and Yunze Man and Yu-Xiong Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=t0FI3Q66K5}\n}"
    },
    {
        "title": "SocioDojo: Building Lifelong Analytical Agents with Real-world Text and Time Series",
        "authorids": [
            "~Junyan_Cheng1",
            "~Peter_Chin1"
        ],
        "keywords": [
            "Large Langauge Models",
            "Agent",
            "Prompt Tunning",
            "Time series forcasting"
        ],
        "abstract": "We introduce SocioDojo, an open-ended lifelong learning environment for developing ready-to-deploy autonomous agents capable of performing human-like analysis and decision-making on societal topics such as economics, finance, politics, and culture. It consists of (1) information sources from news, social media, reports, etc., (2) a knowledge base built from books, journals, and encyclopedias, plus a toolbox of Internet and knowledge graph search interfaces, (3) 30K high-quality time series in finance, economy, society, and polls, which support a novel task called \"hyperportfolio\", that can reliably and scalably evaluate societal analysis and decision-making power of agents, inspired by portfolio optimization with time series as assets to \"invest\". We also propose a novel Analyst-Assistant-Actuator architecture for the hyperportfolio task, and a Hypothesis & Proof prompting for producing in-depth analyses on input news, articles, etc. to assist decision-making. We perform experiments and ablation studies to explore the factors that impact performance. The results show that our proposed method achieves improvements of 32.4% and 30.4% compared to the state-of-the-art method in the two experimental settings.",
        "_bibtex": "@inproceedings{\ncheng2024sociodojo,\ntitle={SocioDojo: Building Lifelong Analytical Agents with Real-world Text and Time Series},\nauthor={Junyan Cheng and Peter Chin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=s9z0HzWJJp}\n}"
    },
    {
        "title": "Learning Performance-Improving Code Edits",
        "authorids": [
            "~Alexander_G_Shypula1",
            "~Aman_Madaan1",
            "~Yimeng_Zeng1",
            "~Uri_Alon1",
            "~Jacob_R._Gardner1",
            "~Yiming_Yang1",
            "~Milad_Hashemi1",
            "~Graham_Neubig1",
            "~Parthasarathy_Ranganathan1",
            "~Osbert_Bastani1",
            "~Amir_Yazdanbakhsh1"
        ],
        "keywords": [
            "Large Language Models",
            "Retrieval Augmented Generation",
            "Program Synthesis",
            "Program Optimization",
            "Fine-Tuning",
            "Goal-Conditioning",
            "Data Augmentation",
            "Self-Play",
            "Synthetic Dataset",
            "Performance Optimization",
            "Machine Learning for Code Optimization",
            "Dataset"
        ],
        "abstract": "With the decline of Moore's law, optimizing program performance has become a major focus of software research. However, high-level optimizations such as API and algorithm changes remain elusive due to the difficulty of understanding the semantics of code. Simultaneously, pretrained large language models (LLMs) have demonstrated strong capabilities at solving a wide range of programming tasks. To that end, we introduce a framework for adapting LLMs to high-level program optimization. First, we curate a dataset of performance-improving edits made by human programmers of over 77,000 competitive C++ programming submission pairs, accompanied by extensive unit tests. A major challenge is the significant variability of measuring performance on commodity hardware, which can lead to spurious \"improvements.\" To isolate and reliably evaluate the impact of program optimizations, we design an environment based on the gem5 full system simulator, the de facto simulator used in academia and industry. Next, we propose a broad range of adaptation strategies for code optimization; for prompting, these include retrieval-based few-shot prompting and chain-of-thought, and for finetuning, these include performance-conditioned generation and synthetic data augmentation based on self-play. A combination of these techniques achieves a mean speedup of 6.86$\\times$ with eight generations, higher than average optimizations from individual programmers (3.66$\\times$). Using our model's fastest generations, we set a new upper limit on the fastest speedup possible for our dataset at 9.64$\\times$ compared to using the fastest human submissions available (9.56$\\times$).",
        "_bibtex": "@inproceedings{\nshypula2024learning,\ntitle={Learning Performance-Improving Code Edits},\nauthor={Alexander G Shypula and Aman Madaan and Yimeng Zeng and Uri Alon and Jacob R. Gardner and Yiming Yang and Milad Hashemi and Graham Neubig and Parthasarathy Ranganathan and Osbert Bastani and Amir Yazdanbakhsh},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ix7rLVHXyY}\n}"
    },
    {
        "title": "Quasi-Monte Carlo for 3D Sliced Wasserstein",
        "authorids": [
            "~Khai_Nguyen1",
            "~Nicola_Bariletto1",
            "~Nhat_Ho1"
        ],
        "keywords": [
            "Sliced Wasserstein",
            "Monte Carlo Methods",
            "Point-Cloud",
            "Quasi-Monte Carlo",
            "Optimal Transport"
        ],
        "abstract": "Monte Carlo (MC) integration has been employed as the standard approximation method for the Sliced Wasserstein (SW) distance, whose analytical expression involves an intractable expectation. However, MC integration is not optimal in terms of absolute approximation error. To provide a better class of empirical SW, we propose quasi-sliced Wasserstein (QSW) approximations that rely on Quasi-Monte Carlo (QMC) methods. For a comprehensive investigation of QMC for SW, we focus on the 3D setting, specifically computing the SW between probability measures in three dimensions. In greater detail, we empirically evaluate various methods to construct QMC point sets on the 3D unit-hypersphere, including the Gaussian-based and equal area mappings, generalized spiral points, and optimizing discrepancy energies. Furthermore, to obtain an unbiased estimator for stochastic optimization, we extend QSW to Randomized Quasi-Sliced Wasserstein (RQSW) by introducing randomness in the discussed point sets. Theoretically, we prove the asymptotic convergence of QSW and the unbiasedness of RQSW. Finally, we conduct experiments on various 3D tasks, such as point-cloud comparison, point-cloud interpolation, image style transfer, and training deep point-cloud autoencoders, to demonstrate the favorable performance of the proposed QSW and RQSW variants.",
        "_bibtex": "@inproceedings{\nnguyen2024quasimonte,\ntitle={Quasi-Monte Carlo for 3D Sliced Wasserstein},\nauthor={Khai Nguyen and Nicola Bariletto and Nhat Ho},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Wd47f7HEXg}\n}"
    },
    {
        "title": "A Poincar\u00e9 Inequality and Consistency Results for Signal Sampling on Large Graphs",
        "authorids": [
            "~Thien_Le1",
            "~Luana_Ruiz1",
            "~Stefanie_Jegelka3"
        ],
        "keywords": [
            "large-scale graphs",
            "signal sampling",
            "graphons"
        ],
        "abstract": "Large-scale graph machine learning is challenging as the complexity of learning models scales with the graph size. Subsampling the graph is a viable alternative, but sampling on graphs is nontrivial as graphs are non-Euclidean. Existing graph sampling techniques require not only computing the spectra of large matrices but also repeating these computations when the graph changes, e.g., grows. In this paper, we introduce a signal sampling theory for a type of graph limit---the graphon. We prove a Poincar\u00e9 inequality for graphon signals and show that complements of node subsets satisfying this inequality are unique sampling sets for Paley-Wiener spaces of graphon signals. Exploiting connections with spectral clustering and Gaussian elimination, we prove that such sampling sets are consistent in the sense that unique sampling sets on a convergent graph sequence converge to unique sampling sets on the graphon. We then propose a related graphon signal sampling algorithm for large graphs, and demonstrate its good empirical performance on graph machine learning tasks.",
        "_bibtex": "@inproceedings{\nle2024a,\ntitle={A Poincar\\'e Inequality and Consistency Results for Signal Sampling on Large Graphs},\nauthor={Thien Le and Luana Ruiz and Stefanie Jegelka},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=l3qtSNsPvC}\n}"
    },
    {
        "title": "Cascading Reinforcement Learning",
        "authorids": [
            "~Yihan_Du2",
            "~R._Srikant1",
            "~Wei_Chen10"
        ],
        "keywords": [
            "reinforcement learning",
            "cascading bandits",
            "combinatorial action space",
            "computational and sample efficiency"
        ],
        "abstract": "Cascading bandits have gained popularity in recent years due to their applicability to recommendation systems and online advertising. In the cascading bandit model, at each timestep, an agent recommends an ordered subset of items (called an item list) from a pool of items, each associated with an unknown attraction probability. Then, the user examines the list, and clicks the first attractive item (if any), and after that, the agent receives a reward. The goal of the agent is to maximize the expected cumulative reward. However, the prior literature on cascading bandits ignores the influences of user states (e.g., historical behaviors) on recommendations and the change of states as the session proceeds. Motivated by this fact, we propose a generalized cascading RL framework, which considers the impact of user states and state transition into decisions. In cascading RL, we need to select items not only with  large attraction probabilities but also leading to good successor states. This imposes a huge computational challenge due to the combinatorial action space. To tackle this challenge, we delve into the properties of value functions, and design an oracle BestPerm to efficiently find the optimal item list. Equipped with BestPerm, we develop two algorithms CascadingVI and CascadingBPI, which are both computationally-efficient and sample-efficient, and provide near-optimal regret and sample complexity guarantees. Furthermore, we present experiments to show the improved computational and sample efficiencies of our algorithms compared to straightforward adaptations of existing RL algorithms in practice.",
        "_bibtex": "@inproceedings{\ndu2024cascading,\ntitle={Cascading Reinforcement Learning},\nauthor={Yihan Du and R. Srikant and Wei Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=KjOAHlKMF5}\n}"
    },
    {
        "title": "Complex priors and flexible inference in recurrent circuits with dendritic nonlinearities",
        "authorids": [
            "~Benjamin_S._H._Lyo1",
            "~Cristina_Savin1"
        ],
        "keywords": [
            "computational neuroscience",
            "probabilistic coding",
            "neural sampling",
            "priors"
        ],
        "abstract": "Despite many successful examples in which probabilistic inference can account for perception, we have little understanding of how the brain represents and uses structured priors that capture the complexity of natural input statistics. Here we construct a recurrent circuit model that can implicitly represent priors over latent variables, and combine them with sensory and contextual sources of information to encode task-specific posteriors. Inspired by the recent success of diffusion models as means of learning and using priors over images, our model uses dendritic nonlinearities optimized for denoising, and stochastic somatic integration with the degree of noise modulated by an oscillating global signal. Combining these elements into a recurrent network yields a stochastic dynamical system that samples from the prior at a rate prescribed by the period of the global oscillator. Additional inputs reflecting sensory or top-down contextual information alter these dynamics to generate samples from the corresponding posterior, with different input gating patterns selecting different inference tasks. We demonstrate that this architecture can sample from low dimensional nonlinear manifolds and multimodal posteriors. Overall, the model provides a new framework for circuit-level representation of probabilistic information, in a format that facilitates flexible inference.",
        "_bibtex": "@inproceedings{\nlyo2024complex,\ntitle={Complex priors and flexible inference in recurrent circuits with dendritic nonlinearities},\nauthor={Benjamin S. H. Lyo and Cristina Savin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=S5aUhpuyap}\n}"
    },
    {
        "title": "On the hardness of learning under symmetries",
        "authorids": [
            "~Bobak_Kiani1",
            "~Thien_Le1",
            "~Hannah_Lawrence1",
            "~Stefanie_Jegelka3",
            "~Melanie_Weber1"
        ],
        "keywords": [
            "Equivariance",
            "statistical query",
            "lower bound",
            "computational hardness",
            "invariance",
            "symmetry",
            "neural networks"
        ],
        "abstract": "We study the problem of learning equivariant neural networks via gradient descent. The incorporation of known  symmetries (\"equivariance\") into neural nets has empirically improved the performance of learning pipelines, in domains ranging from biology to computer vision. However, a rich yet separate line of learning theoretic research has demonstrated that actually learning shallow, fully-connected (i.e. non-symmetric) networks has exponential complexity in the correlational statistical query (CSQ) model, a framework encompassing gradient descent. In this work, we ask: are known problem symmetries sufficient to alleviate the fundamental hardness of learning neural nets with gradient descent? We answer this question in the negative. In particular, we give lower bounds for shallow graph neural networks, convolutional networks, invariant polynomials, and frame-averaged networks for permutation subgroups, which all scale either superpolynomially or exponentially in the relevant input dimension. Therefore, in spite of the significant inductive bias imparted via symmetry, actually learning the complete classes of functions represented by equivariant neural networks via gradient descent remains hard.",
        "_bibtex": "@inproceedings{\nkiani2024on,\ntitle={On the hardness of learning under symmetries},\nauthor={Bobak Kiani and Thien Le and Hannah Lawrence and Stefanie Jegelka and Melanie Weber},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ARPrtuzAnQ}\n}"
    },
    {
        "title": "An Image Is Worth 1000 Lies: Transferability of Adversarial Images across Prompts on Vision-Language Models",
        "authorids": [
            "~Haochen_Luo1",
            "~Jindong_Gu1",
            "~Fengyuan_Liu1",
            "~Philip_Torr1"
        ],
        "keywords": [
            "Vision Language Model",
            "Adversarial Transferability",
            "Prompt Tuning"
        ],
        "abstract": "Different from traditional task-specific vision models, recent large VLMs can readily adapt to different vision tasks by simply using different textual instructions, i.e., prompts. However, a well-known concern about traditional task-specific vision models is that they can be misled by imperceptible adversarial perturbations. Furthermore, the concern is exacerbated by the phenomenon that the same adversarial perturbations can fool different task-specific models. Given that VLMs rely on prompts to adapt to different tasks, an intriguing question emerges: Can a single adversarial image mislead all predictions of VLMs when a thousand different prompts are given? This question essentially introduces a novel perspective on adversarial transferability: cross-prompt adversarial transferability. In this work, we propose the Cross-Prompt Attack (CroPA). This proposed method updates the visual adversarial perturbation with learnable textual prompts, which are designed to counteract the misleading effects of the adversarial image. By doing this, CroPA significantly improves the transferability of adversarial examples across prompts. Extensive experiments are conducted to verify the strong cross-prompt adversarial transferability of CroPA with prevalent VLMs including Flamingo, BLIP-2, and InstructBLIP in various different tasks.",
        "_bibtex": "@inproceedings{\nluo2024an,\ntitle={An Image Is Worth 1000 Lies: Transferability of Adversarial Images across Prompts on Vision-Language Models},\nauthor={Haochen Luo and Jindong Gu and Fengyuan Liu and Philip Torr},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=nc5GgFAvtk}\n}"
    },
    {
        "title": "One For All: Towards Training One Graph Model For All Classification Tasks",
        "authorids": [
            "~Hao_Liu25",
            "~Jiarui_Feng1",
            "~Lecheng_Kong1",
            "~Ningyue_Liang1",
            "~Dacheng_Tao1",
            "~Yixin_Chen1",
            "~Muhan_Zhang1"
        ],
        "keywords": [
            "Graph Neural Network",
            "Large Language Model",
            "In-context Learning"
        ],
        "abstract": "Designing a single model to address multiple tasks has been a long-standing objective in artificial intelligence. Recently, large language models have demonstrated exceptional capability in solving different tasks within the language domain. However, a unified model for various graph tasks remains underexplored, primarily due to the challenges unique to the graph learning domain. First, graph data from different areas carry distinct attributes and follow different distributions. Such discrepancy makes it hard to represent graphs in a single representation space. Second, tasks on graphs diversify into node, link, and graph tasks, requiring distinct embedding strategies. Finally, an appropriate graph prompting paradigm for in-context learning is unclear. We propose **One for All (OFA)**, the first general framework that can use a single graph model to address the above challenges. Specifically, OFA proposes text-attributed graphs to unify different graph data by describing nodes and edges with natural language and uses language models to encode the diverse and possibly cross-domain text attributes to feature vectors in the same embedding space. Furthermore, OFA introduces the concept of nodes-of-interest to standardize different tasks with a single task representation. For in-context learning on graphs, OFA introduces a novel graph prompting paradigm that appends prompting substructures to the input graph, which enables it to address varied tasks without fine-tuning. We train the OFA model using graph data from multiple domains (including citation networks, molecular graphs, knowledge graphs, etc.) simultaneously and evaluate its ability in supervised, few-shot, and zero-shot learning scenarios. OFA performs well across different tasks, making it the first general-purpose across-domains classification model on graphs.",
        "_bibtex": "@inproceedings{\nliu2024one,\ntitle={One For All: Towards Training One Graph Model For All Classification Tasks},\nauthor={Hao Liu and Jiarui Feng and Lecheng Kong and Ningyue Liang and Dacheng Tao and Yixin Chen and Muhan Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=4IT2pgc9v6}\n}"
    },
    {
        "title": "$\\texttt{NAISR}$: A 3D Neural Additive Model for Interpretable Shape Representation",
        "authorids": [
            "~Yining_Jiao1",
            "~Carlton_Jude_ZDANSKI1",
            "~Julia_S_Kimbell1",
            "~Andrew_Prince2",
            "~Cameron_P_Worden1",
            "~Samuel_Kirse1",
            "~Christopher_Rutter1",
            "~Benjamin_Shields1",
            "~William_Alexander_Dunn1",
            "~Jisan_Mahmud1",
            "~Marc_Niethammer1"
        ],
        "keywords": [
            "Shape Modeling",
            "Medical Shape Analysis",
            "Interpretable Representation",
            "AI4Science"
        ],
        "abstract": "Deep implicit functions (DIFs) have emerged as a powerful paradigm for many computer vision tasks such as 3D shape reconstruction, generation, registration, completion, editing, and understanding. However, given a set of 3D shapes with associated covariates there is at present no shape representation method which allows to precisely represent the shapes while capturing the individual dependencies on each covariate. Such a method would be of high utility to researchers to discover knowledge hidden in a population of shapes. For scientific shape discovery purpose, we propose a 3D Neural Additive Model for Interpretable Shape Representation ($\\texttt{NAISR}$) which describes individual shapes by deforming a shape atlas in accordance to the effect of disentangled covariates. Our approach captures shape population trends and allows for patient-specific predictions through shape transfer. $\\texttt{NAISR}$ is the first approach to combine the benefits of deep implicit shape representations with an atlas deforming according to specified covariates. We evaluate $\\texttt{NAISR}$ with respect to shape reconstruction, shape disentanglement, shape evolution, and shape transfer on three datasets, i.e. 1) $\\textit{Starman}$, a simulated 2D shape dataset; 2) ADNI hippocampus 3D shape dataset; 3) pediatric airway 3D shape dataset. Our experiments demonstrate that $\\texttt{NAISR}$ achieves competitive shape reconstruction performance while retaining interpretability. Our code is available at https://github.com/uncbiag/NAISR.",
        "_bibtex": "@inproceedings{\njiao2024textttnaisr,\ntitle={\\${\\textbackslash}texttt\\{{NAISR}\\}\\$: A 3D Neural Additive Model for Interpretable Shape Representation},\nauthor={Yining Jiao and Carlton Jude ZDANSKI and Julia S Kimbell and Andrew Prince and Cameron P Worden and Samuel Kirse and Christopher Rutter and Benjamin Shields and William Alexander Dunn and Jisan Mahmud and Marc Niethammer},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=wg8NPfeMF9}\n}"
    },
    {
        "title": "Feature emergence via margin maximization: case studies in algebraic tasks",
        "authorids": [
            "~Depen_Morwani1",
            "~Benjamin_L._Edelman1",
            "~Costin-Andrei_Oncescu1",
            "~Rosie_Zhao1",
            "~Sham_M._Kakade1"
        ],
        "keywords": [
            "inductive bias",
            "margin maximization",
            "feature learning",
            "mechanistic interpretability"
        ],
        "abstract": "Understanding the internal representations learned by neural networks is a cornerstone challenge in the science of machine learning. While there have been significant recent strides in some cases towards understanding *how* neural networks implement specific target functions, this paper explores a complementary question -- *why* do networks arrive at particular computational strategies? \nOur inquiry focuses on the algebraic learning tasks of modular addition, sparse parities, and finite group operations. Our primary theoretical findings analytically characterize the features learned by stylized neural networks for these algebraic tasks. Notably, our main technique demonstrates how the principle of margin maximization alone can be used to fully specify the features learned by the network. \nSpecifically, we prove that the trained networks utilize Fourier features to perform modular addition and employ features corresponding to irreducible group-theoretic representations to perform compositions in general groups, aligning closely with the empirical observations of Nanda et al. (2023) and Chughtai et al. (2023). More generally, we hope our techniques can help to foster a deeper understanding of why neural networks adopt specific computational strategies.",
        "_bibtex": "@inproceedings{\nmorwani2024feature,\ntitle={Feature emergence via margin maximization: case studies in algebraic tasks},\nauthor={Depen Morwani and Benjamin L. Edelman and Costin-Andrei Oncescu and Rosie Zhao and Sham M. Kakade},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=i9wDX850jR}\n}"
    },
    {
        "title": "On the Stability of Iterative Retraining of Generative Models on their own Data",
        "authorids": [
            "~Quentin_Bertrand1",
            "~Joey_Bose1",
            "~Alexandre_Duplessis1",
            "~Marco_Jiralerspong1",
            "~Gauthier_Gidel1"
        ],
        "keywords": [
            "Generative Models",
            "Iterative Training",
            "Diffusion"
        ],
        "abstract": "Deep generative models have made tremendous progress in modeling complex data, often exhibiting generation quality that surpasses a typical human's ability to discern the authenticity of samples. Undeniably, a key driver of this success is enabled by the massive amounts of web-scale data consumed by these models. Due to these models' striking performance and ease of availability, the web will inevitably be increasingly populated with synthetic content. Such a fact directly implies that future iterations of generative models will be trained on both clean and artificially generated data from past models. In this paper, we develop a framework to rigorously study the impact of training generative models on mixed datasets---from classical training on real data to self-consuming generative models trained on purely synthetic data. We first prove the stability of iterative training under the condition that the initial generative models approximate the data distribution well enough and the proportion of clean training data (w.r.t. synthetic data) is large enough. We empirically validate our theory on both synthetic and natural images by iteratively training normalizing flows and state-of-the-art diffusion models on CIFAR10 and FFHQ.",
        "_bibtex": "@inproceedings{\nbertrand2024on,\ntitle={On the Stability of Iterative Retraining of Generative Models on their own Data},\nauthor={Quentin Bertrand and Joey Bose and Alexandre Duplessis and Marco Jiralerspong and Gauthier Gidel},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=JORAfH2xFd}\n}"
    },
    {
        "title": "Intriguing Properties of Generative Classifiers",
        "authorids": [
            "~Priyank_Jaini1",
            "~Kevin_Clark1",
            "~Robert_Geirhos1"
        ],
        "keywords": [
            "diffusion models",
            "zero-shot",
            "text-to-image",
            "generative models",
            "human visual perception",
            "psychophysics",
            "cognitive science",
            "neuroscience"
        ],
        "abstract": "What is the best paradigm to recognize objects---discriminative inference (fast but potentially prone to shortcut learning) or using a generative model (slow but potentially more robust)? We build on recent advances in generative modeling that turn text-to-image models into classifiers. This allows us to study their behavior and to compare them against discriminative models and human psychophysical data.\nWe report four intriguing emergent properties of generative classifiers: they show a record-breaking human-like shape bias (99% for Imagen), near human-level out-of-distribution accuracy, state-of-the-art alignment with human classification errors, and they understand certain perceptual illusions. Our results indicate that while the current dominant paradigm for modeling human object recognition is discriminative inference, zero-shot generative models approximate human object recognition data surprisingly well.",
        "_bibtex": "@inproceedings{\njaini2024intriguing,\ntitle={Intriguing Properties of Generative Classifiers},\nauthor={Priyank Jaini and Kevin Clark and Robert Geirhos},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rmg0qMKYRQ}\n}"
    },
    {
        "title": "Fast Imitation via Behavior Foundation Models",
        "authorids": [
            "~Matteo_Pirotta1",
            "~Andrea_Tirinzoni2",
            "~Ahmed_Touati1",
            "~Alessandro_Lazaric2",
            "~Yann_Ollivier2"
        ],
        "keywords": [
            "Behavior Foundation Models",
            "unsupervised reinforcement learning",
            "imitation learning"
        ],
        "abstract": "Imitation learning (IL) aims at producing agents that can imitate any behavior given a few expert demonstrations. Yet existing approaches require many demonstrations and/or running (online or offline) reinforcement learning (RL) algorithms for each new imitation task. Here we show that recent RL foundation models based on successor measures can imitate any expert behavior almost instantly with just a few demonstrations and no need for RL or fine-tuning, while accommodating several IL principles (behavioral cloning, feature matching, reward-based, and goal-based reductions). In our experiments, imitation via RL foundation models matches, and often surpasses, the performance of SOTA offline IL algorithms, and produces imitation policies from new demonstrations within seconds instead of hours.",
        "_bibtex": "@inproceedings{\npirotta2024fast,\ntitle={Fast Imitation via Behavior Foundation Models},\nauthor={Matteo Pirotta and Andrea Tirinzoni and Ahmed Touati and Alessandro Lazaric and Yann Ollivier},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=qnWtw3l0jb}\n}"
    },
    {
        "title": "Task Adaptation from Skills: Information Geometry, Disentanglement, and New Objectives for Unsupervised Reinforcement Learning",
        "authorids": [
            "~Yucheng_Yang2",
            "~Tianyi_Zhou1",
            "~Qiang_He1",
            "~Lei_Han1",
            "~Mykola_Pechenizkiy1",
            "~Meng_Fang1"
        ],
        "keywords": [
            "unsupervised skill learning",
            "reward-free RL",
            "downstream task adaptation",
            "wasserstein distance",
            "theoretical analysis"
        ],
        "abstract": "Unsupervised reinforcement learning (URL) aims to learn general skills for unseen downstream tasks. Mutual Information Skill Learning (MISL) addresses URL by maximizing the mutual information between states and skills but lacks sufficient theoretical analysis, e.g., how well its learned skills can initialize a downstream task's policy. Our new theoretical analysis shows that the diversity and separatability of learned skills are fundamentally critical to downstream task adaptation but MISL does not necessarily guarantee them. To improve MISL, we propose a novel disentanglement metric LSEPIN and build an information-geometric connection between LSEPIN and downstream task adaptation cost. For better geometric properties, we investigate a new strategy that replaces the KL divergence in information geometry with Wasserstein distance. We extend the geometric analysis to it, which leads to a novel skill-learning objective WSEP. It is theoretically justified to be helpful to task adaptation and it is capable of discovering more initial policies for downstream tasks than MISL. We further propose a Wasserstein distance-based algorithm PWSEP can theoretically discover all potentially optimal initial policies.",
        "_bibtex": "@inproceedings{\nyang2024task,\ntitle={Task Adaptation from Skills: Information Geometry, Disentanglement, and New Objectives for Unsupervised Reinforcement Learning},\nauthor={Yucheng Yang and Tianyi Zhou and Qiang He and Lei Han and Mykola Pechenizkiy and Meng Fang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=zSxpnKh1yS}\n}"
    },
    {
        "title": "NuwaDynamics: Discovering and Updating in Causal Spatio-Temporal Modeling",
        "authorids": [
            "~Kun_Wang15",
            "~Hao_Wu39",
            "~Yifan_Duan1",
            "~Guibin_Zhang1",
            "~Kai_Wang8",
            "~Xiaojiang_Peng1",
            "~Yu_Zheng11",
            "~Yuxuan_Liang1",
            "~Yang_Wang32"
        ],
        "keywords": [
            "Spatio-temporal data mining",
            "Causal inference",
            "Two-stage framework"
        ],
        "abstract": "Spatio-temporal (ST) prediction plays a pivotal role in earth sciences, such as meteorological prediction, urban computing. Adequate high-quality data, coupled with deep models capable of inference, are both indispensable and prerequisite for achieving meaningful results. However, the sparsity of data and the high costs associated with deploying sensors lead to significant data imbalances. Models that are overly tailored and lack causal relationships further compromise the generalizabilities of inference methods. Towards this end, we first establish a causal concept for ST predictions, named  NuwaDynamics, which targets to identify causal regions in data and endow model with causal reasoning ability in a two-stage process. Concretely, we initially leverage upstream self-supervision to discern causal important patches, imbuing the model with generalized information and conducting informed interventions on complementary trivial patches to extrapolate potential test distributions. This phase is referred to as the discovery step. Advancing beyond discovery step, we transfer the data to downstream tasks for targeted ST objectives, aiding the model in recognizing a broader potential distribution and fostering its causal perceptual capabilities (refer as Update step). Our concept aligns seamlessly with the contemporary backdoor adjustment mechanism in causality theory. Extensive experiments on six real-world ST benchmarks showcase that models can gain outcomes upon the integration of the NuwaDynamics concept. NuwaDynamics also can significantly benefit a wide range of changeable ST tasks like extreme weather and long temporal step super-resolution predictions.",
        "_bibtex": "@inproceedings{\nwang2024nuwadynamics,\ntitle={NuwaDynamics: Discovering and Updating in Causal Spatio-Temporal Modeling},\nauthor={Kun Wang and Hao Wu and Yifan Duan and Guibin Zhang and Kai Wang and Xiaojiang Peng and Yu Zheng and Yuxuan Liang and Yang Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=sLdVl0q68X}\n}"
    },
    {
        "title": "Pre-Training and Fine-Tuning Generative Flow Networks",
        "authorids": [
            "~Ling_Pan1",
            "~Moksh_Jain1",
            "~Kanika_Madan3",
            "~Yoshua_Bengio1"
        ],
        "keywords": [
            "Generative Flow Network (GFlowNets)",
            "Pre-train",
            "Goal-conditioned"
        ],
        "abstract": "Generative Flow Networks (GFlowNets) are amortized samplers that learn stochastic policies to sequentially generate compositional objects from a given unnormalized reward distribution.\nThey can generate diverse sets of high-reward objects, which is an important consideration in scientific discovery tasks. However, as they are typically trained from a given extrinsic reward function, it remains an important open challenge about how to leverage the power of pre-training and train GFlowNets in an unsupervised fashion for efficient adaptation to downstream tasks.\nInspired by recent successes of unsupervised pre-training in various domains, we introduce a novel approach for reward-free pre-training of GFlowNets. By framing the training as a self-supervised problem, we propose an outcome-conditioned GFlowNet (OC-GFN) that learns to explore the candidate space. Specifically, OC-GFN learns to reach any targeted outcomes, akin to goal-conditioned policies in reinforcement learning. \nWe show that the pre-trained OC-GFN model can allow for a direct extraction of a policy capable of sampling from any new reward functions in downstream tasks.\nNonetheless, adapting OC-GFN on a downstream task-specific reward involves an intractable marginalization over possible outcomes. We propose a novel way to approximate this marginalization by learning an amortized predictor enabling efficient fine-tuning.\nExtensive experimental results validate the efficacy of our approach, demonstrating the effectiveness of pre-training the OC-GFN, and its ability to swiftly adapt to downstream tasks and discover modes more efficiently.\nThis work may serve as a foundation for further exploration of pre-training strategies in the context of GFlowNets.",
        "_bibtex": "@inproceedings{\npan2024pretraining,\ntitle={Pre-Training and Fine-Tuning Generative Flow Networks},\nauthor={Ling Pan and Moksh Jain and Kanika Madan and Yoshua Bengio},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ylhiMfpqkm}\n}"
    },
    {
        "title": "CO2: Efficient Distributed Training with Full Communication-Computation Overlap",
        "authorids": [
            "~Weigao_Sun1",
            "~Zhen_Qin6",
            "~Weixuan_Sun1",
            "~Shidi_Li1",
            "~Dong_Li11",
            "~Xuyang_Shen1",
            "~Yu_Qiao1",
            "~Yiran_Zhong1"
        ],
        "keywords": [
            "Distributed Training",
            "Data Parallelism",
            "Local Updating",
            "Asynchronous Communication"
        ],
        "abstract": "The fundamental success of large language models hinges upon the efficacious implementation of large-scale distributed training techniques. Nevertheless, building a vast, high-performance cluster featuring high-speed communication interconnectivity is prohibitively costly, and accessible only to prominent entities. In this work, we aim to lower this barrier and democratize large-scale training with limited bandwidth clusters. We propose a new approach called CO2 that introduces local-updating and asynchronous communication to the distributed data-parallel training, thereby facilitating the full overlap of COmmunication with COmputation. CO2 is able to attain a high scalability even on extensive multi-node clusters constrained by very limited communication bandwidth. We further propose the staleness gap penalty and outer momentum clipping techniques together with CO2 to bolster its convergence and training stability. Besides, CO2 exhibits seamless integration with well-established ZeRO-series optimizers which mitigate memory consumption of model states with large model training. We also provide a mathematical proof of convergence, accompanied by the establishment of a stringent upper bound. Furthermore, we validate our findings through an extensive set of practical experiments encompassing a wide range of tasks in the fields of computer vision and natural language processing. These experiments serve to demonstrate the capabilities of CO2 in terms of convergence, generalization, and scalability when deployed across configurations comprising up to 128 A100 GPUs. The outcomes emphasize the outstanding capacity of CO2 to hugely improve scalability, no matter on clusters with 800Gbps RDMA or 80Gbps TCP/IP inter-node connections.",
        "_bibtex": "@inproceedings{\nsun2024co,\ntitle={{CO}2: Efficient Distributed Training with Full Communication-Computation Overlap},\nauthor={Weigao Sun and Zhen Qin and Weixuan Sun and Shidi Li and Dong Li and Xuyang Shen and Yu Qiao and Yiran Zhong},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ZO5cn4IfaN}\n}"
    },
    {
        "title": "CADS: Unleashing the Diversity of Diffusion Models through Condition-Annealed Sampling",
        "authorids": [
            "~Seyedmorteza_Sadat1",
            "~Jakob_Buhmann1",
            "~Derek_Bradley1",
            "~Otmar_Hilliges1",
            "~Romann_M._Weber1"
        ],
        "keywords": [
            "diffusion models",
            "diversity",
            "generative models"
        ],
        "abstract": "While conditional diffusion models are known to have good coverage of the data distribution, they still face limitations in output diversity, particularly when sampled with a high classifier-free guidance scale for optimal image quality or when trained on small datasets. We attribute this problem to the role of the conditioning signal in inference and offer an improved sampling strategy for diffusion models that can increase generation diversity, especially at high guidance scales, with minimal loss of sample quality. Our sampling strategy anneals the conditioning signal by adding scheduled, monotonically decreasing Gaussian noise to the conditioning vector during inference to balance diversity and condition alignment. Our Condition-Annealed Diffusion Sampler (CADS) can be used with any pretrained model and sampling algorithm, and we show that it boosts the diversity of diffusion models in various conditional generation tasks. Further, using an existing pretrained diffusion model, CADS achieves a new state-of-the-art FID of 1.70 and 2.31 for class-conditional ImageNet generation  at 256$\\times$256 and 512$\\times$512 respectively.",
        "_bibtex": "@inproceedings{\nsadat2024cads,\ntitle={{CADS}: Unleashing the Diversity of Diffusion Models through Condition-Annealed Sampling},\nauthor={Seyedmorteza Sadat and Jakob Buhmann and Derek Bradley and Otmar Hilliges and Romann M. Weber},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=zMoNrajk2X}\n}"
    },
    {
        "title": "Image Inpainting via Iteratively Decoupled Probabilistic Modeling",
        "authorids": [
            "~Wenbo_Li6",
            "~Xin_Yu6",
            "~Kun_Zhou3",
            "~Yibing_Song1",
            "~Zhe_Lin1"
        ],
        "keywords": [
            "Inpainting",
            "Decoupled Probabilistic Modeling",
            "Pixel Spread Model"
        ],
        "abstract": "Generative adversarial networks (GANs) have made great success in image inpainting yet still have difficulties tackling large missing regions. In contrast, iterative probabilistic algorithms, such as autoregressive and denoising diffusion models, have to be deployed with massive computing resources for decent effect. To achieve high-quality results with low computational cost, we present a novel pixel spread model (PSM) that iteratively employs decoupled probabilistic modeling, combining the optimization efficiency of GANs with the prediction tractability of probabilistic models. As a result, our model selectively spreads informative pixels throughout the image in a few iterations, largely enhancing the completion quality and efficiency. On multiple benchmarks, we achieve new state-of-the-art performance. Our code and models will be publicly available.",
        "_bibtex": "@inproceedings{\nli2024image,\ntitle={Image Inpainting via Iteratively Decoupled Probabilistic Modeling},\nauthor={Wenbo Li and Xin Yu and Kun Zhou and Yibing Song and Zhe Lin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rUf9G9k2im}\n}"
    },
    {
        "title": "Image2Sentence based Asymmetrical Zero-shot Composed Image Retrieval",
        "authorids": [
            "~Yongchao_Du1",
            "~Min_Wang9",
            "~Wengang_Zhou1",
            "~Shuping_Hui1",
            "~Houqiang_Li1"
        ],
        "keywords": [
            "zero-shot",
            "composed image retrieval",
            "asymmetrical"
        ],
        "abstract": "The task of composed image retrieval (CIR) aims to retrieve images based on the query image and the text describing the users' intent. \nExisting methods have made great progress with the advanced large vision-language (VL) model in CIR task, however, they generally suffer from two main issues: lack of labeled triplets for model training and difficulty of deployment on resource-restricted environments when deploying the large vision-language model. To tackle the above problems, we propose Image2Sentence based Asymmetric zero-shot composed image retrieval (ISA), which takes advantage of the VL model and only relies on unlabeled images for composition learning. In the framework, we propose a new adaptive token learner that maps an image to a sentence in the word embedding space of VL model.  The sentence adaptively captures discriminative visual information and is further integrated with the text modifier. An asymmetric structure is devised for flexible deployment, in which the lightweight model is adopted for the query side while the large VL model is deployed on the gallery side. The global contrastive distillation and the local alignment regularization are adopted for the alignment between the light model and the VL model for CIR task.  Our experiments demonstrate that the proposed ISA could better cope with the real retrieval scenarios and further improve retrieval accuracy and efficiency.",
        "_bibtex": "@inproceedings{\ndu2024imagesentence,\ntitle={Image2Sentence based Asymmetrical Zero-shot Composed Image Retrieval},\nauthor={Yongchao Du and Min Wang and Wengang Zhou and Shuping Hui and Houqiang Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5BXAXOpaWu}\n}"
    },
    {
        "title": "Bespoke Solvers for Generative Flow Models",
        "authorids": [
            "~Neta_Shaul1",
            "~Juan_Perez1",
            "~Ricky_T._Q._Chen1",
            "~Ali_Thabet1",
            "~Albert_Pumarola2",
            "~Yaron_Lipman1"
        ],
        "keywords": [
            "generative models",
            "flow matching",
            "diffusion models",
            "normalizing flows",
            "ode solver",
            "fast sampling",
            "distillation"
        ],
        "abstract": "Diffusion or flow-based models are powerful generative paradigms that are notoriously hard to sample as samples are defined as solutions to high-dimensional Ordinary or Stochastic Differential Equations (ODEs/SDEs) which require a large Number of Function Evaluations (NFE) to approximate well. Existing methods to alleviate the costly sampling process include model distillation and designing dedicated ODE solvers. However, distillation is costly to train and sometimes can deteriorate quality, while dedicated solvers still require relatively large NFE to produce high quality samples. In this paper we introduce ``Bespoke solvers'', a novel framework for constructing custom ODE solvers tailored to the ODE of a given pre-trained flow model. Our approach optimizes an order consistent and parameter-efficient solver (e.g., with 80 learnable parameters), is trained for roughly 1\\% of the GPU time required for training the pre-trained model, and significantly improves approximation and generation quality compared to dedicated solvers. For example, a Bespoke solver for a CIFAR10 model produces samples with Fr\u00e9chet Inception Distance (FID) of 2.73 with 10 NFE, and gets to 1\\% of the Ground Truth (GT) FID (2.59) for this model with only 20 NFE. On the more challenging ImageNet-64$\\times$64, Bespoke samples at 2.2 FID with 10 NFE, and gets within 2\\% of GT FID (1.71) with 20 NFE.",
        "_bibtex": "@inproceedings{\nshaul2024bespoke,\ntitle={Bespoke Solvers for Generative Flow Models},\nauthor={Neta Shaul and Juan Perez and Ricky T. Q. Chen and Ali Thabet and Albert Pumarola and Yaron Lipman},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=1PXEY7ofFX}\n}"
    },
    {
        "title": "Leveraging augmented-Lagrangian techniques for differentiating over infeasible quadratic programs in machine learning",
        "authorids": [
            "~Antoine_Bambade1",
            "~Fabian_Schramm1",
            "~Adrien_Taylor1",
            "~Justin_Carpentier1"
        ],
        "keywords": [
            "Machine Learning",
            "Optimization",
            "Differentiable Optimization",
            "Optimization layers"
        ],
        "abstract": "Optimization layers within neural network architectures have become increasingly popular for their ability to solve a wide range of machine learning tasks and to model domain-specific knowledge. However, designing optimization layers requires careful consideration as the underlying optimization problems might be infeasible during training. \nMotivated by applications in learning, control and robotics, this work focuses on convex quadratic programming (QP) layers. The specific structure of this type of optimization layer can be efficiently exploited for faster computations while still allowing rich modeling capabilities. We leverage primal-dual augmented Lagrangian techniques for computing derivatives of both feasible and infeasible QP solutions. \nMore precisely, we propose a unified approach which tackles the differentiability of the closest feasible QP solutions in a classical $\\ell_2$ sense. We then harness this approach to enrich the expressive capabilities of existing QP layers. More precisely, we show how differentiating through infeasible QPs during training enables to drive towards feasibility at test time a new range of QP layers. These layers notably demonstrate superior predictive performance in some conventional learning tasks. Additionally, we present alternative formulations that enhance numerical robustness, speed, and accuracy for training such layers. \nAlong with these contributions, we provide an open-source C++ software package called QPLayer for differentiating feasible and infeasible convex QPs and which can be interfaced with modern learning frameworks.",
        "_bibtex": "@inproceedings{\nbambade2024leveraging,\ntitle={Leveraging augmented-Lagrangian techniques for differentiating over infeasible quadratic programs in machine learning},\nauthor={Antoine Bambade and Fabian Schramm and Adrien Taylor and Justin Carpentier},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=YCPDFfmkFr}\n}"
    },
    {
        "title": "ODEFormer: Symbolic Regression of Dynamical Systems with Transformers",
        "authorids": [
            "~St\u00e9phane_d'Ascoli1",
            "~S\u00f6ren_Becker2",
            "~Philippe_Schwaller1",
            "~Alexander_Mathis1",
            "~Niki_Kilbertus1"
        ],
        "keywords": [
            "symbolic regression",
            "dynamical systems",
            "differential equations",
            "transformer"
        ],
        "abstract": "We introduce ODEFormer, the first transformer able to infer multidimensional ordinary differential equation (ODE) systems in symbolic form from the observation of a single solution trajectory. We perform extensive evaluations on two datasets: (i) the existing \u2018Strogatz\u2019 dataset featuring two-dimensional systems; (ii) ODEBench, a collection of one- to four-dimensional systems that we carefully curated from the literature to provide a more holistic benchmark. ODEFormer consistently outperforms existing methods while displaying substantially improved robustness to noisy and irregularly sampled observations, as well as faster inference. We release our code, model and benchmark at https://github.com/sdascoli/odeformer.",
        "_bibtex": "@inproceedings{\nd'ascoli2024odeformer,\ntitle={{ODEF}ormer: Symbolic Regression of Dynamical Systems with Transformers},\nauthor={St{\\'e}phane d'Ascoli and S{\\\"o}ren Becker and Philippe Schwaller and Alexander Mathis and Niki Kilbertus},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TzoHLiGVMo}\n}"
    },
    {
        "title": "Convergence of Bayesian Bilevel Optimization",
        "authorids": [
            "~Shi_Fu1",
            "~Fengxiang_He1",
            "~Xinmei_Tian1",
            "~Dacheng_Tao1"
        ],
        "keywords": [
            "Hyperparameter optimization",
            "Bayesian optimization",
            "Convergence rate",
            "Bilevel optimization",
            "Learning theory"
        ],
        "abstract": "This paper presents the first theoretical guarantee for Bayesian bilevel optimization (BBO) that we term for the prevalent bilevel framework combining Bayesian optimization at the outer level to tune hyperparameters, and the inner-level stochastic gradient descent (SGD) for training the model. We prove sublinear regret bounds suggesting simultaneous convergence of the inner-level model parameters and outer-level hyperparameters to optimal configurations for generalization capability. A pivotal, technical novelty in the proofs is modeling the excess risk of the SGD-trained parameters as evaluation noise during Bayesian optimization. Our theory implies the inner unit horizon, defined as the number of SGD iterations, shapes the convergence behavior of BBO. This suggests practical guidance on configuring the inner unit horizon to enhance training efficiency and model performance.",
        "_bibtex": "@inproceedings{\nfu2024convergence,\ntitle={Convergence of Bayesian Bilevel Optimization},\nauthor={Shi Fu and Fengxiang He and Xinmei Tian and Dacheng Tao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=fLXpXa7iiz}\n}"
    },
    {
        "title": "MovingParts: Motion-based 3D Part Discovery in Dynamic Radiance Field",
        "authorids": [
            "~Kaizhi_Yang1",
            "~Xiaoshuai_Zhang1",
            "~Zhiao_Huang1",
            "~Xuejin_Chen1",
            "~Zexiang_Xu1",
            "~Hao_Su1"
        ],
        "keywords": [
            "NeRF",
            "Dynamic",
            "Motion",
            "Part discovery"
        ],
        "abstract": "We present MovingParts, a NeRF-based method for dynamic scene reconstruction and part discovery. We consider motion as an important cue for identifying parts, that all particles on the same part share the common motion pattern. From the perspective of fluid simulation, existing deformation-based methods for dynamic NeRF can be seen as parameterizing the scene motion under the Eulerian view, i.e., focusing on specific locations in space through which the fluid flows as time passes. However, it is intractable to extract the motion of constituting objects or parts using the Eulerian view representation. In this work, we introduce the dual Lagrangian view and enforce representations under the Eulerian/Lagrangian views to be cycle-consistent. Under the Lagrangian view, we parameterize the scene motion by tracking the trajectory of particles on objects. The Lagrangian view makes it convenient to discover parts by factorizing the scene motion as a composition of part-level rigid motions. Experimentally, our method can achieve fast and high-quality dynamic scene reconstruction from even a single moving camera, and the induced part-based representation allows direct applications of part tracking, animation, 3D scene editing, etc.",
        "_bibtex": "@inproceedings{\nyang2024movingparts,\ntitle={MovingParts: Motion-based 3D Part Discovery in Dynamic Radiance Field},\nauthor={Kaizhi Yang and Xiaoshuai Zhang and Zhiao Huang and Xuejin Chen and Zexiang Xu and Hao Su},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=QQ6RgKYiQq}\n}"
    },
    {
        "title": "Equivariant Matrix Function Neural Networks",
        "authorids": [
            "~Ilyes_Batatia1",
            "~Lars_Leon_Schaaf1",
            "~Gabor_Csanyi1",
            "~Christoph_Ortner1",
            "~Felix_Andreas_Faber1"
        ],
        "keywords": [
            "equivariance",
            "graph neural networks",
            "long range"
        ],
        "abstract": "Graph Neural Networks (GNNs), especially message-passing neural networks (MPNNs), have emerged as powerful architectures for learning on graphs in diverse applications. However, MPNNs face challenges when modeling non-local interactions in systems such as large conjugated molecules, metals, or amorphous materials.\nAlthough Spectral GNNs and traditional neural networks such as recurrent neural networks and transformers mitigate these challenges, they often lack extensivity, adaptability, generalizability, computational efficiency, or fail to capture detailed structural relationships or symmetries in the data. To address these concerns, we introduce Matrix Function Neural Networks (MFNs), a novel architecture that parameterizes non-local interactions through analytic matrix equivariant functions. Employing resolvent expansions offers a straightforward implementation and the potential for linear scaling with system size.\nThe MFN architecture achieves state-of-the-art performance in standard graph benchmarks, such as the ZINC and TU datasets, and is able to capture intricate non-local interactions in quantum systems. The code and the datasets will be made public.",
        "_bibtex": "@inproceedings{\nbatatia2024equivariant,\ntitle={Equivariant Matrix Function Neural Networks},\nauthor={Ilyes Batatia and Lars Leon Schaaf and Gabor Csanyi and Christoph Ortner and Felix Andreas Faber},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=yrgQdA5NkI}\n}"
    },
    {
        "title": "Multi-resolution HuBERT: Multi-resolution Speech Self-Supervised Learning with Masked Unit Prediction",
        "authorids": [
            "~Jiatong_Shi1",
            "~Hirofumi_Inaguma1",
            "~Xutai_Ma1",
            "~Ilia_Kulikov1",
            "~Anna_Sun1"
        ],
        "keywords": [
            "Speech Representation Learning",
            "Self-supervised Learning",
            "Multi-resolution"
        ],
        "abstract": "Existing Self-Supervised Learning (SSL) models for speech typically process speech signals at a fixed resolution of 20 milliseconds. This approach overlooks the varying informational content present at different resolutions in speech signals. In contrast, this paper aims to incorporate multi-resolution information into speech self-supervised representation learning. We introduce an SSL model that leverages a hierarchical Transformer architecture, complemented by HuBERT-style masked prediction objectives, to process speech at multiple resolutions. Experimental results indicate that the proposed model not only achieves more efficient inference but also exhibits superior or comparable performance to the original HuBERT model over various tasks. Specifically, significant performance improvements over the original HuBERT have been observed in fine-tuning experiments on the LibriSpeech speech recognition benchmark as well as in evaluations using the Speech Universal PERformance Benchmark (SUPERB) and Multilingual SUPERB (ML-SUPERB).",
        "_bibtex": "@inproceedings{\nshi2024multiresolution,\ntitle={Multi-resolution Hu{BERT}: Multi-resolution Speech Self-Supervised Learning with Masked Unit Prediction},\nauthor={Jiatong Shi and Hirofumi Inaguma and Xutai Ma and Ilia Kulikov and Anna Sun},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=kUuKFW7DIF}\n}"
    },
    {
        "title": "Input-gradient space particle inference for neural network ensembles",
        "authorids": [
            "~Trung_Trinh1",
            "~Markus_Heinonen1",
            "~Luigi_Acerbi1",
            "~Samuel_Kaski1"
        ],
        "keywords": [
            "deep ensembles",
            "diversity",
            "input gradient",
            "robustness",
            "covariate shift",
            "particle variational inference"
        ],
        "abstract": "Deep Ensembles (DEs) demonstrate improved accuracy, calibration and robustness to perturbations over single neural networks partly due to their functional diversity. Particle-based variational inference (ParVI) methods enhance diversity by formalizing a repulsion term based on a network similarity kernel. However, weight-space repulsion is inefficient due to over-parameterization, while direct function-space repulsion has been found to produce little improvement over DEs. To sidestep these difficulties, we propose First-order Repulsive Deep Ensemble (FoRDE), an ensemble learning method based on ParVI, which performs repulsion in the space of first-order input gradients. As input gradients uniquely characterize a function up to translation and are much smaller in dimension than the weights, this method guarantees that ensemble members are functionally different. Intuitively, diversifying the input gradients encourages each network to learn different features, which is expected to improve the robustness of an ensemble. Experiments on image classification datasets and transfer learning tasks show that FoRDE significantly outperforms the gold-standard DEs and other ensemble methods in accuracy and calibration under covariate shift due to input perturbations.",
        "_bibtex": "@inproceedings{\ntrinh2024inputgradient,\ntitle={Input-gradient space particle inference for neural network ensembles},\nauthor={Trung Trinh and Markus Heinonen and Luigi Acerbi and Samuel Kaski},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=nLWiR5P3wr}\n}"
    },
    {
        "title": "Prototypical Information Bottlenecking and Disentangling for Multimodal Cancer Survival Prediction",
        "authorids": [
            "~Yilan_Zhang1",
            "~Yingxue_Xu1",
            "~Jianqi_Chen1",
            "~Fengying_Xie1",
            "~Hao_Chen1"
        ],
        "keywords": [
            "multimodal survival prediction",
            "computational pathology"
        ],
        "abstract": "Multimodal learning significantly benefits cancer survival prediction, especially the integration of pathological images and genomic data. Despite advantages of multimodal learning for cancer survival prediction, massive redundancy in multimodal data prevents it from extracting discriminative and compact information: (1) An extensive amount of intra-modal task-unrelated information blurs discriminability, especially for gigapixel whole slide images (WSIs) with many patches in pathology and thousands of pathways in genomic data, leading to an \"intra-modal redundancy\" issue. (2) Duplicated information among modalities dominates the representation of multimodal data, which makes modality-specific information prone to being ignored, resulting in an \"inter-modal redundancy\" issue. To address these, we propose a new framework, Prototypical Information Bottlenecking and Disentangling (PIBD), consisting of Prototypical Information Bottleneck (PIB) module for intra-modal redundancy and Prototypical Information Disentanglement (PID) module for inter-modal redundancy. Specifically, a variant of information bottleneck, PIB, is proposed to model prototypes approximating a bunch of instances for different risk levels, which can be used for selection of discriminative instances within modality. PID module decouples entangled multimodal data into compact distinct components: modality-common and modality-specific knowledge, under the guidance of the joint prototypical distribution. Extensive experiments on five cancer benchmark datasets demonstrated our superiority over other methods. The code is released.",
        "_bibtex": "@inproceedings{\nzhang2024prototypical,\ntitle={Prototypical Information Bottlenecking and Disentangling for Multimodal Cancer Survival Prediction},\nauthor={Yilan Zhang and Yingxue Xu and Jianqi Chen and Fengying Xie and Hao Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=otHZ8JAIgh}\n}"
    },
    {
        "title": "MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data",
        "authorids": [
            "~Yinya_Huang1",
            "~Xiaohan_Lin2",
            "~Zhengying_Liu2",
            "~Qingxing_Cao1",
            "~Huajian_Xin1",
            "~Haiming_Wang1",
            "~Zhenguo_Li1",
            "~Linqi_Song1",
            "~Xiaodan_Liang2"
        ],
        "keywords": [
            "theorem proving",
            "math word problem",
            "mathematical reasoning",
            "benchmark"
        ],
        "abstract": "Recent large language models (LLMs) have witnessed significant advancement in various tasks, including mathematical reasoning and theorem proving. As these two tasks require strict and formal multi-step inference, they are appealing domains for exploring the reasoning ability of LLMs but still face important challenges. Previous studies such as Chain-of-Thought (CoT) have revealed the effectiveness of intermediate steps guidance. However, such step-wise annotation requires heavy labor, leading to insufficient training steps for current benchmarks. To fill this gap, this work introduces MUSTARD, a data generation framework that masters uniform synthesis of theorem and proof data of high quality and diversity. MUSTARD synthesizes data in three stages: (1) It samples a few mathematical concept seeds as the problem category. (2) Then, it prompts a generative language model with the sampled concepts to obtain both the problems and their step-wise formal solutions. (3) Lastly, the framework utilizes a proof assistant (e.g., Lean Prover) to filter the valid proofs. With the proposed MUSTARD, we present a theorem-and-proof benchmark MUSTARDSAUCE with 5,866 valid data points. Each data point contains an informal statement, an informal proof, and a translated formal proof that passes the prover validation. We perform extensive analysis and demonstrate that MUSTARD generates validated high-quality step-by-step data. We further apply the MUSTARDSAUCE for fine-tuning smaller language models. The fine-tuned Llama 2-7B achieves a 15.41% average relative performance gain in automated theorem proving, and 8.18% in math word problems. Codes and data are available at https://github.com/Eleanor-H/MUSTARD.",
        "_bibtex": "@inproceedings{\nhuang2024mustard,\ntitle={{MUSTARD}: Mastering Uniform Synthesis of Theorem and Proof Data},\nauthor={Yinya Huang and Xiaohan Lin and Zhengying Liu and Qingxing Cao and Huajian Xin and Haiming Wang and Zhenguo Li and Linqi Song and Xiaodan Liang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=8xliOUg9EW}\n}"
    },
    {
        "title": "FLD: Fourier Latent Dynamics for Structured Motion Representation and Learning",
        "authorids": [
            "~Chenhao_Li3",
            "~Elijah_Stanger-Jones1",
            "~Steve_Heim1",
            "~Sang_bae_Kim1"
        ],
        "keywords": [
            "latent dynamics",
            "motion representation and generation",
            "representation learning",
            "reinforcement learning"
        ],
        "abstract": "Motion trajectories offer reliable references for physics-based motion learning but suffer from sparsity, particularly in regions that lack sufficient data coverage. To address this challenge, we introduce a self-supervised, structured representation and generation method that extracts spatial-temporal relationships in periodic or quasi-periodic motions. The motion dynamics in a continuously parameterized latent space enable our method to enhance the interpolation and generalization capabilities of motion learning algorithms. The motion learning controller, informed by the motion parameterization, operates online tracking of a wide range of motions, including targets unseen during training. With a fallback mechanism, the controller dynamically adapts its tracking strategy and automatically resorts to safe action execution when a potentially risky target is proposed. By leveraging the identified spatial-temporal structure, our work opens new possibilities for future advancements in general motion representation and learning algorithms.",
        "_bibtex": "@inproceedings{\nli2024fld,\ntitle={{FLD}: Fourier Latent Dynamics for Structured Motion Representation and Learning},\nauthor={Chenhao Li and Elijah Stanger-Jones and Steve Heim and Sang bae Kim},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xsd2llWYSA}\n}"
    },
    {
        "title": "Towards Reliable and Efficient Backdoor Trigger Inversion via Decoupling Benign Features",
        "authorids": [
            "~Xiong_Xu1",
            "~Kunzhe_Huang1",
            "~Yiming_Li1",
            "~Zhan_Qin2",
            "~Kui_Ren4"
        ],
        "keywords": [
            "backdoor trigger inversion",
            "backdoor defense",
            "backdoor learning",
            "Trustworthy ML",
            "AI Security"
        ],
        "abstract": "Recent studies revealed that using third-party models may lead to backdoor threats, where adversaries can maliciously manipulate model predictions based on backdoors implanted during model training. Arguably, backdoor trigger inversion (BTI), which generates trigger patterns of given benign samples for a backdoored model, is the most critical module for backdoor defenses used in these scenarios. With BTI, defenders can remove backdoors by fine-tuning based on generated poisoned samples with ground-truth labels or deactivate backdoors by removing trigger patterns during the inference process. However, we find that existing BTI methods suffer from relatively poor performance, $i.e.$, their generated triggers are significantly different from the ones used by the adversaries even in the feature space. We argue that it is mostly because existing methods require to 'extract' backdoor features at first, while this task is very difficult since defenders have no information ($e.g.$, trigger pattern or target label) about poisoned samples. In this paper, we explore BTI from another perspective where we decouple benign features instead of decoupling backdoor features directly. Specifically, our method consists of two main steps, including \\textbf{(1)} decoupling benign features and \\textbf{(2)} trigger inversion by minimizing the differences between benign samples and their generated poisoned version in decoupled benign features while maximizing the differences in remaining backdoor features. In particular, our method is more efficient since it doesn't need to `scan' all classes to speculate the target label, as required by existing BTI. We also exploit our BTI module to further design backdoor-removal and pre-processing-based defenses. Extensive experiments on benchmark datasets demonstrate that our defenses can reach state-of-the-art performances.",
        "_bibtex": "@inproceedings{\nxu2024towards,\ntitle={Towards Reliable and Efficient Backdoor Trigger Inversion via Decoupling Benign Features},\nauthor={Xiong Xu and Kunzhe Huang and Yiming Li and Zhan Qin and Kui Ren},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Tw9wemV6cb}\n}"
    },
    {
        "title": "Long-Term Typhoon Trajectory Prediction: A Physics-Conditioned Approach Without Reanalysis Data",
        "authorids": [
            "~Young-Jae_Park1",
            "~Minseok_Seo1",
            "~Doyi_Kim1",
            "~Hyeri_Kim1",
            "~Sanghoon_Choi1",
            "~Beomkyu_Choi1",
            "~Jeongwon_Ryu1",
            "~Sohee_Son2",
            "~Hae-Gon_Jeon3",
            "~Yeji_Choi1"
        ],
        "keywords": [
            "Weather Forecasting",
            "Typhoon Trajectory Forecasting",
            "Tropical Cyclone",
            "Climate Change"
        ],
        "abstract": "In the face of escalating climate changes, typhoon intensities and their ensuing damage have surged. Accurate trajectory prediction is crucial for effective damage control. Traditional physics-based models, while comprehensive, are computationally intensive and rely heavily on the expertise of forecasters. Contemporary data-driven methods often rely on reanalysis data, which can be considered to be the closest to the true representation of weather conditions. However, reanalysis data is not produced in real-time and requires time for adjustment since prediction models are calibrated with observational data. This reanalysis data, such as ERA5, falls short in challenging real-world situations. Optimal preparedness necessitates predictions at least 72 hours in advance, beyond the capabilities of standard physics models. In response to these constraints, we present an approach that harnesses real-time Unified Model (UM) data, sidestepping the limitations of reanalysis data. Our model provides predictions at 6-hour intervals for up to 72 hours in advance and outperforms both state-of-the-art data-driven methods and numerical weather prediction models. In line with our efforts to mitigate adversities inflicted by \\rthree{typhoons}, we release our preprocessed \\textit{PHYSICS TRACK} dataset, which includes ERA5 reanalysis data, typhoon best-track, and UM forecast data.",
        "_bibtex": "@inproceedings{\npark2024longterm,\ntitle={Long-Term Typhoon Trajectory Prediction: A Physics-Conditioned Approach Without Reanalysis Data},\nauthor={Young-Jae Park and Minseok Seo and Doyi Kim and Hyeri Kim and Sanghoon Choi and Beomkyu Choi and Jeongwon Ryu and Sohee Son and Hae-Gon Jeon and Yeji Choi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ziDFH8TPPK}\n}"
    },
    {
        "title": "Poisoned Forgery Face: Towards Backdoor Attacks on Face Forgery Detection",
        "authorids": [
            "~Jiawei_Liang1",
            "~Siyuan_Liang1",
            "~Aishan_Liu1",
            "~Xiaojun_Jia1",
            "~Junhao_Kuang1",
            "~Xiaochun_Cao3"
        ],
        "keywords": [
            "Deepfake Detection",
            "Backdoor Attack"
        ],
        "abstract": "The proliferation of face forgery techniques has raised significant concerns within society, thereby motivating the development of face forgery detection methods. These methods aim to distinguish forged faces from genuine ones and have proven effective in practical applications. However, this paper introduces a novel and previously unrecognized threat in face forgery detection scenarios caused by backdoor attack. By embedding backdoors into models and incorporating specific trigger patterns into the input, attackers can deceive detectors into producing erroneous predictions for forged faces. To achieve this goal, this paper proposes \\emph{Poisoned Forgery Face} framework, which enables clean-label backdoor attacks on face forgery detectors. Our approach involves constructing a scalable trigger generator and utilizing a novel convolving process to generate translation-sensitive trigger patterns. Moreover, we employ a relative embedding method based on landmark-based regions to enhance the stealthiness of the poisoned samples. Consequently, detectors trained on our poisoned samples are embedded with backdoors. Notably, our approach surpasses SoTA backdoor baselines with a significant improvement in attack success rate (+16.39\\% BD-AUC) and reduction in visibility (-12.65\\% $L_\\infty$). Furthermore, our attack exhibits promising performance against backdoor defenses. We anticipate that this paper will draw greater attention to the potential threats posed by backdoor attacks in face forgery detection scenarios. Our codes will be made available at \\url{https://github.com/JWLiang007/PFF}.",
        "_bibtex": "@inproceedings{\nliang2024poisoned,\ntitle={Poisoned Forgery Face: Towards Backdoor Attacks on Face Forgery Detection},\nauthor={Jiawei Liang and Siyuan Liang and Aishan Liu and Xiaojun Jia and Junhao Kuang and Xiaochun Cao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=8iTpB4RNvP}\n}"
    },
    {
        "title": "Unified Human-Scene Interaction via Prompted Chain-of-Contacts",
        "authorids": [
            "~Zeqi_Xiao2",
            "~Tai_Wang2",
            "~Jingbo_Wang3",
            "~Jinkun_Cao1",
            "~Wenwei_Zhang1",
            "~Bo_Dai2",
            "~Dahua_Lin1",
            "~Jiangmiao_Pang1"
        ],
        "keywords": [
            "Human-Scene Interaction",
            "Chain-of-Contacts",
            "Unified",
            "LLM"
        ],
        "abstract": "Human-Scene Interaction (HSI) is a vital component of fields like embodied AI and virtual reality. Despite advancements in motion quality and physical plausibility, two pivotal factors, versatile interaction control and the development of a user-friendly interface, require further exploration before the practical application of HSI. This paper presents a unified HSI framework, UniHSI, which supports unified control of diverse interactions through language commands. The framework defines interaction as ``Chain of Contacts (CoC)\", representing steps involving human joint-object part pairs. This concept is inspired by the strong correlation between interaction types and corresponding contact regions. Based on the definition, UniHSI constitutes a Large Language Model (LLM) Planner to translate language prompts into task plans in the form of CoC, and a Unified Controller that turns CoC into uniform task execution. To facilitate training and evaluation, we collect a new dataset named ScenePlan that encompasses thousands of task plans generated by LLMs based on diverse scenarios. Comprehensive experiments demonstrate the effectiveness of our framework in versatile task execution and generalizability to real scanned scenes.",
        "_bibtex": "@inproceedings{\nxiao2024unified,\ntitle={Unified Human-Scene Interaction via Prompted Chain-of-Contacts},\nauthor={Zeqi Xiao and Tai Wang and Jingbo Wang and Jinkun Cao and Wenwei Zhang and Bo Dai and Dahua Lin and Jiangmiao Pang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=1vCnDyQkjg}\n}"
    },
    {
        "title": "PTaRL: Prototype-based Tabular Representation Learning via Space Calibration",
        "authorids": [
            "~Hangting_Ye1",
            "~Wei_Fan6",
            "~Xiaozhuang_Song1",
            "~Shun_Zheng1",
            "~He_Zhao1",
            "~Dan_dan_Guo1",
            "~Yi_Chang4"
        ],
        "keywords": [
            "Tabular data",
            "Deep neural networks",
            "Tabular representation learning",
            "Prototype learning"
        ],
        "abstract": "Tabular data have been playing a mostly important role in diverse real-world fields, such as healthcare, engineering, finance, etc.\nWith the recent success of deep learning, many tabular machine learning (ML) methods based on deep networks (e.g., Transformer, ResNet) have achieved competitive performance on tabular benchmarks. However, existing deep tabular ML methods suffer from the representation entanglement and localization, which largely hinders their prediction performance and leads to  performance inconsistency on tabular tasks.\nTo overcome these problems, we explore a novel direction of applying prototype learning for tabular ML and propose a prototype-based tabular representation learning framework, PTaRL, for tabular prediction tasks. The core idea of PTaRL is to construct prototype-based projection space (P-Space) and learn the disentangled representation around global data prototypes. Specifically, PTaRL mainly involves two stages: (i) Prototype Generating, that constructs global prototypes as the basis vectors of P-Space for representation, and (ii) Prototype Projecting, that projects the data samples into P-Space and keeps the core global data information via Optimal Transport. Then, to further acquire the disentangled representations, we constrain PTaRL with two strategies: (i) to diversify the coordinates towards global prototypes of different representations within P-Space, we bring up a diversifying constraint for representation calibration; (ii) to avoid prototype entanglement in P-Space, we introduce a matrix orthogonalization constraint to ensure the independence of global prototypes. \nFinally, we conduct extensive experiments in PTaRL coupled with state-of-the-art deep tabular ML models on various tabular benchmarks and the results have shown our consistent superiority.",
        "_bibtex": "@inproceedings{\nye2024ptarl,\ntitle={{PT}a{RL}: Prototype-based Tabular Representation Learning via Space Calibration},\nauthor={Hangting Ye and Wei Fan and Xiaozhuang Song and Shun Zheng and He Zhao and Dan dan Guo and Yi Chang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=G32oY4Vnm8}\n}"
    },
    {
        "title": "Stable Neural Stochastic Differential Equations in Analyzing Irregular Time Series Data",
        "authorids": [
            "~YongKyung_Oh1",
            "~Dongyoung_Lim1",
            "~Sungil_Kim1"
        ],
        "keywords": [
            "Neural Ordinary Differential Equations",
            "Neural Stochastic Differential Equations",
            "Irregular time series data"
        ],
        "abstract": "Irregular sampling intervals and missing values in real-world time series data present challenges for conventional methods that assume consistent intervals and complete data. Neural Ordinary Differential Equations (Neural ODEs) offer an alternative approach, utilizing neural networks combined with ODE solvers to learn continuous latent representations through parameterized vector fields. Neural Stochastic Differential Equations (Neural SDEs) extend Neural ODEs by incorporating a diffusion term, although this addition is not trivial, particularly when addressing irregular intervals and missing values. Consequently, careful design of drift and diffusion functions is crucial for maintaining stability and enhancing performance, while incautious choices can result in adverse properties such as the absence of strong solutions, stochastic destabilization, or unstable Euler discretizations, significantly affecting Neural SDEs' performance. In this study, we propose three stable classes of Neural SDEs: Langevin-type SDE, Linear Noise SDE, and Geometric SDE. Then, we rigorously demonstrate their robustness in maintaining excellent performance under distribution shift, while effectively preventing overfitting. To assess the effectiveness of our approach, we conduct extensive experiments on four benchmark datasets for interpolation, forecasting, and classification tasks, and analyze the robustness of our methods with 30 public datasets under different missing rates. Our results demonstrate the efficacy of the proposed method in handling real-world irregular time series data.",
        "_bibtex": "@inproceedings{\noh2024stable,\ntitle={Stable Neural Stochastic Differential Equations in Analyzing Irregular Time Series Data},\nauthor={YongKyung Oh and Dongyoung Lim and Sungil Kim},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=4VIgNuQ1pY}\n}"
    },
    {
        "title": "What does the Knowledge Neuron Thesis Have to do with Knowledge?",
        "authorids": [
            "~Jingcheng_Niu1",
            "~Andrew_Liu6",
            "~Zining_Zhu1",
            "~Gerald_Penn1"
        ],
        "keywords": [
            "language model",
            "knowledge neuron",
            "model editing",
            "formal and function competence",
            "syntax",
            "fact"
        ],
        "abstract": "We reassess the Knowledge Neuron (KN) Thesis: an interpretation of the mechanism underlying the ability of large language models to recall facts from a training corpus. This nascent thesis proposes that facts are recalled from the training corpus through the MLP weights in a manner resembling key-value memory, implying in effect that \"knowledge\" is stored in the network. Furthermore, by modifying the MLP modules, one can control the language model's generation of factual information. The plausibility of the KN thesis has been demonstrated by the success of KN-inspired model editing methods (Dai et al., 2022; Meng et al., 2022).\n\nWe find that this thesis is, at best, an oversimplification. Not only have we found that we can edit the expression of certain linguistic phenomena using the same model editing methods but, through a more comprehensive evaluation, we have found that the KN thesis does not adequately explain the process of factual expression. While it is possible to argue that the MLP weights store complex patterns that are interpretable both syntactically and semantically, these patterns do not constitute \"knowledge.\" To gain a more comprehensive understanding of the knowledge representation process, we must look beyond the MLP weights and explore recent models' complex layer structures  and attention mechanisms.",
        "_bibtex": "@inproceedings{\nniu2024what,\ntitle={What does the Knowledge Neuron Thesis Have to do with Knowledge?},\nauthor={Jingcheng Niu and Andrew Liu and Zining Zhu and Gerald Penn},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=2HJRwwbV3G}\n}"
    },
    {
        "title": "Point2SSM: Learning Morphological Variations of Anatomies from Point Clouds",
        "authorids": [
            "~Jadie_Adams1",
            "~Shireen_Elhabian1"
        ],
        "keywords": [
            "Unsupervised learning",
            "global correspondence",
            "point cloud",
            "statsitical shape modeling"
        ],
        "abstract": "We present Point2SSM, a novel unsupervised learning approach for constructing correspondence-based statistical shape models (SSMs) directly from raw point clouds. SSM is crucial in clinical research, enabling population-level analysis of morphological variation in bones and organs. Traditional methods of SSM construction have limitations, including the requirement of noise-free surface meshes or binary volumes, reliance on assumptions or templates, and prolonged inference times due to simultaneous optimization of the entire cohort. Point2SSM overcomes these barriers by providing a data-driven solution that infers SSMs directly from raw point clouds, reducing inference burdens and increasing applicability as point clouds are more easily acquired. While deep learning on 3D point clouds has seen success in unsupervised representation learning and shape correspondence, its application to anatomical SSM construction is largely unexplored. We conduct a benchmark of state-of-the-art point cloud deep networks on the SSM task, revealing their limited robustness to clinical challenges such as noisy, sparse, or incomplete input and limited training data. Point2SSM addresses these issues through an attention-based module, providing effective correspondence mappings from learned point features. Our results demonstrate that the proposed method significantly outperforms existing networks in terms of accurate surface sampling and correspondence, better capturing population-level statistics. The source code is provided at https://github.com/jadie1/Point2SSM.",
        "_bibtex": "@inproceedings{\nadams2024pointssm,\ntitle={Point2{SSM}: Learning Morphological Variations of Anatomies from Point Clouds},\nauthor={Jadie Adams and Shireen Elhabian},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=DqziS8DG4M}\n}"
    },
    {
        "title": "Improving Domain Generalization with Domain Relations",
        "authorids": [
            "~Huaxiu_Yao1",
            "~Xinyu_Yang4",
            "~Xinyi_Pan1",
            "~Shengchao_Liu1",
            "~Pang_Wei_Koh1",
            "~Chelsea_Finn1"
        ],
        "keywords": [
            "Domain Generalization; Domain Relations; Distribution Shift"
        ],
        "abstract": "Distribution shift presents a significant challenge in machine learning, where models often underperform during the test stage when faced with a different distribution than the one they were trained on. In this paper, we focus on domain shifts, which occur when the model is applied to new domains that are different from the ones it was trained on, and propose a new approach called DG. Unlike previous approaches that aim to learn a single model that is domain invariant, DG leverages domain similarities based on domain metadata to learn domain-specific models. Concretely, DG learns a set of training-domain-specific functions during the training stage and reweights them based on domain relations during the test stage. These domain relations can be directly obtained and learned from domain metadata. Under mild assumptions, we theoretically prove that using domain relations to reweight training-domain-specific functions achieves stronger out-of-domain generalization compared to the conventional averaging approach. Empirically, we evaluate the effectiveness of DG using both toy and real-world datasets for tasks such as temperature regression, land use classification, and molecule-protein binding affinity prediction. Our results show that DG consistently outperforms state-of-the-art methods.",
        "_bibtex": "@inproceedings{\nyao2024improving,\ntitle={Improving Domain Generalization with Domain Relations},\nauthor={Huaxiu Yao and Xinyu Yang and Xinyi Pan and Shengchao Liu and Pang Wei Koh and Chelsea Finn},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Dc4rXq3HIA}\n}"
    },
    {
        "title": "Generating Images with 3D Annotations Using Diffusion Models",
        "authorids": [
            "~Wufei_Ma1",
            "~Qihao_Liu1",
            "~Jiahao_Wang5",
            "~Angtian_Wang2",
            "~Xiaoding_Yuan1",
            "~Yi_Zhang20",
            "~Zihao_Xiao2",
            "~Guofeng_Zhang4",
            "~Beijia_Lu1",
            "~Ruxiao_Duan1",
            "~Yongrui_Qi1",
            "~Adam_Kortylewski1",
            "~Yaoyao_Liu1",
            "~Alan_Yuille1"
        ],
        "keywords": [
            "Synthetic Data",
            "Transfer Learning",
            "Diffusion Models",
            "3D"
        ],
        "abstract": "Diffusion models have emerged as a powerful generative method, capable of producing stunning photo-realistic images from natural language descriptions. However, these models lack explicit control over the 3D structure in the generated images. Consequently, this hinders our ability to obtain detailed 3D annotations for the generated images or to craft instances with specific poses and distances. In this paper, we propose 3D Diffusion Style Transfer (3D-DST), which incorporates 3D geometry control into diffusion models. Our method exploits ControlNet, which extends diffusion models by using visual prompts in addition to text prompts. We generate images of the 3D objects taken from 3D shape repositories~(e.g., ShapeNet and Objaverse), render them from a variety of poses and viewing directions, compute the edge maps of the rendered images, and use these edge maps as visual prompts to generate realistic images. With explicit 3D geometry control, we can easily change the 3D structures of the objects in the generated images and obtain ground-truth 3D annotations automatically. This allows us to improve a wide range of vision tasks, e.g., classification and 3D pose estimation, in both in-distribution (ID) and out-of-distribution (OOD) settings. We demonstrate the effectiveness of our method through extensive experiments on ImageNet-100/200, ImageNet-R, PASCAL3D+, ObjectNet3D, and OOD-CV. The results show that our method significantly outperforms existing methods, e.g., 3.8 percentage points on ImageNet-100 using DeiT-B. Our code is available at <https://ccvl.jhu.edu/3D-DST/>",
        "_bibtex": "@inproceedings{\nma2024generating,\ntitle={Generating Images with 3D Annotations Using Diffusion Models},\nauthor={Wufei Ma and Qihao Liu and Jiahao Wang and Angtian Wang and Xiaoding Yuan and Yi Zhang and Zihao Xiao and Guofeng Zhang and Beijia Lu and Ruxiao Duan and Yongrui Qi and Adam Kortylewski and Yaoyao Liu and Alan Yuille},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=XlkN11Xj6J}\n}"
    },
    {
        "title": "High-dimensional SGD aligns with emerging outlier eigenspaces",
        "authorids": [
            "~Gerard_Ben_Arous1",
            "~Reza_Gheissari1",
            "~Jiaoyang_Huang1",
            "~Aukosh_Jagannath1"
        ],
        "keywords": [
            "stochastic gradient descent",
            "Hessian",
            "multi-layer neural networks",
            "high-dimensional classification",
            "Gaussian mixture model",
            "XOR problem"
        ],
        "abstract": "We rigorously study the joint evolution of training dynamics via stochastic gradient descent (SGD) and the spectra of empirical Hessian and gradient matrices. We prove that in two canonical classification tasks for multi-class high-dimensional mixtures and either 1 or 2-layer neural networks, the SGD trajectory rapidly aligns with emerging low-rank outlier eigenspaces of the Hessian and gradient matrices. Moreover, in multi-layer settings this alignment occurs per layer, with the final layer's outlier eigenspace evolving over the course of training, and exhibiting rank deficiency when the SGD converges to sub-optimal classifiers. This establishes  some of the rich predictions that have arisen from extensive numerical studies in the last decade about the spectra of Hessian and information matrices over the course of training in overparametrized networks.",
        "_bibtex": "@inproceedings{\narous2024highdimensional,\ntitle={High-dimensional {SGD} aligns with emerging outlier eigenspaces},\nauthor={Gerard Ben Arous and Reza Gheissari and Jiaoyang Huang and Aukosh Jagannath},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MHjigVnI04}\n}"
    },
    {
        "title": "$\\mathcal{B}$-Coder: Value-Based Deep Reinforcement Learning for Program Synthesis",
        "authorids": [
            "~Zishun_Yu1",
            "~Yunzhe_Tao2",
            "~Liyu_Chen1",
            "~Tao_Sun14",
            "~Hongxia_Yang2"
        ],
        "keywords": [
            "Program Synthesis",
            "Code Generation",
            "Reinforcement Learning",
            "Value-Based RL"
        ],
        "abstract": "Program synthesis aims to create accurate, executable programs from problem specifications, specifically from natural language descriptions in our context. \nRecent studies have leveraged the power of reinforcement learning (RL) in conjunction with large language models (LLMs), significantly enhancing code generation capabilities. The application of RL focuses on directly optimizing for functional correctness, offering an advantage over conventional supervised methods. \nDespite policy-based RL methods dominating the literature on RL for program synthesis, the nature of program synthesis tasks hints at a natural alignment with value-based methods.\nThis stems from the rich collection of off-policy programs, including those developed by human programmers and also historical samples, coupled with the straightforward verification of generated programs through automated unit testing, meaning rewards are easy to obtain.\nDiverging from the dominant use of policy-based algorithms, our work explores the feasibility of value-based approaches, leading to the development of our $\\mathcal{B}$-Coder (pronounced Bellman coder).\nYet, training value-based methods presents challenges due to the enormous search space inherent to program synthesis. \nTo this end, we introduce an initialization protocol for RL agents utilizing pre-trained LMs and a conservative Bellman operator to reduce training complexities. \nMoreover, we demonstrate how to leverage the learned value functions as a dual strategy to post-process generated programs. \nOur empirical evaluations demonstrated $\\mathcal{B}$-Coder's capability in achieving state-of-the-art performance when compared to policy-based methods. \nRemarkably, this achievement is reached with minimal reward engineering effort, highlighting the effectiveness of value-based RL, independent of reward designs.",
        "_bibtex": "@inproceedings{\nyu2024mathcalbcoder,\ntitle={\\${\\textbackslash}mathcal\\{B\\}\\$-Coder: Value-Based Deep Reinforcement Learning for Program Synthesis},\nauthor={Zishun Yu and Yunzhe Tao and Liyu Chen and Tao Sun and Hongxia Yang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=fLf589bx1f}\n}"
    },
    {
        "title": "Adaptive Chameleon  or Stubborn Sloth: Revealing the Behavior of Large Language Models in Knowledge Conflicts",
        "authorids": [
            "~Jian_Xie3",
            "~Kai_Zhang10",
            "~Jiangjie_Chen1",
            "~Renze_Lou1",
            "~Yu_Su2"
        ],
        "keywords": [
            "Large Langugage Model",
            "Knowledge Conflict",
            "Tool Augmentation"
        ],
        "abstract": "By providing external information to large language models (LLMs), tool augmentation (including retrieval augmentation) has emerged as a promising solution for addressing the limitations of LLMs' static parametric memory.\nHowever, how receptive are LLMs to such external evidence, especially when the evidence conflicts with their parametric memory? \nWe present the first comprehensive and controlled investigation into the behavior of LLMs when encountering knowledge conflicts.\nWe propose a systematic framework to elicit high-quality parametric memory from LLMs and construct the corresponding counter-memory, which enables us to conduct a series of controlled experiments.\nOur investigation reveals seemingly contradicting behaviors of LLMs.\nOn the one hand, different from prior wisdom, we find that LLMs can be highly receptive to external evidence even when that conflicts with their parametric memory, given that the external evidence is coherent and convincing.\nOn the other hand, LLMs also demonstrate a strong confirmation bias when the external evidence contains some information that is consistent with their parametric memory, despite being presented with conflicting evidence at the same time.\nThese results pose important implications that are worth careful consideration for the further development and deployment of tool- and retrieval-augmented LLMs.\nResources are available at https://github.com/OSU-NLP-Group/LLM-Knowledge-Conflict.",
        "_bibtex": "@inproceedings{\nxie2024adaptive,\ntitle={Adaptive Chameleon  or Stubborn Sloth: Revealing the Behavior of Large Language Models in Knowledge Conflicts},\nauthor={Jian Xie and Kai Zhang and Jiangjie Chen and Renze Lou and Yu Su},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=auKAUJZMO6}\n}"
    },
    {
        "title": "A Hierarchical Bayesian Model for Few-Shot Meta Learning",
        "authorids": [
            "~Minyoung_Kim2",
            "~Timothy_Hospedales1"
        ],
        "keywords": [
            "Bayesian models",
            "Meta learning",
            "Few-shot learning"
        ],
        "abstract": "We propose a novel hierarchical Bayesian model for the few-shot meta learning problem. We consider episode-wise random variables to model episode-specific generative processes, where these local random variables are governed by a higher-level global random variable. The global variable captures information shared across episodes, while controlling how much the model needs to be adapted to new episodes in a principled Bayesian manner. Within our  framework, prediction on a novel episode/task can be seen as a Bayesian inference problem. For tractable training, we need to be able to relate each local episode-specific solution to the global higher-level parameters. We propose a Normal-Inverse-Wishart model, for which establishing this local-global relationship becomes feasible due to the approximate closed-form solutions for the local posterior distributions. The resulting algorithm is more attractive than the MAML in that it does not maintain a costly computational graph for the sequence of gradient descent steps in an episode. Our approach is also different from existing Bayesian meta learning methods in that rather than modeling a single random variable for all episodes, it leverages a hierarchical structure that exploits the local-global relationships desirable for principled Bayesian learning with many related tasks.",
        "_bibtex": "@inproceedings{\nkim2024a,\ntitle={A Hierarchical Bayesian Model for Few-Shot Meta Learning},\nauthor={Minyoung Kim and Timothy Hospedales},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=mQ72XRfYRZ}\n}"
    },
    {
        "title": "Faithful and Efficient Explanations for Neural Networks via Neural Tangent Kernel Surrogate Models",
        "authorids": [
            "~Andrew_William_Engel1",
            "~Zhichao_Wang3",
            "~Natalie_Frank1",
            "~Ioana_Dumitriu3",
            "~Sutanay_Choudhury2",
            "~Anand_Sarwate1",
            "~Tony_Chiang1"
        ],
        "keywords": [
            "Explainability",
            "Surrogate Models",
            "Neural Tangent Kernel",
            "Deep Learning",
            "Attribution"
        ],
        "abstract": "A recent trend in explainable AI research has focused on surrogate modeling, where neural networks are approximated as simpler ML algorithms such as kernel machines. A second trend has been to utilize kernel functions in various explain-by-example or data attribution tasks. In this work, we combine these two trends to analyze approximate empirical neural tangent kernels (eNTK) for data attribution. Approximation is critical for eNTK analysis due to the high computational cost to compute the eNTK. We define new approximate eNTK and perform novel analysis on how well the resulting kernel machine surrogate models correlate with the underlying neural network. We introduce two new random projection variants of approximate eNTK which allow users to tune the time and memory complexity of their calculation. We conclude that kernel machines using approximate neural tangent kernel as the kernel function are effective surrogate models, with the introduced trace NTK the most consistent performer.",
        "_bibtex": "@inproceedings{\nengel2024faithful,\ntitle={Faithful and Efficient Explanations for Neural Networks via Neural Tangent Kernel Surrogate Models},\nauthor={Andrew William Engel and Zhichao Wang and Natalie Frank and Ioana Dumitriu and Sutanay Choudhury and Anand Sarwate and Tony Chiang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=yKksu38BpM}\n}"
    },
    {
        "title": "Conformal Risk Control",
        "authorids": [
            "~Anastasios_Nikolas_Angelopoulos1",
            "~Stephen_Bates1",
            "~Adam_Fisch2",
            "~Lihua_Lei2",
            "~Tal_Schuster1"
        ],
        "keywords": [
            "conformal prediction",
            "uncertainty quantification"
        ],
        "abstract": "We extend conformal prediction to control the expected value of any monotone loss function. The algorithm generalizes split conformal prediction together with its coverage guarantee. Like conformal prediction, the conformal risk control procedure is tight up to an $\\mathcal{O}(1/n)$ factor. We also introduce extensions of the idea to distribution shift, quantile risk control, multiple and adversarial risk control, and expectations of U-statistics. Worked examples from computer vision and natural language processing demonstrate the usage of our algorithm to bound the false negative rate, graph distance, and token-level F1-score.",
        "_bibtex": "@inproceedings{\nangelopoulos2024conformal,\ntitle={Conformal Risk Control},\nauthor={Anastasios Nikolas Angelopoulos and Stephen Bates and Adam Fisch and Lihua Lei and Tal Schuster},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=33XGfHLtZg}\n}"
    },
    {
        "title": "RetroBridge: Modeling Retrosynthesis with Markov Bridges",
        "authorids": [
            "~Ilia_Igashov1",
            "~Arne_Schneuing1",
            "~Marwin_Segler2",
            "~Michael_M._Bronstein1",
            "~Bruno_Correia1"
        ],
        "keywords": [
            "Retrosynthesis",
            "Reactions",
            "Chemistry",
            "Drug Discovery",
            "Markov Bridge"
        ],
        "abstract": "Retrosynthesis planning is a fundamental challenge in chemistry which aims at designing multi-step reaction pathways from commercially available starting materials to a target molecule. Each step in multi-step retrosynthesis planning requires accurate prediction of possible precursor molecules given the target molecule and confidence estimates to guide heuristic search algorithms. We model single-step retrosynthesis as a distribution learning problem in a discrete state space. First, we introduce the Markov Bridge Model, a generative framework aimed to approximate the dependency between two intractable discrete distributions accessible via a finite sample of coupled data points. Our framework is based on the concept of a Markov bridge, a Markov process pinned at its endpoints. Unlike diffusion-based methods, our Markov Bridge Model does not need a tractable noise distribution as a sampling proxy and directly operates on the input product molecules as samples from the intractable prior distribution. We then address the retrosynthesis planning problem with our novel framework and introduce RetroBridge, a template-free retrosynthesis modeling approach that achieves state-of-the-art results on standard evaluation benchmarks.",
        "_bibtex": "@inproceedings{\nigashov2024retrobridge,\ntitle={RetroBridge: Modeling Retrosynthesis with Markov Bridges},\nauthor={Ilia Igashov and Arne Schneuing and Marwin Segler and Michael M. Bronstein and Bruno Correia},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=770DetV8He}\n}"
    },
    {
        "title": "InstructScene: Instruction-Driven 3D Indoor Scene Synthesis with Semantic Graph Prior",
        "authorids": [
            "~Chenguo_Lin1",
            "~Yadong_MU1"
        ],
        "keywords": [
            "3D indoor scene synthesis",
            "controllable generative models",
            "graph diffusion models"
        ],
        "abstract": "Comprehending natural language instructions is a charming property for 3D indoor scene synthesis systems. Existing methods directly model object joint distributions and express object relations implicitly within a scene, thereby hindering the controllability of generation. We introduce InstructScene, a novel generative framework that integrates a semantic graph prior and a layout decoder to improve controllability and fidelity for 3D scene synthesis. The proposed semantic graph prior jointly learns scene appearances and layout distributions, exhibiting versatility across various downstream tasks in a zero-shot manner. To facilitate the benchmarking for text-driven 3D scene synthesis, we curate a high-quality dataset of scene-instruction pairs with large language and multimodal models. Extensive experimental results reveal that the proposed method surpasses existing state-of-the-art approaches by a large margin. Thorough ablation studies confirm the efficacy of crucial design components. Project page: https://chenguolin.github.io/projects/InstructScene.",
        "_bibtex": "@inproceedings{\nlin2024instructscene,\ntitle={InstructScene: Instruction-Driven 3D Indoor Scene Synthesis with Semantic Graph Prior},\nauthor={Chenguo Lin and Yadong MU},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=LtuRgL03pI}\n}"
    },
    {
        "title": "Single Motion Diffusion",
        "authorids": [
            "~Sigal_Raab1",
            "~Inbal_Leibovitch1",
            "~Guy_Tevet1",
            "~Moab_Arar1",
            "~Amit_Haim_Bermano2",
            "~Daniel_Cohen-Or1"
        ],
        "keywords": [
            "Deep Learning",
            "Motion synthesis",
            "Animation",
            "Single Instance Learning",
            "Generative models"
        ],
        "abstract": "Synthesizing realistic animations of humans, animals, and even imaginary creatures, has long been a goal for artists and computer graphics professionals. Compared to the imaging domain, which is rich with large available datasets, the number of data instances for the motion domain is limited, particularly for the animation of animals and exotic creatures (e.g., dragons), which have unique skeletons and motion patterns. In this work, we introduce SinMDM, a Single Motion Diffusion Model. It is designed to learn the internal motifs of a single motion sequence with arbitrary topology and synthesize a variety of motions of arbitrary length that remain faithful to the learned motifs. We harness the power of diffusion models and present a denoising network explicitly designed for the task of learning from a single input motion. SinMDM is crafted as a lightweight architecture, which avoids overfitting by using a shallow network with local attention layers that narrow the receptive field and encourage motion diversity. Our work applies to multiple contexts, including spatial and temporal in-betweening, motion expansion, style transfer, and crowd animation. Our results show that SinMDM outperforms existing methods both qualitatively and quantitatively. Moreover, while prior network-based approaches require additional training for different applications, SinMDM supports these applications during inference. Our project page, which includes links to the code and trained models, is accessible at https://sinmdm.github.io/SinMDM-page.",
        "_bibtex": "@inproceedings{\nraab2024single,\ntitle={Single Motion Diffusion},\nauthor={Sigal Raab and Inbal Leibovitch and Guy Tevet and Moab Arar and Amit Haim Bermano and Daniel Cohen-Or},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=DrhZneqz4n}\n}"
    },
    {
        "title": "Physics-Regulated Deep Reinforcement Learning: Invariant Embeddings",
        "authorids": [
            "~Hongpeng_Cao1",
            "~Yanbing_Mao1",
            "~Lui_Sha1",
            "~Marco_Caccamo2"
        ],
        "keywords": [
            "Physics-informed deep reinforcement learning",
            "Safety-critical autonomous systems"
        ],
        "abstract": "This paper proposes the Phy-DRL: a physics-regulated deep reinforcement learning (DRL) framework for safety-critical autonomous systems. The Phy-DRL has three distinguished invariant-embedding designs: i) residual action policy (i.e., integrating data-driven-DRL action policy and physics-model-based action policy), ii) automatically constructed safety-embedded reward, and iii) physics-model-guided neural network (NN) editing, including link editing and activation editing. Theoretically, the Phy-DRL exhibits 1) a mathematically provable safety guarantee and 2) strict compliance of critic and actor networks with physics knowledge about the action-value function and action policy. Finally, we evaluate the Phy-DRL on a cart-pole system and a quadruped robot. The experiments validate our theoretical results and demonstrate that Phy-DRL features guaranteed safety compared to purely data-driven DRL and solely model-based design while offering remarkably fewer learning parameters and fast training towards safety guarantee.",
        "_bibtex": "@inproceedings{\ncao2024physicsregulated,\ntitle={Physics-Regulated Deep Reinforcement Learning: Invariant Embeddings},\nauthor={Hongpeng Cao and Yanbing Mao and Lui Sha and Marco Caccamo},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5Dwqu5urzs}\n}"
    },
    {
        "title": "BatteryML: An Open-source Platform for Machine Learning on Battery Degradation",
        "authorids": [
            "~Han_Zhang18",
            "~Xiaofan_Gui1",
            "~Shun_Zheng1",
            "~Ziheng_Lu1",
            "~Yuqi_Li4",
            "~Jiang_Bian1"
        ],
        "keywords": [
            "BatteryML",
            "Battery life prediction",
            "Machine learning",
            "Open-source platform",
            "Unified standards",
            "Collaborative research"
        ],
        "abstract": "Battery degradation remains a pivotal concern in the energy storage domain, with machine learning emerging as a potent tool to drive forward insights and solutions. However, this intersection of electrochemical science and machine learning poses complex challenges. Machine learning experts often grapple with the intricacies of battery science, while battery researchers face hurdles in adapting intricate models tailored to specific datasets. Beyond this, a cohesive standard for battery degradation modeling, inclusive of data formats and evaluative benchmarks, is conspicuously absent.  Recognizing these impediments, we present BatteryML\u2014a one-step, all-encompass, and  open-source platform designed to unify data preprocessing, feature extraction, and the implementation of both traditional and state-of-the-art models. This streamlined approach promises to enhance the practicality and efficiency of research applications. BatteryML seeks to fill this void, fostering an environment where experts from diverse specializations can collaboratively contribute, thus elevating the collective understanding and advancement of battery research.",
        "_bibtex": "@inproceedings{\nzhang2024batteryml,\ntitle={Battery{ML}: An Open-source Platform for Machine Learning on Battery Degradation},\nauthor={Han Zhang and Xiaofan Gui and Shun Zheng and Ziheng Lu and Yuqi Li and Jiang Bian},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=sxGugrYhP9}\n}"
    },
    {
        "title": "SaProt: Protein Language Modeling with Structure-aware Vocabulary",
        "authorids": [
            "~Jin_Su1",
            "~Chenchen_Han1",
            "~Yuyang_Zhou1",
            "~Junjie_Shan1",
            "~Xibin_Zhou1",
            "~Fajie_Yuan2"
        ],
        "keywords": [
            "Protein Language Models",
            "Universal Representations",
            "Downstream Tasks",
            "Protein Structure Modeling"
        ],
        "abstract": "Large-scale protein language models (PLMs), such as the ESM family, have achieved remarkable performance in various downstream tasks related to protein structure and function by undergoing unsupervised training on residue sequences. They have become essential tools for researchers and practitioners in biology.  However, a limitation of vanilla PLMs is their lack of explicit consideration for protein structure information, which suggests the potential for further improvement. Motivated by this, we introduce the concept of a ``structure-aware vocabulary\" that  integrates residue tokens with structure tokens.    The structure tokens are  derived  by encoding the 3D structure of proteins using Foldseek. We then propose SaProt, a large-scale general-purpose PLM trained on an extensive dataset comprising approximately 40 million protein sequences and structures. Through extensive evaluation, our SaProt model surpasses well-established and renowned baselines across 10 significant downstream tasks, demonstrating its exceptional capacity and broad applicability. We have made the code, pre-trained model, and all relevant materials available at https://github.com/westlake-repl/SaProt.",
        "_bibtex": "@inproceedings{\nsu2024saprot,\ntitle={SaProt: Protein Language Modeling with Structure-aware Vocabulary},\nauthor={Jin Su and Chenchen Han and Yuyang Zhou and Junjie Shan and Xibin Zhou and Fajie Yuan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=6MRm3G4NiU}\n}"
    },
    {
        "title": "PixArt-$\\alpha$: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis",
        "authorids": [
            "~Junsong_Chen1",
            "~Jincheng_YU1",
            "~Chongjian_GE1",
            "~Lewei_Yao1",
            "~Enze_Xie1",
            "~Zhongdao_Wang2",
            "~James_Kwok1",
            "~Ping_Luo2",
            "~Huchuan_Lu1",
            "~Zhenguo_Li1"
        ],
        "keywords": [
            "Text-to-Image Diffusion",
            "Transformer"
        ],
        "abstract": "The most advanced text-to-image (T2I) models require significant training costs (e.g., millions of GPU hours), seriously hindering the fundamental innovation for the AIGC community while increasing CO2 emissions. This paper introduces PixArt-$\\alpha$, a Transformer-based T2I diffusion model whose image generation quality is competitive with state-of-the-art image generators (e.g., Imagen, SDXL, and even Midjourney), reaching near-commercial application standards. Additionally, it supports high-resolution image synthesis up to 1024px resolution with low training cost, as shown in Figure 1 and 2. To achieve this goal, three core designs are proposed: (1) Training strategy decomposition: We devise three distinct training steps that separately optimize pixel dependency, text-image alignment, and image aesthetic quality; (2) Efficient T2I Transformer: We incorporate cross-attention modules into Diffusion Transformer (DiT) to inject text conditions and streamline the computation-intensive class-condition branch; (3) High-informative data: We emphasize the significance of concept density in text-image pairs and leverage a large Vision-Language model to auto-label dense pseudo-captions to assist text-image alignment learning. As a result, PixArt-$\\alpha$'s training speed markedly surpasses existing large-scale T2I models, e.g., PixArt-$\\alpha$ only takes 10.8% of Stable Diffusion v1.5's training time (~675 vs. ~6,250 A100 GPU days), saving nearly \\\\$300,000 (\\\\$26,000 vs. \\\\$320,000) and reducing 90% CO2 emissions. Moreover, compared with a larger SOTA model, RAPHAEL, our training cost is merely 1%. Extensive experiments demonstrate that PixArt-$\\alpha$ excels in image quality, artistry, and semantic control. We hope PixArt-$\\alpha$ will provide new insights to the AIGC community and startups to accelerate building their own high-quality yet low-cost generative models from scratch.",
        "_bibtex": "@inproceedings{\nchen2024pixartalpha,\ntitle={PixArt-\\${\\textbackslash}alpha\\$: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis},\nauthor={Junsong Chen and Jincheng YU and Chongjian GE and Lewei Yao and Enze Xie and Zhongdao Wang and James Kwok and Ping Luo and Huchuan Lu and Zhenguo Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=eAKmQPe3m1}\n}"
    },
    {
        "title": "Sentence-level Prompts Benefit Composed Image Retrieval",
        "authorids": [
            "~Yang_bai4",
            "~Xinxing_Xu1",
            "~Yong_Liu10",
            "~Salman_Khan4",
            "~Fahad_Khan1",
            "~Wangmeng_Zuo3",
            "~Rick_Siow_Mong_Goh1",
            "~Chun-Mei_Feng1"
        ],
        "keywords": [
            "Composed Image Retrieval",
            "Vision-Language Pre-trained Models"
        ],
        "abstract": "Composed image retrieval (CIR) is the task of retrieving specific images by using a query that involves both a reference image and a relative caption. Most existing CIR models adopt the late-fusion strategy to combine visual and language features. Besides, several approaches have also been suggested to generate a pseudo-word token from the reference image, which is further integrated into the relative caption for CIR. However, these pseudo-word-based prompting methods have limitations when target image encompasses complex changes on reference image, e.g., object removal and attribute modification. In this work, we demonstrate that learning an appropriate sentence-level prompt for the relative caption (SPRC) is sufficient for achieving effective composed image retrieval. Instead of relying on pseudo- word-based prompts, we propose to leverage pretrained V-L models, e.g., BLIP-2, to generate sentence-level prompts. By concatenating the learned sentence-level prompt with the relative caption, one can readily use existing text-based image retrieval models to enhance CIR performance. Furthermore, we introduce both image-text contrastive loss and text prompt alignment loss to enforce the learning of suitable sentence-level prompts. Experiments show that our proposed method performs favorably against the state-of-the-art CIR methods on the Fashion-IQ and CIRR datasets.",
        "_bibtex": "@inproceedings{\nbai2024sentencelevel,\ntitle={Sentence-level Prompts Benefit Composed Image Retrieval},\nauthor={Yang bai and Xinxing Xu and Yong Liu and Salman Khan and Fahad Khan and Wangmeng Zuo and Rick Siow Mong Goh and Chun-Mei Feng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=m3ch3kJL7q}\n}"
    },
    {
        "title": "Compositional Generative Inverse Design",
        "authorids": [
            "~Tailin_Wu1",
            "~Takashi_Maruyama2",
            "~Long_Wei1",
            "~Tao_Zhang35",
            "~Yilun_Du1",
            "~Gianluca_Iaccarino1",
            "~Jure_Leskovec1"
        ],
        "keywords": [
            "inverse design",
            "generative design",
            "PDE",
            "physical simulation",
            "compositional"
        ],
        "abstract": "Inverse design, where we seek to design input variables in order to optimize an underlying objective function, is an important problem that arises across fields such as mechanical engineering to aerospace engineering. Inverse design is typically formulated as an optimization problem, with recent works leveraging optimization across learned dynamics models. However, as models are optimized they tend to fall into adversarial modes, preventing effective sampling. We illustrate that by instead optimizing over the learned energy function captured by the diffusion model, we can avoid such adversarial examples and significantly improve design performance. We further illustrate how such a design system is compositional, enabling us to combine multiple different diffusion models representing subcomponents of our desired system to design systems with every specified component. In an N-body interaction task and a challenging 2D multi-airfoil design task, we demonstrate that by composing the learned diffusion model at test time, our method allows us to design initial states and boundary shapes that are more complex than those in the training data. Our method generalizes to more objects for N-body dataset and discovers formation flying to minimize drag in the multi-airfoil design task. Project website and code can be found at https://github.com/AI4Science-WestlakeU/cindm.",
        "_bibtex": "@inproceedings{\nwu2024compositional,\ntitle={Compositional Generative Inverse Design},\nauthor={Tailin Wu and Takashi Maruyama and Long Wei and Tao Zhang and Yilun Du and Gianluca Iaccarino and Jure Leskovec},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=wmX0CqFSd7}\n}"
    },
    {
        "title": "What does automatic differentiation compute for neural networks?",
        "authorids": [
            "~Sejun_Park1",
            "~Sanghyuk_Chun1",
            "~Wonyeol_Lee1"
        ],
        "keywords": [
            "automatic differentiation",
            "correctness",
            "neural networks",
            "clarke subdifferential"
        ],
        "abstract": "Forward- or reverse-mode automatic differentiation (AD) is a popular algorithm for computing the derivative of a function expressed by a program. AD always outputs the correct derivative if a program does not use any non-differentiable functions and control flows; however, it may return an arbitrary value otherwise. In this work, we investigate what AD computes for neural networks that may contain non-differentiable functions such as ReLU and maxpools. We first prove that AD always returns a generalized derivative called a Clarke subderivative for networks with pointwise activation functions, if the minibatch size is one and all non-differentiable neurons have distinct bias parameters. We show that the same conclusion does not hold otherwise, but does hold under some mild sufficient conditions. We also prove similar results for more general networks that can use maxpools and bias parameters shared across different neurons. We empirically check our sufficient conditions over popular network architectures and observe that AD almost always computes a Clarke subderivative in practical learning setups.",
        "_bibtex": "@inproceedings{\npark2024what,\ntitle={What does automatic differentiation compute for neural networks?},\nauthor={Sejun Park and Sanghyuk Chun and Wonyeol Lee},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=8vKknbgXxf}\n}"
    },
    {
        "title": "OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models",
        "authorids": [
            "~Wenqi_Shao2",
            "~Mengzhao_Chen1",
            "~Zhaoyang_Zhang1",
            "~Peng_Xu11",
            "~Lirui_Zhao1",
            "~Zhiqian_Li1",
            "~Kaipeng_Zhang1",
            "~Peng_Gao3",
            "~Yu_Qiao1",
            "~Ping_Luo2"
        ],
        "keywords": [
            "Large Language Model Compression",
            "Differentiable Quantization"
        ],
        "abstract": "Large language models (LLMs) have revolutionized natural language processing tasks. However, their practical deployment is hindered by their immense memory and computation requirements. Although recent post-training quantization (PTQ) methods are effective in reducing memory footprint and improving the computational efficiency of LLM, they hand-craft quantization parameters, leading to low performance, especially in extremely low-bit quantization. To tackle this issue, we introduce an Omnidirectionally calibrated Quantization ($\\textbf{OmniQuant}$) technique for LLMs, which achieves good performance in diverse quantization settings while maintaining the computational efficiency of PTQ by efficiently optimizing various quantization parameters. OmniQuant comprises two innovative components including Learnable Weight Clipping (LWC) and Learnable Equivalent Transformation (LET). LWC modulates the extreme values of weights by optimizing the clipping threshold. Meanwhile, LET tackles activation outliers by shifting the challenge of quantization from activations to weights. Operating within a differentiable framework using block-wise error minimization, OmniQuant can optimize the quantization process efficiently for both weight-only and weight-activation quantization. For instance, the LLaMA-2 model family size 7-70B can be processed with OmniQuant on a single A100-40G GPU within 1-16 hours using 128 samples. Extensive experiments validate OmniQuant's superior performance across diverse quantization configurations such as W4A4 (4-bit weight, 4-bit activation), W6A6, W4A16, W3A16, and W2A16. Additionally, OmniQuant demonstrates effectiveness in instruction-tuned models and delivers notable improvements in inference speed and memory reduction on real devices. Codes are available at \n\\url{https://github.com/OpenGVLab/OmniQuant}.",
        "_bibtex": "@inproceedings{\nshao2024omniquant,\ntitle={OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models},\nauthor={Wenqi Shao and Mengzhao Chen and Zhaoyang Zhang and Peng Xu and Lirui Zhao and Zhiqian Li and Kaipeng Zhang and Peng Gao and Yu Qiao and Ping Luo},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=8Wuvhh0LYW}\n}"
    },
    {
        "title": "Ferret: Refer and Ground Anything Anywhere at Any Granularity",
        "authorids": [
            "~Haoxuan_You1",
            "~Haotian_Zhang3",
            "~Zhe_Gan1",
            "~Xianzhi_Du4",
            "~Bowen_Zhang2",
            "~Zirui_Wang1",
            "~Liangliang_Cao1",
            "~Shih-Fu_Chang3",
            "~Yinfei_Yang1"
        ],
        "keywords": [
            "Ferret",
            "Multimodal Large Language Model",
            "Referring",
            "Grounding"
        ],
        "abstract": "We introduce Ferret, a new Multimodal Large Language Model (MLLM) capable of understanding spatial referring of any shape or granularity within an image and accurately grounding open-vocabulary descriptions. To unify referring and grounding in the LLM paradigm, Ferret employs a novel and powerful hybrid region representation that integrates discrete coordinates and continuous features jointly to represent a region in the image. To extract the continuous features of versatile regions,  we propose a spatial-aware visual sampler, adept at handling varying sparsity across different shapes. Consequently, Ferret can accept diverse region inputs, such as points, bounding boxes, and free-form shapes. To bolster the desired capability of Ferret, we curate GRIT, a comprehensive refer-and-ground instruction tuning dataset including 1.1M samples that contain rich hierarchical spatial knowledge, with an additional 130K hard negative data to promote model robustness. The resulting model not only achieves superior performance in classical referring and grounding tasks, but also greatly outperforms existing MLLMs in region-based and localization-demanded multimodal chatting. Our evaluations also reveal a significantly improved capability of describing image details and a remarkable alleviation in object hallucination.",
        "_bibtex": "@inproceedings{\nyou2024ferret,\ntitle={Ferret: Refer and Ground Anything Anywhere at Any Granularity},\nauthor={Haoxuan You and Haotian Zhang and Zhe Gan and Xianzhi Du and Bowen Zhang and Zirui Wang and Liangliang Cao and Shih-Fu Chang and Yinfei Yang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=2msbbX3ydD}\n}"
    },
    {
        "title": "SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation",
        "authorids": [
            "~Chongyu_Fan1",
            "~Jiancheng_Liu2",
            "~Yihua_Zhang1",
            "~Eric_Wong1",
            "~Dennis_Wei1",
            "~Sijia_Liu1"
        ],
        "keywords": [
            "Machine unlearning",
            "generative model",
            "diffusion model",
            "weight saliency"
        ],
        "abstract": "With evolving data regulations, machine unlearning (MU) has become an important tool for fostering trust and safety in today's AI models. However, existing MU methods focusing on data and/or weight perspectives often suffer limitations in unlearning accuracy, stability, and cross-domain applicability. To address these challenges, we introduce the concept of 'weight saliency' for MU, drawing parallels with input saliency in model explanation. This innovation directs MU's attention toward specific model weights rather than the entire model, improving effectiveness and efficiency. The resultant method that we call saliency unlearning (SalUn) narrows the performance gap with 'exact' unlearning (model retraining from scratch after removing the forgetting data points). To the best of our knowledge, SalUn is the first principled MU approach that can effectively erase the influence of forgetting data, classes, or concepts in both image classification and generation tasks. As highlighted below, For example, SalUn yields a stability advantage in high-variance random data forgetting, e.g., with a 0.2% gap compared to exact unlearning on the CIFAR-10 dataset. Moreover, in preventing conditional diffusion models from generating harmful images, SalUn achieves nearly 100% unlearning accuracy, outperforming current state-of-the-art baselines like Erased Stable Diffusion and Forget-Me-Not. Codes are available at https://github.com/OPTML-Group/Unlearn-Saliency.\n\n**WARNING**: This paper contains model outputs that may be offensive in nature.",
        "_bibtex": "@inproceedings{\nfan2024salun,\ntitle={SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation},\nauthor={Chongyu Fan and Jiancheng Liu and Yihua Zhang and Eric Wong and Dennis Wei and Sijia Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=gn0mIhQGNM}\n}"
    },
    {
        "title": "Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization",
        "authorids": [
            "~Weiran_Yao1",
            "~Shelby_Heinecke1",
            "~Juan_Carlos_Niebles1",
            "~Zhiwei_Liu3",
            "~Yihao_Feng1",
            "~Le_Xue1",
            "~Rithesh_R_N1",
            "~Zeyuan_Chen1",
            "~Jianguo_Zhang3",
            "~Devansh_Arpit2",
            "~Ran_Xu1",
            "~Phil_L_Mui1",
            "~Huan_Wang1",
            "~Caiming_Xiong1",
            "~Silvio_Savarese1"
        ],
        "keywords": [
            "Language Agent",
            "AI Agent",
            "Reinforcement Learning"
        ],
        "abstract": "Recent months have seen the emergence of a powerful new trend in which large language models (LLMs) are augmented to become autonomous language agents capable of performing objective oriented multi-step tasks on their own, rather than merely responding to queries from human users. Most existing language agents, however, are not optimized using environment-specific rewards. Although some agents enable iterative refinement through verbal feedback, they do not reason and plan in ways that are compatible with gradient-based learning from rewards. This paper introduces a principled framework for reinforcing large language agents by learning a retrospective model, which automatically tunes the language agent prompts from environment feedback through policy gradient. Specifically, our proposed agent architecture learns from rewards across multiple environments and tasks, for fine-tuning a pre-trained language model which refines the language agent prompt by summarizing the root cause of prior failed attempts and proposing action plans. Experimental results on various tasks demonstrate that the language agents improve over time and that our approach considerably outperforms baselines that do not properly leverage gradients from the environment.",
        "_bibtex": "@inproceedings{\nyao2024retroformer,\ntitle={Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization},\nauthor={Weiran Yao and Shelby Heinecke and Juan Carlos Niebles and Zhiwei Liu and Yihao Feng and Le Xue and Rithesh R N and Zeyuan Chen and Jianguo Zhang and Devansh Arpit and Ran Xu and Phil L Mui and Huan Wang and Caiming Xiong and Silvio Savarese},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=KOZu91CzbK}\n}"
    },
    {
        "title": "BECLR: Batch Enhanced Contrastive Few-Shot Learning",
        "authorids": [
            "~Stylianos_Poulakakis-Daktylidis1",
            "~Hadi_Jamali-Rad1"
        ],
        "keywords": [
            "few-shot classification",
            "unsupervised few-shot learning",
            "deep representation learning"
        ],
        "abstract": "Learning quickly from very few labeled samples is a fundamental attribute that separates machines and humans in the era of deep representation learning. Unsupervised few-shot learning (U-FSL) aspires to bridge this gap by discarding the reliance on annotations at training time. Intrigued by the success of contrastive learning approaches in the realm of U-FSL, we structurally approach their shortcomings in both pretraining and downstream inference stages. We propose a novel Dynamic Clustered mEmory (DyCE) module to promote a highly separable latent representation space for enhancing positive sampling at the pretraining phase and infusing implicit class-level insights into unsupervised contrastive learning. We then tackle the, somehow overlooked yet critical, issue of sample bias at the few-shot inference stage. We propose an iterative Optimal Transport-based distribution Alignment (OpTA) strategy and demonstrate that it efficiently addresses the problem, especially in low-shot scenarios where FSL approaches suffer the most from sample bias. We later on discuss that DyCE and OpTA are two intertwined pieces of a novel end-to-end approach (we coin as BECLR), constructively magnifying each other's impact. We then present a suite of extensive quantitative and qualitative experimentation to corroborate that BECLR sets a new state-of-the-art across ALL existing U-FSL benchmarks (to the best of our knowledge), and significantly outperforms the best of the current baselines (codebase available at https://github.com/stypoumic/BECLR).",
        "_bibtex": "@inproceedings{\npoulakakis-daktylidis2024beclr,\ntitle={{BECLR}: Batch Enhanced Contrastive Few-Shot Learning},\nauthor={Stylianos Poulakakis-Daktylidis and Hadi Jamali-Rad},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=k9SVcrmXL8}\n}"
    },
    {
        "title": "How to Capture Higher-order Correlations? Generalizing Matrix Softmax Attention to Kronecker Computation",
        "authorids": [
            "~Josh_Alman1",
            "~Zhao_Song3"
        ],
        "keywords": [
            "Attention computation",
            "kronecker computation"
        ],
        "abstract": "In the classical transformer attention scheme, we are given three $n \\times d$ size matrices $Q, K, V$ (the query, key, and value tokens), and the goal is to compute a new $n \\times d$ size matrix $D^{-1} \\exp(QK^\\top) V$ where $D = \\mathrm{diag}( \\exp(QK^\\top) {\\bf 1}_n )$. Here, $\\exp()$ is applied entry-wise and ${\\bf 1}_n$ denotes a length-$n$ vector whose entries are all ones.\n\nIntuitively, attention computation captures pairwise information between words in a sentence, but not higher-order information. Indeed, recent work \\cite{sht23} has shown that attention units cannot solve simple problems about detecting triples of connected words.\n\nIn this work, we study a generalization of attention which captures triple-wise  correlations. The generalization is based on computations involving tensors defined by tuples of words. More formally, given five $n \\times d$ size matrices $Q, K_1, K_2, V_1$ and $V_2$ (generalized query, key, and value tokens), our new goal is to compute an $n \\times d$ size matrix $D^{-1} \\exp( Q ( K_1 \\oslash K_2)^\\top ) (V_1 \\oslash V_2) $ where $D = \\mathrm{diag}( \\exp( Q ( K_1 \\oslash K_2)^\\top ) {\\bf 1}_{n^2} )$ and $K_1 \\oslash K_2 \\in \\mathbb{R}^{n^2 \\times d}$ denotes the column-wise Kronecker product of $K_1$ and $K_2$. This generalization is indeed able to solve problems about detecting triple-wise connections that were shown to be impossible for transformers.\n\nThe potential downside of this generalization is that it appears as though computations are even more difficult, since the straightforward algorithm requires cubic time in $n$. However, we show that in the bounded-entry setting (which arises in practice, and which is well-studied in both theory and practice), there is actually a near-linear time algorithm. More precisely, we show that bounded entries are both necessary and sufficient for quickly performing generalized computations:\n\n$\\bullet$ On the positive side, if all entries of the input matrices are bounded above by $o(\\sqrt[3]{\\log n})$ then we show how to approximate the ``tensor-type'' attention matrix in $n^{1+o(1)}$ time.\n\n$\\bullet$ On the negative side, we show that if the entries of the input matrices may be as large as $\\Omega(\\sqrt[3]{\\log n})$, then there is no algorithm that runs faster than $n^{3-o(1)}$ (assuming the Strong Exponential \nTime Hypothesis from fine-grained complexity theory).\n\n\nWe also show that our construction, algorithms, and lower bounds naturally generalize to higher-order tensors and correlations. Interestingly, the higher the order of the tensors, the lower the bound on the entries needs to be for an efficient algorithm. Our results thus yield a natural tradeoff between the boundedness of the entries, and order of the tensor one may use for more expressive, efficient attention computation.\n\nOur constructions make use of a novel connection with a higher-order variant on the kernel density estimation problem. They combine a number of technical tools, including the polynomial method, algebraic geometry codes, and multiparty Merlin-Arthur communication protocols.",
        "_bibtex": "@inproceedings{\nalman2024how,\ntitle={How to Capture Higher-order Correlations? Generalizing Matrix Softmax Attention to Kronecker Computation},\nauthor={Josh Alman and Zhao Song},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=v0zNCwwkaV}\n}"
    },
    {
        "title": "DreamLLM: Synergistic Multimodal Comprehension and Creation",
        "authorids": [
            "~Runpei_Dong1",
            "~Chunrui_Han3",
            "~Yuang_Peng1",
            "~Zekun_Qi2",
            "~Zheng_Ge1",
            "~Jinrong_Yang1",
            "~Liang_Zhao17",
            "~Jianjian_Sun1",
            "~Hongyu_Zhou3",
            "~Haoran_Wei1",
            "~Xiangwen_Kong1",
            "~Xiangyu_Zhang1",
            "~Kaisheng_Ma1",
            "~Li_Yi2"
        ],
        "keywords": [
            "Multimodal Large Language Models",
            "Large Language Models",
            "Generative Models",
            "Vision Language",
            "Representation Learning",
            "GPT"
        ],
        "abstract": "This paper presents DreamLLM, a learning framework that first achieves versatile Multimodal Large Language Models (MLLMs) empowered with frequently overlooked synergy between multimodal comprehension and creation. DreamLLM operates on two fundamental principles. The first focuses on the generative modeling of both language and image posteriors by direct sampling in the raw multimodal space. This approach circumvents the limitations and information loss inherent to external feature extractors like CLIP, and a more thorough multimodal understanding is obtained. Second, DreamLLM fosters the generation of raw, interleaved documents, modeling both text and image contents, along with unstructured layouts. This allows DreamLLM to learn all conditional, marginal, and joint multimodal distributions effectively. As a result, DreamLLM is the first MLLM capable of generating free-form interleaved content. Comprehensive experiments highlight DreamLLM's superior performance as a zero-shot multimodal generalist, reaping from the enhanced learning synergy. Project page: https://dreamllm.github.io.",
        "_bibtex": "@inproceedings{\ndong2024dreamllm,\ntitle={Dream{LLM}: Synergistic Multimodal Comprehension and Creation},\nauthor={Runpei Dong and Chunrui Han and Yuang Peng and Zekun Qi and Zheng Ge and Jinrong Yang and Liang Zhao and Jianjian Sun and Hongyu Zhou and Haoran Wei and Xiangwen Kong and Xiangyu Zhang and Kaisheng Ma and Li Yi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=y01KGvd9Bw}\n}"
    },
    {
        "title": "Learning to Act from Actionless Videos through Dense Correspondences",
        "authorids": [
            "~Po-Chen_Ko1",
            "~Jiayuan_Mao1",
            "~Yilun_Du1",
            "~Shao-Hua_Sun1",
            "~Joshua_B._Tenenbaum1"
        ],
        "keywords": [
            "Video-Based Policy",
            "Video Dense Correspondence"
        ],
        "abstract": "In this work, we present an approach to construct a video-based robot policy capable of reliably executing diverse tasks across different robots and environments from few video demonstrations without using any action annotations. Our method leverages images as a task-agnostic representation, encoding both the state and action information, and text as a general representation for specifying robot goals. By synthesizing videos that \"hallucinate\" robot executing actions and in combination with dense correspondences between frames, our approach can infer the closed-formed action to execute to an environment without the need of any explicit action labels. This unique capability allows us to train the policy solely based on RGB videos and deploy learned policies to various robotic tasks. We demonstrate the efficacy of our approach in learning policies on table-top manipulation and navigation tasks. Additionally, we contribute an open-source framework for efficient video modeling, enabling the training of high-fidelity policy models with four GPUs within a single day.",
        "_bibtex": "@inproceedings{\nko2024learning,\ntitle={Learning to Act from Actionless Videos through Dense Correspondences},\nauthor={Po-Chen Ko and Jiayuan Mao and Yilun Du and Shao-Hua Sun and Joshua B. Tenenbaum},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Mhb5fpA1T0}\n}"
    },
    {
        "title": "On Penalty Methods for Nonconvex Bilevel Optimization and First-Order Stochastic Approximation",
        "authorids": [
            "~Jeongyeol_Kwon1",
            "~Dohyun_Kwon1",
            "~Stephen_Wright1",
            "~Robert_D_Nowak1"
        ],
        "keywords": [
            "Bilevel-Optimization",
            "Penalty Methods",
            "Landscape Analysis",
            "Non-Asymptotic Analysis",
            "First-Order Methods"
        ],
        "abstract": "In this work, we study first-order algorithms for solving Bilevel Optimization (BO) where the objective functions are smooth but possibly nonconvex in both levels and the variables are restricted to closed convex sets. As a first step, we study the landscape of BO through the lens of penalty methods, in which the upper- and lower-level objectives are combined in a weighted sum with penalty parameter $\\sigma > 0$. In particular, we establish a strong connection between the penalty function and the hyper-objective by explicitly characterizing the conditions under which the values and derivatives of the two must be $O(\\sigma)$-close. A by-product of our analysis is the explicit formula for the gradient of hyper-objective when the lower-level problem has multiple solutions under minimal conditions, which could be of independent interest. Next, viewing the penalty formulation as $O(\\sigma)$-approximation of the original BO, we propose first-order algorithms that find an $\\epsilon$-stationary solution by optimizing the penalty formulation with $\\sigma = O(\\epsilon)$. When the perturbed lower-level problem uniformly satisfies the {\\it small-error} proximal error-bound (EB) condition,  we propose a first-order algorithm that converges to an $\\epsilon$-stationary point of the penalty function using in total $O(\\epsilon^{-7})$ accesses to first-order stochastic gradient oracles. Under an additional assumption on stochastic oracles, we show that the algorithm can be implemented in a fully {\\it single-loop} manner, {\\it i.e.,} with $O(1)$ samples per iteration, and achieves the improved oracle-complexity of $O(\\epsilon^{-5})$.",
        "_bibtex": "@inproceedings{\nkwon2024on,\ntitle={On Penalty Methods for Nonconvex Bilevel Optimization and First-Order Stochastic Approximation},\nauthor={Jeongyeol Kwon and Dohyun Kwon and Stephen Wright and Robert D Nowak},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=CvYBvgEUK9}\n}"
    },
    {
        "title": "Scaling Laws for Sparsely-Connected Foundation Models",
        "authorids": [
            "~Elias_Frantar1",
            "~Carlos_Riquelme_Ruiz1",
            "~Neil_Houlsby1",
            "~Dan_Alistarh7",
            "~Utku_Evci1"
        ],
        "keywords": [
            "sparsity",
            "scaling",
            "optimal sparsity",
            "efficiency",
            "foundational models",
            "transformers",
            "structured sparsity",
            "pruning"
        ],
        "abstract": "We explore the impact of parameter sparsity on the scaling behavior of Transformers trained on massive datasets (i.e., \"foundation models\"), in both vision and language domains. In this setting, we identify the first scaling law describing the relationship between weight sparsity, number of non-zero parameters, and amount of training data, which we validate empirically across model and data scales; on ViT/JFT-4B and T5/C4. These results allow us to characterize the \"optimal sparsity\", the sparsity level which yields the best performance for a given effective model size and training budget. For a fixed number of non-zero parameters, we identify that the optimal sparsity increases with the amount of data used for training. We also extend our study to different sparsity structures (such as the hardware-friendly n:m pattern) and strategies (such as starting from a pretrained dense model). Our findings shed light on the power and limitations of weight sparsity across various parameter and computational settings, offering both theoretical understanding and practical implications for leveraging sparsity towards computational efficiency improvements. We provide pruning and scaling law fitting code at: github.com/google-research/jaxpruner/tree/main/jaxpruner/projects/bigsparse.",
        "_bibtex": "@inproceedings{\nfrantar2024scaling,\ntitle={Scaling Laws for Sparsely-Connected Foundation Models},\nauthor={Elias Frantar and Carlos Riquelme Ruiz and Neil Houlsby and Dan Alistarh and Utku Evci},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=i9K2ZWkYIP}\n}"
    },
    {
        "title": "Nearly $d$-Linear Convergence Bounds for Diffusion Models via Stochastic Localization",
        "authorids": [
            "~Joe_Benton1",
            "~Valentin_De_Bortoli1",
            "~Arnaud_Doucet2",
            "~George_Deligiannidis2"
        ],
        "keywords": [
            "diffusion models",
            "score-based generative models",
            "convergence bounds",
            "stochastic localization"
        ],
        "abstract": "Denoising diffusions are a powerful method to generate approximate samples from high-dimensional data distributions. Recent results provide polynomial bounds on their convergence rate, assuming $L^2$-accurate scores. Until now, the tightest bounds were either superlinear in the data dimension or required strong smoothness assumptions. We provide the first convergence bounds which are linear in the data dimension (up to logarithmic factors) assuming only finite second moments of the data distribution. We show that diffusion models require at most $\\tilde O(\\frac{d \\log^2(1/\\delta)}{\\varepsilon^2})$ steps to approximate an arbitrary distribution on $\\mathbb{R}^d$ corrupted with Gaussian noise of variance $\\delta$ to within $\\varepsilon^2$ in KL divergence. Our proof extends the Girsanov-based methods of previous works. We introduce a refined treatment of the error from discretizing the reverse SDE inspired by stochastic localization.",
        "_bibtex": "@inproceedings{\nbenton2024nearly,\ntitle={Nearly \\$d\\$-Linear Convergence Bounds for Diffusion Models via Stochastic Localization},\nauthor={Joe Benton and Valentin De Bortoli and Arnaud Doucet and George Deligiannidis},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=r5njV3BsuD}\n}"
    },
    {
        "title": "DragonDiffusion: Enabling Drag-style Manipulation on Diffusion Models",
        "authorids": [
            "~Chong_Mou1",
            "~Xintao_Wang1",
            "~Jiechong_Song1",
            "~Ying_Shan2",
            "~Jian_Zhang22"
        ],
        "keywords": [
            "Diffusion model",
            "Image editing",
            "Image generation"
        ],
        "abstract": "Despite the ability of text-to-image (T2I) diffusion models to generate high-quality images, transferring this ability to accurate image editing remains a challenge. In this paper, we propose a novel image editing method, DragonDiffusion, enabling Drag-style manipulation on Diffusion models. Specifically, we treat image editing as the change of feature correspondence in a pre-trained diffusion model. By leveraging feature correspondence, we develop energy functions that align with the editing target, transforming image editing operations into gradient guidance. Based on this guidance approach, we also construct multi-scale guidance that considers both semantic and geometric alignment. Furthermore, we incorporate a visual cross-attention strategy based on a memory bank design to ensure consistency between the edited result and original image. Benefiting from these efficient designs, all content editing and consistency operations come from the feature correspondence without extra model fine-tuning. Extensive experiments demonstrate that our method has promising performance on various image editing tasks, including within a single image (e.g., object moving, resizing, and content dragging) or across images (e.g., appearance replacing and object pasting). Code is available at https://github.com/MC-E/DragonDiffusion.",
        "_bibtex": "@inproceedings{\nmou2024dragondiffusion,\ntitle={DragonDiffusion: Enabling Drag-style Manipulation on Diffusion Models},\nauthor={Chong Mou and Xintao Wang and Jiechong Song and Ying Shan and Jian Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=OEL4FJMg1b}\n}"
    },
    {
        "title": "Uni3D: Exploring Unified 3D Representation at Scale",
        "authorids": [
            "~Junsheng_Zhou3",
            "~Jinsheng_Wang1",
            "~Baorui_Ma1",
            "~Yu-Shen_Liu1",
            "~Tiejun_Huang1",
            "~Xinlong_Wang2"
        ],
        "keywords": [
            "3D foundation model",
            "universal 3D representation at scale",
            "open-world 3D understanding"
        ],
        "abstract": "Scaling up representations for images or text has been extensively investigated in the past few years and has led to revolutions in learning vision and language. However, scalable representation for 3D objects and scenes is relatively unexplored. In this work, we present Uni3D, a 3D foundation model to explore the unified 3D representation at scale. Uni3D uses a 2D initialized ViT end-to-end pretrained to align the 3D point cloud features with the image-text aligned features. Via the simple architecture and pretext task, Uni3D can leverage abundant 2D pretrained models as initialization and image-text aligned models as the target, unlocking the great potential of 2D model zoos and scaling-up strategies to the 3D world. We efficiently scale up Uni3D to one billion parameters, and set new records on a broad range of 3D tasks, such as zero-shot classification, few-shot classification, open-world understanding and zero-shot part segmentation.  We show that the strong Uni3D representation also enables applications such as 3D painting and retrieval in the wild. We believe that Uni3D provides a new direction for exploring both scaling up and efficiency of the representation in 3D domain.",
        "_bibtex": "@inproceedings{\nzhou2024unid,\ntitle={Uni3D: Exploring Unified 3D Representation at Scale},\nauthor={Junsheng Zhou and Jinsheng Wang and Baorui Ma and Yu-Shen Liu and Tiejun Huang and Xinlong Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=wcaE4Dfgt8}\n}"
    },
    {
        "title": "CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents",
        "authorids": [
            "~Siyuan_Qi1",
            "~Shuo_Chen3",
            "~Yexin_Li1",
            "~Xiangyu_Kong1",
            "~Junqi_Wang1",
            "~Bangcheng_Yang1",
            "~Pring_Wong2",
            "~Yifan_Zhong2",
            "~Xiaoyuan_Zhang3",
            "~Zhaowei_Zhang2",
            "~Nian_Liu4",
            "~Yaodong_Yang1",
            "~Song-Chun_Zhu1"
        ],
        "keywords": [
            "Interactive Environments",
            "Benchmark",
            "Reinforcement Learning",
            "Language Agent",
            "Multi-agent"
        ],
        "abstract": "The generalization of decision-making agents encompasses two fundamental elements: learning from past experiences and reasoning in novel contexts. However, the predominant emphasis in most interactive environments is on learning, often at the expense of complexity in reasoning. In this paper, we introduce CivRealm, an environment inspired by the Civilization game. Civilization\u2019s profound alignment with human society requires sophisticated learning and prior knowledge, while its ever-changing space and action space demand robust reasoning for generalization. Particularly, CivRealm sets up an imperfect-information general-sum game with a changing number of players; it presents a plethora of complex features, challenging the agent to deal with open-ended stochastic environments that require diplomacy and negotiation skills. Within CivRealm, we provide interfaces for two typical agent types: tensor-based agents that focus on learning, and language-based agents that emphasize reasoning. To catalyze further research, we present initial results for both paradigms. The canonical RL-based agents exhibit reasonable performance in mini-games, whereas both RL- and LLM-based agents struggle to make substantial progress in the full game. Overall, CivRealm stands as a unique learning and reasoning challenge for decision-making agents. The code is available at https://github.com/bigai-ai/civrealm.",
        "_bibtex": "@inproceedings{\nqi2024civrealm,\ntitle={CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents},\nauthor={Siyuan Qi and Shuo Chen and Yexin Li and Xiangyu Kong and Junqi Wang and Bangcheng Yang and Pring Wong and Yifan Zhong and Xiaoyuan Zhang and Zhaowei Zhang and Nian Liu and Yaodong Yang and Song-Chun Zhu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=UBVNwD3hPN}\n}"
    },
    {
        "title": "Open-ended VQA benchmarking of Vision-Language models by exploiting Classification datasets and their semantic hierarchy",
        "authorids": [
            "~Simon_Ging1",
            "~Maria_Alejandra_Bravo1",
            "~Thomas_Brox1"
        ],
        "keywords": [
            "Open-ended VQA",
            "benchmark",
            "Vision-Language",
            "VL",
            "Vision-Text",
            "VLM",
            "Vision-Language models",
            "Image classification",
            "Visual question answering",
            "Text-generating VLM"
        ],
        "abstract": "The evaluation of text-generative vision-language models is a challenging yet crucial endeavor. By addressing the limitations of existing Visual Question Answering (VQA) benchmarks and proposing innovative evaluation methodologies, our research seeks to advance our understanding of these models\u2019 capabilities. We propose a novel VQA benchmark based on well-known visual classification datasets which allows a granular evaluation of text-generative vision-language models and their comparison with discriminative vision-language models. To improve the assessment of coarse answers on fine-grained classification tasks, we suggest using the semantic hierarchy of the label space to ask automatically generated follow-up questions about the ground-truth category. Finally, we compare traditional NLP and LLM-based metrics for the problem of evaluating model predictions given ground-truth answers. We perform a human evaluation study upon which we base our decision on the final metric. We apply our benchmark to a suite of vision-language models and show a detailed comparison of their abilities on object, action, and attribute classification. Our contributions aim to lay the foundation for more precise and meaningful assessments, facilitating targeted progress in the exciting field of vision-language modeling.",
        "_bibtex": "@inproceedings{\nging2024openended,\ntitle={Open-ended {VQA} benchmarking of Vision-Language models by exploiting Classification datasets and their semantic hierarchy},\nauthor={Simon Ging and Maria Alejandra Bravo and Thomas Brox},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=EXitynZhYn}\n}"
    },
    {
        "title": "GIM: Learning Generalizable Image Matcher From Internet Videos",
        "authorids": [
            "~Xuelun_Shen1",
            "~zhipeng_cai3",
            "~Wei_Yin2",
            "~Matthias_M\u00fcller1",
            "~Zijun_Li1",
            "~Kaixuan_Wang2",
            "~Xiaozhi_Chen4",
            "~Cheng_Wang2"
        ],
        "keywords": [
            "Image Matching",
            "Pose Estimation",
            "3D Reconstruction"
        ],
        "abstract": "Image matching is a fundamental computer vision problem. While learning-based methods achieve state-of-the-art performance on existing benchmarks, they generalize poorly to in-the-wild images. Such methods typically need to train separate models for different scene types (e.g., indoor vs. outdoor) and are impractical when the scene type is unknown in advance. One of the underlying problems is the limited scalability of existing data construction pipelines, which limits the diversity of standard image matching datasets. To address this problem, we propose GIM, a self-training framework for learning a single generalizable model based on any image matching architecture using internet videos, an abundant and diverse data source. Given an architecture, GIM first trains it on standard domain-specific datasets and then combines it with complementary matching methods to create dense labels on nearby frames of novel videos. These labels are filtered by robust fitting, and then enhanced by propagating them to distant frames. The final model is trained on propagated data with strong augmentations. Not relying on complex 3D reconstruction makes GIM much more efficient and less likely to fail than standard SfM-and-MVS based frameworks. We also propose ZEB, the first zero-shot evaluation benchmark for image matching. By mixing data from diverse domains, ZEB can thoroughly assess the cross-domain generalization performance of different methods. Experiments demonstrate the effectiveness and generality of GIM. Applying GIM consistently improves the zero-shot performance of 3 state-of-the-art image matching architectures as the number of downloaded videos increases (Fig. 1 (a)); with 50 hours of YouTube videos, the relative zero-shot performance improves by 6.9% \u2212 18.1%. GIM also enables generalization to extreme cross-domain data such as Bird Eye View (BEV) images of projected 3D point clouds (Fig. 1 (c)). More importantly, our single zero-shot model consistently outperforms domain-specific baselines when evaluated on downstream tasks inherent to their respective domains. The code will be released upon acceptance.",
        "_bibtex": "@inproceedings{\nshen2024gim,\ntitle={{GIM}: Learning Generalizable Image Matcher From Internet Videos},\nauthor={Xuelun Shen and zhipeng cai and Wei Yin and Matthias M{\\\"u}ller and Zijun Li and Kaixuan Wang and Xiaozhi Chen and Cheng Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=NYN1b8GRGS}\n}"
    },
    {
        "title": "SyncDreamer: Generating Multiview-consistent Images from a Single-view Image",
        "authorids": [
            "~Yuan_Liu3",
            "~Cheng_Lin1",
            "~Zijiao_Zeng1",
            "~Xiaoxiao_Long2",
            "~Lingjie_Liu1",
            "~Taku_Komura2",
            "~Wenping_Wang1"
        ],
        "keywords": [
            "diffusion model; single-view reconstruction; 3D generation; generative models"
        ],
        "abstract": "In this paper, we present a novel diffusion model called SyncDreamer that generates multiview-consistent images from a single-view image. Using pretrained large-scale 2D diffusion models, recent work Zero123 demonstrates the ability to generate plausible novel views from a single-view image of an object. However, maintaining consistency in geometry and colors for the generated images remains a challenge. To address this issue, we propose a synchronized multiview diffusion model that models the joint probability distribution of multiview images, enabling the generation of multiview-consistent images in a single reverse process. SyncDreamer synchronizes the intermediate states of all the generated images at every step of the reverse process through a 3D-aware feature attention mechanism that correlates the corresponding features across different views. Experiments show that SyncDreamer generates images with high consistency across different views, thus making it well-suited for various 3D generation tasks such as novel-view-synthesis, text-to-3D, and image-to-3D. Project page: https://liuyuan-pal.github.io/SyncDreamer/.",
        "_bibtex": "@inproceedings{\nliu2024syncdreamer,\ntitle={SyncDreamer: Generating Multiview-consistent Images from a Single-view Image},\nauthor={Yuan Liu and Cheng Lin and Zijiao Zeng and Xiaoxiao Long and Lingjie Liu and Taku Komura and Wenping Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MN3yH2ovHb}\n}"
    },
    {
        "title": "Finite-State Autoregressive Entropy Coding for Efficient Learned Lossless Compression",
        "authorids": [
            "~Yufeng_Zhang4",
            "~Hang_Yu1",
            "~Jianguo_Li2",
            "~Weiyao_Lin1"
        ],
        "keywords": [
            "Lossless Compression",
            "Autoregressive Model",
            "Acceleration",
            "Entropy Coding",
            "Autoencoder"
        ],
        "abstract": "Learned lossless data compression has garnered significant attention recently due to its superior compression ratios compared to traditional compressors. However, the computational efficiency of these models jeopardizes their practicality. This paper proposes a novel system for improving the compression ratio while maintaining computational efficiency for learned lossless data compression. Our approach incorporates two essential innovations. First, we propose the Finite-State AutoRegressive (FSAR) entropy coder, an efficient autoregressive Markov model based entropy coder that utilizes a lookup table to expedite autoregressive entropy coding. Next, we present a Straight-Through Hardmax Quantization (STHQ) scheme to enhance the optimization of discrete latent space. Our experiments show that the proposed lossless compression method could improve the compression ratio by up to 6\\% compared to the baseline, with negligible extra computational time. Our work provides valuable insights into enhancing the computational efficiency of learned lossless data compression, which can have practical applications in various fields. Code is available at https://github.com/alipay/Finite_State_Autoregressive_Entropy_Coding.",
        "_bibtex": "@inproceedings{\nzhang2024finitestate,\ntitle={Finite-State Autoregressive Entropy Coding for Efficient Learned Lossless Compression},\nauthor={Yufeng Zhang and Hang Yu and Jianguo Li and Weiyao Lin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=D5mJSNtUtv}\n}"
    },
    {
        "title": "ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs",
        "authorids": [
            "~Yujia_Qin1",
            "~Shihao_Liang1",
            "~Yining_Ye1",
            "~Kunlun_Zhu1",
            "~Lan_Yan4",
            "~Yaxi_Lu1",
            "~Yankai_Lin1",
            "~Xin_Cong1",
            "~Xiangru_Tang2",
            "~Bill_Qian1",
            "~Sihan_Zhao1",
            "~Lauren_Hong1",
            "~Runchu_Tian1",
            "~Ruobing_Xie2",
            "~Jie_Zhou8",
            "~Mark_Gerstein2",
            "~dahai_li1",
            "~Zhiyuan_Liu1",
            "~Maosong_Sun1"
        ],
        "keywords": [
            "Large Language Model",
            "Tool Use",
            "API Use"
        ],
        "abstract": "Despite the advancements of open-source large language models (LLMs), e.g., LLaMA, they remain significantly limited in tool-use capabilities, i.e., using external tools (APIs) to fulfill human instructions. The reason is that current instruction tuning largely focuses on basic language tasks but ignores the tool-use domain. This is in contrast to the excellent tool-use capabilities of state-of-the-art (SOTA) closed-source LLMs, e.g., ChatGPT. To bridge this gap, we introduce ToolLLM, a general tool-use framework encompassing data construction, model training, and evaluation. We first present ToolBench, an instruction-tuning dataset for tool use, which is constructed automatically using ChatGPT. Specifically, the construction can be divided into three stages: (i) API collection: we collect 16,464 real-world RESTful APIs spanning 49 categories from RapidAPI Hub; (ii) instruction generation: we prompt ChatGPT to generate diverse instructions involving these APIs, covering both single-tool and multi-tool scenarios; (iii) solution path annotation: we use ChatGPT to search for a valid solution path (chain of API calls) for each instruction. To enhance the reasoning capabilities of LLMs, we develop a novel depth-first search-based decision tree algorithm. It enables LLMs to evaluate multiple reasoning traces and expand the search space. Moreover, to evaluate the tool-use capabilities of LLMs, we develop an automatic evaluator: ToolEval. Based on ToolBench, we fine-tune LLaMA to obtain an LLM ToolLLaMA, and equip it with a neural API retriever to recommend appropriate APIs for each instruction. Experiments show that ToolLLaMA demonstrates a remarkable ability to execute complex instructions and generalize to unseen APIs, and exhibits comparable performance to ChatGPT. Our ToolLLaMA also demonstrates strong zero-shot generalization ability in an out-of-distribution tool-use dataset: APIBench.",
        "_bibtex": "@inproceedings{\nqin2024toolllm,\ntitle={Tool{LLM}: Facilitating Large Language Models to Master 16000+ Real-world {API}s},\nauthor={Yujia Qin and Shihao Liang and Yining Ye and Kunlun Zhu and Lan Yan and Yaxi Lu and Yankai Lin and Xin Cong and Xiangru Tang and Bill Qian and Sihan Zhao and Lauren Hong and Runchu Tian and Ruobing Xie and Jie Zhou and Mark Gerstein and dahai li and Zhiyuan Liu and Maosong Sun},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=dHng2O0Jjr}\n}"
    },
    {
        "title": "Enhanced Face Recognition using Intra-class Incoherence Constraint",
        "authorids": [
            "~Yuanqing_Huang1",
            "~Yinggui_Wang1",
            "~Le_Yang6",
            "~Lei_Wang30"
        ],
        "keywords": [
            "Representation learning",
            "Computer vision",
            "Face recognition",
            "Intra-class incoherence Constraint"
        ],
        "abstract": "The current face recognition (FR) algorithms has achieved a high level of accuracy, making further improvements increasingly challenging. While existing FR algorithms primarily focus on optimizing margins and loss functions, limited attention has been given to exploring the feature representation space. Therefore, this paper endeavors to improve FR performance in the view of feature representation space. Firstly, we consider two FR models that exhibit distinct performance discrepancies, where one model exhibits superior recognition accuracy compared to the other. We implement orthogonal decomposition on the features from the superior model along those from the inferior model and obtain two sub-features. Surprisingly, we find the sub-feature perpendicular to the inferior still possesses a certain level of face distinguishability. We adjust the modulus of the sub-features and recombine them through vector addition. Experiments demonstrate this recombination is likely to contribute to an improved facial feature representation, even better than features from the original superior model. Motivated by this discovery, we further consider how to improve FR accuracy when there is only one FR model available. Inspired by knowledge distillation, we incorporate the intra-class incoherence constraint (IIC) to solve the problem. Experiments on various FR benchmarks show the existing state-of-the-art method with IIC can be further improved, highlighting its potential to further enhance FR performance.",
        "_bibtex": "@inproceedings{\nhuang2024enhanced,\ntitle={Enhanced Face Recognition using Intra-class Incoherence Constraint},\nauthor={Yuanqing Huang and Yinggui Wang and Le Yang and Lei Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=uELjxVbrqG}\n}"
    },
    {
        "title": "Entropy is not Enough for Test-Time Adaptation: From the Perspective of Disentangled Factors",
        "authorids": [
            "~Jonghyun_Lee1",
            "~Dahuin_Jung2",
            "~Saehyung_Lee1",
            "~Junsung_Park1",
            "~Juhyeon_Shin1",
            "~Uiwon_Hwang1",
            "~Sungroh_Yoon1"
        ],
        "keywords": [
            "Test-time adaptation",
            "Roustness"
        ],
        "abstract": "Test-time adaptation (TTA) fine-tunes pre-trained deep neural networks for unseen test data. The primary challenge of TTA is limited access to the entire test dataset during online updates, causing error accumulation. To mitigate it, TTA methods have utilized the model output's entropy as a confidence metric that aims to determine which samples have a lower likelihood of causing error. Through experimental studies, however, we observed the unreliability of entropy as a confidence metric for TTA under biased scenarios and theoretically revealed that it stems from the neglect of the influence of latent disentangled factors of data on predictions. Building upon these findings, we introduce a novel TTA method named Destroy Your Object (DeYO), which leverages a newly proposed confidence metric named Pseudo-Label Probability Difference (PLPD). PLPD quantifies the influence of the shape of an object on prediction by measuring the difference between predictions before and after applying an object-destructive transformation. DeYO consists of sample selection and sample weighting, which employ entropy and PLPD concurrently. For robust adaptation, DeYO prioritizes samples that dominantly incorporate shape information when making predictions. Our extensive experiments demonstrate the consistent superiority of DeYO over baseline methods across various scenarios, including biased and wild. Project page is publicly available at https://whitesnowdrop.github.io/DeYO/.",
        "_bibtex": "@inproceedings{\nlee2024entropy,\ntitle={Entropy is not Enough for Test-Time Adaptation: From the Perspective of Disentangled Factors},\nauthor={Jonghyun Lee and Dahuin Jung and Saehyung Lee and Junsung Park and Juhyeon Shin and Uiwon Hwang and Sungroh Yoon},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=9w3iw8wDuE}\n}"
    },
    {
        "title": "SEAL: A Framework for Systematic Evaluation of Real-World Super-Resolution",
        "authorids": [
            "~Wenlong_Zhang3",
            "~Xiaohui_Li2",
            "~Xiangyu_Chen5",
            "~Xiaoyun_Zhang1",
            "~Yu_Qiao1",
            "~Xiao-Ming_Wu1",
            "~Chao_Dong4"
        ],
        "keywords": [
            "Image super-resolution; Real-World super-resolution"
        ],
        "abstract": "Real-world Super-Resolution (Real-SR) methods focus on dealing with diverse real-world images and have attracted increasing attention in recent years. The key idea is to use a complex and high-order degradation model to mimic real-world degradations. \nAlthough they have achieved impressive results in various scenarios, they are faced with the obstacle of evaluation. Currently, these methods are only assessed by their average performance on a small set of degradation cases randomly selected from a large space, which fails to provide a comprehensive understanding of their overall performance and often yields inconsistent and potentially misleading results.\nTo overcome the limitation in evaluation, we propose SEAL, a framework for systematic evaluation of real-SR. In particular, we cluster the extensive degradation space to create a set of representative degradation cases, which serves as a comprehensive test set. Next, we propose a coarse-to-fine evaluation protocol to measure the distributed and relative performance of real-SR methods on the test set. The protocol incorporates two new metrics: acceptance rate (AR) and relative performance ratio (RPR), derived from acceptance and excellence lines. Under SEAL, we benchmark existing real-SR methods, obtain new observations and insights into their performance, and develop a new strong baseline. We consider SEAL as the first step towards creating an unbiased and comprehensive real-SR evaluation platform, which can promote the development of real-SR.",
        "_bibtex": "@inproceedings{\nzhang2024seal,\ntitle={{SEAL}: A Framework for Systematic Evaluation of Real-World Super-Resolution},\nauthor={Wenlong Zhang and Xiaohui Li and Xiangyu Chen and Xiaoyun Zhang and Yu Qiao and Xiao-Ming Wu and Chao Dong},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=CGlczSBBSj}\n}"
    },
    {
        "title": "Learning Energy-Based Models by Cooperative Diffusion Recovery Likelihood",
        "authorids": [
            "~Yaxuan_Zhu1",
            "~Jianwen_Xie1",
            "~Ying_Nian_Wu1",
            "~Ruiqi_Gao1"
        ],
        "keywords": [
            "Energy-based model",
            "recovery-likelihood",
            "cooperative learning"
        ],
        "abstract": "Training energy-based models (EBMs) on high-dimensional data can be both challenging and time-consuming, and there exists a noticeable gap in sample quality between EBMs and other generative frameworks like GANs and diffusion models. To close this gap, inspired by the recent efforts of learning EBMs by maximimizing diffusion recovery likelihood (DRL), we propose cooperative diffusion recovery likelihood (CDRL), an effective approach to tractably learn and sample from a series of EBMs defined on increasingly noisy versons of a dataset, paired with an initializer model for each EBM. At each noise level, the two models are jointly estimated within a cooperative training framework: Samples from the initializer serve as starting points that are refined by a few MCMC sampling steps from the EBM. The EBM is then optimized by maximizing recovery likelihood, while the initializer model is optimized by learning from the difference between the refined samples and the initial samples. In addition, we made several practical designs for EBM training to further improve the sample quality. Combining these advances, we significantly boost the generation performance compared to existing EBM methods on CIFAR-10 and ImageNet 32x32. And we have shown that CDRL has great potential to largely reduce the sampling time. We also demonstrate the effectiveness of our models for several downstream tasks, including classifier-free guided generation, compositional generation, image inpainting and out-of-distribution detection.",
        "_bibtex": "@inproceedings{\nzhu2024learning,\ntitle={Learning Energy-Based Models by Cooperative Diffusion Recovery Likelihood},\nauthor={Yaxuan Zhu and Jianwen Xie and Ying Nian Wu and Ruiqi Gao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=AyzkDpuqcl}\n}"
    },
    {
        "title": "MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning",
        "authorids": [
            "~Xiang_Yue1",
            "~Xingwei_Qu1",
            "~Ge_Zhang5",
            "~Yao_Fu3",
            "~Wenhao_Huang1",
            "~Huan_Sun1",
            "~Yu_Su2",
            "~Wenhu_Chen3"
        ],
        "keywords": [
            "Math Reasoning",
            "Instruction Tuning",
            "Large Language Model"
        ],
        "abstract": "We introduce MAmmoTH, a series of open-source large language models (LLMs) specifically tailored for general math problem-solving. The MAmmoTH models are trained on MathInstruct, our meticulously curated instruction tuning dataset. MathInstruct is compiled from 13 math datasets with intermediate rationales, six of which have rationales newly curated by us. It presents a unique hybrid of chain-of-thought (CoT) and program-of-thought (PoT) rationales, and also ensures extensive coverage of diverse fields in math. The hybrid of CoT and PoT not only unleashes the potential of tool use but also allows different thought processes for different math problems. As a result, the MAmmoTH series substantially outperform existing open-source models on nine mathematical reasoning datasets across all scales with an average accuracy gain between 16% and 32%. Remarkably, our MAmmoTH-7B model reaches 33% on MATH (a competition-level dataset), which exceeds the best open-source 7B model (WizardMath) by 23%, and the MAmmoTH-34B model achieves 44% accuracy on MATH, even surpassing GPT-4\u2019s CoT result. Our work underscores the importance of diverse problem coverage and the use of hybrid rationales in developing superior math generalist models.",
        "_bibtex": "@inproceedings{\nyue2024mammoth,\ntitle={{MA}mmo{TH}: Building Math Generalist Models through Hybrid Instruction Tuning},\nauthor={Xiang Yue and Xingwei Qu and Ge Zhang and Yao Fu and Wenhao Huang and Huan Sun and Yu Su and Wenhu Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=yLClGs770I}\n}"
    },
    {
        "title": "Time Travel in LLMs: Tracing Data Contamination in Large Language Models",
        "authorids": [
            "~Shahriar_Golchin1",
            "~Mihai_Surdeanu1"
        ],
        "keywords": [
            "Data Contamination",
            "Large Language Models (LLMs)",
            "Guided Instruction",
            "Memorization"
        ],
        "abstract": "Data contamination, i.e., the presence of test data from downstream tasks in the training data of large language models (LLMs), is a potential major issue in measuring LLMs' real effectiveness on other tasks. We propose a straightforward yet effective method for identifying data contamination within LLMs. At its core, our approach starts by identifying potential contamination at the instance level; using this information, our approach then assesses wider contamination at the partition level. To estimate contamination of individual instances, we employ \"guided instruction:\" a prompt consisting of the dataset name, partition type, and the random-length initial segment of a reference instance, asking the LLM to complete it. An instance is flagged as contaminated if the LLM's output either exactly or nearly matches the latter segment of the reference. To understand if an entire partition is contaminated, we propose two ideas. The first idea marks a dataset partition as contaminated if the average overlap score with the reference instances (as measured by ROUGE-L or BLEURT) is statistically significantly better with the completions from guided instruction compared to a \"general instruction\" that does not include the dataset and partition name. The second idea marks a dataset partition as contaminated if a classifier based on GPT-4 with few-shot in-context learning prompt marks multiple generated completions as exact/near-exact matches of the corresponding reference instances. Our best method achieves an accuracy between 92% and 100% in detecting if an LLM is contaminated with seven datasets, containing train and test/validation partitions, when contrasted with manual evaluation by human experts. Further, our findings indicate that GPT-4 is contaminated with AG News, WNLI, and XSum datasets.",
        "_bibtex": "@inproceedings{\ngolchin2024time,\ntitle={Time Travel in {LLM}s: Tracing Data Contamination in Large Language Models},\nauthor={Shahriar Golchin and Mihai Surdeanu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=2Rwq6c3tvr}\n}"
    },
    {
        "title": "Variational Inference for SDEs Driven by Fractional Noise",
        "authorids": [
            "~Rembert_Daems1",
            "~Manfred_Opper1",
            "~Guillaume_Crevecoeur1",
            "~Tolga_Birdal3"
        ],
        "keywords": [
            "variational inference",
            "neural sdes",
            "stochastic differential equations",
            "brownian motion",
            "fractional noise",
            "fractional brownian motion",
            "markov approximation",
            "markov representation"
        ],
        "abstract": "We present a novel variational framework for performing inference in (neural) stochastic differential equations (SDEs) driven by Markov-approximate fractional Brownian motion (fBM). SDEs offer a versatile tool for modeling real-world continuous-time dynamic systems with inherent noise and randomness. Combining SDEs with the powerful inference capabilities of variational methods, enables the learning of representative distributions through stochastic gradient descent. However, conventional SDEs typically assume  the underlying noise to follow a Brownian motion (BM), which hinders their ability to capture long-term dependencies. In contrast, fractional Brownian motion (fBM) extends BM to encompass non-Markovian dynamics, but existing methods for inferring fBM parameters are either computationally demanding or statistically inefficient. \n\nIn this paper, building upon the Markov approximation of fBM, we derive the evidence lower bound essential for efficient variational inference of posterior path measures, drawing from the well-established field of stochastic analysis. Additionally, we provide a closed-form expression for optimal approximation coefficients and propose to use neural networks to learn the drift, diffusion and control terms within our variational posterior, leading to the variational training of neural-SDEs. In this framework, we also optimize the Hurst index, governing the nature of our fractional noise. Beyond validation on synthetic data, we contribute a novel architecture for variational latent video prediction,\u2014an approach that, to the best of our knowledge, enables the first variational neural-SDE application to video perception.",
        "_bibtex": "@inproceedings{\ndaems2024variational,\ntitle={Variational Inference for {SDE}s Driven by Fractional Noise},\nauthor={Rembert Daems and Manfred Opper and Guillaume Crevecoeur and Tolga Birdal},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rtx8B94JMS}\n}"
    },
    {
        "title": "Implicit regularization of deep residual networks towards neural ODEs",
        "authorids": [
            "~Pierre_Marion1",
            "~Yu-Han_Wu1",
            "~Michael_Eli_Sander1",
            "~G\u00e9rard_Biau1"
        ],
        "keywords": [
            "deep learning theory",
            "residual networks",
            "neural ODEs",
            "optimization",
            "implicit regularization",
            "gradient flow"
        ],
        "abstract": "Residual neural networks are state-of-the-art deep learning models. Their continuous-depth analog, neural ordinary differential equations (ODEs), are also widely used. Despite their success, the link between the discrete and continuous models still lacks a solid mathematical foundation. In this article, we take a step in this direction by establishing an implicit regularization of deep residual networks towards neural ODEs, for nonlinear networks trained with gradient flow. We prove that if the network is initialized as a discretization of a neural ODE, then such a discretization holds throughout training. Our results are valid for a finite training time, and also as the training time tends to infinity provided that the network satisfies a Polyak-\u0141ojasiewicz condition. Importantly, this condition holds for a family of residual networks where the residuals are two-layer perceptrons with an overparameterization in width that is only linear, and implies the convergence of gradient flow to a global minimum. Numerical experiments illustrate our results.",
        "_bibtex": "@inproceedings{\nmarion2024implicit,\ntitle={Implicit regularization of deep residual networks towards neural {ODE}s},\nauthor={Pierre Marion and Yu-Han Wu and Michael Eli Sander and G{\\'e}rard Biau},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=AbXGwqb5Ht}\n}"
    },
    {
        "title": "NetInfoF Framework: Measuring and Exploiting Network Usable Information",
        "authorids": [
            "~Meng-Chieh_Lee1",
            "~Haiyang_Yu6",
            "~Jian_Zhang32",
            "~Vassilis_N._Ioannidis1",
            "~Xiang_song1",
            "~Soji_Adeshina1",
            "~Da_Zheng1",
            "~Christos_Faloutsos1"
        ],
        "keywords": [
            "Graph Neural Networks",
            "Information Theory",
            "Heterophily Graphs"
        ],
        "abstract": "Given a node-attributed graph, and a graph task (link prediction or node classification), can we tell if a graph neural network (GNN) will perform well? More specifically, do the graph structure and the node features carry enough usable information for the task? Our goals are\n(1) to develop a fast tool to measure how much information is in the graph structure and in the node features, and\n(2) to exploit the information to solve the task, if there is enough.\nWe propose NetInfoF, a framework including NetInfoF_Probe and NetInfoF_Act, for the measurement and the exploitation of network usable information (NUI), respectively. Given a graph data, NetInfoF_Probe measures NUI without any model training, and NetInfoF_Act solves link prediction and node classification, while two modules share the same backbone.\nIn summary, NetInfoF has following notable advantages:\n(a) General, handling both link prediction and node classification;\n(b) Principled, with theoretical guarantee and closed-form solution;\n(c) Effective, thanks to the proposed adjustment to node similarity;\n(d) Scalable, scaling linearly with the input size.\nIn our carefully designed synthetic datasets, NetInfoF correctly identifies the ground truth of NUI and is the only method being robust to all graph scenarios. Applied on real-world datasets, NetInfoF wins in 11 out of 12 times on link prediction compared to general GNN baselines.",
        "_bibtex": "@inproceedings{\nlee2024netinfof,\ntitle={NetInfoF Framework: Measuring and Exploiting Network Usable Information},\nauthor={Meng-Chieh Lee and Haiyang Yu and Jian Zhang and Vassilis N. Ioannidis and Xiang song and Soji Adeshina and Da Zheng and Christos Faloutsos},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=KY8ZNcljVU}\n}"
    },
    {
        "title": "BarLeRIa: An Efficient Tuning Framework for Referring Image Segmentation",
        "authorids": [
            "~Yaoming_Wang1",
            "~Jin_Li10",
            "~XIAOPENG_ZHANG7",
            "~Bowen_Shi2",
            "~Chenglin_Li2",
            "~Wenrui_Dai1",
            "~Hongkai_Xiong1",
            "~Qi_Tian3"
        ],
        "keywords": [
            "referring image segmentation; parameter efficient tuning"
        ],
        "abstract": "Pre-training followed by full fine-tuning has gradually been substituted by Parameter-Efficient Tuning (PET) in the field of computer vision. PET has gained popularity, especially in the context of large-scale models, due to its ability to reduce transfer learning costs and conserve hardware resources. However, existing PET approaches primarily focus on recognition tasks and typically support uni-modal optimization, while neglecting dense prediction tasks and vision language interactions. To address this limitation, we propose a novel PET framework called **B**i-direction**a**l Inte**r**twined Vision **L**anguage Effici**e**nt Tuning for **R**eferring **I**mage Segment**a**tion (**BarLeRIa**), which leverages bi-directional intertwined vision language adapters to fully exploit the frozen pre-trained models' potential in cross-modal dense prediction tasks. In BarLeRIa, two different tuning modules are employed for efficient attention, one for global, and the other for local, along with an intertwined vision language tuning module for efficient modal fusion.\nExtensive experiments conducted on RIS benchmarks demonstrate the superiority of BarLeRIa over prior PET methods with a significant margin, i.e., achieving an average improvement of 5.6\\%. Remarkably, without requiring additional training datasets, BarLeRIa even surpasses SOTA full fine-tuning approaches. The code is available at https://github.com/NastrondAd/BarLeRIa.",
        "_bibtex": "@inproceedings{\nwang2024barleria,\ntitle={BarLe{RI}a: An Efficient Tuning Framework for Referring Image Segmentation},\nauthor={Yaoming Wang and Jin Li and XIAOPENG ZHANG and Bowen Shi and Chenglin Li and Wenrui Dai and Hongkai Xiong and Qi Tian},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=wHLDHRkmEu}\n}"
    },
    {
        "title": "Local Search GFlowNets",
        "authorids": [
            "~Minsu_Kim2",
            "~Taeyoung_Yun1",
            "~Emmanuel_Bengio1",
            "~Dinghuai_Zhang1",
            "~Yoshua_Bengio1",
            "~Sungsoo_Ahn1",
            "~Jinkyoo_Park1"
        ],
        "keywords": [
            "GFlowNet",
            "molecule optimization",
            "biological sequence design",
            "local search",
            "reinforcement learning"
        ],
        "abstract": "Generative Flow Networks (GFlowNets) are amortized sampling methods that learn a distribution over discrete objects proportional to their rewards. GFlowNets exhibit a remarkable ability to generate diverse samples, yet occasionally struggle to consistently produce samples with high rewards due to over-exploration on wide sample space. \nThis paper proposes to train GFlowNets with local search, which focuses on exploiting high-rewarded sample space to resolve this issue. Our main idea is to explore the local neighborhood via backtracking and reconstruction guided by backward and forward policies, respectively. This allows biasing the samples toward high-reward solutions, which is not possible for a typical GFlowNet solution generation scheme, which uses the forward policy to generate the solution from scratch. Extensive experiments demonstrate a remarkable performance improvement in several biochemical tasks. Source code is available: \\url{https://github.com/dbsxodud-11/ls_gfn}.",
        "_bibtex": "@inproceedings{\nkim2024local,\ntitle={Local Search {GF}lowNets},\nauthor={Minsu Kim and Taeyoung Yun and Emmanuel Bengio and Dinghuai Zhang and Yoshua Bengio and Sungsoo Ahn and Jinkyoo Park},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=6cFcw1Rxww}\n}"
    },
    {
        "title": "Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt Tensor Products",
        "authorids": [
            "~Shengjie_Luo1",
            "~Tianlang_Chen2",
            "~Aditi_S._Krishnapriyan1"
        ],
        "keywords": [
            "Equivariant Operations; Tensor Product; Change of basis; Spherical Harmonics; Fourier Basis; equivariant neural networks"
        ],
        "abstract": "Developing equivariant neural networks for the E(3) group plays an important role in modeling 3D data across real-world applications. Enforcing this equivariance primarily involves the tensor products of irreducible representations (irreps). However, the computational complexity of such operations increases significantly as higher-order tensors are used. In this work, we propose a systematic approach to substantially accelerate the computation of the tensor products of irreps. We mathematically connect the commonly used Clebsch-Gordan coefficients to the Gaunt coefficients, which are integrals of products of three spherical harmonics. Through Gaunt coefficients, the tensor product of irreps becomes equivalent to the multiplication between spherical functions represented by spherical harmonics. This perspective further allows us to change the basis for the equivariant operations from spherical harmonics to a 2D Fourier basis. Consequently, the multiplication between spherical functions represented by a 2D Fourier basis can be efficiently computed via the convolution theorem and Fast Fourier Transforms. This transformation reduces the complexity of full tensor products of irreps from $\\mathcal{O}(L^6)$ to $\\mathcal{O}(L^3)$, where $L$ is the max degree of irreps. Leveraging this approach, we introduce the Gaunt Tensor Product, which serves as a new method to construct efficient equivariant operations across different model architectures. Our experiments on the Open Catalyst Project and 3BPA datasets demonstrate both the increased efficiency and improved performance of our approach. The code and models will be made publicly available at https://github.com/lsj2408/Gaunt-Tensor-Product.",
        "_bibtex": "@inproceedings{\nluo2024enabling,\ntitle={Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt Tensor Products},\nauthor={Shengjie Luo and Tianlang Chen and Aditi S. Krishnapriyan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=mhyQXJ6JsK}\n}"
    },
    {
        "title": "Idempotence and Perceptual Image Compression",
        "authorids": [
            "~Tongda_Xu1",
            "~Ziran_Zhu1",
            "~Dailan_He1",
            "~Yanghao_Li2",
            "~Lina_Guo1",
            "~Yuanyuan_Wang3",
            "~Zhe_Wang28",
            "~Hongwei_Qin2",
            "~Yan_Wang12",
            "~Jingjing_Liu2",
            "~Ya-Qin_Zhang1"
        ],
        "keywords": [
            "perceptual image compression",
            "neural image compression"
        ],
        "abstract": "Idempotence is the stability of image codec to re-compression. At the first glance, it is unrelated to perceptual image compression. However, we find that theoretically: 1) Conditional generative model-based perceptual codec satisfies idempotence; 2) Unconditional generative model with idempotence constraint is equivalent to conditional generative codec. Based on this newfound equivalence, we propose a new paradigm of perceptual image codec by inverting unconditional generative model with idempotence constraints. Our codec is theoretically equivalent to conditional generative codec, and it does not require training new models. Instead, it only requires a pre-trained mean-square-error codec and unconditional generative model. Empirically, we show that our proposed approach outperforms state-of-the-art methods such as HiFiC and ILLM, in terms of Fr\u00e9chet Inception Distance (FID). The source code is provided in https://github.com/tongdaxu/Idempotence-and-Perceptual-Image-Compression.",
        "_bibtex": "@inproceedings{\nxu2024idempotence,\ntitle={Idempotence and Perceptual Image Compression},\nauthor={Tongda Xu and Ziran Zhu and Dailan He and Yanghao Li and Lina Guo and Yuanyuan Wang and Zhe Wang and Hongwei Qin and Yan Wang and Jingjing Liu and Ya-Qin Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Cy5v64DqEF}\n}"
    },
    {
        "title": "Forward $\\chi^2$ Divergence Based Variational Importance Sampling",
        "authorids": [
            "~Chengrui_Li1",
            "~Yule_Wang1",
            "~Weihan_Li1",
            "~Anqi_Wu3"
        ],
        "keywords": [
            "Importance sampling",
            "$\\chi^2$ divergence",
            "latent variable models"
        ],
        "abstract": "Maximizing the marginal log-likelihood is a crucial aspect of learning latent variable models, and variational inference (VI) stands as the commonly adopted method. However, VI can encounter challenges in achieving a high marginal log-likelihood when dealing with complicated posterior distributions. In response to this limitation, we introduce a novel variational importance sampling (VIS) approach that directly estimates and maximizes the marginal log-likelihood. VIS leverages the optimal proposal distribution, achieved by minimizing the forward $\\chi^2$ divergence, to enhance marginal log-likelihood estimation. We apply VIS to various popular latent variable models, including mixture models, variational auto-encoders, and partially observable generalized linear models. Results demonstrate that our approach consistently outperforms state-of-the-art baselines, in terms of both log-likelihood and model parameter estimation. Code: \\url{https://github.com/JerrySoybean/vis}.",
        "_bibtex": "@inproceedings{\nli2024forward,\ntitle={Forward \\${\\textbackslash}chi{\\textasciicircum}2\\$ Divergence Based Variational Importance Sampling},\nauthor={Chengrui Li and Yule Wang and Weihan Li and Anqi Wu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=HD5Y7M8Xdk}\n}"
    },
    {
        "title": "Noisy Interpolation Learning with Shallow Univariate ReLU Networks",
        "authorids": [
            "~Nirmit_Joshi1",
            "~Gal_Vardi1",
            "~Nathan_Srebro1"
        ],
        "keywords": [
            "Interpolation Learning",
            "Benign Overfitting",
            "ReLU Networks"
        ],
        "abstract": "Understanding how overparameterized neural networks generalize despite perfect interpolation of noisy training data is a fundamental question. Mallinar et. al. (2022) noted that neural networks seem to often exhibit ``tempered overfitting'', wherein the population risk does not converge to the Bayes optimal error, but neither does it approach infinity, yielding non-trivial generalization. However, this has not been studied rigorously.  We provide the first rigorous analysis of the overfiting behaviour of regression with minimum norm ($\\ell_2$ of weights), focusing on univariate two-layer ReLU networks.  We show overfitting is tempered (with high probability) when measured with respect to the $L_1$ loss, but also show that the situation is more complex than suggested by Mallinar et. al., and overfitting is catastrophic with respect to the $L_2$ loss, or when taking an expectation over the training set.",
        "_bibtex": "@inproceedings{\njoshi2024noisy,\ntitle={Noisy Interpolation Learning with Shallow Univariate Re{LU} Networks},\nauthor={Nirmit Joshi and Gal Vardi and Nathan Srebro},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=GTUoTJXPBf}\n}"
    },
    {
        "title": "Initializing Models with Larger Ones",
        "authorids": [
            "~Zhiqiu_Xu1",
            "~Yanjie_Chen2",
            "~Kirill_Vishniakov1",
            "~Yida_Yin1",
            "~Zhiqiang_Shen1",
            "~Trevor_Darrell2",
            "~Lingjie_Liu1",
            "~Zhuang_Liu1"
        ],
        "keywords": [
            "Deep Learning",
            "Neural Networks",
            "Weight Initialization",
            "Small Models",
            "Computer Vision"
        ],
        "abstract": "Weight initialization plays an important role in neural network training. Widely used initialization methods are proposed and evaluated for networks that are trained from scratch. However, the growing number of pretrained models now offers new opportunities for tackling this classical problem of weight initialization. In this work, we introduce weight selection, a method for initializing smaller models by selecting a subset of weights from a pretrained larger model. This enables the transfer of knowledge from pretrained weights to smaller models. Our experiments demonstrate that weight selection can significantly enhance the performance of small models and reduce their training time.  Notably, it can also be used together with knowledge distillation. Weight selection offers a new approach to leverage the power of pretrained models in resource-constrained settings, and we hope it can be a useful tool for training small models in the large-model era.",
        "_bibtex": "@inproceedings{\nxu2024initializing,\ntitle={Initializing Models with Larger Ones},\nauthor={Zhiqiu Xu and Yanjie Chen and Kirill Vishniakov and Yida Yin and Zhiqiang Shen and Trevor Darrell and Lingjie Liu and Zhuang Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=dyrGMhicMw}\n}"
    },
    {
        "title": "DMV3D: Denoising Multi-view Diffusion Using 3D Large Reconstruction Model",
        "authorids": [
            "~Yinghao_Xu1",
            "~Hao_Tan1",
            "~Fujun_Luan2",
            "~Sai_Bi1",
            "~Peng_Wang17",
            "~Jiahao_Li2",
            "~Zifan_Shi2",
            "~Kalyan_Sunkavalli1",
            "~Gordon_Wetzstein3",
            "~Zexiang_Xu1",
            "~Kai_Zhang7"
        ],
        "keywords": [
            "3D Generation; Single-view 3D Reconstruction; text-to-3D"
        ],
        "abstract": "We propose DMV3D, a novel 3D generation approach that uses a transformer-based 3D large reconstruction model to denoise multi-view diffusion. Our reconstruction model incorporates a triplane NeRF representation and, functioning as a denoiser, can denoise noisy multi-view images via 3D NeRF reconstruction and rendering, achieving single-stage 3D generation in the 2D diffusion denoising process. We train DMV3D on large-scale multi-view image datasets of extremely diverse objects using only image reconstruction losses, without accessing 3D assets. We demonstrate state-of-the-art results for the single-image reconstruction problem where probabilistic modeling of unseen object parts is required for generating diverse reconstructions with sharp textures. We also show high-quality text-to-3D generation results outperforming previous 3D diffusion models. Our project website is at: https://dmv3d.github.io/.",
        "_bibtex": "@inproceedings{\nxu2024dmvd,\ntitle={{DMV}3D: Denoising Multi-view Diffusion Using 3D Large Reconstruction Model},\nauthor={Yinghao Xu and Hao Tan and Fujun Luan and Sai Bi and Peng Wang and Jiahao Li and Zifan Shi and Kalyan Sunkavalli and Gordon Wetzstein and Zexiang Xu and Kai Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=H4yQefeXhp}\n}"
    },
    {
        "title": "Influencer Backdoor Attack on Semantic Segmentation",
        "authorids": [
            "~Haoheng_Lan2",
            "~Jindong_Gu1",
            "~Philip_Torr1",
            "~Hengshuang_Zhao2"
        ],
        "keywords": [
            "Semantic Segmentation",
            "Backdoor Attack"
        ],
        "abstract": "When a small number of poisoned samples are injected into the training dataset of a deep neural network, the network can be induced to exhibit malicious behavior during inferences, which poses potential threats to real-world applications. While they have been intensively studied in classification, backdoor attacks on semantic segmentation have been largely overlooked. Unlike classification, semantic segmentation aims to classify every pixel within a given image. In this work, we explore backdoor attacks on segmentation models to misclassify all pixels of a victim class by injecting a specific trigger on non-victim pixels during inferences, which is dubbed Influencer Backdoor Attack (IBA). IBA is expected to maintain the classification accuracy of non-victim pixels and mislead classifications of all victim pixels in every single inference and could be easily applied to real-world scenes. Based on the context aggregation ability of segmentation models, we proposed a simple, yet effective, Nearest-Neighbor trigger injection strategy. We also introduce an innovative Pixel Random Labeling strategy which maintains optimal performance even when the trigger is placed far from the victim pixels. Our extensive experiments reveal that current segmentation models do suffer from backdoor attacks, demonstrate IBA real-world applicability, and show that our proposed techniques can further increase attack performance.",
        "_bibtex": "@inproceedings{\nlan2024influencer,\ntitle={Influencer Backdoor Attack on Semantic Segmentation},\nauthor={Haoheng Lan and Jindong Gu and Philip Torr and Hengshuang Zhao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=VmGRoNDQgJ}\n}"
    },
    {
        "title": "PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape Prediction",
        "authorids": [
            "~Peng_Wang17",
            "~Hao_Tan1",
            "~Sai_Bi1",
            "~Yinghao_Xu1",
            "~Fujun_Luan2",
            "~Kalyan_Sunkavalli1",
            "~Wenping_Wang1",
            "~Zexiang_Xu1",
            "~Kai_Zhang7"
        ],
        "keywords": [
            "Pose estimation",
            "NeRF",
            "3D Reconstruction",
            "Transformer"
        ],
        "abstract": "We propose a Pose-Free Large Reconstruction Model (PF-LRM) for reconstructing a 3D object from a few unposed images even with little visual overlap, while simultaneously estimating the relative camera poses in ~1.3 seconds on a single A100 GPU. PF-LRM is a highly scalable method utilizing self-attention blocks to exchange information between 3D object tokens and 2D image tokens; we predict a coarse point cloud for each view, and then use a differentiable Perspective-n-Point (PnP) solver to obtain camera poses. When trained on a huge amount of multi-view posed data of ~1M objects, PF-LRM shows strong cross-dataset generalization ability, and outperforms baseline methods by a large margin in terms of pose prediction accuracy and 3D reconstruction quality on various unseen evaluation datasets. We also demonstrate our model's applicability in downstream text/image-to-3D task with fast feed-forward inference. Our project website is at: https://totoro97.github.io/pf-lrm.",
        "_bibtex": "@inproceedings{\nwang2024pflrm,\ntitle={{PF}-{LRM}: Pose-Free Large Reconstruction Model for Joint Pose and Shape Prediction},\nauthor={Peng Wang and Hao Tan and Sai Bi and Yinghao Xu and Fujun Luan and Kalyan Sunkavalli and Wenping Wang and Zexiang Xu and Kai Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=noe76eRcPC}\n}"
    },
    {
        "title": "Procedural Fairness Through Decoupling Objectionable Data Generating Components",
        "authorids": [
            "~Zeyu_Tang1",
            "~Jialu_Wang1",
            "~Yang_Liu3",
            "~Peter_Spirtes1",
            "~Kun_Zhang1"
        ],
        "keywords": [
            "Procedural Fairness",
            "Decouple Objectionable Component",
            "Reference Point",
            "Causal Fairness",
            "Data Generating Process",
            "Bias Mitigation"
        ],
        "abstract": "We reveal and address the frequently overlooked yet important issue of _disguised procedural unfairness_, namely, the potentially inadvertent alterations on the behavior of neutral (i.e., not problematic) aspects of data generating process, and/or the lack of procedural assurance of the greatest benefit of the least advantaged individuals. Inspired by John Rawls's advocacy for _pure procedural justice_ (Rawls, 1971; 2001), we view automated decision-making as a microcosm of social institutions, and consider how the data generating process itself can satisfy the requirements of procedural fairness. We propose a framework that decouples the objectionable data generating components from the neutral ones by utilizing reference points and the associated value instantiation rule. Our findings highlight the necessity of preventing _disguised procedural unfairness_, drawing attention not only to the objectionable data generating components that we aim to mitigate, but also more importantly, to the neutral components that we intend to keep unaffected.",
        "_bibtex": "@inproceedings{\ntang2024procedural,\ntitle={Procedural Fairness Through Decoupling Objectionable Data Generating Components},\nauthor={Zeyu Tang and Jialu Wang and Yang Liu and Peter Spirtes and Kun Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=cxfPefbu1s}\n}"
    },
    {
        "title": "Vision-Language Foundation Models as Effective Robot Imitators",
        "authorids": [
            "~Xinghang_Li1",
            "~Minghuan_Liu1",
            "~Hanbo_Zhang1",
            "~Cunjun_Yu1",
            "~Jie_Xu17",
            "~Hongtao_Wu2",
            "~Chilam_Cheang1",
            "~Ya_Jing2",
            "~Weinan_Zhang1",
            "~Huaping_Liu3",
            "~Hang_Li4",
            "~Tao_Kong3"
        ],
        "keywords": [
            "Large Visual Language Model",
            "Robotics",
            "Imitation Learning"
        ],
        "abstract": "Recent progress in vision language foundation models has shown their ability to understand multimodal data and resolve complicated vision language tasks, including robotics manipulation. We seek a straightforward way of making use of existing vision-language models (VLMs) with simple fine-tuning on robotics data.\nTo this end, we derive a simple and novel vision-language manipulation framework, dubbed RoboFlamingo, built upon the open-source VLMs, OpenFlamingo. Unlike prior works, RoboFlamingo utilizes pre-trained VLMs for single-step vision-language comprehension, models sequential history information with an explicit policy head, and is slightly fine-tuned by imitation learning only on language-conditioned manipulation datasets. Such a decomposition provides RoboFlamingo the flexibility for open-loop control and deployment on low-performance platforms. By exceeding the state-of-the-art performance with a large margin on the tested benchmark, we show RoboFlamingo can be an effective and competitive alternative to adapt VLMs to robot control.\nOur extensive experimental results also reveal several interesting conclusions regarding the behavior of different pre-trained VLMs on manipulation tasks. We believe RoboFlamingo has the potential to be a cost-effective and easy-to-use solution for robotics manipulation, empowering everyone with the ability to fine-tune their own robotics policy. Our code will be made public upon acceptance.",
        "_bibtex": "@inproceedings{\nli2024visionlanguage,\ntitle={Vision-Language Foundation Models as Effective Robot Imitators},\nauthor={Xinghang Li and Minghuan Liu and Hanbo Zhang and Cunjun Yu and Jie Xu and Hongtao Wu and Chilam Cheang and Ya Jing and Weinan Zhang and Huaping Liu and Hang Li and Tao Kong},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=lFYj0oibGR}\n}"
    },
    {
        "title": "OctoPack: Instruction Tuning Code Large Language Models",
        "authorids": [
            "~Niklas_Muennighoff1",
            "~Qian_Liu2",
            "~Armel_Randy_Zebaze1",
            "~Qinkai_Zheng2",
            "~Binyuan_Hui1",
            "~Terry_Yue_Zhuo1",
            "~Swayam_Singh1",
            "~Xiangru_Tang2",
            "~Leandro_Von_Werra1",
            "~Shayne_Longpre1"
        ],
        "keywords": [
            "large language models",
            "large code models",
            "instruction tuning"
        ],
        "abstract": "Finetuning large language models (LLMs) on instructions leads to vast performance improvements on natural language tasks. We apply instruction tuning using code, leveraging the natural structure of Git commits, which pair code changes with human instructions. We compile CommitPack: 4 terabytes of Git commits across 350 programming languages. We benchmark CommitPack against other natural and synthetic code instructions (xP3x, Self-Instruct, OASST) on the 16B parameter StarCoder model, and achieve state-of-the-art performance among models not trained on OpenAI outputs, on the HumanEval Python benchmark (46.2% pass@1). We further introduce HumanEvalPack, expanding the HumanEval benchmark to a total of 3 coding tasks (Code Repair, Code Explanation, Code Synthesis) across 6 languages (Python, JavaScript, Java, Go, C++, Rust). Our models, OctoCoder and OctoGeeX, achieve the best performance across HumanEvalPack among all permissive models, demonstrating CommitPack's benefits in generalizing to a wider set of languages and natural coding tasks. Code, models and data are freely available at https://github.com/bigcode-project/octopack.",
        "_bibtex": "@inproceedings{\nmuennighoff2024octopack,\ntitle={OctoPack: Instruction Tuning Code Large Language Models},\nauthor={Niklas Muennighoff and Qian Liu and Armel Randy Zebaze and Qinkai Zheng and Binyuan Hui and Terry Yue Zhuo and Swayam Singh and Xiangru Tang and Leandro Von Werra and Shayne Longpre},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=mw1PWNSWZP}\n}"
    },
    {
        "title": "Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision",
        "authorids": [
            "~Haoning_Wu1",
            "~Zicheng_Zhang7",
            "~Erli_Zhang1",
            "~Chaofeng_Chen1",
            "~Liang_Liao3",
            "~Annan_Wang1",
            "~Chunyi_Li1",
            "~Wenxiu_Sun1",
            "~Qiong_Yan1",
            "~Guangtao_Zhai1",
            "~Weisi_Lin1"
        ],
        "keywords": [
            "Benchmark",
            "Vision-Language",
            "Large Language Models",
            "Low-level Vision",
            "Image Quality Assessment"
        ],
        "abstract": "The rapid evolution of Multi-modality Large Language Models (MLLMs) has catalyzed a shift in computer vision from specialized models to general-purpose foundation models. Nevertheless, there is still an inadequacy in assessing the abilities of MLLMs on **low-level visual perception and understanding**. To address this gap, we present **Q-Bench**, a holistic benchmark crafted to systematically evaluate potential abilities of MLLMs on three realms: low-level visual perception, low-level visual description, and overall visual quality assessment. **_a)_** To evaluate the low-level **_perception_** ability, we construct the **LLVisionQA** dataset, consisting of 2,990 diverse-sourced images, each equipped with a human-asked question focusing on its low-level attributes. We then measure the correctness of MLLMs on answering these questions. **_b)_** To examine the **_description_** ability of MLLMs on low-level information, we propose the **LLDescribe** dataset consisting of long expert-labelled *golden* low-level text descriptions on 499 images, and a GPT-involved comparison pipeline between outputs of MLLMs and the *golden* descriptions. **_c)_** Besides these two tasks, we further measure their visual quality **_assessment_** ability to align with human opinion scores. Specifically, we design a softmax-based strategy that enables MLLMs to predict *quantifiable* quality scores, and evaluate them on various existing image quality assessment (IQA) datasets. Our evaluation across the three abilities confirms that MLLMs possess preliminary low-level visual skills. However, these skills are still unstable and relatively imprecise, indicating the need for specific enhancements on MLLMs towards these abilities. We hope that our benchmark can encourage the research community to delve deeper to discover and enhance these untapped potentials of MLLMs.",
        "_bibtex": "@inproceedings{\nwu2024qbench,\ntitle={Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision},\nauthor={Haoning Wu and Zicheng Zhang and Erli Zhang and Chaofeng Chen and Liang Liao and Annan Wang and Chunyi Li and Wenxiu Sun and Qiong Yan and Guangtao Zhai and Weisi Lin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=0V5TVt9bk0}\n}"
    },
    {
        "title": "iTransformer: Inverted Transformers Are Effective for Time Series Forecasting",
        "authorids": [
            "~Yong_Liu15",
            "~Tengge_Hu1",
            "~Haoran_Zhang9",
            "~Haixu_Wu1",
            "~Shiyu_Wang3",
            "~Lintao_Ma1",
            "~Mingsheng_Long5"
        ],
        "keywords": [
            "Time Series Forecasting",
            "Transformer"
        ],
        "abstract": "The recent boom of linear forecasting models questions the ongoing passion for architectural modifications of Transformer-based forecasters. These forecasters leverage Transformers to model the global dependencies over temporal tokens of time series, with each token formed by multiple variates of the same timestamp. However, Transformers are challenged in forecasting series with larger lookback windows due to performance degradation and computation explosion. Besides, the embedding for each temporal token fuses multiple variates that represent potential delayed events and distinct physical measurements, which may fail in learning variate-centric representations and result in meaningless attention maps. In this work, we reflect on the competent duties of Transformer components and repurpose the Transformer architecture without any modification to the basic components. We propose iTransformer that simply applies the attention and feed-forward network on the inverted dimensions. Specifically, the time points of individual series are embedded into variate tokens which are utilized by the attention mechanism to capture multivariate correlations; meanwhile, the feed-forward network is applied for each variate token to learn nonlinear representations. The iTransformer model achieves state-of-the-art on challenging real-world datasets, which further empowers the Transformer family with promoted performance, generalization ability across different variates, and better utilization of arbitrary lookback windows, making it a nice alternative as the fundamental backbone of time series forecasting. Code is available at this repository: https://github.com/thuml/iTransformer.",
        "_bibtex": "@inproceedings{\nliu2024itransformer,\ntitle={iTransformer: Inverted Transformers Are Effective for Time Series Forecasting},\nauthor={Yong Liu and Tengge Hu and Haoran Zhang and Haixu Wu and Shiyu Wang and Lintao Ma and Mingsheng Long},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=JePfAI8fah}\n}"
    },
    {
        "title": "De novo Protein Design Using Geometric Vector Field Networks",
        "authorids": [
            "~Weian_Mao2",
            "~Muzhi_Zhu1",
            "~Zheng_Sun7",
            "~Shuaike_Shen1",
            "~Lin_Yuanbo_Wu1",
            "~Hao_Chen17",
            "~Chunhua_Shen2"
        ],
        "keywords": [
            "Protein design",
            "Protein structure encoder",
            "Inverse folding",
            "Protein diffusion"
        ],
        "abstract": "Advances like protein diffusion have marked revolutionary progress in $\\textit{de novo}$ protein design, a central topic in life science. These methods typically depend on protein structure encoders to model residue backbone frames, where atoms do not exist. Most prior encoders rely on atom-wise features, such as angles and distances between atoms, which are not available in this context. Only a few basic encoders, like IPA, have been proposed for this scenario, exposing the frame modeling as a bottleneck. In this work, we introduce the Vector Field Network (VFN), that enables network layers to perform learnable vector computations between coordinates of frame-anchored virtual atoms, thus achieving a higher capability for modeling frames. The vector computation operates in a manner similar to a linear layer, with each input channel receiving 3D virtual atom coordinates instead of scalar values. The multiple feature vectors output by the vector computation are then used to update the residue representations and virtual atom coordinates via attention aggregation. Remarkably, VFN also excels in modeling both frames and atoms, as the real atoms can be treated as the virtual atoms for modeling, positioning VFN as a potential $\\textit{universal encoder}$. In protein diffusion (frame modeling), VFN exhibits a impressive performance advantage over IPA, excelling in terms of both designability ($\\textbf{67.04}$\\% vs. 53.58\\%) and diversity ($\\textbf{66.54}$\\% vs. 51.98\\%). In inverse folding(frame and atom modeling), VFN outperforms the previous SoTA model, PiFold ($\\textbf{54.7}$\\% vs. 51.66\\%), on sequence recovery rate; we also propose a method of equipping VFN with the ESM model, which significantly surpasses the previous ESM-based SoTA ($\\textbf{62.67}$\\% vs. 55.65\\%), LM-Design, by a substantial margin. Code is available at https://github.com/aim-uofa/VFN",
        "_bibtex": "@inproceedings{\nmao2024de,\ntitle={De novo Protein Design Using Geometric Vector Field Networks},\nauthor={Weian Mao and Muzhi Zhu and Zheng Sun and Shuaike Shen and Lin Yuanbo Wu and Hao Chen and Chunhua Shen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=9UIGyJJpay}\n}"
    },
    {
        "title": "Prompt Gradient Projection for Continual Learning",
        "authorids": [
            "~Jingyang_Qiao1",
            "~zhizhong_zhang1",
            "~Xin_Tan2",
            "~Chengwei_Chen2",
            "~Yanyun_Qu1",
            "~Yong_Peng4",
            "~Yuan_Xie5"
        ],
        "keywords": [
            "Continual Learning",
            "Prompt Tuning",
            "Gradient Projection",
            "Anti-forgetting"
        ],
        "abstract": "Prompt-tuning has demonstrated impressive performance in continual learning by querying relevant prompts for each input instance, which can avoid the introduction of task identifier. Its forgetting is therefore reduced as this instance-wise query mechanism enables us to select and update only relevant prompts. In this paper, we further integrate prompt-tuning with gradient projection approach. Our observation is: prompt-tuning releases the necessity of task identifier for gradient projection method; and gradient projection provides theoretical guarantees against forgetting for prompt-tuning. This inspires a new prompt gradient projection approach (PGP) for continual learning. In PGP, we deduce that reaching the orthogonal condition for prompt gradient can effectively prevent forgetting via the self-attention mechanism in vision-transformer. The condition equations are then realized by conducting Singular Value Decomposition (SVD) on an element-wise sum space between input space and prompt space. We validate our method on diverse datasets and experiments demonstrate the efficiency of reducing forgetting both in class incremental, online class incremental, and task incremental settings. The code is available at https://github.com/JingyangQiao/prompt-gradient-projection.",
        "_bibtex": "@inproceedings{\nqiao2024prompt,\ntitle={Prompt Gradient Projection for Continual Learning},\nauthor={Jingyang Qiao and zhizhong zhang and Xin Tan and Chengwei Chen and Yanyun Qu and Yong Peng and Yuan Xie},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=EH2O3h7sBI}\n}"
    },
    {
        "title": "R-EDL: Relaxing Nonessential Settings of Evidential Deep Learning",
        "authorids": [
            "~Mengyuan_Chen1",
            "~Junyu_Gao1",
            "~Changsheng_Xu1"
        ],
        "keywords": [
            "uncertainty quantification",
            "evidential deep learning",
            "subjective logic",
            "single-forward-pass uncertainty method"
        ],
        "abstract": "A newly-arising uncertainty estimation method named Evidential Deep Learning (EDL), which can obtain reliable predictive uncertainty in a single forward pass, has garnered increasing interest. Guided by the subjective logic theory, EDL obtains Dirichlet concentration parameters from deep neural networks, thus constructing a Dirichlet probability density function (PDF) to model the distribution of class probabilities. Despite its great success, we argue that EDL keeps nonessential settings in both stages of model construction and optimization.\nIn this work, our analysis indicates that (1) in the construction of the Dirichlet PDF, a commonly ignored parameter termed prior weight governs the balance between leveraging the proportion of evidence and its magnitude in deriving predictive scores, and (2) in model optimization, a variance-minimized regularization term adopted by traditional EDL encourages the Dirichlet PDF to approach a Dirac delta function, potentially exacerbating overconfidence. Therefore, we propose the R-EDL (Relaxed-EDL) method by relaxing these nonessential settings. Specifically, R-EDL treats the prior weight as an adjustable hyper-parameter instead of a fixed scalar, and directly optimizes the expectation of the Dirichlet PDF provided to deprecate the variance-minimized regularization term. Extensive experiments and SOTA performances demonstrate the effectiveness of our method. Source codes are provided in Appendix E.",
        "_bibtex": "@inproceedings{\nchen2024redl,\ntitle={R-{EDL}: Relaxing Nonessential Settings of Evidential Deep Learning},\nauthor={Mengyuan Chen and Junyu Gao and Changsheng Xu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Si3YFA641c}\n}"
    },
    {
        "title": "Neuron Activation Coverage: Rethinking Out-of-distribution Detection and Generalization",
        "authorids": [
            "~Yibing_Liu1",
            "~Chris_XING_TIAN1",
            "~Haoliang_Li2",
            "~Lei_Ma1",
            "~Shiqi_Wang1"
        ],
        "keywords": [
            "Out-of-distribution",
            "Generalization",
            "Neuron Activation"
        ],
        "abstract": "The out-of-distribution (OOD) problem generally arises when neural networks encounter data that significantly deviates from the training data distribution, i.e., in-distribution (InD). In this paper, we study the OOD problem from a neuron activation view. We first formulate neuron activation states by considering both the neuron output and its influence on model decisions. Then, to characterize the relationship between neurons and OOD issues, we introduce the *neuron activation coverage* (NAC) -- a simple measure for neuron behaviors under InD data. Leveraging our NAC, we show that 1) InD and OOD inputs can be largely separated based on the neuron behavior, which significantly eases the OOD detection problem and beats the 21 previous methods over three benchmarks (CIFAR-10, CIFAR-100, and ImageNet-1K). 2) a positive correlation between NAC and model generalization ability consistently holds across architectures and datasets, which enables a NAC-based criterion for evaluating model robustness. Compared to prevalent InD validation criteria, we show that NAC not only can select more robust models, but also has a stronger correlation with OOD test performance.",
        "_bibtex": "@inproceedings{\nliu2024neuron,\ntitle={Neuron Activation Coverage: Rethinking Out-of-distribution Detection and Generalization},\nauthor={Yibing Liu and Chris XING TIAN and Haoliang Li and Lei Ma and Shiqi Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=SNGXbZtK6Q}\n}"
    },
    {
        "title": "ResFields: Residual Neural Fields for Spatiotemporal Signals",
        "authorids": [
            "~Marko_Mihajlovic1",
            "~Sergey_Prokudin1",
            "~Marc_Pollefeys2",
            "~Siyu_Tang1"
        ],
        "keywords": [
            "neural fields",
            "NeRF",
            "reconstruction"
        ],
        "abstract": "Neural fields, a category of neural networks trained to represent high-frequency signals, have gained significant attention in recent years due to their impressive performance in modeling complex 3D data, such as signed distance (SDFs) or radiance fields (NeRFs), via a single multi-layer perceptron (MLP). However, despite the power and simplicity of representing signals with an MLP, these methods still face challenges when modeling large and complex temporal signals due to the limited capacity of MLPs. In this paper, we propose an effective approach to address this limitation by incorporating temporal residual layers into neural fields, dubbed ResFields. It is a novel class of networks specifically designed to effectively represent complex temporal signals. We conduct a comprehensive analysis of the properties of ResFields and propose a matrix factorization technique to reduce the number of trainable parameters and enhance generalization capabilities. Importantly, our formulation seamlessly integrates with existing MLP-based neural fields and consistently improves results across various challenging tasks: 2D video approximation, dynamic shape modeling via temporal SDFs, and dynamic NeRF reconstruction. Lastly, we demonstrate the practical utility of ResFields by showcasing its effectiveness in capturing dynamic 3D scenes from sparse RGBD cameras of a lightweight capture system.",
        "_bibtex": "@inproceedings{\nmihajlovic2024resfields,\ntitle={ResFields: Residual Neural Fields for Spatiotemporal Signals},\nauthor={Marko Mihajlovic and Sergey Prokudin and Marc Pollefeys and Siyu Tang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=EHrvRNs2Y0}\n}"
    },
    {
        "title": "TD-MPC2: Scalable, Robust World Models for Continuous Control",
        "authorids": [
            "~Nicklas_Hansen1",
            "~Hao_Su1",
            "~Xiaolong_Wang3"
        ],
        "keywords": [
            "reinforcement learning",
            "model-based reinforcement learning",
            "world models"
        ],
        "abstract": "TD-MPC is a model-based reinforcement learning (RL) algorithm that performs local trajectory optimization in the latent space of a learned implicit (decoder-free) world model. In this work, we present TD-MPC2: a series of improvements upon the TD-MPC algorithm. We demonstrate that TD-MPC2 improves significantly over baselines across 104 online RL tasks spanning 4 diverse task domains, achieving consistently strong results with a single set of hyperparameters. We further show that agent capabilities increase with model and data size, and successfully train a single 317M parameter agent to perform 80 tasks across multiple task domains, embodiments, and action spaces. We conclude with an account of lessons, opportunities, and risks associated with large TD-MPC2 agents.\n\nExplore videos, models, data, code, and more at https://tdmpc2.com",
        "_bibtex": "@inproceedings{\nhansen2024tdmpc,\ntitle={{TD}-{MPC}2: Scalable, Robust World Models for Continuous Control},\nauthor={Nicklas Hansen and Hao Su and Xiaolong Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Oxh5CstDJU}\n}"
    },
    {
        "title": "Stochastic Controlled Averaging for Federated Learning with Communication Compression",
        "authorids": [
            "~Xinmeng_Huang1",
            "~Ping_Li3",
            "~Xiaoyun_Li2"
        ],
        "keywords": [
            "federated learning",
            "communication compression",
            "data heterogeneity",
            "controlled averaging"
        ],
        "abstract": "Communication compression has been an important topic in Federated Learning (FL) for alleviating the communication overhead. However, communication compression brings forth new challenges in FL due to the interplay of compression-incurred information distortion and inherent characteristics of FL such as partial participation and data heterogeneity. Despite the recent development, the existing approaches either cannot accommodate arbitrary data heterogeneity or partial participation, or require stringent conditions on compression. In this paper, we revisit the seminal stochastic controlled averaging method by proposing an equivalent but more efficient/simplified formulation with halved uplink communication costs, building upon which we propose two compressed FL algorithms, SCALLION and  SCAFCOM, to support unbiased and biased compression, respectively. Both the proposed methods outperform the existing compressed FL methods in terms of communication and computation complexities. Moreover,SCALLION and SCAFCOM attain fast convergence rates under arbitrary data heterogeneity without any additional assumptions on compression errors. Experiments show that \\scallion and  \\scafcom outperform recent compressed FL methods under the same communication budget.",
        "_bibtex": "@inproceedings{\nhuang2024stochastic,\ntitle={Stochastic Controlled Averaging for Federated Learning with Communication Compression},\nauthor={Xinmeng Huang and Ping Li and Xiaoyun Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=jj5ZjZsWJe}\n}"
    },
    {
        "title": "AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning",
        "authorids": [
            "~Yuwei_Guo1",
            "~Ceyuan_Yang2",
            "~Anyi_Rao2",
            "~Zhengyang_Liang2",
            "~Yaohui_Wang1",
            "~Yu_Qiao1",
            "~Maneesh_Agrawala2",
            "~Dahua_Lin1",
            "~Bo_Dai2"
        ],
        "keywords": [
            "Deep Learning",
            "Diffusion Model",
            "Video Generation"
        ],
        "abstract": "With the advance of text-to-image (T2I) diffusion models (e.g., Stable Diffusion) and corresponding personalization techniques such as DreamBooth and LoRA, everyone can manifest their imagination into high-quality images at an affordable cost. However, adding motion dynamics to existing high-quality personalized T2Is and enabling them to generate animations remains an open challenge. In this paper, we present AnimateDiff, a practical framework for animating personalized T2I models without requiring model-specific tuning. At the core of our framework is a plug-and-play motion module that can be trained once and seamlessly integrated into any personalized T2Is originating from the same base T2I. Through our proposed training strategy, the motion module effectively learns transferable motion priors from real-world videos. Once trained, the motion module can be inserted into a personalized T2I model to form a personalized animation generator. We further propose MotionLoRA, a lightweight fine-tuning technique for AnimateDiff that enables a pre-trained motion module to adapt to new motion patterns, such as different shot types, at a low training and data collection cost. We evaluate AnimateDiff and MotionLoRA on several public representative personalized T2I models collected from the community. The results demonstrate that our approaches help these models generate temporally smooth animation clips while preserving the visual quality and motion diversity. Codes and pre-trained weights are available at https://github.com/guoyww/AnimateDiff.",
        "_bibtex": "@inproceedings{\nguo2024animatediff,\ntitle={AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning},\nauthor={Yuwei Guo and Ceyuan Yang and Anyi Rao and Zhengyang Liang and Yaohui Wang and Yu Qiao and Maneesh Agrawala and Dahua Lin and Bo Dai},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Fx2SbBgcte}\n}"
    },
    {
        "title": "Guiding Instruction-based Image Editing via Multimodal Large Language Models",
        "authorids": [
            "~Tsu-Jui_Fu2",
            "~Wenze_Hu4",
            "~Xianzhi_Du4",
            "~William_Yang_Wang2",
            "~Yinfei_Yang1",
            "~Zhe_Gan1"
        ],
        "keywords": [
            "image editing",
            "multimodal large language model"
        ],
        "abstract": "Instruction-based image editing improves the controllability and flexibility of image manipulation via natural commands without elaborate descriptions or regional masks. However, human instructions are sometimes too brief for current methods to capture and follow. Multimodal large language models (MLLMs) show promising capabilities in cross-modal understanding and visual-aware response generation via LMs. We investigate how MLLMs facilitate edit instructions and present MLLM-Guided Image Editing (MGIE). MGIE learns to derive expressive instructions and provides explicit guidance. The editing model jointly captures this visual imagination and performs manipulation through end-to-end training. We evaluate various aspects of Photoshop-style modification, global photo optimization, and local editing. Extensive experimental results demonstrate that expressive instructions are crucial to instruction-based image editing, and our MGIE can lead to a notable improvement in automatic metrics and human evaluation while maintaining competitive inference efficiency.",
        "_bibtex": "@inproceedings{\nfu2024guiding,\ntitle={Guiding Instruction-based Image Editing via Multimodal Large Language Models},\nauthor={Tsu-Jui Fu and Wenze Hu and Xianzhi Du and William Yang Wang and Yinfei Yang and Zhe Gan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=S1RKWSyZ2Y}\n}"
    },
    {
        "title": "Tuning LayerNorm in Attention: Towards Efficient Multi-Modal LLM Finetuning",
        "authorids": [
            "~Bingchen_Zhao1",
            "~Haoqin_Tu1",
            "~Chen_Wei2",
            "~Jieru_Mei2",
            "~Cihang_Xie3"
        ],
        "keywords": [
            "multi-modality; large language models; generation; model efficiency;"
        ],
        "abstract": "This paper introduces an efficient strategy to transform Large Language Models (LLMs) into Multi-Modal Large Language Models. \nBy conceptualizing this transformation as a domain adaptation process, \\ie, transitioning from text understanding to embracing multiple modalities, we intriguingly note that, within each attention block, tuning LayerNorm suffices to yield strong performance. \nMoreover, when benchmarked against other tuning approaches like full parameter finetuning or LoRA, its benefits on efficiency are substantial.\nFor example, when compared to LoRA on a 13B model scale, performance can be enhanced by an average of over 20\\% across five multi-modal tasks, and meanwhile, \nresults in a significant reduction of trainable parameters by 41.9\\% and a decrease in GPU memory usage by 17.6\\%. On top of this LayerNorm strategy, we showcase that selectively tuning only with conversational data can improve efficiency further. \nBeyond these empirical outcomes, we provide a comprehensive analysis to explore the role of LayerNorm in adapting LLMs to the multi-modal domain and improving the expressive power of the model.",
        "_bibtex": "@inproceedings{\nzhao2024tuning,\ntitle={Tuning LayerNorm in Attention: Towards Efficient Multi-Modal {LLM} Finetuning},\nauthor={Bingchen Zhao and Haoqin Tu and Chen Wei and Jieru Mei and Cihang Xie},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=YR3ETaElNK}\n}"
    },
    {
        "title": "Universal Humanoid Motion Representations for Physics-Based Control",
        "authorids": [
            "~Zhengyi_Luo1",
            "~Jinkun_Cao1",
            "~Josh_Merel1",
            "~Alexander_Winkler1",
            "~Jing_Huang1",
            "~Kris_M._Kitani1",
            "~Weipeng_Xu1"
        ],
        "keywords": [
            "humanoid control",
            "motion generation",
            "physics simulation"
        ],
        "abstract": "We present a universal motion representation that encompasses a comprehensive range of motor skills for physics-based humanoid control. Due to the high dimensionality of humanoids and the inherent difficulties in reinforcement learning, prior methods have focused on learning skill embeddings for a narrow range of movement styles (e.g. locomotion, game characters) from specialized motion datasets. This limited scope hampers their applicability in complex tasks. We close this gap by significantly increasing the coverage of our motion representation space. To achieve this, we first learn a motion imitator that can imitate all of human motion from a large, unstructured motion dataset. We then create our motion representation by distilling skills directly from the imitator. This is achieved by using an encoder-decoder structure with a variational information bottleneck. Additionally, we jointly learn a prior conditioned on proprioception (humanoid's own pose and velocities) to improve model expressiveness and sampling efficiency for downstream tasks. By sampling from the prior, we can generate long, stable, and diverse human motions. Using this latent space for hierarchical RL, we show that our policies solve tasks using human-like behavior. We demonstrate the effectiveness of our motion representation by solving generative tasks (e.g. strike, terrain traversal) and motion tracking using VR controllers.",
        "_bibtex": "@inproceedings{\nluo2024universal,\ntitle={Universal Humanoid Motion Representations for Physics-Based Control},\nauthor={Zhengyi Luo and Jinkun Cao and Josh Merel and Alexander Winkler and Jing Huang and Kris M. Kitani and Weipeng Xu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=OrOd8PxOO2}\n}"
    },
    {
        "title": "Adaptive Rational Activations to Boost Deep Reinforcement Learning",
        "authorids": [
            "~Quentin_Delfosse1",
            "~Patrick_Schramowski1",
            "~Martin_Mundt1",
            "~Alejandro_Molina1",
            "~Kristian_Kersting1"
        ],
        "keywords": [
            "Deep Reinforcement Learning",
            "Neural Plasticity",
            "Activation Functions",
            "Rational Functions"
        ],
        "abstract": "Latest insights from biology show that intelligence not only emerges from the connections between neurons, but that individual neurons shoulder more computational responsibility than previously anticipated. Specifically, neural plasticity should be critical in the context of constantly changing reinforcement learning (RL) environments, yet current approaches still primarily employ static activation functions. In this work, we motivate the use of adaptable activation functions in RL and show that rational activation functions are particularly suitable for augmenting plasticity. Inspired by residual networks, we derive a condition under which rational units are closed under residual connections and formulate a naturally regularised version. The proposed joint-rational activation allows for desirable degrees of flexibility, yet regularises plasticity to an extent that avoids overfitting by leveraging a mutual set of activation function parameters across layers. We demonstrate that equipping popular algorithms with (joint) rational activations leads to consistent improvements on different games from the Atari Learning Environment benchmark, notably making DQN competitive to DDQN and Rainbow.",
        "_bibtex": "@inproceedings{\ndelfosse2024adaptive,\ntitle={Adaptive Rational Activations to Boost Deep Reinforcement Learning},\nauthor={Quentin Delfosse and Patrick Schramowski and Martin Mundt and Alejandro Molina and Kristian Kersting},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=g90ysX1sVs}\n}"
    },
    {
        "title": "Learning No-Regret Sparse Generalized Linear Models with Varying Observation(s)",
        "authorids": [
            "~Diyang_Li1",
            "~Charles_Ling1",
            "~zhiqiang_xu1",
            "~Huan_Xiong1",
            "~Bin_Gu1"
        ],
        "keywords": [
            "Generalized Linear Models",
            "Learning with Varying Data",
            "Differential Equations"
        ],
        "abstract": "Generalized Linear Models (GLMs) encompass a wide array of regression and classification models, where prediction is a function of a linear combination of the input variables. Often in real-world scenarios, a number of observations would be added into or removed from the existing training dataset, necessitating the development of learning systems that can efficiently train optimal models with varying observations in an online (sequential) manner instead of retraining from scratch. Despite the significance of data-varying scenarios, most existing approaches to sparse GLMs concentrate on offline batch updates, leaving online solutions largely underexplored. In this work, we present the first algorithm without compromising accuracy for GLMs regularized by sparsity-enforcing penalties trained on varying observations. Our methodology is capable of handling the addition and deletion of observations simultaneously, while adaptively updating data-dependent regularization parameters to ensure the best statistical performance. Specifically, we recast sparse GLMs as a bilevel optimization objective upon varying observations and characterize it as an explicit gradient flow in the underlying space for the inner and outer subproblems we are optimizing over, respectively. We further derive a set of rules to ensure a proper transition at regions of non-smoothness, and establish the guarantees of theoretical consistency and finite convergence. Encouraging results are exhibited on real-world benchmarks.",
        "_bibtex": "@inproceedings{\nli2024learning,\ntitle={Learning No-Regret Sparse Generalized Linear Models with Varying Observation(s)},\nauthor={Diyang Li and Charles Ling and zhiqiang xu and Huan Xiong and Bin Gu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=wISvONp3Kq}\n}"
    },
    {
        "title": "Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game",
        "authorids": [
            "~Sam_Toyer1",
            "~Olivia_Watkins1",
            "~Ethan_Adrian_Mendes1",
            "~Justin_Svegliato2",
            "~Luke_Bailey1",
            "~Tiffany_Wang1",
            "~Isaac_Ong1",
            "~Karim_Elmaaroufi1",
            "~Pieter_Abbeel2",
            "~Trevor_Darrell2",
            "~Alan_Ritter1",
            "~Stuart_Russell1"
        ],
        "keywords": [
            "large language models",
            "LLMs",
            "security",
            "adversarial examples",
            "prompt extraction",
            "prompt injection",
            "prompt hijacking",
            "prompt engineering"
        ],
        "abstract": "While Large Language Models (LLMs) are increasingly being used in real-world applications, they remain vulnerable to *prompt injection attacks*: malicious third party prompts that subvert the intent of the system designer. To help researchers study this problem, we present a dataset of over 563,000 prompt injection attacks and 118,000 prompt-based \"defenses\" against prompt injection, all created by players of an online game called Tensor Trust. To the best of our knowledge, this is the first dataset that includes both human-generated attacks and defenses for instruction-following LLMs. The attacks in our dataset have easily interpretable structure, and shed light on the weaknesses of LLMs. We also use the dataset to create a benchmark for resistance to two types of prompt injection, which we refer to as *prompt extraction* and *prompt hijacking*. Our benchmark results show that many models are vulnerable to the attack strategies in the Tensor Trust dataset. Furthermore, we show that some attack strategies from the dataset generalize to deployed LLM-based applications, even though they have a very different set of constraints to the game. We release data and code at [tensortrust.ai/paper](https://tensortrust.ai/paper)",
        "_bibtex": "@inproceedings{\ntoyer2024tensor,\ntitle={Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game},\nauthor={Sam Toyer and Olivia Watkins and Ethan Adrian Mendes and Justin Svegliato and Luke Bailey and Tiffany Wang and Isaac Ong and Karim Elmaaroufi and Pieter Abbeel and Trevor Darrell and Alan Ritter and Stuart Russell},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=fsW7wJGLBd}\n}"
    },
    {
        "title": "Leveraging Unpaired Data for Vision-Language Generative Models via Cycle Consistency",
        "authorids": [
            "~Tianhong_Li3",
            "~Sangnie_Bhardwaj1",
            "~Yonglong_Tian1",
            "~Han_Zhang5",
            "~Jarred_Barber1",
            "~Dina_Katabi1",
            "~Guillaume_Lajoie1",
            "~Huiwen_Chang2",
            "~Dilip_Krishnan1"
        ],
        "keywords": [
            "vision-language generative model",
            "cycle consistency"
        ],
        "abstract": "Current vision-language generative models rely on expansive corpora of $\\textit{paired}$ image-text data to attain optimal performance and generalization capabilities. However, automatically collecting such data (e.g. via large-scale web scraping) leads to low quality and poor image-text correlation, while human annotation is more accurate but requires significant manual effort and expense. We introduce $\\textbf{ITIT}$ ($\\textbf{I}$n$\\textbf{T}$egrating $\\textbf{I}$mage $\\textbf{T}$ext): an innovative training paradigm grounded in the concept of cycle consistency which allows vision-language training on $\\textit{unpaired}$ image and text data. ITIT is comprised of a joint image-text encoder with disjoint image and text decoders that enable bidirectional image-to-text and text-to-image generation in a single framework. During training, ITIT leverages a small set of paired image-text data to ensure its output matches the input reasonably well in both directions. Simultaneously, the model is also trained on much larger datasets containing only images or texts. This is achieved by enforcing cycle consistency between the original unpaired samples and the cycle-generated counterparts. For instance, it generates a caption for a given input image and then uses the caption to create an output image, and enforces similarity between the input and output images. Our experiments show that ITIT with unpaired datasets exhibits similar scaling behavior as using high-quality paired data. We demonstrate image generation and captioning performance on par with state-of-the-art text-to-image and image-to-text models with orders of magnitude fewer (only 3M) paired image-text data. Code will be released at https://github.com/LTH14/itit.",
        "_bibtex": "@inproceedings{\nli2024leveraging,\ntitle={Leveraging Unpaired Data for Vision-Language Generative Models via Cycle Consistency},\nauthor={Tianhong Li and Sangnie Bhardwaj and Yonglong Tian and Han Zhang and Jarred Barber and Dina Katabi and Guillaume Lajoie and Huiwen Chang and Dilip Krishnan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=kNjrhD67LP}\n}"
    },
    {
        "title": "Learning the greatest common divisor: explaining transformer predictions",
        "authorids": [
            "~Francois_Charton1"
        ],
        "keywords": [
            "mathematics",
            "arithmetic",
            "transformers",
            "explainability"
        ],
        "abstract": "The predictions of small transformers, trained to calculate the greatest common divisor (GCD) of two positive integers, can be fully characterized by looking at model inputs and outputs.\nAs training proceeds, the model learns a list $\\mathcal D$ of integers, products of divisors of the base used to represent integers and small primes, and predicts the largest element of $\\mathcal D$ that divides both inputs. \nTraining distributions impact performance. Models trained from uniform operands only learn a handful of GCD (up to $38$ GCD $\\leq100$). Log-uniform operands boost performance to $73$ GCD $\\leq 100$, and a log-uniform distribution of outcomes (i.e. GCD) to $91$. However, training from uniform (balanced) GCD breaks explainability.",
        "_bibtex": "@inproceedings{\ncharton2024learning,\ntitle={Learning the greatest common divisor: explaining transformer predictions},\nauthor={Francois Charton},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=cmcD05NPKa}\n}"
    },
    {
        "title": "Space and time continuous physics simulation from partial observations",
        "authorids": [
            "~Steeven_JANNY2",
            "~Madiha_Nadri1",
            "~Julie_Digne1",
            "~Christian_Wolf5"
        ],
        "keywords": [
            "Physics",
            "simulation",
            "interpolation"
        ],
        "abstract": "Modern techniques for physical simulations rely on numerical schemes and mesh-refinement methods to address trade-offs between precision and complexity, but these handcrafted solutions are tedious and require high computational power. Data-driven methods based on large-scale machine learning promise high adaptivity by integrating long-range dependencies more directly and efficiently. In this work, we focus on computational fluid dynamics and address the shortcomings of a large part of the literature, which are based on fixed support for computations and predictions in the form of regular or irregular grids. We propose a novel setup to perform predictions in a continuous spatial and temporal domain while being trained on sparse observations. We formulate the task as a double observation problem and propose a solution with two interlinked dynamical systems defined on, respectively, the sparse positions and the continuous domain, which allows to forecast and interpolate a solution from the initial condition. Our practical implementation involves recurrent GNNs and a spatio-temporal attention observer capable of interpolating the solution at arbitrary locations. Our model not only generalizes to new initial conditions (as standard auto-regressive models do) but also performs evaluation at arbitrary space and time locations. We evaluate on three standard datasets in fluid dynamics and compare to strong baselines, which are outperformed in classical settings and the extended new task requiring continuous predictions.",
        "_bibtex": "@inproceedings{\njanny2024space,\ntitle={Space and time continuous physics simulation from partial observations},\nauthor={Steeven JANNY and Madiha Nadri and Julie Digne and Christian Wolf},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=4yaFQ7181M}\n}"
    },
    {
        "title": "GROOT: Learning to Follow Instructions by Watching Gameplay Videos",
        "authorids": [
            "~Shaofei_Cai2",
            "~Bowei_Zhang2",
            "~Zihao_Wang23",
            "~Xiaojian_Ma1",
            "~Anji_Liu1",
            "~Yitao_Liang1"
        ],
        "keywords": [
            "Agent",
            "Goal-conditioned Policy",
            "Imitation Learning",
            "Open World",
            "Minecraft"
        ],
        "abstract": "We study the problem of building a controller that can follow open-ended instructions in open-world environments. We propose to follow reference videos as instructions, which offer expressive goal specifications while eliminating the need for expensive text-gameplay annotations. A new learning framework is derived to allow learning such instruction-following controllers from gameplay videos while producing a video instruction encoder that induces a structured goal space. We implement our agent GROOT in a simple yet effective encoder-decoder architecture based on causal transformers. We evaluate GROOT against open-world counterparts and human players on a proposed Minecraft SkillForge benchmark. The Elo ratings clearly show that GROOT is closing the human-machine gap as well as exhibiting a 70% winning rate over the best generalist agent baseline. Qualitative analysis of the induced goal space further demonstrates some interesting emergent properties, including the goal composition and complex gameplay behavior synthesis.",
        "_bibtex": "@inproceedings{\ncai2024groot,\ntitle={{GROOT}: Learning to Follow Instructions by Watching Gameplay Videos},\nauthor={Shaofei Cai and Bowei Zhang and Zihao Wang and Xiaojian Ma and Anji Liu and Yitao Liang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=uleDLeiaT3}\n}"
    },
    {
        "title": "Mask-Based Modeling for Neural Radiance Fields",
        "authorids": [
            "~Ganlin_Yang1",
            "~Guoqiang_Wei1",
            "~Zhizheng_Zhang1",
            "~Yan_Lu7",
            "~Dong_Liu6"
        ],
        "keywords": [
            "NeRF",
            "Pretraining",
            "Mask-Based Modeling"
        ],
        "abstract": "Most Neural Radiance Fields (NeRFs) exhibit limited generalization capabilities,which restrict their applicability in representing multiple scenes using a single model. To address this problem, existing generalizable NeRF methods simply condition the model on image features. These methods still struggle to learn precise global representations over diverse scenes since they lack an effective mechanism for interacting among different points and views. In this work, we unveil that 3D implicit representation learning can be significantly improved by mask-based modeling. Specifically, we propose **m**asked **r**ay and **v**iew **m**odeling for generalizable **NeRF** (**MRVM-NeRF**), which is a self-supervised pretraining target to predict complete scene representations from partially masked features along each ray. With this pretraining target, MRVM-NeRF enables better use of correlations across different rays and views as the geometry priors, which thereby strengthens the capability of capturing intricate details within the scenes and boosts the generalization capability across different scenes. Extensive experiments demonstrate the effectiveness of our proposed MRVM-NeRF on both synthetic and real-world datasets, qualitatively and quantitatively. Besides, we also conduct experiments to show the compatibility of our proposed method with various backbones and its superiority under few-shot cases.",
        "_bibtex": "@inproceedings{\nyang2024maskbased,\ntitle={Mask-Based Modeling for Neural Radiance Fields},\nauthor={Ganlin Yang and Guoqiang Wei and Zhizheng Zhang and Yan Lu and Dong Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=SEiuSzlD1d}\n}"
    },
    {
        "title": "Large Language Models Are Not Robust Multiple Choice Selectors",
        "authorids": [
            "~Chujie_Zheng2",
            "~Hao_Zhou8",
            "~Fandong_Meng3",
            "~Jie_Zhou8",
            "~Minlie_Huang1"
        ],
        "keywords": [
            "large language model",
            "bias",
            "robustness",
            "multiple choice question",
            "evaluation"
        ],
        "abstract": "Multiple choice questions (MCQs) serve as a common yet important task format in the evaluation of large language models (LLMs). This work shows that modern LLMs are vulnerable to option position changes in MCQs due to their inherent \u201cselection bias\u201d, namely, they prefer to select specific option IDs as answers (like \u201cOption A\u201d). Through extensive empirical analyses with 20 LLMs on three benchmarks, we pinpoint that this behavioral bias primarily stems from LLMs\u2019 token bias, where the model a priori assigns more probabilistic mass to specific option ID tokens (e.g., A/B/C/D) when predicting answers from the option IDs. To mitigate selection bias, we propose a label-free, inference-time debiasing method, called PriDe, which separates the model\u2019s prior bias for option IDs from the overall prediction distribution. PriDe first estimates the prior by permutating option contents on a small number of test samples, and then applies the estimated prior to debias the remaining samples. We demonstrate that it achieves interpretable and transferable debiasing with high computational efficiency. We hope this work can draw broader research attention to the bias and robustness of modern LLMs.",
        "_bibtex": "@inproceedings{\nzheng2024large,\ntitle={Large Language Models Are Not Robust Multiple Choice Selectors},\nauthor={Chujie Zheng and Hao Zhou and Fandong Meng and Jie Zhou and Minlie Huang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=shr9PXz7T0}\n}"
    },
    {
        "title": "Robust Adversarial Reinforcement Learning via Bounded Rationality Curricula",
        "authorids": [
            "~Aryaman_Reddi1",
            "~Maximilian_T\u00f6lle1",
            "~Jan_Peters3",
            "~Georgia_Chalvatzaki1",
            "~Carlo_D'Eramo2"
        ],
        "keywords": [
            "reinforcement learning",
            "adversarial",
            "bounded rationality",
            "curriculum"
        ],
        "abstract": "Robustness against adversarial attacks and distribution shifts is a long-standing goal of Reinforcement Learning (RL). To this end, Robust Adversarial Reinforcement Learning (RARL) trains a protagonist against destabilizing forces exercised by an adversary in a competitive zero-sum Markov game, whose optimal solution, i.e., rational strategy, corresponds to a Nash equilibrium. However, finding Nash equilibria requires facing complex saddle point optimization problems, which can be prohibitive to solve, especially for high-dimensional control. In this paper, we propose a novel approach for adversarial RL based on entropy regularization to ease the complexity of the saddle point optimization problem. We show that the solution of this entropy-regularized problem corresponds to a Quantal Response Equilibrium (QRE), a generalization of Nash equilibria that accounts for bounded rationality, i.e., agents sometimes play random actions instead of optimal ones. Crucially, the connection between the entropy-regularized objective and QRE enables free modulation of the rationality of the agents by simply tuning the temperature coefficient. We leverage this insight to propose our novel algorithm, Quantal Adversarial RL (QARL), which gradually increases the rationality of the adversary in a curriculum fashion until it is fully rational, easing the complexity of the optimization problem while retaining robustness. We provide extensive evidence of QARL outperforming RARL and recent baselines across several MuJoCo locomotion and navigation problems in overall performance and robustness.",
        "_bibtex": "@inproceedings{\nreddi2024robust,\ntitle={Robust Adversarial Reinforcement Learning via Bounded Rationality Curricula},\nauthor={Aryaman Reddi and Maximilian T{\\\"o}lle and Jan Peters and Georgia Chalvatzaki and Carlo D'Eramo},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=pFOoOdaiue}\n}"
    },
    {
        "title": "Fine-tuning Multimodal LLMs to Follow Zero-shot Demonstrative Instructions",
        "authorids": [
            "~Juncheng_Li3",
            "~Kaihang_Pan1",
            "~Zhiqi_Ge1",
            "~Minghe_Gao1",
            "~Wei_Ji1",
            "~Wenqiao_Zhang1",
            "~Tat-Seng_Chua2",
            "~Siliang_Tang1",
            "~Hanwang_Zhang3",
            "~Yueting_Zhuang1"
        ],
        "keywords": [
            "Multimodal Large Language Models",
            "Demonstrative Instruction"
        ],
        "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have been utilizing Visual Prompt Generators (VPGs) to convert visual features into tokens that LLMs can recognize. This is achieved by training the VPGs on millions of image-caption pairs, where the VPG-generated tokens of images are fed into a frozen LLM to generate the corresponding captions. However, this image-captioning based training objective inherently biases the VPG to concentrate solely on the primary visual contents sufficient for caption generation, often neglecting other visual details. This shortcoming results in MLLMs\u2019 underperformance in comprehending demonstrative instructions consisting of multiple, interleaved, and multimodal instructions that demonstrate the required context to complete a task. To address this issue, we introduce a generic and lightweight Visual Prompt Generator Complete module (VPG-C), which can infer and complete the missing details essential for comprehending demonstrative instructions. Further, we propose a synthetic discriminative training strategy to fine-tune VPG-C, eliminating the need for supervised demonstrative instructions. As for evaluation, we build DEMON, a comprehensive benchmark for demonstrative instruction understanding. Synthetically trained with the proposed strategy, VPG-C achieves significantly stronger zero-shot performance across all tasks of DEMON. Further evaluation on the MME and OwlEval benchmarks also demonstrate the superiority of VPG-C. The code and models are available at https://github.com/DCDmllm/Cheetah.",
        "_bibtex": "@inproceedings{\nli2024finetuning,\ntitle={Fine-tuning Multimodal {LLM}s to Follow Zero-shot Demonstrative Instructions},\nauthor={Juncheng Li and Kaihang Pan and Zhiqi Ge and Minghe Gao and Wei Ji and Wenqiao Zhang and Tat-Seng Chua and Siliang Tang and Hanwang Zhang and Yueting Zhuang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=BXY6fe7q31}\n}"
    },
    {
        "title": "CLAP: Collaborative Adaptation for Patchwork Learning",
        "authorids": [
            "~Sen_Cui1",
            "~Abudukelimu_Wuerkaixi1",
            "~Weishen_Pan1",
            "~Jian_Liang3",
            "~Lei_Fang6",
            "~Changshui_Zhang2",
            "~Fei_Wang3"
        ],
        "keywords": [
            "Patchwork learning",
            "robustness"
        ],
        "abstract": "In this paper, we investigate a new practical learning scenario, where the data distributed in different sources/clients are typically generated with various modalities. Existing research on learning from multi-source data mostly assume that each client owns the data of all modalities, which may largely limit its practicability. In light of the expensiveness and sparsity of multimodal data, we propose patchwork learning to jointly learn from fragmented multimodal data in distributed clients. Considering the concerns on data privacy, patchwork learning aims to impute incomplete multimodal data for diverse downstream tasks without accessing the raw data directly. Local clients could miss different modality combinations. Due to the statistical heterogeneity induced by non-i.i.d. data, the imputation is more challenging since the learned dependencies fail to adapt to the imputation of other clients. In this paper, we provide a novel imputation framework to tackle modality combination heterogeneity and statistical heterogeneity simultaneously, called ``collaborative adaptation''. In particular, for two observed modality combinations from two clients, we learn the transformations between their maximal intersection and other modalities by proposing a novel ELBO. We improve the worst-performing required transformations through a Pareto min-max optimization framework. In extensive experiments, we demonstrate the superiority of the proposed method compared to existing related methods on benchmark data sets and a real-world clinical data set.",
        "_bibtex": "@inproceedings{\ncui2024clap,\ntitle={{CLAP}: Collaborative Adaptation for Patchwork Learning},\nauthor={Sen Cui and Abudukelimu Wuerkaixi and Weishen Pan and Jian Liang and Lei Fang and Changshui Zhang and Fei Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=8EyRkd3Qj2}\n}"
    },
    {
        "title": "Towards Energy Efficient Spiking Neural Networks: An Unstructured Pruning Framework",
        "authorids": [
            "~Xinyu_Shi2",
            "~Jianhao_Ding1",
            "~Zecheng_Hao1",
            "~Zhaofei_Yu1"
        ],
        "keywords": [
            "Spiking Neural Networks",
            "Network Pruning"
        ],
        "abstract": "Spiking Neural Networks (SNNs)  have emerged as energy-efficient alternatives to  Artificial Neural Networks (ANNs) when deployed on neuromorphic chips.  While recent studies have demonstrated the impressive performance of deep SNNs on challenging tasks, their energy efficiency advantage has been diminished. Existing methods targeting energy consumption reduction do not fully exploit sparsity, whereas powerful pruning methods can achieve high sparsity but are not directly targeted at energy efficiency, limiting their effectiveness in energy saving. Furthermore, none of these works fully exploit the sparsity of neurons or the potential for unstructured neuron pruning in SNNs. In this paper, we propose a novel pruning framework that combines unstructured weight pruning with unstructured neuron pruning to maximize the utilization of the sparsity of neuromorphic computing, thereby enhancing energy efficiency. To the best of our knowledge, this is the first application of unstructured neuron pruning to deep SNNs. Experimental results demonstrate that  our method achieves impressive energy efficiency gains. The sparse network pruned by our method with only 0.63\\% remaining connections can achieve a remarkable 91 times increase in energy efficiency compared to the original dense network, requiring only 8.5M SOPs for inference, with merely 2.19\\% accuracy loss on the CIFAR-10 dataset. Our work suggests that deep and dense SNNs exhibit high redundancy in energy consumption, highlighting the potential for targeted SNN sparsification to save energy.",
        "_bibtex": "@inproceedings{\nshi2024towards,\ntitle={Towards Energy Efficient Spiking Neural Networks: An Unstructured Pruning Framework},\nauthor={Xinyu Shi and Jianhao Ding and Zecheng Hao and Zhaofei Yu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=eoSeaK4QJo}\n}"
    },
    {
        "title": "Online Stabilization of Spiking Neural Networks",
        "authorids": [
            "~Yaoyu_Zhu1",
            "~Jianhao_Ding1",
            "~Tiejun_Huang1",
            "~Xiaodong_Xie1",
            "~Zhaofei_Yu1"
        ],
        "keywords": [
            "spiking neural networks",
            "online training"
        ],
        "abstract": "Spiking neural networks (SNNs), attributed to the binary, event-driven nature of spikes, possess heightened biological plausibility and enhanced energy efficiency on neuromorphic hardware compared to analog neural networks (ANNs). Mainstream SNN training schemes apply backpropagation-through-time (BPTT) with surrogate gradients to replace the non-differentiable spike emitting process during backpropagation. While achieving competitive performance, the requirement for storing intermediate information at all time-steps incurs higher memory consumption and fails to fulfill the online property crucial to biological brains. \nOur work focuses on online training techniques, aiming for memory efficiency while preserving biological plausibility. \nThe limitation of not having access to future information in early time steps in online training has constrained previous efforts to incorporate advantageous modules such as batch normalization. \nTo address this problem, we propose Online Spiking Renormalization (OSR) to ensure consistent parameters between testing and training, and Online Threshold Stabilizer (OTS) to stabilize neuron firing rates across time steps. Furthermore, we design a novel online approach to compute the sample mean and variance over time for OSR. Experiments conducted on various datasets demonstrate the proposed method's superior performance among SNN online training algorithms.\nOur code is available at https://github.com/zhuyaoyu/SNN-online-normalization.",
        "_bibtex": "@inproceedings{\nzhu2024online,\ntitle={Online Stabilization of Spiking Neural Networks},\nauthor={Yaoyu Zhu and Jianhao Ding and Tiejun Huang and Xiaodong Xie and Zhaofei Yu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=CIj1CVbkpr}\n}"
    },
    {
        "title": "CrIBo: Self-Supervised Learning via Cross-Image Object-Level Bootstrapping",
        "authorids": [
            "~Tim_Lebailly1",
            "~Thomas_Stegm\u00fcller1",
            "~Behzad_Bozorgtabar1",
            "~Jean-Philippe_Thiran1",
            "~Tinne_Tuytelaars1"
        ],
        "keywords": [
            "self-supervised learning",
            "representation learning"
        ],
        "abstract": "Leveraging nearest neighbor retrieval for self-supervised representation learning has proven beneficial with object-centric images. However, this approach faces limitations when applied to scene-centric datasets, where multiple objects within an image are only implicitly captured in the global representation. Such global bootstrapping can lead to undesirable entanglement of object representations. Furthermore, even object-centric datasets stand to benefit from a finer-grained bootstrapping approach. In response to these challenges, we introduce a novel $\\textbf{Cr}$oss-$\\textbf{I}$mage Object-Level $\\textbf{Bo}$otstrapping method tailored to enhance dense visual representation learning. By employing object-level nearest neighbor bootstrapping throughout the training, CrIBo emerges as a notably strong and adequate candidate for in-context learning, leveraging nearest neighbor retrieval at test time. CrIBo shows state-of-the-art performance on the latter task while being highly competitive in more standard downstream segmentation tasks. Our code and pretrained models are publicly available at https://github.com/tileb1/CrIBo.",
        "_bibtex": "@inproceedings{\nlebailly2024cribo,\ntitle={Cr{IB}o: Self-Supervised Learning via Cross-Image Object-Level Bootstrapping},\nauthor={Tim Lebailly and Thomas Stegm{\\\"u}ller and Behzad Bozorgtabar and Jean-Philippe Thiran and Tinne Tuytelaars},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3M0GXoUEzP}\n}"
    },
    {
        "title": "Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis",
        "authorids": [
            "~Zhenhui_Ye1",
            "~Tianyun_Zhong3",
            "~Yi_Ren2",
            "~Jiaqi_Yang8",
            "~Weichuang_Li1",
            "~Jiawei_Huang5",
            "~Ziyue_Jiang1",
            "~Jinzheng_He1",
            "~Rongjie_Huang1",
            "~Jinglin_Liu1",
            "~Chen_Zhang3",
            "~Xiang_Yin2",
            "~Zejun_MA1",
            "~Zhou_Zhao3"
        ],
        "keywords": [
            "One-shot Talking Face Generation",
            "Neural Radiance Field"
        ],
        "abstract": "One-shot 3D talking portrait generation aims to reconstruct a 3D avatar from an unseen image, and then animate it with a reference video or audio to generate a talking portrait video. The existing methods fail to simultaneously achieve the goals of accurate 3D avatar reconstruction and stable talking face animation. Besides, while the existing works mainly focus on synthesizing the head part, it is also vital to generate natural torso and background segments to obtain a realistic talking portrait video. To address these limitations, we present Real3D-Potrait, a framework that (1) improves the one-shot 3D reconstruction power with a large image-to-plane model that distills 3D prior knowledge from a 3D face generative model; (2) facilitates accurate motion-conditioned animation with an efficient motion adapter; (3) synthesizes realistic video with natural torso movement and switchable background using a head-torso-background super-resolution model; and (4) supports one-shot audio-driven talking face generation with a generalizable audio-to-motion model. Extensive experiments show that Real3D-Portrait generalizes well to unseen identities and generates more realistic talking portrait videos compared to previous methods. Video samples are available at https://real3dportrait.github.io.",
        "_bibtex": "@inproceedings{\nye2024realdportrait,\ntitle={Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis},\nauthor={Zhenhui Ye and Tianyun Zhong and Yi Ren and Jiaqi Yang and Weichuang Li and Jiawei Huang and Ziyue Jiang and Jinzheng He and Rongjie Huang and Jinglin Liu and Chen Zhang and Xiang Yin and Zejun MA and Zhou Zhao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=7ERQPyR2eb}\n}"
    }
]